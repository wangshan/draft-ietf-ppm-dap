{
  "magic": "E!vIA5L86J2I",
  "timestamp": "2022-06-23T01:10:36.786915+00:00",
  "repo": "ietf-wg-ppm/draft-ietf-ppm-dap",
  "labels": [
    {
      "name": "bug",
      "description": "Something isn't working",
      "color": "d73a4a"
    },
    {
      "name": "documentation",
      "description": "Improvements or additions to documentation",
      "color": "0075ca"
    },
    {
      "name": "duplicate",
      "description": "This issue or pull request already exists",
      "color": "ffffff"
    },
    {
      "name": "enhancement",
      "description": "New feature or request",
      "color": "a2eeef"
    },
    {
      "name": "good first issue",
      "description": "Good for newcomers",
      "color": "7057ff"
    },
    {
      "name": "help wanted",
      "description": "Extra attention is needed",
      "color": "008672"
    },
    {
      "name": "invalid",
      "description": "This doesn't seem right",
      "color": "e4e669"
    },
    {
      "name": "question",
      "description": "Further information is requested",
      "color": "d876e3"
    },
    {
      "name": "wontfix",
      "description": "This will not be worked on",
      "color": "ffffff"
    },
    {
      "name": "parking-lot",
      "description": "Parking lot for future discussions",
      "color": "cfd3d7"
    },
    {
      "name": "editorial",
      "description": "The issue raised is purely editorial (i.e., doesn't impact implementations).",
      "color": "C2E0C6"
    },
    {
      "name": "draft-01",
      "description": "",
      "color": "bfdadc"
    }
  ],
  "issues": [
    {
      "number": 1,
      "id": "MDU6SXNzdWU4MTE2MjU1ODM=",
      "title": "Describe cryptographic dependencies",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/issues/1",
      "state": "CLOSED",
      "author": "chris-wood",
      "authorAssociation": "COLLABORATOR",
      "assignees": [
        "chris-wood",
        "cjpatton"
      ],
      "labels": [],
      "body": "Key encapsulation mechanisms, PRGs, and a sprinkle finite fields. (We can of course elaborate on these in the actual PR.)",
      "createdAt": "2021-02-19T02:21:26Z",
      "updatedAt": "2021-02-27T03:20:25Z",
      "closedAt": "2021-02-27T03:20:25Z",
      "comments": []
    },
    {
      "number": 4,
      "id": "MDU6SXNzdWU4MTc4MDU2NjI=",
      "title": "Cross-aggregator data consistency ",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/issues/4",
      "state": "CLOSED",
      "author": "chris-wood",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [
        "duplicate"
      ],
      "body": "We assume that all aggregators process the share of a client's input, but what happens if one aggregator loses its share of the client input? How do we accommodate one aggregator losing its view of a share, either maliciously or accidentally? ",
      "createdAt": "2021-02-27T03:01:08Z",
      "updatedAt": "2021-12-30T17:43:04Z",
      "closedAt": "2021-12-30T17:43:04Z",
      "comments": [
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "[BCC+19](https://eprint.iacr.org/2019/188) consider two settings for ZKP systems on distributed data: one in which either the client or a subset of aggregators is malicious (this is the setting in which Prio was analyzed); and another in which the client may collude with a subset of aggregators. This issue corresponds to the latter setting.\r\n\r\nSecurity in this setting is addressed in Section 6.3. The basic idea seems to be to run the input-validation protocol with every subset of servers.",
          "createdAt": "2021-02-27T03:16:32Z",
          "updatedAt": "2021-02-27T03:16:32Z"
        },
        {
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "body": "We addressed this problem in Prio v2 by having each aggregator evaluate proofs independently. So during intake, when an aggregator receives a data share, it extracts the proof share and transmits it to the other aggregator. At aggregation time, an aggregator will not include a data share in a sum unless it can assemble the triple of (data share, own proof share, peer proof share) and verify the proof. If it can't do that because the peer proof is unavailable, the aggregator drops the share from the sum, but still sums everything else.\r\n\r\nIn our design, the leader could be responsible for this. Clients would send encrypted data shares and proof shares to aggregators, and aggregators would then have to extract the proof share and send it to the leader. The leader could then work out the intersection of the sets of proof shares provided by all aggregators (which is the set of data that can be summed in the aggregation) and then only instruct aggregators to sum that set of shares.",
          "createdAt": "2021-03-18T23:41:59Z",
          "updatedAt": "2021-03-18T23:41:59Z"
        },
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "> We addressed this problem in Prio v2 by having each aggregator evaluate proofs independently. So during intake, when an aggregator receives a data share, it extracts the proof share and transmits it to the other aggregator. At aggregation time, an aggregator will not include a data share in a sum unless it can assemble the triple of (data share, own proof share, peer proof share) and verify the proof. If it can't do that because the peer proof is unavailable, the aggregator drops the share from the sum, but still sums everything else.\r\n\r\nHmm, having all of the proof shares is a potential privacy issue, no? If I have all of the proof shares, then I can assemble the entire proof polynomial, which gives me the output of each intermediate G-gate evaluation and not just the final output. (Perhaps you mean \"verification share\"? See https://github.com/abetterinternet/prio-documents/pull/16#discussion_r600081599.)\r\n\r\n> In our design, the leader could be responsible for this. Clients would send encrypted data shares and proof shares to aggregators, and aggregators would then have to extract the proof share and send it to the leader. The leader could then work out the intersection of the sets of proof shares provided by all aggregators (which is the set of data that can be summed in the aggregation) and then only instruct aggregators to sum that set of shares.\r\n\r\nThis sounds like a good idea.\r\n",
          "createdAt": "2021-03-24T02:16:09Z",
          "updatedAt": "2021-03-24T02:16:09Z"
        },
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "As of 2021/7/14, our answer is as follows: all aggregators need to be online for the duration of the protocol. In order to recover in case an aggregator drops, the collector could spin up multiple tasks, each with different sets of aggregators. We briefly considered formalizing this in the protocol, but decided this was too complex. (See #68.) Another protocol-level option is, potentially, threshold secret sharing (#22).",
          "createdAt": "2021-07-14T20:58:50Z",
          "updatedAt": "2021-07-14T20:58:50Z"
        }
      ]
    },
    {
      "number": 5,
      "id": "MDU6SXNzdWU4MTc4MDk4NjA=",
      "title": "Detail threat models",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/issues/5",
      "state": "CLOSED",
      "author": "chris-wood",
      "authorAssociation": "COLLABORATOR",
      "assignees": [
        "tgeoghegan"
      ],
      "labels": [],
      "body": "The title says it all.",
      "createdAt": "2021-02-27T03:22:04Z",
      "updatedAt": "2021-06-11T01:22:19Z",
      "closedAt": "2021-06-11T01:22:18Z",
      "comments": [
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "IMO this issue is closed by https://github.com/abetterinternet/prio-documents/pull/16. Eventually we'll want a more fleshed out \"Security Considerations\" section, but for now, I think we're all on the same page on this.",
          "createdAt": "2021-06-09T18:36:26Z",
          "updatedAt": "2021-06-09T18:36:26Z"
        },
        {
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "body": "Closing per @cjpatton's comment above",
          "createdAt": "2021-06-11T01:22:18Z",
          "updatedAt": "2021-06-11T01:22:18Z"
        }
      ]
    },
    {
      "number": 7,
      "id": "MDU6SXNzdWU4MjAwNzg0MTE=",
      "title": "Compare to alternatives",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/issues/7",
      "state": "OPEN",
      "author": "chris-wood",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [
        "parking-lot"
      ],
      "body": "We should probably describe applications wherein Prio is necessary (or at least desired) compared to other systems that might work, such as [ANONIZE](https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.732.3675&rep=rep1&type=pdf). The original paper explains that the difference is in threat model: Prio assumes an adversary that can control the entire network, so outsourcing things to a proxy simply doesn't work. However, in practice, there may be circumstances wherein there *are* trusted proxies. In such cases, whether or not one actually wants to use them seems to depend on the application and data being collected. Specifically, if privacy depends on a collector not seeing individual client inputs, then Prio fits the bill, and if not, then perhaps simpler systems would work. It would probably be good to discuss this in more detail, if only to further motivate Prio.",
      "createdAt": "2021-03-02T14:37:05Z",
      "updatedAt": "2021-07-14T20:59:21Z",
      "closedAt": null,
      "comments": [
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "Some alternatives worth considering:\r\n* Use an [OHTTP](https://datatracker.ietf.org/doc/draft-thomson-http-oblivious/) proxy to strip personally identifiable metadata, like client IP, from reports. The downside is that the collector still sees the set of inputs (and not just the output, as in Prio or, to a lesser degree, HH).\r\n* A pure differential privacy approach, like [RAPPOR](https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/42852.pdf). The upside is that the communication model is much simpler, since RAPPOR doesn't require multiple aggregators. The downside is the privacy budget.",
          "createdAt": "2021-06-09T18:44:00Z",
          "updatedAt": "2021-06-09T18:44:00Z"
        }
      ]
    },
    {
      "number": 8,
      "id": "MDU6SXNzdWU4MjAwODY5ODY=",
      "title": "Consensus protocol",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/issues/8",
      "state": "CLOSED",
      "author": "chris-wood",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "We currently have an open issue for tracking the consensus protocol needed for this system to work. In working through this text, we should make note of what sort of synchronization we assume between different participants of the system.",
      "createdAt": "2021-03-02T14:46:50Z",
      "updatedAt": "2021-07-14T20:54:49Z",
      "closedAt": "2021-07-14T20:54:49Z",
      "comments": [
        {
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "body": "In the 3/17 design call we agreed that for purposes of the design doc and probably the initial deployments of Prio, we would assume that shared parameters (e.g., arithmetic circuits, primes, aggregation identifiers) would be exchanged between all parties (i.e., clients, aggregators, collector, leader) before the start of the protocol over some unspecified secure channel.\r\n\r\nHowever, eventually, it should be possible for a client that wishes to use Prio to programmatically:\r\n\r\n- discover participating servers (i.e., a directory of aggregators)\r\n- discover the capabilities of participating servers (i.e., what algorithms do they support for secret sharing or validity proofs or aggregations? What optional protocol features do they support?)\r\n- configure a Prio aggregation (i.e., select some number of aggregation servers, getting a unique handle, configuring field size, etc.)",
          "createdAt": "2021-03-18T23:50:31Z",
          "updatedAt": "2021-03-18T23:50:31Z"
        },
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "One thing that's still TBD is how to choose the joint randomness. It could be as simple as having the leader choose a seed for a PRG and distributing it to the aggregators over secure channels. It could be as complicated as querying [DRAND](https://drand.love/) at some point after the shares are received by the aggregators. ",
          "createdAt": "2021-03-24T02:10:47Z",
          "updatedAt": "2021-03-24T02:10:47Z"
        },
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "To close the loop on this issue: the PDA parameters are distributed to all entities out-of-band.",
          "createdAt": "2021-07-14T20:54:49Z",
          "updatedAt": "2021-07-14T20:54:49Z"
        }
      ]
    },
    {
      "number": 9,
      "id": "MDU6SXNzdWU4MjAyNzU1NDA=",
      "title": "Aggregator discovery",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/issues/9",
      "state": "CLOSED",
      "author": "chris-wood",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "Clients need to obtain aggregator public keys to encrypt shares. While we may not want to specify the exact mechanism by which deployments do this, we should minimally state the requirements for discovery, perhaps with a RECOMMENDED version.\r\n\r\ncc @ekr",
      "createdAt": "2021-03-02T18:29:30Z",
      "updatedAt": "2021-06-09T18:49:04Z",
      "closedAt": "2021-06-09T18:49:04Z",
      "comments": [
        {
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "body": "Some quick thoughts: \r\n\r\n1. Thus far we have talked about clients discovering and trusting aggregators. There is a related problem of aggregators discovering each other (e.g. in order to exchange validations, or just for each aggregator to discover the leader), which can be probably be solved the same way.\r\n2. We didn't do an amazing job of client<->aggregator trust in Prio v2 (mostly because no matter how you sliced it, we had to trust that Apple and Google's client implementations weren't just sending data to Cupertino or Mountain View in the clear anyway), but we addressed aggregator<->aggregator and aggregator<->collector trust by bootstrapping from the web PKI: each participating server vended configuration parameters (including crypto keys) from a JSON file vended over TLS. Participating organizations agreed out of band on what trusted domains for config should be (i.e., `isrg-prio.org` for us, `en-analytics.cancer.gov` for the feds, `apple.com/exposure-notifications`, and so on). So one could imagine the leader in the Prio v3 scheme serving a directory of aggregators, which would be a list of URLs from which the config for each server could then be fetched and validated, independently of the client's trust relationship with the leader.",
          "createdAt": "2021-03-02T18:45:04Z",
          "updatedAt": "2021-03-02T18:45:04Z"
        },
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "Closing this issue because it's now subsumed by #50.",
          "createdAt": "2021-06-09T18:49:04Z",
          "updatedAt": "2021-06-09T18:49:04Z"
        }
      ]
    },
    {
      "number": 10,
      "id": "MDU6SXNzdWU4MjEzOTQ1MTU=",
      "title": "Define \"Collector\"",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/issues/10",
      "state": "CLOSED",
      "author": "aaomidi",
      "authorAssociation": "NONE",
      "assignees": [],
      "labels": [],
      "body": "Currently we use it in the document but we don't define it here: https://github.com/abetterinternet/prio-documents/blob/83c4ad39a101c17dcfc2421353996297aa503506/design-document.md#terminology",
      "createdAt": "2021-03-03T18:58:46Z",
      "updatedAt": "2021-03-04T03:53:09Z",
      "closedAt": "2021-03-04T03:53:09Z",
      "comments": []
    },
    {
      "number": 14,
      "id": "MDU6SXNzdWU4MjQ5OTY2MjE=",
      "title": "Bias in output of PRG",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/issues/14",
      "state": "CLOSED",
      "author": "tlepoint",
      "authorAssociation": "NONE",
      "assignees": [],
      "labels": [],
      "body": "> This can be instantiated using a standard stream cipher, e.g.., ChaCha20 as follows. Interpret k as the cipher key, and using a fixed nonce, generate l*n bytes of output, where l is the number of bytes needed to encode an element of K, then map each chunk of l bytes to an element of K by interpreting the chunk as an l-byte integer and reducing it modulo the prime modulus.\r\n> [[OPEN ISSUE: Mapping the output of PRG(.,.) to a vector over K induces a small amount of bias on the output. How much bias is induced depends on the how close the prime is to a power of 2. Should this be a criterion for selecting the prime?]]\r\n\r\nI strongly recommend **against** using a biased PRG (even though the bias is small). There are two easy way to solve this:\r\n- *Rejection sampling*: Accept the `l`-byte integer if it is strictly smaller than the prime. To increase the probability of accepting a number, you may want to zero the most significant bits (e.g., if the prime is in (2^125, 2^126), zero the two most significant bits of your 16-byte randomness, then do rejection sampling). This is the approach currently followed in [libprio-rs](https://github.com/abetterinternet/libprio-rs) and [libprio-cc](https://github.com/google/libprio-cc). The distribution is exactly the uniform distribution modulo the prime.\r\n- *Flooding/Extra Bits*: Reduce a `(l+l')`-byte integer modulo the prime, which gives a distribution close to the uniform distribution modulo the prime when l' is large enough. In practice however, we may want to set `l'=8`, which would be quite wasteful.\r\nBoth approaches are recommended for example when generating keys for EC cryptography, see Sections B.4.1 and B.4.2 of [NIST FIPS 186-4](https://nvlpubs.nist.gov/nistpubs/FIPS/NIST.FIPS.186-4.pdf).",
      "createdAt": "2021-03-08T22:03:27Z",
      "updatedAt": "2021-06-17T19:55:10Z",
      "closedAt": "2021-06-17T19:55:10Z",
      "comments": [
        {
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "body": "My vote is for generating more bits than are necessary, where the amount of extra bits is a function of the system security parameter. The [hash-to-curve](https://cfrg.github.io/draft-irtf-cfrg-hash-to-curve/draft-irtf-cfrg-hash-to-curve.html#name-security-considerations) draft captures this quite nicely, I think. (Okay, I'm biased.)\r\n\r\n> In practice however, we may want to set l'=8, which would be quite wasteful.\r\n\r\nSomewhat of a bikeshed, but: is generating 8 extra bytes of randomness *really* a big deal? ",
          "createdAt": "2021-03-09T21:11:48Z",
          "updatedAt": "2021-03-09T21:11:48Z"
        },
        {
          "author": "tlepoint",
          "authorAssociation": "NONE",
          "body": "> Somewhat of a bikeshed, but: is generating 8 extra bytes of randomness really a big deal?\r\n\r\nGood question. I actually don't think it's a bikeshed, because the main difference with hash-to-curve and EC key generation is that, in Prio, there are > # bins random values to generate, _per user_, and the extra bits needs to be generated for _every_ random value. \r\n\r\nFor example, if p is a 32-bit prime, `l=8` means that you are generating *12 bytes* to obtain _one_ 32-bit random integer via a modular reduction of a 96-bit integer. That's 3 times the amount of bytes used to represent the result and the code needs to perform modular arithmetic with numbers that do not fit in a `uint64` (but fits in a `uint128`). With rejection sampling instead, in *expectation* you generate less than 2*4 = 8 bytes, and you only need to perform comparisons over `uint32`, albeit the execution time may be varying.",
          "createdAt": "2021-03-09T22:47:29Z",
          "updatedAt": "2021-03-09T22:47:29Z"
        },
        {
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "body": "> For example, if p is a 32-bit prime, l=8 means that you are generating 12 bytes to obtain one 32-bit random integer via a modular reduction of a 96-bit integer. That's 3 times the amount of bytes used to represent the result and the code needs to perform modular arithmetic with numbers that do not fit in a uint64 (but fits in a uint128). With rejection sampling instead, in expectation you generate less than 2*4 = 8 bytes, and you only need to perform comparisons over uint32, albeit the execution time may be varying.\r\n\r\nYeah, I get that it's excessively wasteful (relatively speaking). What it not clear to me is if it's actually wasteful in absolute terms. \r\n\r\nEither way, we can certainly be precise in the minimum number of extra bits needed. We should just do that!",
          "createdAt": "2021-03-09T22:50:30Z",
          "updatedAt": "2021-03-09T22:50:30Z"
        },
        {
          "author": "tlepoint",
          "authorAssociation": "NONE",
          "body": "I wrote a small [benchmark in C++](https://gist.github.com/tlepoint/11d6fc3e8c763b080334009e98c14147) to compare the performance of the two PRGs approaches above for different vector sizes and the cost of an elliptic curve Diffie-Hellman. You can run it as follows\r\n```\r\nbazel run -c opt :prg_bench\r\n```\r\n\r\n***Disclaimer: It may not be the most optimized implementations***\r\n\r\nI think it is valuable to keep this issue open and experiment more comprehensively before choosing the definitive approach, because:\r\n1. Computing the PRG is likely to become the bottleneck compared to the ECDH, henceforth it will be important to optimize it;\r\n2. Using rejection sampling is likely giving a 2-5x speedup compared to drawing extra bits.\r\n\r\nOn my macbook air, I obtain the following timings\r\n```\r\nRun on (4 X 1700 MHz CPU s)\r\nCPU Caches:\r\n  L1 Data 32 KiB (x2)\r\n  L1 Instruction 32 KiB (x2)\r\n  L2 Unified 256 KiB (x2)\r\n  L3 Unified 4096 KiB (x1)\r\nLoad Average: 6.86, 6.66, 5.96\r\n------------------------------------------------------------------------------------------\r\nBenchmark                                                Time             CPU   Iterations\r\n------------------------------------------------------------------------------------------\r\nBM_Extra32Bits_4293918721/8                            438 ns          432 ns      1604290\r\nBM_Extra32Bits_4293918721/64                           895 ns          879 ns       794083\r\nBM_Extra32Bits_4293918721/512                         3236 ns         3206 ns       217997\r\nBM_Extra32Bits_4293918721/4096                       24580 ns        24432 ns        28410\r\nBM_Extra32Bits_4293918721/32768                     201733 ns       199986 ns         3485\r\nBM_Extra96Bits_4293918721/8                            556 ns          554 ns      1245042\r\nBM_Extra96Bits_4293918721/64                           916 ns          901 ns       765404\r\nBM_Extra96Bits_4293918721/512                         4930 ns         4899 ns       137825\r\nBM_Extra96Bits_4293918721/4096                       41145 ns        40808 ns        17028\r\nBM_Extra96Bits_4293918721/32768                     341149 ns       338716 ns         2073\r\nBM_Extra64Bits_15564440312192434177/8                  611 ns          574 ns      1243273\r\nBM_Extra64Bits_15564440312192434177/64                 916 ns          908 ns       770985\r\nBM_Extra64Bits_15564440312192434177/512               5047 ns         4998 ns       136890\r\nBM_Extra64Bits_15564440312192434177/4096             42041 ns        41743 ns        16057\r\nBM_Extra64Bits_15564440312192434177/32768           356554 ns       349632 ns         2062\r\nBM_RejectionSampling_4293918721/8                      389 ns          387 ns      1772125\r\nBM_RejectionSampling_4293918721/64                     577 ns          574 ns      1179206\r\nBM_RejectionSampling_4293918721/512                   1417 ns         1400 ns       496095\r\nBM_RejectionSampling_4293918721/4096                  8928 ns         8879 ns        77181\r\nBM_RejectionSampling_4293918721/32768                75661 ns        75260 ns         8604\r\nBM_RejectionSampling_15564440312192434177/8            497 ns          491 ns      1390710\r\nBM_RejectionSampling_15564440312192434177/64           806 ns          800 ns       826046\r\nBM_RejectionSampling_15564440312192434177/512         2780 ns         2750 ns       255927\r\nBM_RejectionSampling_15564440312192434177/4096       21339 ns        21210 ns        32438\r\nBM_RejectionSampling_15564440312192434177/32768     174767 ns       173535 ns         4005\r\nBM_Prg/8                                               121 ns          120 ns      5771625\r\nBM_Prg/64                                              140 ns          128 ns      5836641\r\nBM_Prg/512                                             212 ns          211 ns      3297873\r\nBM_Prg/4096                                           1609 ns         1595 ns       434891\r\nBM_Prg/32768                                         12901 ns        12790 ns        54085\r\nBM_ECDH                                                298 ns          286 ns      2516772\r\n```\r\n\r\nIn particular, I looked at `ExtraXXBits` where `XX` is the number of extra bits, and looked at two moduli from the documentation, of respectively 32 and 64 bits. The value after the `/` is the size of the output vector. ",
          "createdAt": "2021-03-14T17:08:58Z",
          "updatedAt": "2021-03-14T17:08:58Z"
        },
        {
          "author": "tlepoint",
          "authorAssociation": "NONE",
          "body": "Additionally, I would like to point out that the analysis in the hash-to-curve draft is for generating a _single_ random value. If the approach of extra bits is chosen, when generating `N` random values, the statistical distance also depends on `N`, and henceforth more than `k` bits should be used for a statistical distance of `2^(-k)` for the whole vector. (In which case, you may actually want to consider different methods to quantify the closeness of the distributions, such as [R\u00e9nyi divergences](https://en.wikipedia.org/wiki/R%C3%A9nyi_entropy#R%C3%A9nyi_divergence)).",
          "createdAt": "2021-03-14T17:13:53Z",
          "updatedAt": "2021-03-14T17:13:53Z"
        },
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "It seems like rejection sampling is clearly the better method, based on the above benchmarks. It's also fairly straightforward to implement. I would favor updating the text to require this method.",
          "createdAt": "2021-03-18T21:06:08Z",
          "updatedAt": "2021-03-18T21:06:08Z"
        },
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "I'm working on a PR to close this issue (we'll go with rejection sampling). @tlepoint, I can't confirm all of the behavior of libprio-rs and libprio-cc that you pointed to. Specifically, neither library appears to clear the two most significant bits, as you suggested they do. Here's the pertinent code in the latter: https://github.com/google/libprio-cc/blob/master/prio/prng/aes_128_ctr_seeded_prng.cc#L118-L121\r\n\r\nCan you confirm that the bits aren't being cleared?",
          "createdAt": "2021-06-09T18:20:51Z",
          "updatedAt": "2021-06-09T18:20:51Z"
        },
        {
          "author": "tlepoint",
          "authorAssociation": "NONE",
          "body": "In libprio-rs (at least initially) and libprio-cc, the prime is hardcoded to a 32-bit prime, so you actually should *not* clear the most significant bits. More generally, if p is a k-bit prime in a word of l bits, you will want to clear the `l-k` most significant bits.\r\n- for k = 32, l=32, you want to clear 0 bits;\r\n- for k = 126, l=128, you want to clear 2 bits (example I gave in the first comment).",
          "createdAt": "2021-06-10T18:00:38Z",
          "updatedAt": "2021-06-10T18:00:38Z"
        },
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "Ah, yes. That makes sense. Thanks!",
          "createdAt": "2021-06-10T22:16:46Z",
          "updatedAt": "2021-06-10T22:16:46Z"
        }
      ]
    },
    {
      "number": 15,
      "id": "MDU6SXNzdWU4MjUwMDY0MjA=",
      "title": "Enforce batch size (was \"Trust in the leader / Aggregation size enforcement at the aggregator\")",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/issues/15",
      "state": "CLOSED",
      "author": "tlepoint",
      "authorAssociation": "NONE",
      "assignees": [],
      "labels": [],
      "body": "If I am not mistaken, the current design would actually allow a malicious leader to learn single client contributions, by only sending that specific data to the aggregator, reporting that the proof is valid, ask the aggregator to \"sum\" the single element and return the answer. While the current design is motivated by different types of constraints (soft deadlines / privacy threshold defined by a minimum number of input shares), it must be observed that such a responsibility should not only be that of the leader.\r\n\r\nIs there a plan to have aggregation size enforcement by the aggregators, and avoid aggregation of a small amount of (even a single) records?",
      "createdAt": "2021-03-08T22:16:48Z",
      "updatedAt": "2021-07-28T21:24:38Z",
      "closedAt": "2021-07-28T21:24:38Z",
      "comments": [
        {
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "body": "We did discuss that problem, but it's good to have an open issue on it so we don't forget to address it; thank you for filing this! \r\n\r\nOne tricky dimension to this question is what the minimum threshold should be. I'm not sure if a single threshold value is appropriate for all use cases, and it might be that it's something the client should select while onboarding into the system.",
          "createdAt": "2021-03-08T22:37:16Z",
          "updatedAt": "2021-03-08T22:37:16Z"
        },
        {
          "author": "tlepoint",
          "authorAssociation": "NONE",
          "body": "Having that be a choice of the client is interesting, but such value would need to be visible to the leader (since the leader needs to ask the aggregators to aggregate at least that number of shares together), but also need to be authenticated by the client for the aggregators (so that the leader cannot arbitrarily modify the value). This brings quite a few complications, especially with the optimization of using a KEM.\r\n\r\nAnother option (beyond enforcement by the aggregators, which I still find preferable) could be for the aggregators to keep a public and transparent log of how many shares a specific leader asked to aggregate. Such a public log may act as a deterrent for leader to ask for small aggregations, and they would need a strong justification on why a small aggregation was performed. On the downside, this would reveal publicly how much data is flowing throughout the system.",
          "createdAt": "2021-03-08T22:50:36Z",
          "updatedAt": "2021-03-08T22:51:00Z"
        },
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "My $0.02: aggregators should enforce the number of input shares aggregated before releasing their share of the output. One way to do this is, as you suggested, might be to replace the KEM with IND-CCA-secure encryption --- say, full HPKE, which takes associated data --- and authenticate the threshold by passing it in as associated data.",
          "createdAt": "2021-03-18T21:19:10Z",
          "updatedAt": "2021-03-18T21:19:10Z"
        }
      ]
    },
    {
      "number": 18,
      "id": "MDU6SXNzdWU4MjgxNDI3NTY=",
      "title": "Heavy Hitters is in scope",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/issues/18",
      "state": "CLOSED",
      "author": "chris-wood",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "See [the paper](https://eprint.iacr.org/2021/017.pdf). ",
      "createdAt": "2021-03-10T18:12:53Z",
      "updatedAt": "2021-07-15T01:25:56Z",
      "closedAt": "2021-07-15T01:25:56Z",
      "comments": [
        {
          "author": "tlepoint",
          "authorAssociation": "NONE",
          "body": "Please note that (regular, not necessarily incremental) DPFs can also be used for aggregation, and are described in a series of papers: \r\n- [Function Secret Sharing: Improvements and Extensions](https://eprint.iacr.org/2018/707)\r\n- [Function Secret Sharing](https://link.springer.com/chapter/10.1007/978-3-662-46803-6_12)\r\n- [Distributed Point Functions and Their Applications](https://link.springer.com/chapter/10.1007/978-3-642-55220-5_35)\r\n\r\nProof of concept implementations of DPFs can be found [here (golang)](https://github.com/dkales/dpf-go) or [here (C++)](https://github.com/dkales/dpf-cpp).",
          "createdAt": "2021-03-12T21:18:50Z",
          "updatedAt": "2021-03-12T21:19:00Z"
        },
        {
          "author": "csharrison",
          "authorAssociation": "CONTRIBUTOR",
          "body": "Strong +1 to this idea. I had a longer write-up motiving a use case and outlining a high level solution which leverages this technology for a web API use-case. Then I found this existing issue. Here's what I had:\r\n\r\n### Motivation: Aggregation under very large domains\r\nThe existing Prio protocol enables distributed computation of histograms which have buckets determined by a set of aggregation ids. This construction requires communication overhead per contribution per client that scales linearly with the size of the domain of aggregation (i.e. the size of the histogram vector).\r\n\r\nThis solution works for modest domains (e.g. ~1000s of entries), but starts to incur significant communication overhead as domains get larger (~1M entries or more).\r\n\r\nWith the [Privacy Sandbox](https://www.chromium.org/Home/chromium-privacy/privacy-sandbox) effort, we are looking at aggregation use-cases where domain sizes for aggregation are extremely large and sparse e.g. on the order of ~1B possible aggregation buckets, with ~1k - 1M non-zero buckets. This is analogous to the \u201cheavy hitters\u201d problem. Additionally, we are looking at protecting the output with central differential privacy noise.\r\n\r\nIn trying to solve for these use-cases, we are exploring a few optimizations:\r\n - Improving communication overhead via compression techniques that grow only logarithmically in the size of the output domain\r\n - Improving server-side performance by allowing for dynamic / hierarchical query models and partial evaluations of the output domain\r\n\r\nThese techniques are inspired by [Lightweight Techniques for Private Heavy Hitters](https://arxiv.org/abs/2012.14884).\r\n\r\nNote: we are also exploring MPC protocols which don\u2019t grow proportionally to the output domain at all, but they are at an early stage.\r\n\r\n### Function secret sharing and distributed point functions\r\nA new cryptographic primitive can help us achieve these goals.\r\n\r\nGiven a function f(x): X -> Y, a function secret sharing is a primitive defined by two algorithms\r\n - GenKey(f) outputs two keys K0 and K1\r\n - Eval(K_b, x) outputs value z_b for b=0, 1 and all x\u2208X such that z_0 and z_1 are two random shares of f(x) in Zp, i.e z_0 + z_1 = f(x) mod p.\r\n\r\nA point function fa,b(x) : X -> Y is a function such that f(a) = b and f(a) = 0 for all x \u2260 a.\r\n\r\nA distributed point function is a function secret sharing for a point function fa,b(x). There exist [DPF constructions](https://eprint.iacr.org/2018/707.pdf) such that the size of the DPF keys K0 and K1 is logarithmic in the function input domain |X| and output domain |Y|. \r\n\r\nBy themselves, DPFs can be drop-in replacements for vector secret shares (via calling Eval on the full domain), and there are secure ways of verifying input consistency, like in Prio, with interaction between the servers. This trades off a cpu increase for a large communication overhead decrease.\r\n\r\nAdditionally, Boneh et. al. have shown that these techniques can be extended to allow for evaluation on prefixes of the input point (\u201cincremental\u201d DPFs or \"IDPFs\"). In other words:\r\n - Eval(K_b, x_t) outputs value z_b for b=0, 1 and all x\u2208X such that z0 and z1 are two random shares of f(x) in Zp, i.e z_0 + z_1 = f(x) mod p, for x_t a t-bit prefix of x.\r\n\r\nPrefix evaluation critically allows for evaluating input in a hierarchical manner (i.e. counts at a fixed prefix).\r\n\r\n### Hierarchical / dynamic queries\r\nBy leveraging IDPFs, we can allow for dynamic queries on large, sparse domain data that traverses a hierarchy. For example, imagine a domain of size 2^25 where only a small fraction of the entries are expected to be non-zero. Both vector secret sharing and naive DPF expansion would struggle with this problem. \r\n\r\nWith IDPFs though, a client could:\r\n - Evaluate the data at a 12-bit prefix\r\n - Find that only 2^5 prefixes hold meaningful amounts of data\r\n - Partially evaluate the data again (unprefixed), but only for entries which match the 2^5 prefixes that have data. This will end up evaluating 2^(5 + 25 - 12) = 2^18 entries, which is more manageable (~250 kb expansion per record) than expanding the whole domain from the beginning\r\n - Timings from preliminary C++ benchmarks: \r\n   - 526ms for a full domain evaluation (size 2^25)\r\n   - 12ms for incremental / sparse evaluation.\r\n\r\nThis single pruning step is a simple example, but this technique can be leveraged in much more complex ways to solve real world private metrics problems. Of course, if we are applying DP noise in the computation we may need to split a privacy budget across each of these dynamic queries.\r\n\r\n### Existing implementations\r\n- Internally at Google we are working on a production C++ implementation of IDPFs (for fast performance), to be open sourced very soon. We are seeing ~10ms to fully expand a ~4 mb vector from a ~350 byte key, and ~1ms to expand a 500kb vector from a ~300 byte key. \r\n - There is a (non-production) [Rust implementation](https://github.com/henrycg/heavyhitters) of IDPFs by Henry Corrigan-Gibbs\r\n - @tlepoint referenced a golang and C++ implementation of DPFs above\r\n",
          "createdAt": "2021-03-17T16:58:34Z",
          "updatedAt": "2021-03-17T19:13:05Z"
        },
        {
          "author": "stpeter",
          "authorAssociation": "COLLABORATOR",
          "body": "@henrycg we'd welcome your thoughts in this thread :-) ",
          "createdAt": "2021-03-17T17:40:25Z",
          "updatedAt": "2021-03-17T17:40:25Z"
        },
        {
          "author": "henrycg",
          "authorAssociation": "COLLABORATOR",
          "body": "Thanks for looping me in here!\r\n\r\nIt would definitely be nice if Prio v3 could support heavy-hitters queries. There are a number of applications that need this, so I like the idea of building it into the design. At the same time, the machinery needed to support these heavy-hitter applications involves a quite a few moving parts that are not needed for Prio v1/v2 functionality.\r\n\r\nIn particular, Prio v1/v2 uses:\r\n\r\n- Two or more servers (where privacy holds if at least one is honest)\r\n- Simple additive secret sharing with finite-field arithmetic\r\n- **ZK proofs on secret-shared data (called \"SNIPs\" in the Prio paper)**\r\n\r\nThe simplest version of the heavy-hitters scheme from the [BBCGI21](https://arxiv.org/abs/2012.14884) paper needs:\r\n\r\n- Two servers (where privacy holds if at least one is honest)\r\n- Simple additive secret sharing with finite-field arithmetic\r\n- **Distributed point functions**\r\n- **Sketch-verification schemes (Section 4 in the BBCGI21 paper)**\r\n\r\nDo we want to expand the scope of this document to include the more recent and more advanced techniques? Or, is it better to stick with the Prio v1/v2 technology, which is quite stable and which we understand pretty well at this point\u2014even if it does not support all of the functionality that we want?\r\n",
          "createdAt": "2021-03-18T21:36:58Z",
          "updatedAt": "2021-03-18T21:36:58Z"
        },
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "I think it's worth spinning up a new doc, though presumably there are pieces shared by both (i.e., ZK proofs on secret shared data). These could live in a third doc.",
          "createdAt": "2021-03-18T21:55:48Z",
          "updatedAt": "2021-03-18T21:55:48Z"
        },
        {
          "author": "schoppmp",
          "authorAssociation": "NONE",
          "body": "The C++ implementation of (I)DPFs mentioned by @csharrison above is now public:\r\nhttps://github.com/google/distributed_point_functions",
          "createdAt": "2021-03-19T14:45:59Z",
          "updatedAt": "2021-03-19T14:45:59Z"
        },
        {
          "author": "csharrison",
          "authorAssociation": "CONTRIBUTOR",
          "body": "FYI I published an example query model for how the flexible, non-interactive heavy hitters could work via some configuration here:\r\nhttps://github.com/WICG/conversion-measurement-api/blob/main/AGGREGATE.md#example-query-model\r\n\r\nIt basically requires either the collector or leader to give some configuration outlining which bit-prefixes to expand.",
          "createdAt": "2021-05-07T21:08:07Z",
          "updatedAt": "2021-05-07T21:08:07Z"
        },
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "I think we're well passed the relevant point on the decision tree here :) Any reason to keep this issue open? I suppose the links are useful, but it's easy enough to rummage around in the closed issues to find them.",
          "createdAt": "2021-07-14T20:53:35Z",
          "updatedAt": "2021-07-14T20:53:35Z"
        },
        {
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "body": "Let's close it out.",
          "createdAt": "2021-07-15T01:25:56Z",
          "updatedAt": "2021-07-15T01:25:56Z"
        }
      ]
    },
    {
      "number": 19,
      "id": "MDU6SXNzdWU4MjgxNjk4ODM=",
      "title": "Accommodating randomized inputs (a la DP)",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/issues/19",
      "state": "OPEN",
      "author": "chris-wood",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "@tlepoint pointed out that PrioV2 requires all clients to submit randomized values for the purposes of ensuring that identical inputs don't yield the same output. Basically, with some very small probability, clients flip some bits in their data to maximize aggregate utility and privacy (in terms of differential privacy bounds). [Apple's paper](https://arxiv.org/abs/2012.12803) on this topic has details. \r\n\r\nWe should probably design the system such that either clients or aggregators can inject this sort of noise. ",
      "createdAt": "2021-03-10T18:33:51Z",
      "updatedAt": "2022-06-01T14:13:54Z",
      "closedAt": null,
      "comments": [
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "This seems orthogonal to the core protocol logic, since its applicability depends on the data type. ",
          "createdAt": "2021-03-18T21:22:06Z",
          "updatedAt": "2021-03-18T21:22:06Z"
        },
        {
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "body": "There's an open question that fell out of the review of #91 that feels appropriate for this issue. Aggregators are encouraged to apply differential privacy noise to outputs. Collectors and aggregators may need to agree on DP parameters (e.g., the probability with which values are flipped) so that collectors can de-noise outputs. I think we might need to have a field in `PDAParams` for differential privacy parameters.",
          "createdAt": "2021-07-30T19:19:59Z",
          "updatedAt": "2021-07-30T19:19:59Z"
        },
        {
          "author": "csharrison",
          "authorAssociation": "CONTRIBUTOR",
          "body": "It's worth noting that in many situations (especially with server-added noise), the collectors don't need to do anything special to \"de-noise\" since it's often going to have a mean of 0. However, collectors may want to know things like the variance of the noise, or what distribution the noise was sampled from so they can understand the effective error.",
          "createdAt": "2021-07-30T19:25:03Z",
          "updatedAt": "2021-07-30T19:25:03Z"
        },
        {
          "author": "csharrison",
          "authorAssociation": "CONTRIBUTOR",
          "body": "I was originally going to post this as a new issue but I think this one should suffice. Originally titled \"Optional DAP configuration that achieves differential privacy\". Apologies in advance for the wall of text, I hope it is useful to the discussion.\r\n\r\n-----\r\n\r\nDifferential privacy (DP) is a useful property of an aggregate system. Among other things, it is a mitigation against Sybil attacks that aim to violate user privacy. This is because differential privacy holds under worst-case assumptions, including when the adversary knows the contents of the entire database except for the targeted user. In other words, malicious clients submitting data to the system does not adversely affect the privacy (in this worst-case sense) of any honest user.\r\n\r\nWe should consider whether we want to specify an optional configuration in DAP which deployments can use to achieve DP output. @cjpatton mentions [here](https://github.com/ietf-wg-ppm/ppm-specification/pull/235#discussion_r865016936) it would be useful, so here are my thoughts:\r\n\r\nDP typically involves noise addition, we ought to consider two flavors, since I think both are relevant and useful to this work:\r\n\r\n## 1. Clients add noise to their input\r\n\r\nWhen clients add noise to their input, it is possible to show the system is differentially private (in the \u201clocal\u201d model) without any downstream changes in DAP or VDAF. This is a trivial result though, and does not take advantage of anything relevant to DAP.\r\n\r\nThe security model of DAP is that input is sent to the system through input shares, which eliminates any knowledge in the system of which client sent which report. I believe that, by using a similar line of argument as the [ENPA white paper](https://covid19-static.cdn-apple.com/applications/covid19/current/static/contact-tracing/pdf/ENPA_White_Paper.pdf) (section 4.5), we can show that using local noise in DAP should always achieve differential privacy in the shuffle model, without any change to the protocol (or restriction on VDAF). This yields [much stronger](https://arxiv.org/abs/2012.12803) privacy bounds than purely local DP. It will depend on the number of users contributing in a given batch, so increasing the minimum batch size should increase privacy.\r\n\r\nSide note: with some specific VDAFs, and some specific types of local noise, you could show stronger privacy bounds than shuffle DP, even if noise is only added on the client. This is similar to the case of each aggregator adding independent noise, where you consider the client to be a 1-record aggregator.\r\n\r\nSide note: If clients add noise to their input, it puts at risk the \u201cverifiable\u201d aspect of VDAF, since the input is falsey from the very start. However, we can still add noise such that the output is well-bounded, and downstream VDAFs can expect data within the expected bounds.\r\n\r\n## 2. Noise is added during aggregation\r\n\r\nThere are a couple of ways I could see specifying this. This is an example of central DP, or more specifically, distributed DP since it is done via distributed noise addition.\r\n\r\n### 2A. VDAFs add noise\r\n\r\nThe idea here is that a particular VDAF could be implemented such that noise is added to each `agg_share` independently, resulting in a noisy `agg_result` that could be shown to be differentially private. Noise should be added in such a way that agg_result has summed noise distributed according to a particular distribution that we know achieves DP (e.g. discrete laplace, etc).\r\n\r\nFor example, n aggregators adding noise distributed according to difference-of-Polya distributions would, summed together, yield noise distributed according to two-sided geometric distribution ([link](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5598559/), theorem 5.1) which we can show central DP bounds for. It is worth mentioning that in these schemes, you can often show (reduced) DP bounds even if only a subset of the aggregators are honestly adding noise, which is exactly the kind of property that you want out of DAP. In general, this is possible when the final distribution you want the output noise to follow is [infinitely divisible](https://en.wikipedia.org/wiki/Infinite_divisibility_(probability)), or has good infinitely divisible approximations.\r\n\r\nVDAFs should probably not make any assumptions about their input shares (i.e. how many are coming from which users, etc). However, if they know both:\r\n- The range that inputs to the VDAF must fall under, and\r\n- The amount of noise the VDAF adds\r\nThen we can specify in some cases the record-level differential privacy claim. That is, how much privacy loss we could expect (in the worst case) on any particular record in the input.\r\n\r\nThis means a DP-aware VDAF could parametrize itself with a new `PublicParam` that encodes a `(epsilon, delta)` tuple describing the desired record-level differential privacy bounds. Then the VDAF could configure itself to add noise scaled properly to achieve this bound. It\u2019s possible the VDAF would need new constants to advertise bounds on epsilon / delta if only some configurations are possible. VDAFs can also have public parameters specifying the distribution they are sampling from to add noise, so users of the VDAF can properly understand the expected variance from aggregating.\r\n\r\nWith VDAFs supporting record-level DP, it should be easy to achieve user-level DP in DAP. The easiest way would be to include a new constraint that each user produces exactly the same number of inputs as any other user (say, N inputs) in a given batch (see #210 also). It is straightforward to show (via group privacy, see Lemma 2.2 [here](https://privacytools.seas.harvard.edu/files/privacytools/files/complexityprivacy_1.pdf)) that this would result in user-level privacy loss at most `(N*epsilon, N*exp(N*epsilon)*delta)`. It should be possible to make DP claims in other settings, but it will be a bit more challenging.\r\n\r\n### 2B. Add noise as a post-processing step after VDAF aggregation\r\n\r\nVDAFs are already complicated things, so it might be possible for noise to be added outside that system (e.g. by DAP). This is appealing, but introduces some new challenges.\r\n\r\nDAP will need to know the effective sensitivity of the VDAF, i.e. how much each record can maximally impact the agg result in order to calibrate the noise. Note that there are multiple ways of measuring sensitivity (L0, L1, L2, Linf, etc.) that could be relevant here, and it might be more optimal to add noise if you know the L2 sensitivity vs. the L1 sensitivity.\r\n\r\nWhen this information is known, and using the type information that DAP should already know about the VDAF, DAP could specify techniques for adding noise to each agg share before they get sent to the collector, based on the exposed sensitivity, a desired privacy level, and the maximum number of input records a user could contribute. We would want generic methods for supporting DP given an arbitrary function F, its sensitivity, type, and #`SHARES` that a DAP deployment could use.\r\n\r\nIn offline discussions with @marianapr, she preferred this approach, but in my opinion it feels pretty complicated to decouple noise addition generically from the aggregation function itself. I'd be interested in other opinions though.\r\n\r\nOf course, we can also discuss parametrizing DAP as well as @tgeoghegan mentions above.\r\n\r\ncc @badih who double checked some of my work here.",
          "createdAt": "2022-05-05T16:59:56Z",
          "updatedAt": "2022-05-05T16:59:56Z"
        },
        {
          "author": "degregat",
          "authorAssociation": "NONE",
          "body": "Some information regarding de-risking of approach **2B**: \r\n\r\nA prototype extension for libprio based on this approach can be found [here](https://github.com/degregat/libprio/blob/345ab6f9795dcd60fddc54a24b43eefe9e48a0bd/pclient_dp/main.c#L201), this one being meant to be used as a backend for federated learning. \r\n\r\nProperties for the distributed discrete gaussian can be found [in this paper by google research](https://arxiv.org/abs/2102.06387).\r\nLooking at the above, one could use noise scaling techniques similar to **2A** and would receive an analogous graceful privacy reduction per defecting aggregator (implemented [here](https://github.com/degregat/libprio/blob/345ab6f9795dcd60fddc54a24b43eefe9e48a0bd/prio/server.c#L362)). Though I'm wondering how to think about the case when a subset is defecting, since then the validity checking from the PCPs breaks down, and we get different problems as well. (This should be true for **2A** as well, no?)\r\n\r\nThere are now [prototype tools](https://diffmu.github.io/DiffPrivacyInference.jl/dev/tutorial/01_sensitivity_functions/#Sensitivity), to infer sensitivity as well as privacy guarantees of functions, so it sounds more feasible by the day to find out the sensitivity of a given VDAF, without it being too labor intensive.\r\n\r\nIn any case, it is advisable to use discrete distributions to prevent being vulnerable to [floating point attacks](https://www.microsoft.com/en-us/research/wp-content/uploads/2012/10/lsbs.pdf).",
          "createdAt": "2022-05-31T20:05:46Z",
          "updatedAt": "2022-06-01T08:45:59Z"
        },
        {
          "author": "csharrison",
          "authorAssociation": "CONTRIBUTOR",
          "body": "Thanks @degregat ! I think the distrusted aggregators adding \"too much noise\" to compromise the result is a good thing to try to protect against. However, I am not sure how necessary it is given that malicious aggregators can [already compromise the result](https://ietf-wg-ppm.github.io/draft-ietf-ppm-dap/draft-ietf-ppm-dap.html#section-6.1.2.2) in the DAP threat model. In any case it's not obvious to me whether this is easier to achieve in 2A or 2B.\r\n- In 2A we could add another round to the initialization step to pass around noise shares.\r\n- In 2B perhaps the leader crafts noise shares before interacting with the other aggregators. This would move the idea from \"post-processing\" to \"pre-processing\", to take advantage of the VDAFs verification.\r\n\r\n> There are now [prototype tools](https://diffmu.github.io/DiffPrivacyInference.jl/dev/tutorial/01_sensitivity_functions/#Sensitivity), to infer sensitivity as well as privacy guarantees of functions, so it sounds more feasible by the day to find out the sensitivity of a given VDAF, without it being too labor intensive.\r\n\r\nThat is very interesting! Thanks for sharing.\r\n\r\n> In any case, it is advisable to use discrete distributions to prevent being vulnerable to [floating point attacks](https://www.microsoft.com/en-us/research/wp-content/uploads/2012/10/lsbs.pdf).\r\n\r\nI agree, I think it's generally easier in the MPC to have support only on integers, so I don't think that's a big constraint.\r\n",
          "createdAt": "2022-06-01T14:13:54Z",
          "updatedAt": "2022-06-01T14:13:54Z"
        }
      ]
    },
    {
      "number": 20,
      "id": "MDU6SXNzdWU4MjgxNzk0MDU=",
      "title": "Data stuffing",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/issues/20",
      "state": "OPEN",
      "author": "chris-wood",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [
        "duplicate"
      ],
      "body": "To what extent should the system detect or mitigate fake clients from stuffing data into the system? We could so far as to say that all data must come from an authenticated client. (Maybe there's something with anonymous credentials we can do here?) We might also recommend simple mitigations, such as checking for repeated entries from the \"same client\" (same IP, same application-layer identifier, etc) during a batch. ",
      "createdAt": "2021-03-10T18:41:28Z",
      "updatedAt": "2021-08-10T21:49:48Z",
      "closedAt": null,
      "comments": [
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "In today's design call we discussed mitigating this issue using an \"ingestion server\" that sits in front of the leader. In practice, the leader and ingestor might be the same entity.",
          "createdAt": "2021-04-14T18:12:11Z",
          "updatedAt": "2021-04-14T18:12:11Z"
        },
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "@csharrison, this issue tracks the \"double counting\" problem we discussed today.",
          "createdAt": "2021-04-14T18:19:41Z",
          "updatedAt": "2021-04-14T18:19:41Z"
        },
        {
          "author": "csharrison",
          "authorAssociation": "CONTRIBUTOR",
          "body": "For our use-case, we'd likely want an application-layer identifier to impose limits on clients or even batches of clients (to make this kind of input tracking scale a bit better).\r\n\r\nWe are also interested in allowing clients to input the same piece of data multiple times, up to some fixed number. This is to support the batch querying model where a server has a collection of records and would like to learn e.g. both daily aggregates and weekly aggregates, which would require every piece of data getting processed twice.",
          "createdAt": "2021-04-28T17:08:03Z",
          "updatedAt": "2021-04-28T17:08:03Z"
        }
      ]
    },
    {
      "number": 21,
      "id": "MDU6SXNzdWU4MzQwMzU1MzY=",
      "title": "Client configuration information",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/issues/21",
      "state": "CLOSED",
      "author": "chris-wood",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "We should probably assume that configuration information, including the desired aggregation function, encoding details, choice of aggregators, etc., are all known to the client before it creates any data for submission. Online parameters such as batch identifiers should also be assumed known for a given client when producing data for the system. In practice, clients might be given batch identifiers to use for a given aggregation from some trusted party, or they might query it from the leader, or something else. The details are probably out of scope. \r\n\r\nEssentially, clients can submit data given configuration parameters and a batch identifier. And that's probably(?) the minimum dependencies here.",
      "createdAt": "2021-03-17T17:48:44Z",
      "updatedAt": "2021-07-14T21:00:29Z",
      "closedAt": "2021-07-14T21:00:29Z",
      "comments": []
    },
    {
      "number": 22,
      "id": "MDU6SXNzdWU4NDEzMTI3NjY=",
      "title": "Explore Shamir secret sharing (was \"Multiple protocol runs and/or threshold secret sharing\")",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/issues/22",
      "state": "OPEN",
      "author": "tgeoghegan",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [
        "parking-lot"
      ],
      "body": "Prio v2 employs a linear secret sharing scheme in which all input shares are required in order to produce coherent outputs. This gives us robustness against malicious clients, but not malicious servers ([robustness per section 2 of the 2017 paper](https://crypto.stanford.edu/prio/paper.pdf)).\r\n\r\nWe could provide robustness against a minority of malicious servers by running the protocol over multiple subsets of aggregators. If the outputs across all aggregator subsets do not agree, then participants know that there is at least one malicious server.\r\n\r\nIf linear secret sharing is employed, then clients would have to generate input shares once for each subset. We could also use a threshold secret sharing scheme (e.g., [Shamir](https://en.wikipedia.org/wiki/Shamir%27s_Secret_Sharing)), which would reduce work for clients.",
      "createdAt": "2021-03-25T21:13:29Z",
      "updatedAt": "2021-07-14T20:39:47Z",
      "closedAt": null,
      "comments": [
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "This will be interesting :) ",
          "createdAt": "2021-03-25T23:42:08Z",
          "updatedAt": "2021-03-25T23:42:08Z"
        },
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "#43 partially addresses this issue by deciding that multiple helpers will be used for resilience. Whether we can use Shamir secret sharing to provide robustness against cheating servers is still an open question. Though IMO we shouldn't try to change the spec to allow for this.",
          "createdAt": "2021-06-09T17:48:25Z",
          "updatedAt": "2021-06-09T17:50:01Z"
        }
      ]
    },
    {
      "number": 24,
      "id": "MDU6SXNzdWU4NDIyNzk1MTA=",
      "title": "Try to write an overview so the cryptographic details aren't such a jump",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/issues/24",
      "state": "CLOSED",
      "author": "ekr",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "",
      "createdAt": "2021-03-26T20:35:15Z",
      "updatedAt": "2021-04-14T18:10:48Z",
      "closedAt": "2021-04-14T18:10:48Z",
      "comments": [
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "(Linking PR #26)",
          "createdAt": "2021-04-05T23:13:39Z",
          "updatedAt": "2021-04-05T23:13:39Z"
        },
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "Closing this since the PR has landed.",
          "createdAt": "2021-04-14T18:10:48Z",
          "updatedAt": "2021-04-14T18:10:48Z"
        }
      ]
    },
    {
      "number": 27,
      "id": "MDU6SXNzdWU4NDczMzA5MzY=",
      "title": "Some notes on requirements",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/issues/27",
      "state": "CLOSED",
      "author": "ekr",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "I tend to think of this from two perspectives (1) the client and\r\n(2) the collector. At a high level, we expect them to coordinate.\r\n\r\nThe basic unit here is the measurement, which is just a value\r\ncollected by the client. In a normal system, each value is\r\ncharacterized by:\r\n\r\n- A name\r\n- A type [scalar, integer, etc.]\r\n- Externally, some description of what it measures\r\n- Some description of what reasnable values are (so we can do outlier\r\n  rejection)\r\n\r\nIn Prio, you would also have:\r\n\r\n- The aggregation function you want to use with the measurement.\r\n- The precise ranges of a valid input (replacing the \"reasonable\")\r\n  filter above\r\n\r\nNote that this might mean you needed to duplicate measurements if you\r\nwanted to be able to do multiple aggregation functions.  This isn't\r\nnecessarily with traditional telemetry.\r\n\r\nThis information needs to be propagated both to the client and the\r\ncollector and they need to match. Practically, once a name is\r\nreserved, its properties shouldn't change because otherwise things get\r\nweird. Though sometimes we will slightly change how we collect some\r\nmeasurement a bit, but keep the types the same, etc.\r\n\r\n\r\nOperationally, clients will have some set of measurements that they\r\nmaintain and then will just periodically send them all to the server\r\nin a single package (Mozilla calls this a \"ping\"). In Mozilla\r\ntelemetry this is just a JSON blob, e.g.,\r\n\r\n         \"scalars\": {\r\n            \"contentblocking.trackers_blocked_count\": 258,\r\n            \"media.element_in_page_count\": 42,\r\n            \"browser.engagement.session_time_including_suspend\": 90858058,\r\n            \"browser.engagement.active_ticks\": 612,\r\n            \"browser.engagement.session_time_excluding_suspend\": 49487949\r\n          },\r\n\r\nWhen you want to add a new measurement, you just add a new entry to\r\nthe JSON blob. And in principle you could remove them, though that's\r\nless common. So, for instance, version 20 might have these scalars and\r\nversion 21 might have these plus another.\r\n\r\n\r\nOn the collector side, what you generally want to be able to do is to\r\nfilter the reports by demographic type information (e.g., browser\r\nversion, location, time) and then compute some aggregate over the\r\nfiltered result. For instance, suppose you wanted to know the fraction\r\nof IPv4 versus IPv6, you might just take every client that reported\r\nthat measurement, but you might also want to look at Beta versus\r\nRelease. One important implication is that when you are looking\r\nat measurement A, you don't care if the client reported measurement\r\nB. And in particular, if some clients report [A, B] and others report\r\n[A], you want to capture all of them (unless you don't!).\r\n\r\nObviously Prio limits what you can do here. In particular:\r\n\r\n- You can't just compute any statistic over a given measurement,\r\n  but only the ones compatible with the encoding.\r\n\r\n- It's not safe to let people just compute aggregates over\r\n  arbitrary-sized subsets of the data because then they can\r\n  pull out specific reports.\r\n\r\nHowever, we'd obviously like to support as flexible queries as\r\npossible. In particular, it's desirable to have modes in which\r\nyou can \"drill down\" into the data. For instance, you might\r\nnotice that the rate of some error had gone up recently and\r\nwant to try to isolate it to some subpopulation. This implies\r\nthat you don't just want pure batch processing.\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n",
      "createdAt": "2021-03-31T21:01:52Z",
      "updatedAt": "2021-08-11T22:12:46Z",
      "closedAt": "2021-08-11T22:12:46Z",
      "comments": [
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "Thanks for writing up this clear description of the use case, @ekr. Your understanding of the limits of Prio with respect to this particular usage appears to match my own. The good news is that there's lots of ways to provide flexibility of the system, though perhaps at the cost of time complexity, communication overhead, or both. By way of fleshing out the design space, let me sketch what I see as the two possible extremes.\r\n\r\n**Maximizing flexibility.** Let's start with how we would maximize flexibility of the system. Essentially what we need to do is move all metadata and versioning logic outside of Prio. Concretely, we secret share and validate each value in the JSON object Individually. So instead of the plaintext JSON blob above, each aggregator would see something like\r\n```\r\n     \"scalars\": {\r\n        \"contentblocking.trackers_blocked_count\": {\r\n           \"proof share\": <share of proof 1>, \r\n           \"input share\": <share of input 1>\r\n        },\r\n        \"media.element_in_page_count\": {\r\n           \"proof share\": <share of proof 2>, \r\n           \"input share\": <share of input 2>\r\n        },\r\n        \"browser.engagement.session_time_including_suspend\": {\r\n           \"proof share\": <share of proof 3>, \r\n           \"input share\": <share of input 3>\r\n        },\r\n        \"browser.engagement.active_ticks\": {\r\n           \"proof share\": <share of proof 4>, \r\n           \"input share\": <share of input 4>\r\n        },\r\n        \"browser.engagement.session_time_excluding_suspend\": {\r\n           \"proof share\": <share of proof 5>, \r\n           \"input share\": <share of input 5>\r\n        }\r\n      }\r\n```\r\nHere, the proof and input shares look like sequences of random field elements. The aggregators would collectively validate each input using the proof share corresponding to their input share. Since there are 5 inputs here, the aggregators would do 5 runs of the input validation protocol. Notice, however, that since the runs are independent, it's possible to batch the messages together so that the round complexity (i.e, round trips over the network) is the same as if there were just one input to validate.\r\n\r\nHaving validated all of the inputs, the aggregators can do whatever they want with them. For example, if they want to compute a statistic over the measurements by all clients of a particular agent type, then each aggregator would simply sum up the inputs shares sent by clients with that agent type. (One only needs to take care that this doesn't reduce the anonymity set further than the threshold specified by the collector: see https://github.com/abetterinternet/prio-documents/issues/15.) Versioning is also pretty straightforward, since each input is labeled separately.\r\n\r\nAs you correctly point out, the main limitation of Prio is that you need to know in advance what sorts of statistics you want to compute over measurements. This is because the client needs to know beforehand how to encode and generate a proof for each input. However, inputs can be encoded in a way that allows for multiple statistics to be computed about the same set of measurements. For example, if we're already computing the mean over a set of measurements, then it's fairly cheap to add the standard deviation. We could also throw in other statistics, like median, min, or max, but we need to be careful because some statistics have a higher communication cost than others.\r\n\r\n**Minimize overhead.** The main downside to the above approach is that it usually won't provide optimal time complexity or communication overhead. The reason, basically, is that by handling all of the inputs \"monolithically\", we can take advantage of redundancy in the structure of the input in order to construct a more efficient proof system. In particular, the JSON becomes simply\r\n```\r\n     \"scalars\": {\r\n           \"proof share\": <share of proof>, \r\n           \"input share\": <share of input>\r\n      }\r\n```\r\nand there are procedures for encoding and decoding this \"monolithic input\" as measurements `contentblocking.trackers_blocked_count`, `media.element_in_page_count`, and so on.\r\n\r\nHere, the length of the input share is about the same as the sum of the lengths of the input shares above; however, it is often possible to reduce the size of the proof share significantly compared to the proof shares above. In more detail, the main way we optimize the proof size is by being creative in how we apply Theorem 4.3 of [[BBG+19]](https://eprint.iacr.org/2019/188.pdf). The proof size is linear in the number of \"G-gate\" evaluations in the validity circuit that recognizes valid inputs. If there is lots of redundancy in the validity circuit, then we can make G \"big\", thereby reducing the number evaluations of G and shortening the proof.\r\n\r\nSo what's the downside of the \"monolithic input\" approach? In terms of flexibility, it's still possible to do things like aggregate measurements based on agent type, Beta/Release, etc. However, versioning becomes much more difficult: if we want to change the set of measurements that are encoded by the input, then we would need to change the way we construct the proof system. This isn't so bad if the client and aggregators are running the same code (there are lots of situations in which this is feasible), but if they are running different code, then coordinating this will be significant.\r\n\r\n**So, what do we do?** The best solution for a given deployment is going to lie somewhere in the middle of these two extremes. I think it should be a goal of ours to design the protocol in a way that allows deployments to make different trade-offs between flexibility and efficiency. Regardless of what trade-off a particular deployment makes, what is needed is a way of annotating inputs in a way that ensures clients and aggregators know how to generate and verify them. We also need a way of failing gracefully if an aggregator doesn't know how to verify an input.\r\n\r\nThat said, it's important to note that this problem isn't knew. It's somewhat akin to assigning code points to DH groups in TLS, in the sense that the code point prescribes the code that is going to be run by the parties.",
          "createdAt": "2021-04-02T22:52:53Z",
          "updatedAt": "2021-04-02T22:59:47Z"
        },
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "@ekr, I wanted to follow up on the performance benefits of stuffing many measurements into the same proof. If we know in advance that clients will submit many measurements of the same type, then it's possible to construct a proof that is much smaller than the sum of the sizes of proofs for the individual measurements. The following PR for libprio-rs demonstrates this for vectors of booleans:\r\nhttps://github.com/abetterinternet/libprio-rs/pull/30\r\n\r\nThe table compares the proof size of \"Prio v2\", the current proof system for boolean vectors, to \"PolyCheckedVector\", the proof system that the PR implements. Prio v2 constructs an `O(n)` sized proof, where `n` is the number of booleans. In terms of communication overhead, this is no better than constructing a constant-sized proof for each bit individually. ~PolyCheckedVector constructs a proof of size `O(sqrt(n))`.~ UPDATE: There should be a way to get this down to `O(sqrt(n))`: see https://github.com/abetterinternet/libprio-rs/issues/35.\r\n\r\nThe same optimization is possible for a vector of integers, so long as each of the integers has the same range of valid values. In fact, this optimization can be applied regardless of the set of aggregates we want for each integer, so long as as the set is the same for each aggregator.\r\n\r\nThis optimization won't make sense everywhere, of course, but one instance in which I can imagine using it is when clients report several counts or timings that have the same expected range.\r\n",
          "createdAt": "2021-04-14T23:47:31Z",
          "updatedAt": "2021-04-22T02:31:39Z"
        }
      ]
    },
    {
      "number": 30,
      "id": "MDU6SXNzdWU4NjQxMTM3MTQ=",
      "title": "Message encoding",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/issues/30",
      "state": "CLOSED",
      "author": "chris-wood",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "We should specify structure and syntax for messages exchange in the protocol, e.g., data/proof shares. We'll pass these around with high-level HTTP APIs, maybe carried in JSON messages or whatever. ",
      "createdAt": "2021-04-21T17:29:47Z",
      "updatedAt": "2021-06-09T22:56:38Z",
      "closedAt": "2021-06-09T22:56:38Z",
      "comments": [
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "+1 to JSON blobs, as long as input shares can be encoded in binary. Seems to be the simplest to implement in JS.",
          "createdAt": "2021-04-21T18:15:09Z",
          "updatedAt": "2021-04-21T18:15:09Z"
        },
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "I guess I don't much care if we need to encode input shares in base64 or whatever.",
          "createdAt": "2021-04-21T18:22:41Z",
          "updatedAt": "2021-04-21T18:22:41Z"
        },
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "With #43 we are now using a binary format, specifically TLS syntax. Does anyone have any objections to continuing to use it?",
          "createdAt": "2021-06-09T19:18:20Z",
          "updatedAt": "2021-06-09T19:18:20Z"
        },
        {
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "body": "None -- let's just stick with TLS. :-) ",
          "createdAt": "2021-06-09T22:56:38Z",
          "updatedAt": "2021-06-09T22:56:38Z"
        }
      ]
    },
    {
      "number": 32,
      "id": "MDU6SXNzdWU4NjY0MjU2MTg=",
      "title": "Update field section criteria for Prio",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/issues/32",
      "state": "CLOSED",
      "author": "cjpatton",
      "authorAssociation": "COLLABORATOR",
      "assignees": [
        "cjpatton"
      ],
      "labels": [
        "parking-lot"
      ],
      "body": "The current criteria:\r\n\r\n> 1. **Field size.** How big the field needs to be depends on the type of data\r\n>    being aggregated and how many users there are. The field size also impacts\r\n>    the security level: the longer the validity circuit, the larger the field\r\n>    needs to be in order to effectively detect malicious clients. Typically the \r\n>    soundness error (i.e., the probability of an invalid input being deemed valid\r\n>    by the aggregators) will be 2n/(p-n), where n is the size of the input and p\r\n>    is the prime modulus.\r\n> 2. **Fast polynomial operations.** In order to make Prio practical, it's\r\n>    important that implementations employ FFT to speed up polynomial operations.\r\n>    In particular, the prime modulus p should be chosen so that (p-1) = 2^b * s \r\n>    for large b and odd s. Then g^s is a principle, 2^b-th root of unity (i.e.,\r\n>    g^(s\\*2^b) = 1), where g is the generator of the multiplicative subgroup.\r\n>    This fact allows us to quickly evaluate and interpolate polynomials at 2^a-th\r\n>    roots of unity for 1 <= a <= b.\r\n> 3. **Highly composite subgroup.** Suppose that (p-1) = 2^b * s. It's best if s\r\n>    is highly composite because this minimizes the number of multiplications\r\n>    required to compute the inverse or apply Fermat's Little Theorem. (See\r\n>    [BBG+19, Section 5.2].)\r\n> 4. **Code optimization.** [[TODO: What properties of the field make\r\n>    it possible to write faster implementations?]]\r\n\r\nCriterion (3) doesn't seem that important to me any more. I've yet to think of a use case where we want to do inversion in a validity circuit, or for which we don't have an alternative to FLT. In any case, we already can get pretty good performance with a more standard, generic algorithm: https://github.com/abetterinternet/libprio-rs/blob/main/src/fp.rs#L156-L167\r\n\r\nIn addition to dropping (3), we should modify (2) by saying that `2^b` needs to be large enough to accommodate the largest proofs we would ever generate. `b=20` seems like a reasonable minimum.\r\n\r\nFinally, an important criterion to add would be to pick a field size that is as close as possible to a power of 2 without being larger. This helps to minimize the cost of rejection sampling when generating random field elements (see #14).",
      "createdAt": "2021-04-23T20:54:38Z",
      "updatedAt": "2021-10-08T18:00:20Z",
      "closedAt": "2021-10-08T18:00:20Z",
      "comments": [
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "Closing this since it's no longer relevant to this document. (It will be relevant to https://github.com/cjpatton/vdaf, however.)",
          "createdAt": "2021-10-08T18:00:18Z",
          "updatedAt": "2021-10-08T18:00:18Z"
        }
      ]
    },
    {
      "number": 39,
      "id": "MDU6SXNzdWU4NzUwMjAwMDU=",
      "title": "Which LICENSE is right?",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/issues/39",
      "state": "CLOSED",
      "author": "martinthomson",
      "authorAssociation": "CONTRIBUTOR",
      "assignees": [],
      "labels": [],
      "body": "LICENSE (CC) or LICENSE.md ?",
      "createdAt": "2021-05-04T01:01:40Z",
      "updatedAt": "2021-05-04T01:43:31Z",
      "closedAt": "2021-05-04T01:08:53Z",
      "comments": [
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "https://github.com/abetterinternet/prio-documents/blob/main/LICENSE",
          "createdAt": "2021-05-04T01:04:15Z",
          "updatedAt": "2021-05-04T01:04:15Z"
        },
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "Thanks for flagging! I just pushed a fix.",
          "createdAt": "2021-05-04T01:06:22Z",
          "updatedAt": "2021-05-04T01:06:22Z"
        },
        {
          "author": "ekr",
          "authorAssociation": "COLLABORATOR",
          "body": "I think we may actually want something more like CC(0). If we submit to IETF we don't want to carry this copyright notice around.",
          "createdAt": "2021-05-04T01:43:31Z",
          "updatedAt": "2021-05-04T01:43:31Z"
        }
      ]
    },
    {
      "number": 41,
      "id": "MDU6SXNzdWU4NzUwMjE1MTU=",
      "title": "Maybe reconsider the draft name",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/issues/41",
      "state": "CLOSED",
      "author": "martinthomson",
      "authorAssociation": "CONTRIBUTOR",
      "assignees": [],
      "labels": [],
      "body": "The template things that this is for the \"core\" working group:\r\n\r\n> Discussion of this document takes place on the Constrained RESTful Environments Working Group mailing list (core@ietf.org), which is archived at https://mailarchive.ietf.org/arch/browse/core/.\r\n\r\nThat's probably not what you wanted.",
      "createdAt": "2021-05-04T01:06:11Z",
      "updatedAt": "2021-05-21T16:17:08Z",
      "closedAt": "2021-05-21T16:16:47Z",
      "comments": [
        {
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "body": "Good catch, thank you @martinthomson!",
          "createdAt": "2021-05-21T16:17:08Z",
          "updatedAt": "2021-05-21T16:17:08Z"
        }
      ]
    },
    {
      "number": 44,
      "id": "MDU6SXNzdWU4NzkyNzA1ODk=",
      "title": "Possible performance impact of decoupled verify / collect stages with heavy hitters",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/issues/44",
      "state": "CLOSED",
      "author": "csharrison",
      "authorAssociation": "CONTRIBUTOR",
      "assignees": [],
      "labels": [],
      "body": "(moving a comment made in https://github.com/abetterinternet/prio-documents/pull/43 to an issue)\r\nI have a high level concern with the architecture here, following up from our meeting on Wednesday related to heavy hitters.\r\n\r\n**TL;DR evaluating a hierarchy at only a subset of levels (which are specified at query time) is not optimal for performance if the verification step does not have access to those specified levels.**\r\n\r\nFor heavy hitters, we are considering a model where records form a binary tree, where aggregates can be reported at different levels of the tree. There are a few possible ways this could go:\r\n\r\n 1. For every record, verify and evaluate the entire binary tree (i.e. bit-by-bit evaluation)\r\n 2. For every record, verify and evaluate only a subset of the tree (at the limit, this can look more like Prio which only evaluates the last level of the tree)\r\n    2a. The subset of the tree to evaluate is configured within a particular record at record-creation time\r\n    2b. The subset of the tree to evaluate is configured dynamically at collection / aggregation time\r\n\r\nFor our use-case (discussed in #18 (comment)), we are interested in (2b), for a few reasons:\r\n\r\n(1) is potentially inefficient from both a performance and accuracy POV in that it requires more rounds, and additionally when used with differential privacy requires splitting a DP budget across all levels. Some prefixes might just not be interesting to the caller so we shouldn't waste privacy budget / compute on them.\r\n\r\n(2a) is problematic in two dimensions.\r\n-  Embedding configuration in records may compromise user privacy if the configurations can be set by an adversary colluding with one of the aggregators (e.g. you can leak log2(n choose k) bits of information if you allow any subset of k prefixes for an n-bit domain).\r\n- Levels must be pre-specified at record-creation time, which is non-ideal if new information comes up at collection time which informs how aggregation should work (e.g. realizing you have fewer records than expected so it is better to focus on querying only up to a given prefix).\r\n\r\nHowever, I think (2b) runs into a few issues with this architecture that separates verification from collection, in that without knowing the specific levels to evaluate, we run the risk of spending unnecessary compute verifying levels that will never end up being used. The protocol is more efficient (less computation, fewer rounds) if we can verify multiple levels at once (i.e. the levels the collector cares about).\r\n\r\nPossible solutions:\r\n\r\n1. Add a step where the collector and leader communicate prior to verification (but keep verification and collection separate)\r\n2. More tightly couple \"verify\" and \"collect\" stages, so that verification can be done based on communication with the collector.\r\n3. \r\nIn our setting, the \"leader\" and \"collector\" roles are somewhat merged which aligns with option (1), but it seems like a good idea to make the general architecture robust to this use-case.\r\n\r\ncc @schoppmp who is working on our C++ implementation of IDPFs.\r\n",
      "createdAt": "2021-05-07T16:01:38Z",
      "updatedAt": "2021-07-07T21:27:20Z",
      "closedAt": "2021-07-07T21:27:20Z",
      "comments": [
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "Thanks for the feedback @csharrison! I've finally had a chance today to dig into the heavy hitters paper. I agree that the framework described in #43 isn't going to be feasible for heavy hitters. I think your option (2b) is the only way to go, as I explain below.\r\n\r\nFor context, #43 thinks of PA (\"Private Aggregation\") protocols as having three distinct \"phases\": \r\n* **Upload**: Each client uploads its input shares to the aggregators.\r\n* **Verify**: The aggregators verify each client's input.\r\n* **Collect**: Each aggregators add up their verified input shares and emits its output share to the collector.\r\n\r\nIn order to fit heavy hitters into his framework, we could take your option (1) or (2a). However, these options are only  feasible for very small inputs, say, `N=16`, where `N` is the length of each client input in bits. In order to make the protocol feasible for large inputs, heavy hitters involves multiple rounds of the Verify/Collect phases, where the output of the previous Collect phase is used to decide what to do in the next Verify phase. So that we're all on the same page about why interaction is necessary, I've included a brief overview of the protocol below [1]. (Please correct me if I've misunderstood anything!)\r\n\r\nAccounting for this interaction in the protocol spec should be fairly straightforward. The delta, I think, is that there needs to be a way to re-run the Verify/Collect phases on the same inputs, but using different parameters each time, i.e., with different sets of prefixes specified by the collector.\r\n\r\n___\r\n[1] Here's a bird's eye view of the protocol, as I understand it. (I'm ignoring DP for now.) First, (**Upload**) each client generates IDPF shares of its `N`-bit input and sends a share to each aggregator. After all clients have uploaded their IDPF key shares, the collector and aggregators verify and collect the heavy hitters as follows. Let `S(1) = {0,1}`. For each `L=1, ..., N`:\r\n1. (**Verify**) For each client upload:\r\n  a. For each prefix `p` in `S(L)`, each aggregator evaluates its IDPF share on input of `p`.\r\n  b. The aggregators verify (in zero-knowledge) that their IDPF outputs are well-formed, i.e., that only one of the outputs is `1` and the rest are `0`.\r\n2. (**Collect**) \r\n  a. For each verified IDPF output, each aggregator adds up its shares and sends the resulting \"histogram share\" to the collector.\r\n  b. The collector adds the histogram shares together to get the histogram. This encodes the frequency of each prefix `p` in `S(L)` among the client inputs.\r\n  c. The collector assembles `S(L+1)`, the next set of candidate prefixes. To do so, it collects the set `M` of prefixes that appear at least `t` times in the histogram. It lets `S(L+1)` be the set of strings obtained by appending `1` or `0` to each element of `M`.\r\n  d. Finally, the collector  disseminates `S(L+1)` among the aggregators.\r\n\r\nWhat makes this feasible is that the size of each `S(L)` is at most the number of clients divided `t`. \r\n\r\n\r\n\r\n\r\n",
          "createdAt": "2021-05-09T00:47:57Z",
          "updatedAt": "2021-05-09T00:47:57Z"
        },
        {
          "author": "csharrison",
          "authorAssociation": "CONTRIBUTOR",
          "body": "@cjpatton this sounds about right to me. Just a small nit but I wanted to point out that your (Collect) stage, multiple interactions with the collector are not strictly necessary. What you described is a zero-knowledge protocol but alternatively the aggregators could interact to learn the aggregates at each level and proceed down without interaction with the collector.\r\n\r\nWe discussed this variant a few weeks ago, it trades off aggregator knowledge with protocol simplicity (e.g. collectors don't need to follow an interactive protocol).",
          "createdAt": "2021-05-10T22:08:34Z",
          "updatedAt": "2021-05-10T22:08:34Z"
        },
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "> @cjpatton this sounds about right to me. Just a small nit but I wanted to point out that your (Collect) stage, multiple interactions with the collector are not strictly necessary. What you described is a zero-knowledge protocol but alternatively the aggregators could interact to learn the aggregates at each level and proceed down without interaction with the collector.\r\n\r\nLet me see if I understand you correctly. Concretely, the helper would send the leader its share of the aggregate at the end of each round. Next, the leader would use the aggregate shares to compute the next set of prefixes, then  send this to the helper for the next round.\r\n\r\nIf my understanding is right, then it seems to me that this is the same protocol as [1], but with leader == collector. What do you think?\r\n\r\n> We discussed this variant a few weeks ago, it trades off aggregator knowledge with protocol simplicity (e.g. collectors don't need to follow an interactive protocol).\r\n\r\nMaybe I'm missing something. I'll do my best to read the design doc you shared by the end of the week.\r\n\r\n",
          "createdAt": "2021-05-11T15:07:06Z",
          "updatedAt": "2021-05-11T15:07:06Z"
        },
        {
          "author": "csharrison",
          "authorAssociation": "CONTRIBUTOR",
          "body": "> If my understanding is right, then it seems to me that this is the same protocol as [1], but with leader == collector. What do you think?\r\n\r\nYes that's right. I was outlining a \"simpler\" communication model where helpers communicated directly with each other but  in this architecture it would go through the leader.",
          "createdAt": "2021-05-12T16:47:31Z",
          "updatedAt": "2021-05-12T16:47:31Z"
        }
      ]
    },
    {
      "number": 45,
      "id": "MDU6SXNzdWU4ODQ5NjUwNjM=",
      "title": "Mode to make proof optional ",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/issues/45",
      "state": "CLOSED",
      "author": "siyengar",
      "authorAssociation": "NONE",
      "assignees": [],
      "labels": [
        "parking-lot"
      ],
      "body": "Some applications might not need as much protection against malicious users and might be okay with a malicious user changing the values by a larger amount.  They might be using Prio purely for privacy and might have other ways to guard against malicious inputs, for example by verify the user account or by attesting the application. \r\nIt might be useful for the Validity proof to be optional depending on the application. This would reduce overheads perhaps of  communication between servers to validate the proofs and also in communication of the proofs from the client -> server.  \r\n\r\nThese applications could still benefit from:\r\n1. the multi-server deployment model\r\n2. AFE encoding specifications",
      "createdAt": "2021-05-10T19:44:28Z",
      "updatedAt": "2022-03-15T18:51:10Z",
      "closedAt": "2022-03-15T18:51:10Z",
      "comments": [
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "This seems reasonable to me. Right now we have several pending design decisions floating around, so I'd like to suggest we wait on text until more of the protocol is settled.",
          "createdAt": "2021-05-11T15:09:49Z",
          "updatedAt": "2021-05-11T15:09:49Z"
        },
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "2021/6/16 design call: Something to note here: if we have have a bit in the PA parameters that disables verification, we'll need to make sure this bit is explicitly authenticated.",
          "createdAt": "2021-06-16T17:20:32Z",
          "updatedAt": "2021-06-16T17:41:33Z"
        },
        {
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "body": "@cjpatton can we close this out and track under the VDAF draft? In particular, Prio without verification can just be a different VDAF from the perspective of PPM. I don't think anything else really needs to change.",
          "createdAt": "2022-03-15T18:31:47Z",
          "updatedAt": "2022-03-15T18:31:47Z"
        },
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "Sounds good to me. Here is the issue for reference: https://github.com/cjpatton/vdaf/issues/20",
          "createdAt": "2022-03-15T18:51:10Z",
          "updatedAt": "2022-03-15T18:51:10Z"
        }
      ]
    },
    {
      "number": 48,
      "id": "MDU6SXNzdWU5MTA2OTc4NDI=",
      "title": "Consider making Upload Start an idempotent GET",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/issues/48",
      "state": "CLOSED",
      "author": "tgeoghegan",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "Per #43, the first step in the upload protocol is a POST to the leader server which returns information about helpers. In some yet to be specified cases, the response could include a challenge to be incorporated into reports. However I suspect that in most cases, the response will be static and so an idempotent, cacheable GET would be a better fit, especially since it would save clients a roundtrip to the helper on the hot path of submitting reports, and would make it possible for helpers to implement upload_start by putting some static content in a CDN.\r\n\r\nHTTP GET requests don't have bodies, so we would have to figure out how to encode all the data in the current `PAUploadStartReq` into the `upload_start` URI, which could be done as either path fragments in the URI (i.e., `[leader]/upload_start/[task.version]/[task.id]`) or as query parameters (i.e., `[leader]/upload_start?version=[task.version];id=[task.id]`).\r\n\r\nWe would of course need to make sure that [the semantics of HTTP GET](https://developer.mozilla.org/en-US/docs/Web/HTTP/Methods/GET) don't preclude proof systems like the one alleged to exist in section 5.2 of \"BBCp19\".",
      "createdAt": "2021-06-03T17:14:10Z",
      "updatedAt": "2021-07-14T20:35:34Z",
      "closedAt": "2021-07-14T20:35:34Z",
      "comments": [
        {
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "body": "Also, because the current protocol uses a POST for upload_start, the implication is that for every report they submit, clients need to hit `upload_start` and then `upload_finish`. If we make `upload_start` idempotent and cacheable, then that request can be skipped in the majority of cases. I suppose the significance of this depends on how we expect clients to use PDA: are they going to be continuously streaming hundreds or thousands of reports into the leader as events of interest occur (in which case I think eliminating `upload_start` requests is interesting) or are they expected to accumulate several reports locally before submitting them all in one or a few requests?",
          "createdAt": "2021-06-03T17:29:23Z",
          "updatedAt": "2021-06-03T17:29:23Z"
        },
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "I agree this would be a good change, if we can swing it. It's notable that Prio v2 and HH don't require a random challenge from the leader. But as discussed, this is useful for other proof systems one might want to implement for Prio. For example, see the data type implemented here: https://github.com/abetterinternet/libprio-rs/pull/48. See below for an explanation.\r\n\r\nThere might be other ways to implement the challenge.\r\n* One possibility is to derive the challenge from the TLS key schedule (or from whatever state the client and leader share for the secure channel). @ekr and @tgeoghegan  have both pointed out that adding this dependency on the underlying transport is problematic.\r\n* Another possibility might be to use some external source of randomness that the leader trusts. [DRAND](https://drand.love/) comes to mind, though it is somewhat problematic because clients would effectively use the same randomness for some period of time. The security model of BBCp19 would need to be extended to account for this. (I believe this could be done.)\r\n* Some other solution I'm missing?\r\n\r\n____\r\nThis data type is used to compute the mean and variance of each integer in a sequence of integers. To do so, the client encodes each integer `x` of its input vector as a pair `(x_vec, xx)`, where `x_vec` is the representation of `x` as a bit vector and `xx` is equal to `x^2`. To prove validity of its input, the proof needs to do two things: verify that (a) `x_vec` is indeed a bit vector, and (b) the integer encoded by `x_vec` is the square root of `xx`.\r\n\r\nIn order to check these things efficiently, the proof system uses a random challenge generated by the leader. At a very high level, the client wants to prove that the following boolean conjunction holds: `x_vec[0]` is 1 or 0 *AND* `x_vec[1]` is 1 or 0 *AND* ... *AND* `x_vec` encodes the square root of `xx`. In Prio, we need to represent this conjunction as an arithmetic circuit, which the random challenge helps us do.\r\n\r\nIn a bit more detail now: Let's rewrite this expression as w[0] *AND* w[1] *AND* ... *AND* w[s]. As an arithmetic circuit, this expression is actually `v[0] + v[1] + ... + v[s]`, where `v[i] == 0` if and only if w[i] is true. If the input is valid, then the expression should evaluate to `0`. But because we're talking about field elements, a malicious client may try to play games like setting `v[i] = 2` and `v[j] = -2` so that the sum is still `0`, but the statement is false. To detect this, we actually compute the following expression: `v[0] * r + v[1] * r^2 + ... v[s] * r^(s+1)`, where `r` is a randomly chosen field element. If the statement is true, then the expression evaluates to `0`. If the statement is false, then with high probability, the expression will evaluate to something other than `0`. (This idea comes from Theorem 5.3)",
          "createdAt": "2021-06-09T17:38:15Z",
          "updatedAt": "2021-06-09T17:38:15Z"
        },
        {
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "body": "Thank you for the detailed explanalation @cjpatton! Having thought about it more, I suspect an HTTP GET wouldn't be the right way to support proof systems that need a challenge. Assuming that a unique challenge is needed for every report[^1], then intuitively the leader would have to maintain a mapping of reports to issued challenges so that the leader and helper(s) can later use the challenge value when evaluating the client's proof.\r\n\r\nBut now that the leader has to maintain state per-report, I think the upload protocol is missing a notion of a report identifier. The `PAUploadStartReq` contains a `PATask`, but IIUC the `PATask` will be the same across many reports[^2] (e.g., if a browser is sending daily reports on how often users click a button, they use the same `PATask` every time they submit). So `PAUploadStartResp` needs to include a report ID, which must be echoed back to the leader in `PAUploadFinishReq` so that the leader can look up the challenge for the report. \r\n\r\n[^1] Is this true? Or would it suffice for each `PATask` to use the same challenge across multiple reports?\r\n[^2] I notice that the design doc lacks a strong definition of a report and how it relates to tasks, inputs, measurements: #53\r\n because GET should be \"safe\" in the sense of not changing any server state, and it seems like the server would have to maintain a mapping of reports to issued challenges so that the leader and helper can later use the challenge value when evaluating the client's proof.",
          "createdAt": "2021-06-09T19:16:23Z",
          "updatedAt": "2021-06-09T19:16:23Z"
        },
        {
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "body": "Continuing on the assumption that `upload_start` causes a state change on the leader, POST is then the appropriate HTTP method to use. [Mozilla sez POST is cacheable](https://developer.mozilla.org/en-US/docs/Web/HTTP/Methods/POST), though it's a little unusual. There may be some big drawback to cacheable POST responses, but I think that might let us support proof systems that require live challenges while also eliminating the majority of `upload_start` requests when the proof system is such that the `PAUploadStartResp` will change very rarely.",
          "createdAt": "2021-06-09T19:20:01Z",
          "updatedAt": "2021-06-09T19:20:01Z"
        },
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "> But now that the leader has to maintain state per-report, I think the upload protocol is missing a notion of a report identifier. The `PAUploadStartReq` contains a `PATask`, but IIUC the `PATask` will be the same across many reports[^2] (e.g., if a browser is sending daily reports on how often users click a button, they use the same `PATask` every time they submit). So `PAUploadStartResp` needs to include a report ID, which must be echoed back to the leader in `PAUploadFinishReq` so that the leader can look up the challenge for the report.\r\n\r\nThe requirement for the leader to keep state across upload start and upload finish may be avoidable. Suppose the leader has a long-lived PRF key K. It would could choose a random nonce N, compute R = PRF(K, N) as the challenge, and hand (N, R) to the client in its upload start response. The client would then use R to generate the proof and send N to the leader in its upload finish request. The leader could then re-derive R.\r\n\r\n@chris-wood and I kicked around the idea of having the client generate a report ID. I think this may end up being useful, but we weren't sure if it was better to have the leader choose it or the client.\r\n\r\n> [^1] Is this true? Or would it suffice for each `PATask` to use the same challenge across multiple reports?\r\n\r\nTo conform to the security model of BBCp19, each report would need its own challenge. It may be possible to relax this, but this would be risky.",
          "createdAt": "2021-06-09T19:59:59Z",
          "updatedAt": "2021-06-09T19:59:59Z"
        },
        {
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "body": "> The requirement for the leader to keep state across upload start and upload finish may be avoidable. Suppose the leader has a long-lived PRF key K. It would could choose a random nonce N, compute R = PRF(K, N) as the challenge, and hand (N, R) to the client in its upload start response. The client would then use R to generate the proof and send N to the leader in its upload finish request. The leader could then re-derive R.\r\n\r\nI like this a lot! I'm a big fan of deterministic derivation schemes like this -- besides reintroducing the possibility of an idempotent GET, eliminating storage requirements for challenges makes it much easier to scale up leaders. If the report IDs are big enough (UUIDs?) we could even use them as `N`.\r\n\r\n> @chris-wood and I kicked around the idea of having the client generate a report ID. I think this may end up being useful, but we weren't sure if it was better to have the leader choose it or the client.\r\n\r\nI would say the leader, because if you let the client do it, then the leader would have to check for things like collisions with existing report IDs or other malicious ID choices. If the leader chooses it, then all it has to do is generate a few bytes of randomness.\r\n\r\n> > [^1] Is this true? Or would it suffice for each `PATask` to use the same challenge across multiple reports?\r\n> \r\n> To conform to the security model of BBCp19, each report would need its own challenge. It may be possible to relax this, but this would be risky.\r\n\r\nI agree.",
          "createdAt": "2021-06-09T22:36:37Z",
          "updatedAt": "2021-06-09T22:36:37Z"
        },
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "@henrycg, we'd appreciate your feedback on this issue because it involves security considerations for ZKP systems on secret-shared data [1]. I'll quickly sum up the problem so that you don't need to worry about the conversation above.\r\n\r\nThe problem at hand regards systems like [1, Theorem 5.3] that require interaction between the prover and verifier. Specifically, we're considering a special case of Theorem 5.3 in which the verifier sends the prover a random \"challenge\" `R` that is used to generate and verify a (non-interactive) FLPCP (call it `P`):\r\n```\r\n                    Prover                               Verifier\r\n                        | (upload start)                  |\r\n                        |-------------------------------> |  Generate R\r\n                        |                      R          |\r\n                        | <------------------------------ |\r\n                        | (upload finish)      P          |\r\n             Generate P |-------------------------------> |  Verify P\r\n             (using R)  |                                 |  (using R)\r\n                        V                                 V\r\n```\r\nWe refer to the prover's first and second messages as \"upload start\" and \"upload finish\" respectively. Each message corresponds to an HTTP request made by a web client to a web server. Ideally, the verifier would be able to handle these requests *statelessly*, i.e., without having to store `R`.\r\n\r\nConsider the following change. Suppose the verifier has a long-term PRF key `K`. In response to an upload start request, it chooses a unique \"upload id\" `N` --- maybe this is a 16-byte integer chosen at random --- and computes `R = PRF(K, N)` and sends `(R, N)` to the prover. In the upload finish request, the prover sends `N` so that the verifier can re-derive `R` instead of needing to remember it:\r\n```\r\n                    Prover                               Verifier^K\r\n                        | (upload start)                  |\r\n                        |-------------------------------> |  Generate N\r\n                        |                     (R, N)      |  Compute R = PRF(K, N)\r\n                        | <------------------------------ |\r\n                        | (upload finish)     (P, N)      |\r\n             Generate P |-------------------------------> |  Verify P\r\n             (using R)  |                                 |  (using R = PRF(K, N))\r\n                        V                                 V\r\n```\r\nThe (potential) problem with this variant is that a malicious client is able to replay a challenge as many times as it wants. This behavior isn't accounted for in Definition 3.9, so when you try to \"compile\" this system into a ZKP on secret-shared data as described in Section 6.2 and consider its security with respect to Definition 6.4 (Setting I), you can no longer appeal to Theorem 6.6 to reason about its security.\r\n\r\nOur question is therefore: **What impact do you expect this change to have on the soundness of the system?** Can you think of an attack that exploits the fact that challenges can be replayed? My expectation is that the problem is merely theoretical, i.e., we ought to be able to close the gap with an appropriate refinement of Definition of 3.9 and reproving Theorem 5.3.\r\n\r\n[1] https://eprint.iacr.org/2019/188\r\n",
          "createdAt": "2021-06-18T00:11:18Z",
          "updatedAt": "2021-06-18T17:59:55Z"
        },
        {
          "author": "henrycg",
          "authorAssociation": "COLLABORATOR",
          "body": "Thanks for looping me in. In the discussion below, I am assuming that the client sends its data vector (called \"x\" in the paper [1]) at the same time as it sends its proof to the verifier. Even if the client sends its data vector in the first message, it seems that the client can reuse an (R,N) pair from upload request 1  to later submit upload request 2, in which case the client sees (R, N) before it chooses its data vector and proof. So I think we can assume that the client's data vector and proof can depend on the verifier's random value R. (I'll call this value \"r\" to match the paper.)\r\n\r\nFor soundness: the client/prover must commit to its data vector _before_ it learns the verifier's random value r. If the prover can choose its data value and proof in a way that depends on the verifier's randomness r, the soundness guarantee no longer holds. There is also an efficient attack. So I suspect that the stateless-verifier optimization is unsound.\r\n\r\nThe attack works as follows: given r, the verifier finds a non-satisfying vector x such that \\sum_i r_i C(A_i(x)) = 0, again using the notation from Theorem 5.3 in the paper [1]. For the circuits C used in most applications, it will be easy to find such a vector x. Then, the prover constructs a proof that x that  \\sum_i r_i C(A_i(x)) = 0. The proof is valid, so the verifier will accept always.\r\n\r\n\r\nTo remove interaction, the Fiat-Shamir-like technique in Section 6.2.3 is probably the best way to go. We only sketched the idea in the paper (without formal analysis or proof) but if it's going to be important for your application, I'm happy to sanity-check the protocol you come up with.\r\n\r\nAnother idea\u2014the details of which I have not checked carefully\u2014would be to modify your protocol as follows:\r\n\r\n1. The prover sends its data vector x to verifiers, split into k shares x_1, ..., x_k\u2014one for each of the k verifiers.\r\n2. Each verifier holds a PRF key k_i computes r_i = PRF(k_i, x_i) and they return r = r_1 + ... + r_k to the prover. The verifiers store no state.\r\n3. The prover computes the proof \\pi and sends (x_1, \\pi_1), ..., (x_k, \\pi_k) to the verifiers\u2014again, one for each of the k verifiers. Each verifier computes r_i = PRF(k_i, x_i), they jointly compute r = r_1 + ... + r_k, and check the proof using randomness r.\r\n\r\nThe Fiat-Shamir-like approach seems slightly cleaner to me, since it only requires a single prover-to-verifier message.\r\n\r\nEither way, please let me know if I misunderstood your question or if anything else here is unclear.\r\n\r\n[1] https://eprint.iacr.org/2019/188",
          "createdAt": "2021-06-18T20:28:39Z",
          "updatedAt": "2021-06-18T20:28:39Z"
        },
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "Thanks for the nice explanation, Henry. It's perfectly clear and answers my question. It also points to something that I, for one, missed the importance of: the need for the prover to \"commit\" to the input shares before generating the r-dependent proof. I appreciate you pointing this out.\r\n\r\nThe only requirement for making upload start not idempotent is so that the randomness r can be sent to the client. It would be nice to do away with this requirement. I think the way forward is using the Fiat-Shamir technique. @henrycg, I'll get cracking on this and let you know when I have something for you to look at.",
          "createdAt": "2021-06-18T21:15:19Z",
          "updatedAt": "2021-06-18T21:15:19Z"
        },
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "@henrycg, I believe the change is something like this. Let `H` be a hash function with range `\\bits^h`. Suppose there are `k` verifiers. The prover proceeds as follows:\r\n- Splits its inputs `x` into shares `x_1, ..., x_k`.\r\n- For each `i \\in \\{1, ..., k\\}`, do:\r\n  - Choose blinding factor `V_i` from `\\bits^h` at random.\r\n  - Let `R_i \\gets H(i, x_i, V_i)`.\r\n- Set `R \\gets R_1 \\xor ... \\xor R_k`.\r\n- Derive field element `r` from `R` (e.g., seed a PRNG with `R` and map the output to a field element by rejection sampling on chunks of the output).\r\n- Generate the proof `\\pi` using `x` and `r`.\r\n- Split `\\pi` into shares `\\pi_1, ..., \\pi_k`.\r\n- For each `i \\in \\[1, ..., k\\}` send `(x_i, \\pi_i, V_i)` to the `i`-th verifier.",
          "createdAt": "2021-06-21T16:58:13Z",
          "updatedAt": "2021-06-21T16:58:13Z"
        },
        {
          "author": "henrycg",
          "authorAssociation": "COLLABORATOR",
          "body": "Yes, this looks right to me!",
          "createdAt": "2021-06-21T20:23:30Z",
          "updatedAt": "2021-06-21T20:23:30Z"
        },
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "As of https://github.com/abetterinternet/prio-documents/pull/79, the upload start request no longer exists. When we're ready to specify Prio, we'll want to include the Fiat-Shamir approach for protocols that use joint randomness. I've noted this and am closing the issue.",
          "createdAt": "2021-07-14T20:35:34Z",
          "updatedAt": "2021-07-14T20:35:34Z"
        }
      ]
    },
    {
      "number": 49,
      "id": "MDU6SXNzdWU5MTA3MDE5MzQ=",
      "title": "Rotation of HPKE keys for encrypting helper shares",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/issues/49",
      "state": "CLOSED",
      "author": "tgeoghegan",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "#43 includes a detailed specification of how helpers advertise HPKE configs for clients to use when encrypting helper shares. We should consider how key rotation works.",
      "createdAt": "2021-06-03T17:18:30Z",
      "updatedAt": "2021-07-14T19:28:01Z",
      "closedAt": "2021-07-14T19:28:01Z",
      "comments": [
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "Might this just be deployment specific, or should all helpers do the same thing?\r\n\r\nWhat we (i.e., Cloudflare) do for [the ECH extension for TLS](https://datatracker.ietf.org/doc/html/draft-ietf-tls-esni-10) is rotate the HPKE config every hour. To add reliability in case a client has an old key, we keep around a rotating set of keys from the last hour or so. The config id is used to determine which key was used to encrypt the payload.",
          "createdAt": "2021-06-09T17:44:09Z",
          "updatedAt": "2021-06-09T17:53:00Z"
        },
        {
          "author": "ekr",
          "authorAssociation": "COLLABORATOR",
          "body": "This seems deployment specific.\n\nOn Wed, Jun 9, 2021 at 10:44 AM Christopher Patton ***@***.***>\nwrote:\n\n> Might this just be deployment specific, or should all helpers do the same\n> thing?\n>\n> What we do for the ECH extension for TLS\n> <https://datatracker.ietf.org/doc/html/draft-ietf-tls-esni-10> is rotate\n> the HPKE config every hour. To add reliability in case a client has an old\n> key, we keep around a rotating set of keys from the last hour or so. The\n> config id is used to determine which key was used to encrypt the payload.\n>\n> \u2014\n> You are receiving this because you are subscribed to this thread.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/abetterinternet/prio-documents/issues/49#issuecomment-857903832>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/AAIPLIKL7RRTTFTPY62E4EDTR6R7RANCNFSM46BGCH5Q>\n> .\n>\n",
          "createdAt": "2021-06-09T17:49:06Z",
          "updatedAt": "2021-06-09T17:49:06Z"
        },
        {
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "body": "I agree that the rotation _mechanism_ is deployment specific, but how the protocol reacts when a key rotation event occurs, possibly causing a mismatch between client and helper keys, should be in scope. (I assumed this issue was meant to address the latter.)",
          "createdAt": "2021-06-10T12:21:18Z",
          "updatedAt": "2021-06-10T12:21:18Z"
        },
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "2021/06/16 design call: The servers need to agree, roughly, on how long reports are valid. (Once a helper rotates its key, reports encrypted under the previous key won't be decryptable.) Should the HPKE config lifetime be a paramater (e.g., of PAParam)? Does the report need to carry this parameter as well?",
          "createdAt": "2021-06-16T17:40:50Z",
          "updatedAt": "2021-06-16T17:46:26Z"
        },
        {
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "body": "Do they need to agree, or should the data just naturally become invalid once rotation occurs? ",
          "createdAt": "2021-06-16T18:08:30Z",
          "updatedAt": "2021-06-16T18:08:30Z"
        },
        {
          "author": "ekr",
          "authorAssociation": "COLLABORATOR",
          "body": "It would be nice if submissions were rejected if they used invalid keys\n\nOn Wed, Jun 16, 2021 at 11:08 AM Christopher Wood ***@***.***>\nwrote:\n\n> Do they need to agree, or should the data just naturally become invalid\n> once rotation occurs?\n>\n> \u2014\n> You are receiving this because you commented.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/abetterinternet/prio-documents/issues/49#issuecomment-862599002>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/AAIPLIKJTDGWHD6D6Y7VSBLTTDSC5ANCNFSM46BGCH5Q>\n> .\n>\n",
          "createdAt": "2021-06-16T18:20:29Z",
          "updatedAt": "2021-06-16T18:20:29Z"
        },
        {
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "body": "Clients reports encrypted with a public key that's too old will indeed be rejected by helper. The validity period we're talking about is of interest for the collector in a protocol like Hits where the collector makes multiple, interactive requests to the aggregators: collectors need to have a sense of how long after the verify phase they can expect to be able to make collect requests before helpers are unable to decrypt the reports. i.e., collectors may not be able to make collect queries over reports that are more than 30 days old. In some cases, a validity period of hours could suffice if the successive queries are being made by an automated system, but maybe the queries are being formulated by a team of human analysts who need a day or so to consider what the n+1th query they want to send is based on the results of the nth query.",
          "createdAt": "2021-06-16T18:36:58Z",
          "updatedAt": "2021-06-16T18:36:58Z"
        },
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "I think we might be converging on something like this: There's no explicit notion of report lifetime that's enforced by the protocol. Perhaps what we need instead is a way for the helper to tell the leader which reports are invalid and should be pruned. (Note that this is not unrelated to #57.)",
          "createdAt": "2021-06-16T19:37:33Z",
          "updatedAt": "2021-06-16T19:37:33Z"
        },
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "Any solution to #57 will also solve this problem. I'm going to make a call and say this issue is a duplicate and can be closed.",
          "createdAt": "2021-07-14T19:28:01Z",
          "updatedAt": "2021-07-14T19:28:01Z"
        }
      ]
    },
    {
      "number": 50,
      "id": "MDU6SXNzdWU5MTA3MTM0OTI=",
      "title": "Specify how clients choose helpers",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/issues/50",
      "state": "CLOSED",
      "author": "tgeoghegan",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "Currently, clients obtain a list of supported helpers from the leader. They are then expected to select some subset of the supported helpers to run the protocol with. Clients must be able to establish trust with helpers independently from the leader to prevent leaders from impersonating helpers and obtaining all the shares of an input.\r\n\r\nWhile clients will establish an authenticated channel with helpers (typically over TLS), clients still need some way to know what helpers they trust (in the TLS case, what SANs they trust to run a helper).\r\n\r\nThe simplest way forward would be to require clients to maintain their own list of trusted helpers and intersect that with the list of supported helpers provided by the leader.",
      "createdAt": "2021-06-03T17:35:44Z",
      "updatedAt": "2021-07-14T20:30:48Z",
      "closedAt": "2021-07-14T20:30:48Z",
      "comments": [
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "An even simpler solution (though it may not be desirable from a security standpoint) is to lean on X.509 and trust the client's set of root certificates. That is, if the client can verify the helper's SAN using one of its root certs, then it trusts whatever public key it gets from the helper over the secure channel.",
          "createdAt": "2021-06-09T17:41:07Z",
          "updatedAt": "2021-06-09T17:41:07Z"
        },
        {
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "body": "This is now obsolete because we have agreed that PAParams will only have a single helper in them.",
          "createdAt": "2021-07-14T20:30:48Z",
          "updatedAt": "2021-07-14T20:30:48Z"
        }
      ]
    },
    {
      "number": 51,
      "id": "MDU6SXNzdWU5MTY0MDQ4MTA=",
      "title": "Requirements for Collect (or, Revisiting the Pipeline Model)",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/issues/51",
      "state": "CLOSED",
      "author": "cjpatton",
      "authorAssociation": "COLLABORATOR",
      "assignees": [
        "chris-wood"
      ],
      "labels": [],
      "body": "At the moment, the spec thinks of a PA task as a one-way data-processing pipeline with three phases: upload, in which clients send inputs to the leader; verify, in which the leader and helper verify each input; and collect, in which the leader and helper aggregate inputs and push the output to the collector. The upload and verify phases are currently specified; our next task is to specify the collect phase.\r\n\r\nThis pipeline model is a perfectly fine way of thinking about Prio. (Although there are ways in which one might use Prio metrics that don't quite fit into this model; see #27.) However, HH doesn't fit into this model at all (see #44). It's apparently necessary to re-think the communication model for PA protocols. @chris-wood and I were kicking this around and wanted to share some thoughts.\r\n\r\nFirst off, let's try to enumerate the relevant requirements for the PA framework.\r\n\r\n1. The helper is stateless.\r\n2. Aggregators (i.e., the leader and helper) enforce the batch size (#15): As long as one of the aggregators is honest, the collector should be unable to see outputs aggregated over a small amount of inputs.\r\n3. Aggregators should never learn more information about outputs than the collector. Moreover, it should be possible to design a PA protocol in which neither the aggregator sees the output in the clear. (This is possible for Prio. In HH, the aggregators inevitably learn the set of candidate prefixes at each round, which leaks some information about the output.)\r\n4. Implementing HH requires O(n) space for the leader, where n is the number of inputs. However, it should be possible for the leader to implement Prio with O(1) space.\r\n5. The aggregators verify and aggregate inputs over multiple rounds. In each round, the collector specifies the parameters that will be used. (In HH, the parameters are the set of candidate prefixes.)\r\n6. [Needs discussion] Not every PA protocol will verify inputs (#45).\r\n\r\nWe can't satisfy all of these requirements in the upload->verify->collect model. Instead, we might think of a PA task as two concurrent processes running asynchronously:\r\n* **Upload process:** Clients *push* inputs to the leader via the upload start and upload finish requests.\r\n* **Collect process:** Collector *pulls* outputs from the leader via a yet-to-be-specified collect request. The request carries the parameters the aggregators will use for verification and aggregation.\r\n\r\nIn this communication model, the collector may attempt to pull the output for a PA task whenever it likes. A pull will only be successful if the aggregators have verified and aggregated enough inputs.\r\n\r\nIf/when inputs are verified is up to the PA protocol, but must occur before the leader can respond to a collect request. (In Prio, reports can verified as soon as they're uploaded; in HH, verification can only occur once all the reports have been uploaded and the collector has issued a collect request.)\r\n\r\nThe helper will keep a long-term symmetric key for encrypting the state that's managed by the collector. This ensures privacy while allowing the helper to be stateless.\r\n\r\nAt the end of aggregation, each of the aggregators holds a share of the output. Before responding to a collect request, the leader requests the helper's output share. To ensure that the leader doesn't see the output in the clear, the helper encrypts its share under the collector's HPKE public key.\r\n\r\nOpen questions\r\n1. Should collect requests be idempotent?\r\n2. A collect request may take a long time. (For HH, the latency may be several minutes!) Is HTTP the right application?\r\n3. How does the helper learn the collector's HPKE public key? The collector needs to prove ownership of the corresponding secret key in some way.",
      "createdAt": "2021-06-09T16:40:23Z",
      "updatedAt": "2021-08-11T14:01:00Z",
      "closedAt": "2021-08-11T14:01:00Z",
      "comments": [
        {
          "author": "acmiyaguchi",
          "authorAssociation": "COLLABORATOR",
          "body": "Perhaps a slight adjustment to upload-verify-collect would be to split `collect` into `aggregate` and `publish`/`reconstruct` like the v1/v2 protocols. It would prevent overloading the term `collect` e.g.:\r\n\r\nPrio: upload -> verify -> aggregate -> publish\r\nHH: upload -> (verify -> aggregate -> verify -> ... -> aggregate) -> publish\r\n\r\nI've been thinking about the protocol through the lens of map-reduce pipeline with network storage (e.g. Spark and S3), where computation is represented as a DAG. It looks the like HH computation would fit neatly into a batched pipeline, given a fixed number of verify-aggregate rounds. \r\n\r\n> Should collect requests be idempotent?\r\n\r\nWhat is the benefit of idempotency in this context? This is so the results of earlier rounds can be used as inputs into later rounds to improve performance?\r\n\r\n> A collect request may take a long time. (For HH, the latency may be several minutes!) Is HTTP the right application?\r\n\r\nOne way to deal with the long latency time is to use a task queue e.g. rabbitmq to wait for responses. The collector would then poll the task queue for completion before moving onto the next step (pushing the results to the leader for another round?). \r\n\r\n> How does the helper learn the collector's HPKE public key? The collector needs to prove ownership of the corresponding secret key in some way.\r\n\r\nIs this not solved as part of the upload phase? Or does the upload phase only authenticate the leader with the helpers?",
          "createdAt": "2021-06-09T18:41:50Z",
          "updatedAt": "2021-06-09T18:41:50Z"
        },
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "> Perhaps a slight adjustment to upload-verify-collect would be to split `collect` into `aggregate` and `publish`/`reconstruct` like the v1/v2 protocols. It would prevent overloading the term `collect` e.g.:\r\n> \r\n> Prio: upload -> verify -> aggregate -> publish\r\n> HH: upload -> (verify -> aggregate -> verify -> ... -> aggregate) -> publish\r\n> \r\n> I've been thinking about the protocol through the lens of map-reduce pipeline with network storage (e.g. Spark and S3), where computation is represented as a DAG. It looks the like HH computation would fit neatly into a batched pipeline, given a fixed number of verify-aggregate rounds.\r\n\r\nThis seems reasonable to me. The one downside I see is that the number of verify-aggregate rounds may not be fixed. For example, the collector might want to start with a set of candidate prefixes. By doing so, it can reduce the number of rounds significantly in applications where the search space can be constrained in some way. (I'd love to hear @csharrison's thoughts on this.)\r\n\r\nCan you be more specific on how this fits into a map-reduce pipeline? My guess is that you'd have a map-reduce for each round. It seems to me like this is still possible.\r\n\r\n> > Should collect requests be idempotent?\r\n> \r\n> What is the benefit of idempotency in this context? This is so the results of earlier rounds can be used as inputs into later rounds to improve performance?\r\n\r\nThis question is about usability, not performance. Imagine the collector is some person on their laptop, interacting with the system. Should the protocol ensure that they can re-run a query multiple times and get back the same result? Or is this up to the implementation?\r\n\r\n> > How does the helper learn the collector's HPKE public key? The collector needs to prove ownership of the corresponding secret key in some way.\r\n> \r\n> Is this not solved as part of the upload phase? Or does the upload phase only authenticate the leader with the helpers?\r\n\r\nSorry, this is a bit confusing. The upload process involves the helper's public key (used by the clients); the collector phase involves collector's public key (used by the helper).\r\n\r\n",
          "createdAt": "2021-06-09T19:08:48Z",
          "updatedAt": "2021-06-09T19:08:48Z"
        },
        {
          "author": "acmiyaguchi",
          "authorAssociation": "COLLABORATOR",
          "body": "> Can you be more specific on how this fits into a map-reduce pipeline? My guess is that you'd have a map-reduce for each round. It seems to me like this is still possible.\r\n\r\nEach verification/aggregation step would just map over the data, joining appropriately with the outputs of the previous step. The reduce step is done at the very end (with the collect phase). Iterative algorithms work fine with map-reduce (e.g. power iteration with thresholds for eigenvector computation). It's trickier when the workflow involves multiple parties because you have to persist intermediate results to a shared location, but it's certainly doable.\r\n\r\nCoordinating work is the challenge, a task queue or something similar in the collector/leader would abstract some of those details. \r\n\r\n> Should the protocol ensure that they can re-run a query multiple times and get back the same result? Or is this up to the implementation?\r\n\r\nIt would be difficult to guarantee idempotency if differential privacy were applied server-side, something which has been mentioned before.",
          "createdAt": "2021-06-09T20:00:51Z",
          "updatedAt": "2021-06-09T20:00:51Z"
        },
        {
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "body": "> I've been thinking about the protocol through the lens of map-reduce pipeline with network storage (e.g. Spark and S3), where computation is represented as a DAG. It looks the like HH computation would fit neatly into a batched pipeline, given a fixed number of verify-aggregate rounds.\r\n\r\n@acmiyaguchi I think the difference being proposed in this issue is, rather than have the servers drive aggregation (by running some map and reduce functions), it has the collector drive aggregation. This seems to have the benefit of turning aggregators into very dumb entities that hold reports and compute functions over them. (One could still build the map-reduce pipeline that sends aggregate data to some sink this way by having the collector drive aggregation and write it to a sink.)",
          "createdAt": "2021-06-09T21:10:26Z",
          "updatedAt": "2021-06-09T21:10:26Z"
        },
        {
          "author": "acmiyaguchi",
          "authorAssociation": "COLLABORATOR",
          "body": "At a high level, there's still a comparable amount of coordination and delegation. Scheduling is nontrivial (\"A collect request may take a long time\") and will probably involve some task management in the collector.\r\n\r\nFor reference, here's the cluster management model of Spark. I don't think it's too far fetched to imagine the collector as a driver program and stateless cloud functions as executors. \r\n\r\n![image](https://user-images.githubusercontent.com/3304040/121431113-d5a4f100-c92d-11eb-92df-5a35b15bb88f.png)\r\nhttps://spark.apache.org/docs/latest/cluster-overview.html\r\n\r\nThis is (mostly?) orthogonal to the data flow e.g. upload -> verify -> aggregate -> publish.\r\n",
          "createdAt": "2021-06-09T21:50:24Z",
          "updatedAt": "2021-06-09T21:50:24Z"
        },
        {
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "body": "> At a high level, there's still a comparable amount of coordination and delegation. Scheduling is nontrivial (\"A collect request may take a long time\") and will probably involve some task management in the collector.\r\n\r\nYep, they seem to match pretty nicely!\r\n\r\n> This is (mostly?) orthogonal to the data flow e.g. upload -> verify -> aggregate -> publish.\r\n\r\nI need to think about this more, but in my mental model, the protocol looks very different if, say, the collector drives things instead of the being a dumb consumer of data output from the aggregators, even though the flow of data is mostly the same. ",
          "createdAt": "2021-06-09T21:58:44Z",
          "updatedAt": "2021-06-09T21:58:44Z"
        },
        {
          "author": "ekr",
          "authorAssociation": "COLLABORATOR",
          "body": "A few thoughts here.\r\n\r\nAs a preliminary, I want to talk about the commercial relationships\r\nrather than the network relationships.  First, let's call the\r\n\"Customer\" the entity which is paying for the service and presumably\r\n(1) is deploying the clients and (2) is interested in the data. So, in\r\nthe case where we are doing Fx telemetry, Mozilla would be the\r\nCustomer. The Customer contracts with 1 or more Operators who\r\ncollectively run the service.\r\n\r\nIn the simplest conceptual topology, there are two Operators, call\r\nthem A and B, each of whom runs an Aggregator. One could also have a\r\nsituation in which the Customer contracts with one Operator and then\r\nruns the second Aggregator themselves, but that seems like a\r\ncase that is likely to be less widely used. In the former scenario,\r\n\r\n\r\nWith that as background:\r\n\r\n1. I think this is going to work best if the PA system presents as a\r\n   single service to the common Customer, at least technically.  By\r\n   this I mean that once it's set up, the Customer/Collecter should\r\n   only have to talk to one system (presumably operated by the same\r\n   entity that operates the Leader). The Leader would in turn talk to\r\n   the other aggregators. This does not preclude concealing the\r\n   results from the Leader, but merely requires that the aggregated\r\n   shares be encrypted so that the Leader cannot see them.\r\n\r\n2. We have been a bit vague about what the Leader/Collector interface\r\n   is, but I think it's most reasonable to think of it as a standard\r\n   Web service API. This of course means that if you just want\r\n   a dashboard a la Amplitude, someone will have to implement that,\r\n   but the most flexible way to do so is as a system that talks\r\n   to the Leader over that API. It's been noted that there are\r\n   times when things are long-running, but there are well-established\r\n   mechanisms for Web services APIs to handle this kind of thing,\r\n   such as by the Collector having a notification endpoint or\r\n   polling.\r\n\r\n3. There are multiple kinds of state to be stored. My expectation\r\n   is that the Leader operates as effectively a query oracle,\r\n   but that the Collector be responsible for the direction\r\n   and order of queries.\r\n\r\n   - The Leader will be responsible for storing the reports and\r\n     whatever memoized information is necessary between queries\r\n     (e.g., suppose for query A you need to verify X, Y, Z\r\n     and then for B you need to verify X, Y, W, the Leader\r\n     could memoize X and Y.). Some of this can be soft state\r\n     and the Leader can recompute as needed.\r\n\r\n   - The Collector is responsible for storing its own context\r\n     and for knowing what's already been asked and what is\r\n     to be asked next.\r\n\r\n   - The Helpers are stateless.\r\n   \r\n   Note that this doesn't address the question of any limits on\r\n   what queries can be made (e.g., for DP). Those have to be\r\n   enforced at the Leader.\r\n\r\n",
          "createdAt": "2021-06-11T13:39:09Z",
          "updatedAt": "2021-06-11T13:39:09Z"
        },
        {
          "author": "csharrison",
          "authorAssociation": "CONTRIBUTOR",
          "body": "Two quick comments:\r\n> This seems reasonable to me. The one downside I see is that the number of verify-aggregate rounds may not be fixed. For example, the collector might want to start with a set of candidate prefixes. By doing so, it can reduce the number of rounds significantly in applications where the search space can be constrained in some way. (I'd love to hear @csharrison's thoughts on this.)\r\n\r\nYes I think we want the computational model to be robust enough to handle dynamic # of rounds, although maybe it is sufficient to just have the \"stopping point\" of the protocol be dynamic to fail early when there is no point further expanding the domain.\r\n\r\nTo ekr's point on helpers being stateless and\r\n> Note that this doesn't address the question of any limits on\r\nwhat queries can be made (e.g., for DP). Those have to be\r\nenforced at the Leader\r\n\r\nI wanted to point out that this choice affects the security guarantees of DP since we wouldn't be ensuring DP for repeated queries / data-stuffing in the 2-pc model but by a single actor (the leader). Within the MPC system we'd only be guaranteeing per-query DP.\r\n\r\ncc @hostirosti who is starting to look at these problems on our side as well.",
          "createdAt": "2021-06-11T15:24:22Z",
          "updatedAt": "2021-06-11T15:24:22Z"
        },
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "Uh, not sure how that got closed! Re-opening.",
          "createdAt": "2021-06-17T19:56:29Z",
          "updatedAt": "2021-06-17T19:56:29Z"
        },
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "Hi folks, PR #59 tries to specify data collection in a way that satisfies the requirements enumerated here. Also, I believe this closes #44.",
          "createdAt": "2021-06-21T16:38:51Z",
          "updatedAt": "2021-06-21T16:38:51Z"
        },
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "As discussed on the 2021/7/14 call, all that's left for this issue is to enumerate the design constraints discussed here in the spec. (@chris-wood will file a PR.)",
          "createdAt": "2021-07-14T20:25:02Z",
          "updatedAt": "2021-07-14T20:25:02Z"
        },
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "#93  enumerates the design constraints considered here. It's time to close out this sucker.",
          "createdAt": "2021-08-11T14:01:00Z",
          "updatedAt": "2021-08-11T14:01:00Z"
        }
      ]
    },
    {
      "number": 53,
      "id": "MDU6SXNzdWU5MTY1NzcxODI=",
      "title": "Terminology section should define \"report\" ",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/issues/53",
      "state": "CLOSED",
      "author": "tgeoghegan",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "The design document discusses \"reports\" which are a group of measurements being submitted to a DPA instantiation. There should be an entry in the \"Terminology\" section that explicitly defines a report and how it relates to \"measurements\" and \"inputs\".",
      "createdAt": "2021-06-09T19:07:09Z",
      "updatedAt": "2021-06-09T19:59:34Z",
      "closedAt": "2021-06-09T19:59:34Z",
      "comments": []
    },
    {
      "number": 57,
      "id": "MDU6SXNzdWU5MjI5Mjc2NTA=",
      "title": "Propagation of errors from helper/leader to collector",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/issues/57",
      "state": "OPEN",
      "author": "tgeoghegan",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [
        "parking-lot"
      ],
      "body": "Client reports could be rejected by the leader and helper for any number of reasons (decryption failure, proof didn't check out, malformed data, etc.). Since client participation in the protocol ends after the upload phase, there is no way for the client to find out about it (even if we move as much validation as possible to the upload phase, I believe there will always be failures that can't be detected until verify). The protocol should provide a way for leaders and helpers to inform collectors of errors so that misbehaving clients can be fixed.",
      "createdAt": "2021-06-16T18:02:36Z",
      "updatedAt": "2022-04-12T10:43:00Z",
      "closedAt": null,
      "comments": [
        {
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "body": "Some prior art here from Prio v2: https://github.com/abetterinternet/prio-server/issues/6. We never implemented this, except that a list of UUIDs of packets (packets are analogous to a report in Priov3) rejected due to bad proofs is included with the sum parts transmitted to the portal server.",
          "createdAt": "2021-06-16T18:03:44Z",
          "updatedAt": "2021-06-16T18:03:44Z"
        },
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "A specific error we need to account for here is decryption failure due to a stale HPKE config. (This was discussed originally in #49.)",
          "createdAt": "2021-07-14T20:31:23Z",
          "updatedAt": "2021-07-14T20:31:23Z"
        },
        {
          "author": "simon-friedberger",
          "authorAssociation": "NONE",
          "body": "Side-note: As long as the aggregators can decrypt their shares they can run validation even if a report would not be included in a batch because it has expired. I doubt that it would be worth the effort but since Max was asking about detecting when validation is too restrictive on the mailing list it might make sense in some cases.",
          "createdAt": "2022-04-12T10:43:00Z",
          "updatedAt": "2022-04-12T10:43:00Z"
        }
      ]
    },
    {
      "number": 58,
      "id": "MDU6SXNzdWU5MjI5MzQ2NzQ=",
      "title": "Consider using OHTTP ",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/issues/58",
      "state": "CLOSED",
      "author": "tgeoghegan",
      "authorAssociation": "COLLABORATOR",
      "assignees": [
        "tgeoghegan"
      ],
      "labels": [],
      "body": "Prio v2 incorporates ingestion servers which sit between clients and aggregators. The ingestion servers:\r\n\r\n- verify attestations from a trusted computing base in the client (i.e., secure enclave or TrustZone), making it harder for malicious clients to submit invalid inputs;\r\n- remove any potentially identifying metadata from client reports before forwarding them to aggregators.\r\n\r\n[Oblivious HTTP](https://datatracker.ietf.org/doc/draft-thomson-http-oblivious/) \"allows a client to make multiple requests of a server without the server being able to link those requests to the client or to identify the requests as having come from the same client.\" We should see if we can integrate OHTTP into the DPA protocol as an optional extension that achieves the goals of the Prio v2 ingestion servers.",
      "createdAt": "2021-06-16T18:09:29Z",
      "updatedAt": "2021-07-28T21:24:38Z",
      "closedAt": "2021-07-28T21:24:38Z",
      "comments": [
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "I think this issue is orthogonal to the PA protocol spec, but is certainly a useful enhancement for deployments.",
          "createdAt": "2021-06-25T21:44:14Z",
          "updatedAt": "2021-06-25T21:44:14Z"
        }
      ]
    },
    {
      "number": 61,
      "id": "MDU6SXNzdWU5Mjc3MDgxNTE=",
      "title": "Align spec with ACME (was \"Version all API endpoints\")",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/issues/61",
      "state": "OPEN",
      "author": "tgeoghegan",
      "authorAssociation": "COLLABORATOR",
      "assignees": [
        "chris-wood"
      ],
      "labels": [],
      "body": "The protocol doc specifies HTTP endpoints like `[leader]/upload_start` or `[helper]/key_config`. We should make sure to insert a protocol version in the endpoints so that we can iterate on this in the future. i.e., `[leader]/v1/upload_start`.",
      "createdAt": "2021-06-22T23:27:45Z",
      "updatedAt": "2021-07-15T00:20:28Z",
      "closedAt": null,
      "comments": [
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "I was thinking the same thing :)\r\n\r\nIn fact, we might always include the version and task id in the request URI. For example:\r\n\r\nexample.com/[version]/[task_id]/upload_start",
          "createdAt": "2021-06-22T23:32:46Z",
          "updatedAt": "2021-06-22T23:32:46Z"
        },
        {
          "author": "ekr",
          "authorAssociation": "COLLABORATOR",
          "body": "I don't believe that this is considered current best practice. See, rather,\nthe structure used by ACME:\n\nhttps://tools.ietf.org/rfcmarkup?doc=8555#section-7.1\n\nOn Tue, Jun 22, 2021 at 4:32 PM Christopher Patton ***@***.***>\nwrote:\n\n> I was thinking the same thing :)\n>\n> In fact, we might always include the version and task id in the request\n> URI. For example:\n>\n> example.com/[version]/[task_id]/upload_start\n> <http://example.com/%5Bversion%5D/%5Btask_id%5D/upload_start>\n>\n> \u2014\n> You are receiving this because you are subscribed to this thread.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/abetterinternet/prio-documents/issues/61#issuecomment-866404758>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/AAIPLIOWFWVODVT55LTWJALTUEMSRANCNFSM47EUXJWQ>\n> .\n>\n",
          "createdAt": "2021-06-22T23:52:15Z",
          "updatedAt": "2021-06-22T23:52:15Z"
        },
        {
          "author": "martinthomson",
          "authorAssociation": "CONTRIBUTOR",
          "body": "I don't know if this is recorded anywhere, but that is a bad way to version APIs.  Mostly because it is unnecessary.  Just change the `[leader]` part to something different.  [Don't standardize URIs](https://datatracker.ietf.org/doc/html/rfc8820).  Our services team has a simple policy: if you are going to make an incompatible change,  spin up an entirely new endpoint on a new domain name.  Compatible changes (new request or response formats for example) can use content negotiation.  And generally we use extensible formats (like JSON) that allow you to add protocol elements in a consistent fashion that result in predictable outcomes.",
          "createdAt": "2021-06-23T00:08:27Z",
          "updatedAt": "2021-06-23T00:09:38Z"
        },
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "The reason to do this is not just about versioning, since we also want to specify a \"task id\" for the request.\r\n",
          "createdAt": "2021-06-23T21:59:39Z",
          "updatedAt": "2021-06-23T21:59:39Z"
        },
        {
          "author": "ekr",
          "authorAssociation": "COLLABORATOR",
          "body": "On Wed, Jun 23, 2021 at 2:59 PM Christopher Patton ***@***.***>\nwrote:\n\n> The reason to do this is not just about versioning, since we also want to\n> specify a \"task id\" for the request.\n>\n\nI'm not following how that changes the situation. Can you expand?\n",
          "createdAt": "2021-06-23T22:06:38Z",
          "updatedAt": "2021-06-23T22:06:38Z"
        },
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "I'm responding to @martinthomson's comment that the URI should not encode the version. I'm fine with that, I'm just not sure how to structure the request in a way that conveys the task id as well as the version. (I haven't yet looked at your link to the ACME spec, but I will)\r\n",
          "createdAt": "2021-06-23T22:25:09Z",
          "updatedAt": "2021-06-23T22:25:09Z"
        },
        {
          "author": "martinthomson",
          "authorAssociation": "CONTRIBUTOR",
          "body": "If the goal is to ensure that a client is able to communicate specific information to a server, in HTTP that's something we use headers for sometimes, but mostly it is what the content of a request is for.  I imagine here that we're talking about posting a bunch of stuff to a server, so there will be a payload into which you can put lots of goodies.\r\n\r\nThe message content might include a version, but versioning for content can and should use media types instead.  That too doesn't directly need an explicit version (not `application/my-protocol-v1` or far worse `application/my-protocol;v=1`), you just use a media type to ensure that if the client wants to send something else, the server won't get confused.\r\n\r\nIn practice, if you need to make a breaking change, it's better to do that at the level of URI (as stated earlier).  You might also make new content types at the same time, which is good practice, but the primary thing that stops things from going badly is the entirely new endpoint that you talk to.",
          "createdAt": "2021-06-24T02:13:31Z",
          "updatedAt": "2021-06-24T02:13:31Z"
        },
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "Another thing to consider here (came up in the 2021/7/14 call): Responding to requests may take some time:\r\n1. Collect requests are blocked until the batch is saturated\r\n2. In Hits, each collect request is blocked until the previous requests is finished.\r\n\r\n@ekr mentioned that ACME has a way of dealing with this.",
          "createdAt": "2021-07-14T19:21:18Z",
          "updatedAt": "2021-07-14T19:21:18Z"
        },
        {
          "author": "martinthomson",
          "authorAssociation": "CONTRIBUTOR",
          "body": "ACME effectively uses what you might call a \"transaction resource\" for this purpose.  When a request is made, the response does not answer that request, but instead provides an link to an alternative resource from which the answer will eventually be available.  Clients then poll that resource to learn when their certificate is ready.  For the stated reasons, this is probably necessary here also.",
          "createdAt": "2021-07-15T00:20:27Z",
          "updatedAt": "2021-07-15T00:20:27Z"
        }
      ]
    },
    {
      "number": 62,
      "id": "MDU6SXNzdWU5Mjg2MDI2NzU=",
      "title": "Replay attacks by the leader and helper statefulness",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/issues/62",
      "state": "CLOSED",
      "author": "csharrison",
      "authorAssociation": "CONTRIBUTOR",
      "assignees": [],
      "labels": [],
      "body": "**TL;DR both aggregators need to maintain state to enforce privacy guarantees. Seems like there is an explicit state/communication trade-off to allow this**\r\n\r\nFiling this issue based on the design meeting today.\r\n\r\nIn the updated design in https://github.com/abetterinternet/prio-documents/pull/59 the leader is in a somewhat privileged position in that it receives reports/batches directly and is the primary entity that keeps track of state.\r\n\r\nFor differential privacy guarantees, we want to bound the number of times any record / batch can contribute to an output to the collector. This requires some statefulness that the leader could help facilitate. However, if the leader is colluding with the collector the following attack is possible:\r\n\r\n1. Collector issues a query to the leader: \"aggregate the last day of data\"\r\n2. The protocol proceeds as normal and the collector receives the aggregate data + noise\r\n3. Collector issues a similar query to the (corrupt) leader, asking for that same data again\r\n4. Leader ignores its state that would otherwise say not to aggregate this data again and communicates to the helper the same data as in (2)\r\n5. The collector receives the same data with newly sampled noise, and can leverage averaging attacks to diminish privacy\r\n\r\nThis is all possible because keeping track of \"budgets\" is the sole responsibility of the leader in step (4). To mitigate this we would need both helper and leader to maintain this information independently, so that neither aggregator has an advantage or can reduce user privacy on their own.\r\n\r\nTo do this, the helper will be required to keep track of (some) state. Additionally, we can rely on the leader to keep some state on behalf of the helper in some way that maintains the integrity of the data and prevents mutation. I believe there is an explicit tradeoff here in terms of (a) statefulness of the helper and (b) communication cost with the leader to maintain the auxiliary state.\r\n\r\nOn one extreme is the maximum statefulness in which all state is maintained by the helper (i.e. the helper and leader keep similar privacy budget databases). On the other extreme is maximum statelessness which would entail something like the helper keeping track of a single counter which \"versions\" the helper's database stored on the leader. The entire database would be communicated to the helper during the protocol, and a new version would be pushed to the leader for storage.\r\n\r\nHow big would this database be? This is a bit of an open question but it will scale proportionally to the number of _partitions_ of the data we would support querying independently (without impacting budget of other partitions). In the design outlined in https://github.com/WICG/conversion-measurement-api/blob/main/AGGREGATE.md we would partition based on:\r\n - Some time window (e.g. hour)\r\n - The collector's identity\r\n - Some application specific key which is specified by the client\r\n\r\nI could imagine this being large in practice though I don't have exact numbers. One natural compromise design between these two extreme options would be to partition the auxiliary databases stored on the leader per one of these keys (e.g. collector identity). This would entail the helper keeping c counters, one for each collector. Then the aux state transferred during each protocol is just the state for the relevant collector. You could presumably do this for any number of parameters that are available in the clear to both aggregators (e.g. information added to or already in `PAParam`).",
      "createdAt": "2021-06-23T20:13:32Z",
      "updatedAt": "2021-06-30T21:24:01Z",
      "closedAt": "2021-06-30T21:24:00Z",
      "comments": [
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "After the design call I made two changes to #59 that might help:\r\n\r\n1. The client now includes with its report a timestamp for report creation time. The associated data for encryption of the helper's helper's share will include this timestamp. That means the helper can authenticate the creation time for reports generated by honest clients.\r\n2. The PA parameters now include a \"batch window\", which specifies the minimum time difference between the oldest and newest report in a batch. Moreover, collect requests specify the batch via a contiguous sequence of batch windows.\r\n\r\nI wonder if this is enough plumbing to allow the helper to prevent replays without needing more overhead than a counter. Suppose for simplicity that a helper is configured for only one PA task and only handles requests from a single leader. Its encrypted state (held by the leader) could keep track of the number of times a collect request has been made for the reports in a given window. It knows the set of reports that fall in that window, so it also knows how many times each report has been used.\r\n\r\n\r\n",
          "createdAt": "2021-06-23T22:23:03Z",
          "updatedAt": "2021-06-23T22:23:03Z"
        },
        {
          "author": "csharrison",
          "authorAssociation": "CONTRIBUTOR",
          "body": "> Its encrypted state (held by the leader) could keep track of the number of times a collect request has been made for the reports in a given window. It knows the set of reports that fall in that window, so it also knows how many times each report has been used.\r\n\r\nCan you elaborate on exactly what the encrypted state is going to look like? It seems like your suggestion is the \"stateless extreme\" option I outlined in the original post. My concern is that the state will need to be a map of {batch_identifier --> counter} for all possible batch identifiers. A batch identifier could contain a time window for sure, but there may be other parameters that make this map large (collector identity, etc.).\r\n\r\nFor example, we probably want to support multiple collectors issuing queries (with different data) for batches in the same time window.",
          "createdAt": "2021-06-23T22:38:50Z",
          "updatedAt": "2021-06-23T22:38:50Z"
        },
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "Yes, I'm advocating for the stateless extreme. My assessement is that the communication overhead will be negligible compared to the cost of re-transmitting (intermediate stages of) the IDPF shares in some aggregate requests:\r\n* IIUC the cost of the counters is `O(num_batches)` bits, where where `num_batches` is the number of batches that are valid for a collect request at any given time.  If multiple collectors are allowed to make requests for any window, then this increases to `O(num_batches * num_collectors)`. Concretely, if the batch window is 1 hour, and the leader agrees to hang on to reports for at least 24 hours, then `num_batches == 24`. (Not sure what a realistic value of `num_collectors` would be.)\r\n* Each aggregate query includes (some intermediate stage of) the encrypted IDPF shares of a subset of reports in a batch. The size of each IDPF share is `O(n)` bits, where `n` is the number of bits of each input. That's `O(n * batch_size)` bits, summing over all the aggregate requests, where `batch_size` is the minimum number of reports per batch. Concretely, `batch_size` might be on the order of a million.\r\n\r\nPerhaps I'm missing something?",
          "createdAt": "2021-06-23T23:19:22Z",
          "updatedAt": "2021-06-30T15:43:47Z"
        },
        {
          "author": "csharrison",
          "authorAssociation": "CONTRIBUTOR",
          "body": "Sorry for the delay on this. Yeah I think this hinges on num_collectors and num_batches. For ad-tech consumers I think this could be in the thousands+. I think num_batches may need to be larger than 24 too, if we wanted to support something like larger like weekly / monthly aggregations.\r\n\r\nBut I agree this may not be a problem in practice depending on these params and I see the benefit in avoiding premature optimization.",
          "createdAt": "2021-06-30T16:54:49Z",
          "updatedAt": "2021-06-30T16:54:49Z"
        },
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "As discussed on today's design call, we'll resolve this issue by allowing trade-off to be made by the helper implementation. In particular, we will neither specify how the helper's state is encrypted nor \"require\" the helper to be stateless. (I pushed a change to #59 that reflects this resolution.)",
          "createdAt": "2021-06-30T20:53:53Z",
          "updatedAt": "2021-06-30T20:53:53Z"
        },
        {
          "author": "csharrison",
          "authorAssociation": "CONTRIBUTOR",
          "body": "> As discussed on today's design call, we'll resolve this issue by allowing trade-off to be made by the helper implementation. In particular, we will neither specify how the helper's state is encrypted nor \"require\" the helper to be stateless. (I pushed a change to #59 that reflects this resolution.)\r\n\r\nThis looks good. This model supports a stateful helper and a \"mostly stateless\" helper that gets all its state from the cookie (It doesn't support sharding the cookie, but I think that's fine for the time being.)\r\n\r\nClosing this out!",
          "createdAt": "2021-06-30T21:24:00Z",
          "updatedAt": "2021-06-30T21:24:00Z"
        }
      ]
    },
    {
      "number": 64,
      "id": "MDU6SXNzdWU5MzQxNzI3OTc=",
      "title": "Supporting batch uploads from the client (and routing reports through the collector)",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/issues/64",
      "state": "OPEN",
      "author": "csharrison",
      "authorAssociation": "CONTRIBUTOR",
      "assignees": [],
      "labels": [
        "parking-lot"
      ],
      "body": "In today's design call we discussed the collector receiving encrypted reports from clients and forwarding them to the leader. This aligns with the design we have in the WICG with some of the reasoning documented [here](https://github.com/WICG/conversion-measurement-api/blob/main/SERVICE.md#sending-data-directly-to-the-helper-servers).\r\n\r\nI also brought this up for discussion on our regular calls in the WICG ([minutes](https://github.com/WICG/conversion-measurement-api/blob/main/meetings/2021-06-28-minutes.md)). Where there was some agreement that this was a good idea.\r\n\r\n\r\n### Pros / Cons of routing reports through the collector\r\nThese are probably non-exhaustive.\r\nPros:\r\n\r\n- Doesn't require aggregation servers to be highly online / available\r\n- Supports graceful failure (\"If something goes wrong, we could re-query\")\r\n- Gives some indication that \"the API is working\" on the server without needing to wait until query time, or via some other side-channel.\r\n- Distributes state out of the aggregation servers (% protection from replay attacks). Arguably this aligns more in our API with who \"owns\" the data at some fundamental level.\r\n- Adds query flexibility \"for free\" without explicitly adding support in the aggregation servers by allowing querying subsets of reports (for instance)\r\n- Allows support for some level of report authentication by the collector, who (in our model) is the entity that is best in the position to validate reports. This could be done completely outside the protocol.\r\n\r\nCons:\r\n\r\n- Adds query flexibility, which could be detrimental to privacy\r\n- Leaks some metadata about each request that may otherwise be only visible to the leader (e.g. ip address), unless using some anonymizing proxy\r\n- Introduces a new vector for replay attacks\r\n\r\n### Protocol solution\r\nIt seems there is a fairly simple solution to this problem, and that is to simply:\r\n\r\n- Instantiate the protocol where the collector is also the client, where the interactions between the \"real clients\" and the \"client/collector\" is unspecified by the protocol.\r\n- Allow the \"client\" to optionally batch upload reports in the protocol rather than sending them one by one.\r\n\r\nIn the existing protocol there is no client authentication so it is technically possible to have a collector that just collects encrypted reports from clients and forwards them on to the leader. Of course the actual clients would need to be set up to do this but it is permitted by the protocol. By allowing batch uploads we just optimize this already-permitted configuration.\r\n\r\nAlternatively, if we deem collector-clients to be bad for the protocol, we ought to have a mechanism which actually forbids them (e.g. by authenticating clients). However, I think that it is pretty reasonable to have this allowed by the protocol and leave it up to specific instantiations how the \"client\" is configured/trusted.",
      "createdAt": "2021-06-30T22:25:06Z",
      "updatedAt": "2021-07-14T18:00:54Z",
      "closedAt": null,
      "comments": [
        {
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "body": ">Gives some indication that \"the API is working\" on the server without needing to wait until query time, or via some other side-channel.\r\n\r\nCan you elaborate on this? Is the idea here that when a client (that is, a real end user client, not a batching one) gets a 200 OK after posting a report to a batching client, the client can be assured that its report has been durably persisted somewhere? I think a leader server could provide a similar guarantee at the end of the upload phase so i'm trying to understand what extra assurances the batching client provides.\r\n\r\n>Adds query flexibility \"for free\" without explicitly adding support in the aggregation servers by allowing querying subsets of reports (for instance)\r\n\r\nIIUC the query flexibility is because the batching client can submit the same reports multiple times, in different-sized batches. If we decide this query flexibility is bad, we could mitigate this by having the original client include a report timestamp in the encrypted input, where it can't be tampered with by the batching client. Aggregators would then maintain query/privacy budgets per aggregation window and would be able to refuse queries on reports that fall in an aggregation window whose budget is already spent.",
          "createdAt": "2021-07-02T21:34:19Z",
          "updatedAt": "2021-07-02T21:34:19Z"
        },
        {
          "author": "csharrison",
          "authorAssociation": "CONTRIBUTOR",
          "body": "> Can you elaborate on this? Is the idea here that when a client (that is, a real end user client, not a batching one) gets a 200 OK after posting a report to a batching client, the client can be assured that its report has been durably persisted somewhere? I think a leader server could provide a similar guarantee at the end of the upload phase so i'm trying to understand what extra assurances the batching client provides.\r\n\r\nI think the use-case is more that the collector is assured the system is working without requiring an interaction with the helpers. It is possible this case could be met by introducing some \"do I have some reports\" functionality though.\r\n\r\n> IIUC the query flexibility is because the batching client can submit the same reports multiple times, in different-sized batches. If we decide this query flexibility is bad, we could mitigate this by having the original client include a report timestamp in the encrypted input, where it can't be tampered with by the batching client. Aggregators would then maintain query/privacy budgets per aggregation window and would be able to refuse queries on reports that fall in an aggregation window whose budget is already spent.\r\n\r\nI think this is one part of it. There are a few ways this batching introduces flexibility even if reports can only be queried once. Mainly this is via separating / combining reports across multiple in-the-clear dimensions (in our design we give some info in the clear like the advertiser site a user converted on). A collector could combine multiple small advertisers reports together if they are too small to receive aggregate data. This is recoverable with a robust query model in the helpers though it adds complexity.\r\n\r\nAnother example along these lines is time-based querying. One collector might want data on hour boundaries, another might want on 4 hour boundaries etc.",
          "createdAt": "2021-07-07T16:51:10Z",
          "updatedAt": "2021-07-07T19:35:10Z"
        },
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "Closed the PR, but here's where we left the discussion: https://github.com/abetterinternet/prio-documents/pull/78#issuecomment-880096898 ",
          "createdAt": "2021-07-14T18:00:43Z",
          "updatedAt": "2021-07-14T18:00:43Z"
        }
      ]
    },
    {
      "number": 65,
      "id": "MDU6SXNzdWU5MzUyODgyNTc=",
      "title": "Deployment architecture and PAParam",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/issues/65",
      "state": "CLOSED",
      "author": "ekr",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "In the current design, the leader provides the configuration information to the client in response to ```upload_start```.  This is conceptually problematic for several reasons:\r\n\r\n1. The leader cannot be trusted to tell the client about the helpers because it might supply its own helpers.\r\n2. The client learns all kinds of information it doesn't need (e.g., batch size).\r\n3. It is an error for the client and the PA system to disagree about a number of parameters, so why are we giving this an opportunity for it to happen? For instance, suppose the client thinks it's doing Prio but the leader says it's doing heavy hitters? Why is that even possible.\r\n\r\nForgetting about the protocol for a second, IMO the right way for this to work is:\r\n\r\n1. The *collector* decides on all the parameters, potentially in cooperation with the rest of the PA system (e.g., the leader might have a minimum batch size, not be able to do some protocol, etc.)\r\n1. The *collector* then configures those parameters into the leader, helpers, etc. as well as the client\r\n1. The *PA system* (probably the leader?) provides a task ID associated with those parameters.\r\n1. The *client* connects to the leader and tells it it wants to use a specific task ID.\r\n1. The leader then responds with an OK or error and any information that might be needed to actually deliver that data, which might well be empty (or could be \"here is the node to upload to\").\r\n\r\nThe key point here is that the client's trust relationship is with the collector, not the PA system, and so the PA system shouldn't be telling it much of anything.\r\n\r\nTwo asides:\r\n1. You might, I suppose, want the collector to be able to reconfigure the client through the leader, but then this structure would need to be signed by the collector, which sounds like more trouble than it's worth.\r\n1. You might also want some way to verify that there hadn't been some kind of configuration mismatch (e.g., the collector changed the size of the prime but didn't change the task ID) but the way you do that is by having the client supply a hash of the config and the leader return an error on mismatch.\r\n\r\n",
      "createdAt": "2021-07-01T23:31:14Z",
      "updatedAt": "2021-08-11T22:13:07Z",
      "closedAt": "2021-08-11T22:13:07Z",
      "comments": [
        {
          "author": "ekr",
          "authorAssociation": "COLLABORATOR",
          "body": "To expand on these points a bit, the parameters need to be determined by the entity operating the collector and the propagated to:\r\n\r\n1. The aggregators\r\n1. The collector\r\n1. The client\r\n\r\nOnly the first of these necessarily requires any kind of cooperation within the scope of this protocol: the collector and clients are effectively operated by the same entity and can be configured in some out of band mechanism. This leaves us with the aggregators. If we want to define a complete system, we might need some way for them to be in-band configured, though you could also imagine a simpler system in which that was done by some unspecified mechanism, which you'll probably need anyway for account creation etc. For instance, you could just have a Web page. If you do that, we don't need PAParam at all. OTOH, if we don't do that, then we need to define a helper configuration protocol.\r\n",
          "createdAt": "2021-07-01T23:41:55Z",
          "updatedAt": "2021-07-01T23:41:55Z"
        },
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "Thanks for the thoughtful feedback, @ekr! I largely agree with how you envision the protocol working. The specific issues with the current spec notwithstanding, I think a big chunk of this question ties into nailing down how parameters are distributed, which we haven't done. It seems to me like the collector is going to have to sign PAParam at some point, at least so that the helper can ensure the leader isn't giving it the wrong parameters; but we probably don't want to require that the client be able to verify that signature.\r\n\r\n> The key point here is that the client's trust relationship is with the collector, not the PA system, and so the PA system shouldn't be telling it much of anything.\r\n\r\nThis is an interesting point. I have been thinking of the collector/client relationship differently, but perhaps there's an inconsistency in my mental model of the problem. I would think that, ideally, the client would only need to trust that the aggregators don't collude. In particular, it wouldn't even need to trust the collector, at least not directly, to even choose the parameters honestly. Our goal would be that, as long as least one of the aggregator is honest, some standard of privacy can be enforced (batch size, DP budget, etc.). Perhaps this trust model is too pessimistic for security to be achievable? In any case, our protocol certainly doesn't achieve it right now.",
          "createdAt": "2021-07-02T01:34:48Z",
          "updatedAt": "2021-07-02T01:43:35Z"
        },
        {
          "author": "ekr",
          "authorAssociation": "COLLABORATOR",
          "body": "> This is an interesting point. I have been thinking of the collector/client relationship differently, but perhaps there's an inconsistency in my mental model of the problem. I would think that, ideally, the client would only need to trust that the aggregators don't collude. In particular, it wouldn't even need to trust the collector, at least not directly. Our goal would be that, as long as least one of the aggregator is honest, some standard of privacy can be enforced (batch size, DP budget, etc.). Perhaps this trust model is too pessimistic for security to be achievable? In any case, our protocol certainly doesn't achieve it right now.\r\n\r\nWell, I think the relationship of the client and the collector is different than the relationship with the rest of the system.\r\n\r\nIn the simplest case, the client was actually written by the collector (that's what you would see in product telemetry, for instance). So, then how does the *user* get confidence that the client is using reasonable parameters, having a set of helpers that the user can trust, etc.? At some level, they can inspect the source code, but more likely the expectation is that the vendor makes assertions about their practices and then the code is open to inspection to verify that those assertions are correct. But note that set of mechanisms needs to not just cover PA but also ensure that that software is otherwise behaving as advertised, so this is a more general problem that we need not solve here (this is where open source, reproducible builds, and binary transparency come in).\r\n\r\nNow there is a more generic case in which the client is written separately but for some reason wants to report to the collector, in which case I would assume that the client vendor somehow imports the parameters (again, in a way we don't need to standardize) from the operator of the collector, but I would assume that here too we would expect the client vendor to assure themselves that those parameters were reasonable.\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n",
          "createdAt": "2021-07-02T01:45:01Z",
          "updatedAt": "2021-07-02T01:45:01Z"
        },
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "It sounds like you don't see much value in the client discovering parameters online? This might be useful, say, if the client has a binary that it can use to run many different PA tasks, with different parameters.",
          "createdAt": "2021-07-02T01:57:33Z",
          "updatedAt": "2021-07-02T01:57:33Z"
        },
        {
          "author": "ekr",
          "authorAssociation": "COLLABORATOR",
          "body": "> It sounds like you don't see much value in the client discovering parameters online? This might be useful, say, if the client has a binary that it can use to run many different PA tasks, with different parameters.\r\n\r\nWell, it's not clear to me how this case would arise. I mean, the client still has to *collect* the data before it submits it in a report, so presumably that part is code, right?\r\n\r\n",
          "createdAt": "2021-07-02T02:02:13Z",
          "updatedAt": "2021-07-02T02:02:13Z"
        },
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "True, though it might be useful to tune the parameters used to collect the same data. I don't have a specific use case in mind, so this optimization could be premature.",
          "createdAt": "2021-07-02T02:06:34Z",
          "updatedAt": "2021-07-02T02:06:34Z"
        },
        {
          "author": "ekr",
          "authorAssociation": "COLLABORATOR",
          "body": "Well but in this case, why can't the client just download it from the vendor somehow? I mean, you've probably already got some channel for updates. Why does this have to be something that this protocol solves?",
          "createdAt": "2021-07-02T02:08:34Z",
          "updatedAt": "2021-07-02T02:08:34Z"
        },
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "Hey @ekr, have we addressed everything in this issue?",
          "createdAt": "2021-08-04T17:46:17Z",
          "updatedAt": "2021-08-04T17:46:17Z"
        }
      ]
    },
    {
      "number": 66,
      "id": "MDU6SXNzdWU5MzUyODg4NTI=",
      "title": "PAParam needs a length field",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/issues/66",
      "state": "CLOSED",
      "author": "ekr",
      "authorAssociation": "COLLABORATOR",
      "assignees": [
        "cjpatton"
      ],
      "labels": [],
      "body": "PAParam now has:\r\n\r\n```\r\nstruct {\r\n  PATask task;\r\n  uint64 batch_size;\r\n  PAProto proto;\r\n  select (PAClientParam.proto) {\r\n    case prio: PrioParam;\r\n    case hits: HitsParam;\r\n  }\r\n} PAParam;\r\n```\r\nIf you introduce a new protocol, this structure will not be parseable by anyone who doesn't know about it. The fix is to put a length field here, typically before the ```select```",
      "createdAt": "2021-07-01T23:32:46Z",
      "updatedAt": "2021-07-08T12:15:42Z",
      "closedAt": "2021-07-08T12:15:42Z",
      "comments": []
    },
    {
      "number": 67,
      "id": "MDU6SXNzdWU5MzUyODg5ODg=",
      "title": "Why does PATask include version?",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/issues/67",
      "state": "CLOSED",
      "author": "ekr",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "This seems unnecessary.",
      "createdAt": "2021-07-01T23:33:09Z",
      "updatedAt": "2021-07-13T18:54:04Z",
      "closedAt": "2021-07-13T18:54:04Z",
      "comments": [
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "The PATask is always the first bit of a protocol message, and the version is the first bit of the PATask. I figured it would be helpful to version each message because messages are carried by HTTP requests. There might be a simpler/better way to do this.",
          "createdAt": "2021-07-02T00:14:16Z",
          "updatedAt": "2021-07-02T00:14:16Z"
        },
        {
          "author": "ekr",
          "authorAssociation": "COLLABORATOR",
          "body": "I don't think we should assume that's the case. If we want to have the version not determined at the URL level (a mistake, IMO) then we should have some sort of message wrapper that contains that, rather than overloading PATask.",
          "createdAt": "2021-07-02T00:21:40Z",
          "updatedAt": "2021-07-02T00:21:40Z"
        },
        {
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "body": "I'm inclined to agree with @ekr: we're discussing versioning the whole API in #61, so PATask doesn't need to also provide version information. So, setting aside the question of message format versions, is there any value in maintaining a version on PATasks at the protocol level? I say no, because we want to be able to treat different PATasks completely independently and don't otherwise have any notion of a relationship between any two PATasks in the protocol.",
          "createdAt": "2021-07-02T21:46:23Z",
          "updatedAt": "2021-07-02T21:46:23Z"
        }
      ]
    },
    {
      "number": 68,
      "id": "MDU6SXNzdWU5MzUyOTE0Mjc=",
      "title": "PPM protocols with multiple helpers (was \"Should multipler helpers be baked into the core protocol?\")",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/issues/68",
      "state": "OPEN",
      "author": "cjpatton",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [
        "parking-lot"
      ],
      "body": "The reason for having multiple helpers is to (partially) recover the protocol output in case a helper goes offline. (See #4.) We currently bake this into the protocol by associating a set of helper URLs with the PPM parameters. This complicates the protocol in two ways:\r\n1. When uploading reports, the client has to pick the set of helpers it will upload reports for (see #50).\r\n2. When collecting outputs (see #59), the collector has to specify which helper the leader will engage with.\r\n\r\nWhen reviewing #59, @chris-wood pointed out that we can simplify the protocol by having one helper per task. If deployments want to add redundancy, they can do so by spinning up more tasks with identical parameter except with a different helper for each task.",
      "createdAt": "2021-07-01T23:39:36Z",
      "updatedAt": "2022-01-14T21:49:39Z",
      "closedAt": null,
      "comments": [
        {
          "author": "ekr",
          "authorAssociation": "COLLABORATOR",
          "body": "I don't think that high availability is a good reason to allow for multiple helpers. If you want HA, stand up multiple instances in different data centers, etc.\r\n\r\nThe reason to allow for multiple helpers is to provide a higher level of assurance, namely to require >2 entities to collude in order to violate user privacy. It might be that we could defer that, though it's not clear to me why a fixed set of 2 helpers is more complicated than a fixed set of 1 helper.\r\n\r\nWRT #50 I don't think that the leader should e telling the client about helpers at all. See #65 \r\n\r\n\r\n\r\n\r\n\r\n",
          "createdAt": "2021-07-01T23:47:28Z",
          "updatedAt": "2021-07-01T23:47:28Z"
        },
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "> I don't think that high availability is a good reason to allow for multiple helpers. If you want HA, stand up multiple instances in different data centers, etc.\r\n\r\nWhen we discussed this last we agreed that multiple helpers would be used for resiliency and not for weakening the trust model. Making this change at this point is fine, but I just want to note that it's a course correction and want to make sure we're all on the same page about.\r\n\r\n> The reason to allow for multiple helpers is to provide a higher level of assurance, namely to require >2 entities to collude in order to violate user privacy. It might be that we could defer that, though it's not clear to me why a fixed set of 2 helpers is more complicated than a fixed set of 1 helper.\r\n\r\nThere are two ways in which this complicates things:\r\n\r\n1. Not every PA protocol is well-defined for more than one helper. In particular, heavy hitters, as specified in [1], is defined for exactly two servers (one leader and one helper). The protocol could probably be extended, but the cost might be high in terms of round complexity.\r\n2. Input validation gets more complicated. For Prio, the leader will have to make a request to each helper, combine the results and make the validity decision, then make a second request to each helper in order to disseminate the decision. Right now Prio can be implemented with just one request to the helper.\r\n\r\nWith these wrinkles in mind, I'd be in favor of allowing multiple helpers to be used this way.\r\n\r\n[1] https://eprint.iacr.org/2021/017",
          "createdAt": "2021-07-02T00:12:23Z",
          "updatedAt": "2021-07-02T00:18:51Z"
        },
        {
          "author": "ekr",
          "authorAssociation": "COLLABORATOR",
          "body": "> > I don't think that high availability is a good reason to allow for multiple helpers. If you want HA, stand up multiple instances in different data centers, etc.\r\n> \r\n> When we discussed this last we agreed that multiple helpers would be used for resiliency and not for weakening the trust model. Making this change at this point is fine, but I just want to note that it's a course correction and want to make sure we're all on the same page about.\r\n\r\nWell, at this non-WG stage of the process \"we\" and \"agreed\" are necessarily kind of fuzzy. so I think there's really a presumption that there's a high bar to make changes. In any case, I don't recall being part of that discussion, so what was the rationale for this? Remember, we're not talking about multiple machines here but rather multiple operators. Is there some reason that ISRG is the leader and Cloudflare is the helper that the system needs to survive a Cloudflare outage? It seems like we've got bigger problems in that case. And note that the system as specified won't survive an outage at the leader.\r\n\r\n> \r\n> > The reason to allow for multiple helpers is to provide a higher level of assurance, namely to require >2 entities to collude in order to violate user privacy. It might be that we could defer that, though it's not clear to me why a fixed set of 2 helpers is more complicated than a fixed set of 1 helper.\r\n> \r\n> There are two ways in which this complicates things:\r\n> \r\n>     1. Not every PA protocol is well-defined for more than one helper. In particular, heavy hitters, as specified in [1], is defined for exactly two servers (one leader and one helper).\r\n> \r\n>     2. Input validation gets more complicated. For Prio, the leader will have to make a request to each helper, combine the results and make the validity decision, then make a second request to each helper in order to disseminate the decision. Right now Prio can be implemented with just one request to the helper.\r\n> \r\n> \r\n> With these wrinkles in mind, I'd be in favor of allowing multiple helpers to be used this way.\r\n\r\nWell, I'm certainly open to having only one helper, if that makes things much easier; I'm just saying that that's the only reason  I am aware of for having > 1\r\n> \r\n> [1] https://eprint.iacr.org/2021/017\r\n\r\n",
          "createdAt": "2021-07-02T00:19:17Z",
          "updatedAt": "2021-07-02T00:19:17Z"
        },
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "> Well, at this non-WG stage of the process \"we\" and \"agreed\" are necessarily kind of fuzzy. so I think there's really a presumption that there's a high bar to make changes.\r\n\r\nBy \"we\" I mean the folks who were on the call when we discussed it and who have chimed in on issues and PRs. Yes, this is necessarily fuzzy and subject to change.\r\n\r\n> In any case, I don't recall being part of that discussion, so what was the rationale for this? Remember, we're not talking about multiple machines here but rather multiple operators. Is there some reason that ISRG is the leader and Cloudflare is the helper that the system needs to survive a Cloudflare outage? It seems like we've got bigger problems in that case. And note that the system as specified won't survive an outage at the leader.\r\n\r\nNo, we were thinking more of a scenario where the leader is a well-provisioned service provider, like ISRG or Cloudflare, and the helper is a dinky third-party that fails to handle a sudden load spike.\r\n\r\n\r\n",
          "createdAt": "2021-07-02T00:28:35Z",
          "updatedAt": "2021-07-02T00:28:35Z"
        },
        {
          "author": "ekr",
          "authorAssociation": "COLLABORATOR",
          "body": "> No, we were thinking more of a scenario where the leader is a well-provisioned service provider, like ISRG or Cloudflare, and the helper is a dinky third-party that fails to handle a sudden load spike.\r\n\r\nI think this is a case of \"don't do that then\", especially given how straightforward it now is to set up HA systems on cloud services.",
          "createdAt": "2021-07-02T00:29:47Z",
          "updatedAt": "2021-07-02T00:30:10Z"
        },
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "The only way I would push back is that requiring that everyone be on a cloud service means there's less diversity in where secret shares are going. If they're going to service providers on the same infrastructure (GCP, say), I could argue that this isn't adding much to privacy.\r\n\r\nPut another way: I think it's good if the bar for running a helper is low.",
          "createdAt": "2021-07-02T00:31:48Z",
          "updatedAt": "2021-07-02T00:32:40Z"
        },
        {
          "author": "ekr",
          "authorAssociation": "COLLABORATOR",
          "body": "Sure, but I think one deals with that by having the Collector retry.",
          "createdAt": "2021-07-02T00:33:06Z",
          "updatedAt": "2021-07-02T00:33:06Z"
        },
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "Well, you're not going to be able to solve every problem this way. It's easy to imagine a helper getting into a state in which the output can't be recovered for a batch. (As a simple example, suppose the helper forgets its key.)\r\n\r\nBut getting back to the original issue: if you want to add redundancy, you can do so without the details of how you do it bleeding into the protocol. I'm fine with that. But we do need to make a decision on the scope of a task.",
          "createdAt": "2021-07-02T00:35:25Z",
          "updatedAt": "2021-07-02T00:37:51Z"
        },
        {
          "author": "ekr",
          "authorAssociation": "COLLABORATOR",
          "body": "> Well, you're not going to be able to solve every problem this way. It's easy to imagine a helper getting into a state in which the output can't be recovered for a batch. (As a simple example, suppose the helper forgets its key.)\r\n\r\nWell, now we're not talking about load spikes but about something different.\r\n\r\n\r\n> But getting back to the original issue: if you want to add redundancy, you can do so without the details of how you do it bleeding into the protocol. I'm fine with that. But we do need to make a decision on the scope of a task.\r\n\r\nI don't know what you mean here. Can you elaborate?\r\n\r\n",
          "createdAt": "2021-07-02T00:38:38Z",
          "updatedAt": "2021-07-02T00:38:38Z"
        },
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "> > Well, you're not going to be able to solve every problem this way. It's easy to imagine a helper getting into a state in which the output can't be recovered for a batch. (As a simple example, suppose the helper forgets its key.)\r\n> \r\n> Well, now we're not talking about load spikes but about something different.\r\n\r\nThat's just an example. My larger point is that we should lower the bar to entry wherever possible. And to re-iterate, this was the original intention of multiple helpers. (Personally, I'm open to changing this requirement.)\r\n\r\n> > But getting back to the original issue: if you want to add redundancy, you can do so without the details of how you do it bleeding into the protocol. I'm fine with that. But we do need to make a decision on the scope of a task.\r\n> \r\n> I don't know what you mean here. Can you elaborate?\r\n\r\nIf we change the spec so that there's just one helper per PAParam, then adding another helper (for redundancy) would require distributing another PAParam. That's fine, except that right now we're assuming a 1:1 correspondence between PATask and PAParam.\r\n",
          "createdAt": "2021-07-02T00:50:12Z",
          "updatedAt": "2021-07-02T00:50:12Z"
        },
        {
          "author": "ekr",
          "authorAssociation": "COLLABORATOR",
          "body": "> That's just an example. My larger point is that we should lower the bar to entry wherever possible.\r\n\r\nI would say \"where practical\". \r\n\r\n> And to re-iterate, this was the original intention of multiple helpers. (Personally, I'm open to changing this requirement.)\r\n\r\nOK. Well, perhaps we should press pause on this discussion and see what others say.\r\n\r\n\r\n\r\n> If we change the spec so that there's just one helper per PAParam, then adding another helper (for redundancy) would require distributing another PAParam. That's fine, except that right now we're assuming a 1:1 correspondence between PATask and PAParam.\r\n\r\nWell, this is more of a topic for #65. But I don't see a problem with having multiple task IDs for the same logical operation with different helpers. That seems a lot simpler in general and in specific pushes complexity out from the main system into the collector/clients, which, as noted in #65, have an arbitrarily rich channel that we don't need to standardize.\r\n\r\n",
          "createdAt": "2021-07-02T00:53:43Z",
          "updatedAt": "2021-07-02T00:53:43Z"
        },
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "Just want to cross-reference this comment here: https://github.com/abetterinternet/prio-documents/pull/70#pullrequestreview-703109761\r\n",
          "createdAt": "2021-07-09T16:05:12Z",
          "updatedAt": "2021-07-09T16:05:12Z"
        },
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "What's left for this issue is to decide if/how to allow for multiple helpers for privacy.",
          "createdAt": "2021-07-12T15:34:52Z",
          "updatedAt": "2021-07-12T15:34:52Z"
        }
      ]
    },
    {
      "number": 69,
      "id": "MDU6SXNzdWU5MzUyOTkxOTY=",
      "title": "Encrypt to the leader as well",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/issues/69",
      "state": "CLOSED",
      "author": "ekr",
      "authorAssociation": "COLLABORATOR",
      "assignees": [
        "cjpatton"
      ],
      "labels": [],
      "body": "ACME originally had this \"just trust TLS\" structure and then ended up with end-to-end signatures to support designs in which you might have some kind of TLS decryption device on-path (either a forward proxy on the client or a reverse proxy on the server). ISTM that similar concerns apply here, and we should just HPKE to the leader. Note that this would also simplify the protocol because you wouldn't need to have parallel structures of leader/helper and could just have:\r\n\r\n```\r\nPAEncryptedInputShare input_share<..2^24-1>;\r\n```\r\n\r\nWith the convention that leader was 0.",
      "createdAt": "2021-07-02T00:00:54Z",
      "updatedAt": "2021-07-12T15:04:33Z",
      "closedAt": "2021-07-12T15:04:33Z",
      "comments": [
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "I'd be fine with this change.",
          "createdAt": "2021-07-02T00:17:13Z",
          "updatedAt": "2021-07-02T00:17:13Z"
        },
        {
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "body": "I think this is especially important in light of #64: if we're going to allow* batching clients to sit between real clients and leaders, then we should prevent those batching clients from being able to observe or tamper with the contents of individual reports, especially if we're going to put some information (timestamps or some unique identifier) into the report to enable aggregators to enforce query/privacy budgets.\r\n\r\n* or rather, \"if we're going to acknowledge that we can't prevent\"",
          "createdAt": "2021-07-02T21:38:29Z",
          "updatedAt": "2021-07-02T21:38:29Z"
        }
      ]
    },
    {
      "number": 72,
      "id": "MDU6SXNzdWU5MzkzMDg2NDI=",
      "title": "Derive the PA task from the parameters",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/issues/72",
      "state": "CLOSED",
      "author": "cjpatton",
      "authorAssociation": "COLLABORATOR",
      "assignees": [
        "tgeoghegan"
      ],
      "labels": [],
      "body": "On the 2021/7/7 design call we decided that the ID should be derived deterministically from the serialized PAParam by, for example, hashing it. This solves a few problems simultaneously. This settles the question of whether there should be 1:1 correspondence between a task ID and the parameters used for that task.\r\n\r\n@tgeoghegan brought up an interesting question, which is how to make the task ID unique when two different data collection tasks use the same parameters. Thoughts?",
      "createdAt": "2021-07-07T22:24:36Z",
      "updatedAt": "2021-07-20T17:54:50Z",
      "closedAt": "2021-07-20T17:54:50Z",
      "comments": [
        {
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "body": "The consensus here is to do SHA-256 over the PDAParams structure and use that as the 32 byte PDATaskID. However, hashing a protocol message requires us to decide on a canonical representation of a protocol message, which I think forces us to decide how to encode messages on the wire. I filed #85 for that question. I'll proceed with a PR for this issue on the assumption that we'll pick JSON.",
          "createdAt": "2021-07-14T23:19:49Z",
          "updatedAt": "2021-07-14T23:19:49Z"
        },
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "As I mentioned there, the assumption would be that we're adopting TLS' binary encoding. If so, in TLS notation, you would write `SHA-256(PDAParam)` as the hash of `PDAParam`, which itself is a serialized data structure.",
          "createdAt": "2021-07-14T23:34:40Z",
          "updatedAt": "2021-07-14T23:34:40Z"
        },
        {
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "body": "> @tgeoghegan brought up an interesting question, which is how to make the task ID unique when two different data collection tasks use the same parameters. Thoughts?\r\n\r\nAll we require is that each PAParam have some unique value, right? A random nonce would probably suffice.\r\n\r\nr.e. the encoding, yes, let's stick with TLS's wire format as @cjpatton suggests.",
          "createdAt": "2021-07-15T01:24:54Z",
          "updatedAt": "2021-07-15T01:24:54Z"
        },
        {
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "body": "Yes, my thinking was that we would just stick 16 bytes of random data in `PDAParams` (a UUID's worth). I agree that we should stick with TLS binary encoding.",
          "createdAt": "2021-07-15T01:43:35Z",
          "updatedAt": "2021-07-15T01:43:35Z"
        }
      ]
    },
    {
      "number": 75,
      "id": "MDU6SXNzdWU5NDEwNjgwMDY=",
      "title": "PAUploadFinishReq timestamp",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/issues/75",
      "state": "CLOSED",
      "author": "chris-wood",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "Currently, clients specify the report timestamp when uploading a report for a task. Presumably this timestamp is used to determine the window/batch in which a report is aggregated. Do we care if clients can spoof or change this timestamp to put reports into different batches? Since clients have no understanding of what batch their report goes into, and this is something that aggregators manage, perhaps we should drop this and let the aggregators figure out the report<>batch grouping?",
      "createdAt": "2021-07-09T21:11:59Z",
      "updatedAt": "2021-07-14T01:30:53Z",
      "closedAt": "2021-07-14T01:30:53Z",
      "comments": [
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "> Currently, clients specify the report timestamp when uploading a report for a task. Presumably this timestamp is used to determine the window/batch in which a report is aggregated.\r\n\r\nYes, that's the idea.\r\n\r\n> Do we care if clients can spoof or change this timestamp to put reports into different batches?\r\n\r\nWe have no way of ensuring that the client doesn't lie about the timestamp. This \"attack\" is akin to the client just lying about the input itself (see #20): It's something we can't do anything about, short of using a secure enclave on the client's machine. I think dealing with these problems is orthogonal to the spec here. On the other hand, it should our goal to allow an honest aggregator to ensure that each report appears in most one batch.\r\n\r\n> Since clients have no understanding of what batch their report goes into, and this is something that aggregators manage, perhaps we should drop this and let the aggregators figure out the report<>batch grouping?\r\n\r\nThe timestamp and batch window is intended to allow an honest aggregator to manage this report<->batch mapping *efficiently*, i.e., with minimal state between aggregate requests. Unless we can think of a better way, I think we should keep this in.",
          "createdAt": "2021-07-12T14:58:39Z",
          "updatedAt": "2021-07-12T14:58:39Z"
        },
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "This issue is now subsumed by #82.",
          "createdAt": "2021-07-14T01:30:53Z",
          "updatedAt": "2021-07-14T01:30:53Z"
        }
      ]
    },
    {
      "number": 81,
      "id": "MDU6SXNzdWU5NDM3ODA0NDE=",
      "title": "Intra-batch replay detection",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/issues/81",
      "state": "CLOSED",
      "author": "chris-wood",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "For privacy reasons, leaders should not be allowed to replay a given report more than once within the context of a single batch. The current verify+collect model runs in a \"streaming mode,\" wherein the leader sends slices of batch shares to helpers for verification and aggregation. \r\n\r\nIf we changed this to require the leader to send _all_ batch shares in a single verify+collect flow, then replay prevention would be simpler: just scan the list and check for dupes. \r\n\r\nIf we stick with the current model, then the helper must necessarily store some state (on the leader, most likely) representing the shares processed. This state could then be consulted when asked to verify+collect any new share. (We can probably spell out a number of ways to do store this state, but ideally it should not be linear in the number of shares collected so far.) We'd likely also need a way for the leader to request that the helper produce the final aggregate output once the batch is \"done\" being verified and collected.",
      "createdAt": "2021-07-13T19:59:13Z",
      "updatedAt": "2021-07-29T20:55:06Z",
      "closedAt": "2021-07-29T20:55:06Z",
      "comments": [
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "> If we changed this to require the leader to send _all_ batch shares in a single verify+collect flow, then replay prevention would be simpler: just scan the list and check for dupes.\r\n\r\nOne downside to this approach is that it requires the leader to queue up the entire batch of reports before sending the first aggregate request to the helper. This may be OK for some deployments, but it might not be workable for all. \r\n \r\n> If we stick with the current model, then the helper must necessarily store some state (on the leader, most likely) representing the shares processed. This state could then be consulted when asked to verify+collect any new share. (We can probably spell out a number of ways to do store this state, but ideally it should not be linear in the number of shares collected so far.)\r\n\r\nI think this is worth pursuing.\r\n\r\n> We'd likely also need a way for the leader to request that the helper produce the final aggregate output once the batch is \"done\" being verified and collected.\r\n\r\nThis is already in the protocol. (See \"output share request\".)\r\n\r\n",
          "createdAt": "2021-07-14T00:48:25Z",
          "updatedAt": "2021-07-14T00:48:25Z"
        },
        {
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "body": "> (We can probably spell out a number of ways to do store this state, but ideally it should not be linear in the number of shares collected so far.)\r\n\r\nWe could require that the leader feed the helper reports with monotonically increasing timestamps, such that the helper can simply maintain a single timestamp and reject any report older than that. However I'm not sure if that's practical given that clients may submit reports out of order.",
          "createdAt": "2021-07-14T16:12:11Z",
          "updatedAt": "2021-07-14T16:12:11Z"
        },
        {
          "author": "ekr",
          "authorAssociation": "COLLABORATOR",
          "body": "One intermediate option would be to maintain a jitter buffer on the leader,\nso that they keep reports for a few minutes and then feed them out in\norder. You would still lose some reports, but not too many.\n\nOn Wed, Jul 14, 2021 at 9:12 AM Tim Geoghegan ***@***.***>\nwrote:\n\n> (We can probably spell out a number of ways to do store this state, but\n> ideally it should not be linear in the number of shares collected so far.)\n>\n> We could require that the leader feed the helper reports with\n> monotonically increasing timestamps, such that the helper can simply\n> maintain a single timestamp and reject any report older than that. However\n> I'm not sure if that's practical given that clients may submit reports out\n> of order.\n>\n> \u2014\n> You are receiving this because you are subscribed to this thread.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/abetterinternet/prio-documents/issues/81#issuecomment-880024893>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/AAIPLIL2KNYFFHI2IGAFBGLTXWZONANCNFSM5AKAXSFA>\n> .\n>\n",
          "createdAt": "2021-07-14T16:22:01Z",
          "updatedAt": "2021-07-14T16:22:01Z"
        }
      ]
    },
    {
      "number": 82,
      "id": "MDU6SXNzdWU5NDM4MTgxNDQ=",
      "title": "Allow batch \"replay\" as required by the PDA protocol (was \"Inter-batch replay prevention\")",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/issues/82",
      "state": "CLOSED",
      "author": "chris-wood",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "Similar to #81, it should not be possible for a share to be included in more than one batch. The timestamp currently gives us some way of ensuring that reports map to at most batch, but not a way of ensuring that reports aren't included two _overlapping_ batch windows. It's not immediately clear if include a single report in two overlapping batch windows is a problem, or if a problem only arises when these windows are disjoint. We should probably clarify what are the inter-batch requirements here and what sort of replay prevention is required.",
      "createdAt": "2021-07-13T20:52:28Z",
      "updatedAt": "2021-12-29T20:03:37Z",
      "closedAt": "2021-12-29T20:03:37Z",
      "comments": [
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "The aggregators (either the leader or helper) can prevent the collector from getting outputs from overlapping batches by remembering batch intervals. For example, suppose the leader responded successfully to a collect request for time interval `[t0, t1)`. Then suppose that, some time later, the collector requests output shares for `[t0, t2)`, where `t0 < t1 < t2`. The potential privacy violation occurs because the sets of reports in each batch are non-disjoint. To prevent this, the leader might respond to the second request with an error, or it might just include the reports in `[t1, t2)`.",
          "createdAt": "2021-07-14T00:37:47Z",
          "updatedAt": "2021-07-14T00:37:47Z"
        },
        {
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "body": "If aggregators are meant to use the report timestamp to protect against replay, then I think it needs to appear in the AEAD-ed message constructed by the client (i.e. `PAEncryptedInputShare`). Otherwise a leader could insert arbitrary timestamps into `PAAggregateSubReq.time` and trick helpers into exceeding privacy budgets or double counting inputs.\r\n\r\nAdditionally, a batching client could insert arbitrary values into `PAUploadFinishReq.time`.",
          "createdAt": "2021-07-14T15:56:12Z",
          "updatedAt": "2021-07-14T15:57:50Z"
        },
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "I created a PR that addresses this issue partially. What's left to do is allow multiple collect requests over the same batch, *as required by the PDA protocol* (e.g., Hits). I have an idea for how to do this, I'll follow up with a PR.",
          "createdAt": "2021-08-04T19:24:34Z",
          "updatedAt": "2021-08-04T19:24:34Z"
        },
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "Closed by https://github.com/abetterinternet/ppm-specification/pull/137.",
          "createdAt": "2021-12-29T20:03:37Z",
          "updatedAt": "2021-12-29T20:03:37Z"
        }
      ]
    },
    {
      "number": 85,
      "id": "MDU6SXNzdWU5NDQ4NjUwMTU=",
      "title": "Choose encoding format for protocol messages",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/issues/85",
      "state": "CLOSED",
      "author": "tgeoghegan",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "The protocol document uses TLS notation to describe messages exchanged between servers, e.g.:\r\n```\r\nstruct {\r\n  uint8 config_id;\r\n  opaque enc<1..2^16-1>;\r\n  opaque payload<1..2^16-1>;\r\n} PDAEncryptedInputShare;\r\n```\r\n\r\nHowever it's not clear how we will actually encode messages on the wire. JSON bodies seems most conventional for REST APIs, but at least @ekr assumed we would use TLS encoding. We should choose an encoding format and update the document appropriately.",
      "createdAt": "2021-07-14T23:17:54Z",
      "updatedAt": "2021-07-15T01:42:47Z",
      "closedAt": "2021-07-15T01:42:47Z",
      "comments": [
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "The document should specify the encoding. We went with TLS binary encoding because it's what most folks were comfortable with at the time of writing. FWIW, I'm happy to change course if there's a good reason to :)",
          "createdAt": "2021-07-14T23:32:29Z",
          "updatedAt": "2021-07-14T23:32:29Z"
        },
        {
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "body": "I think we should close this and stick with TLS.",
          "createdAt": "2021-07-15T01:25:15Z",
          "updatedAt": "2021-07-15T01:25:15Z"
        },
        {
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "body": "Having thought about it over dinner: I raised this because I assumed that \"most people\" would prefer JSON bodies over a binary encoding, but personally I've never liked JSON (too much `\"`) so I'll let \"most people\" argue for it somewhere down the line instead of making a poor case for it myself.",
          "createdAt": "2021-07-15T01:42:47Z",
          "updatedAt": "2021-07-15T01:42:47Z"
        }
      ]
    },
    {
      "number": 86,
      "id": "MDU6SXNzdWU5NDQ4NjY5OTg=",
      "title": "Revisiting the security model",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/issues/86",
      "state": "CLOSED",
      "author": "cjpatton",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "This is a follow up to a discussion we had during the 2021/7/14 design call. We were concerned about a handful of attacks that may require some fundamental design changes to address properly. To focus this discussion, it was decided that we would revisit the security model consider how those attacks fit in. I've taken the liberty of recalling the model and filling in some gaps where necessary. Please, feel free to correct anything that is incorrect or unclear --- we can edit the description as we go. The goal is to get a common understanding of what attacks are in scope and which aren't.\r\n\r\ncc/ @ekr, @csharrison\r\n\r\n### Security model (for privacy)\r\n\r\n**Execution model.** Our execution model has two phases.\r\n\r\n1. In the _trusted setup phase_, public parameters, like the PDAParam and any assets needed to establish a server-authenticated secure channel (i.e., certificates and signing keys) are distributed. The adversary is given the public parameters as well.\r\n1. In the _attack phase_, the adversary runs the attack on the protocol. We assume the adversary has complete control of the network, meaning it relays all protocol messages and may send any message it wants to any party at any time. Further, it may corrupt any party it wants at any time, so long as this doesn't violate the non-collusion assumption of the security goal. In doing so, it learns that party's secret assets, i.e., any signing or encryption keys.\r\n\r\n[UPDATE 2021/7/26] An important difference between our execution model and that of Prio [BC17] and Hits [BBC+21] is that their network is synchronous (the adversary doesn't control transmission of messages from honest parties) and they assume each connection is ideally authenticated. We're assuming neither, which means our attacker is significantly stronger.\r\n\r\n**Privacy goal.** Currently the doc describes the following, informal security goal: As long as one of the aggregators is honest, the adversary learns nothing about the inputs of honest clients _except what it can infer from the output of the protocol_. This thinks of the attacker as colluding with the collector.\r\n\r\nThe details vary slightly, but the Prio [BC17] and Hits [BBC+21] papers formalize this security goal in roughly the following way (see [BC17, Appendix A]): The \"view\" of the adversary is defined to be the set of messages exchanged during the trusted setup and attack phases, as well as any assets belonging to corrupted parties. A PDA protocol is \"private\" if the view of every reasonably efficient (i.e., PPT) adversary can be efficiently simulated, _given the output of the aggregation function computed over the honest inputs_. More precisely, for all inputs `x_1, ..., x_N` and every PPT adversary that corrupts all but one aggregator and all but `N` clients, there exists a PPT simulator that, on input of `f(x_1, ..., x_N)`, outputs a string that is computationally indistinguishable from the adversary's view.\r\n\r\n### Current attacks\r\n\r\nThe attacks we discussed are:\r\n1. #82 A malicious leader can replay a report across two batches (this may be mitigated already).\r\n1. #81 A malicious leader can replay a report within a batch.\r\n1. #20 A network attacker can try a Sybil attack (\"stuff\" the batch with `n-1` bogus reports).\r\n\r\n(As a reminder, these kinds of attacks were anticipated in the original Prio paper. I would suggest folks go back and read [BC17, Section 7]. I found it to be a helpful refresher.)\r\n\r\nWhat's notable about the formalism above is that it concedes Sybil attacks: An attacker can learn a client's input in full, but this would not be deemed an attack by the model. (In other words, the expression \"except what it can infer from the output of the protocol\" is doing a lot of heavy lifting! See [BC17, Section 7].) On the other hand, a malicious aggregator attempting to replay an honestly generated report would be considered an attack in our model.\r\n\r\n[UPDATE 2021/7/26] I don't think the replay attacks are captured by existing formal definitions [BC17, BBC+21].\r\n\r\n---\r\n[BC17] Boneh and Corrigan-Gibbs. \"Prio: Private, Robust, and Scalable Computation of Aggregate Statistics.\" https://crypto.stanford.edu/prio/paper.pdf\r\n[BBC+21] Boneh et al. \"Lightweight Techniques for Private Heavy Hitters.\" https://eprint.iacr.org/2021/017",
      "createdAt": "2021-07-14T23:22:32Z",
      "updatedAt": "2021-12-30T17:18:59Z",
      "closedAt": "2021-12-30T17:18:59Z",
      "comments": [
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "For my part, I will concede that, if the attacker colludes with the collector, then there is no hope of defeating Sybil attacks without doing more than what we're doing. Further, I tend to agree with @csharrison and @hostirosti's assessment that client authentication is the best mitigation. However, I don't think we want to _require_ client authentication, do we? There are cheaper (if less complete) ways to mitigate these attacks. In any case, they're out-of-scope for the current model. (We might also consider changing the model.)",
          "createdAt": "2021-07-14T23:28:06Z",
          "updatedAt": "2021-07-14T23:35:54Z"
        },
        {
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "body": "> However, I don't think we want to require client authentication, do we?\r\n\r\nYeah, requiring client authentication seems like a non-starter for a lot of use cases.",
          "createdAt": "2021-07-15T01:29:27Z",
          "updatedAt": "2021-07-15T01:29:27Z"
        },
        {
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "body": "I agree that we should not require client authentication because it sets a high bar for what kind of client can participate in a private data aggregation system. Additionally, I think that we would have a hard time usefully specifying how client authentication should work because the means of injecting identities into clients and establishing trust between clients and aggregation servers will vary widely from deployment to deployment.\r\n\r\nHowever, it's not hard to imagine deployments where client auth is viable and valuable so we should make sure that it's possible for deployments to use an authenticating proxy that can defend against Sybil attacks for additional assurances beyond what this protocol offers. The idea is that the real clients (i.e., app installations or individual garage door openers) can authenticate to a batching client server using some bespoke authentication protocol, and then the batching client can relay a batch of reports to a PDA leader. Since we're already talking about allowing batching clients (#64), I think we're on our way.\r\n\r\nTo enable that, I think we need a way for a deployment of PDA to restrict who can submit reports. In a batching client setup, if an attacker can obtain the `PDAParam`s (which we don't consider confidential; some deployments may wish to make them widely available for transparency, and reverse engineers will be able to extract them from clients anyway), then they can submit reports directly to the leader and defeat the batching client's Sybil attack protection.\r\n\r\nSo maybe I've come back around to convincing myself that we do want client authentication, or at least enough of it to enable deployments to implement batching clients?\r\n\r\nI think we should also evaluate what the state of the art in the space of metrics collection is. What do existing, non-MPC telemetry systems do to protect against Sybil attacks?",
          "createdAt": "2021-07-21T15:55:19Z",
          "updatedAt": "2021-07-21T15:58:33Z"
        },
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "> I think we should also evaluate what the state of the art in the space of metrics collection is. What do existing, non-MPC telemetry systems do to protect against Sybil attacks?\r\n\r\nSuch defenses aren't necessary, since normally the collector sees all users' data in the clear. They only matter in the context of anonymous communication.\r\n",
          "createdAt": "2021-07-21T16:02:37Z",
          "updatedAt": "2021-07-21T16:02:37Z"
        },
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "As of the 2021/07/21 design call, I think this is where we are: Sybil attacks are out-of-scope for the core protocol, but we ought to account for deployments that can afford some sort of client attestation mechanism to mitigate them.",
          "createdAt": "2021-07-21T21:34:23Z",
          "updatedAt": "2021-07-21T21:34:23Z"
        }
      ]
    },
    {
      "number": 89,
      "id": "MDU6SXNzdWU5NTAxMzYzMzQ=",
      "title": "Client attestation",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/issues/89",
      "state": "OPEN",
      "author": "cjpatton",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [
        "parking-lot"
      ],
      "body": "Many deployments will be in a position to have clients attest that (1) the report was generated by a trusted client or (2) the report was generated within a trusted execution environment. (1) allows you to mitigate Sybil attacks by only consuming reports generated by trusted clients (#86, #20). On top of that, with (2) you might choose to forego expensive MPC for validating inputs altogether (#45). We don't want to require these features for all deployments, but they're useful enough that we should make sure our protocol accommodates them.\r\n\r\nWith that in mind, it would be useful if folks that plan to do this would provide some details about how they envision composing (1) or (2) with PDA**. The question to answer is what changes, if any, are needed for the core spec.\r\n\r\ncc/ @tgeoghegan, @csharrison, and @hostirosti\r\n\r\n** 2022/1/18: Note that \"PDA\" was the working name for the PPM protocol at the time this issue was initially discussed.",
      "createdAt": "2021-07-21T21:49:00Z",
      "updatedAt": "2022-01-19T02:43:11Z",
      "closedAt": null,
      "comments": [
        {
          "author": "csharrison",
          "authorAssociation": "CONTRIBUTOR",
          "body": "For our use-case we were thinking of something like [Privacy Pass](https://datatracker.ietf.org/wg/privacypass/documents/) for anonymous attestation. However, this was in the context of a collector / proxy sitting between the client and the leader who is responsible for issuing and redeeming tokens. This design would put all attestation outside of the PDA protocol, and allow the collector to determine which clients are trusted. However, it only benefits the collector which has a different set of requirements from the PDA system.\r\n\r\nCollectors want to make sure their data is accurate. The PDA system wants to ensure privacy. To that end I could imagine two layers of attestation:\r\n1. A layer of attestation that records are trusted by the collector\r\n2. A layer of attestation that records are trusted by PDA\r\n\r\nHowever, I don't have any concrete ideas on how to accomplish (2) for our use-case realistically.",
          "createdAt": "2021-07-23T02:05:25Z",
          "updatedAt": "2021-07-23T02:05:25Z"
        },
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "> For our use-case we were thinking of something like [Privacy Pass](https://datatracker.ietf.org/wg/privacypass/documents/) for anonymous attestation. However, this was in the context of a collector / proxy sitting between the client and the leader who is responsible for issuing and redeeming tokens. This design would put all attestation outside of the PDA protocol, and allow the collector to determine which clients are trusted. \r\n\r\nThis batched upload idea is still on the table, I think: see https://github.com/abetterinternet/prio-documents/issues/64. In particular, I think we're all in agreement that some collector/proxy should be able to opaquely carry out some client attestation thing and upload only \"trusted\" reports to the leader. (@tgeoghegan calls this the \"ingestor\", I believe.) The problem, as you point out, is the trust relationship between the leader and uploader.\r\n\r\n> Collectors want to make sure their data is accurate. The PDA system wants to ensure privacy. To that end I could imagine two layers of attestation:\r\n> \r\n>     1. A layer of attestation that records are trusted by the collector\r\n> \r\n>     2. A layer of attestation that records are trusted by PDA\r\n> \r\n> \r\n> However, I don't have any concrete ideas on how to accomplish (2) for our use-case realistically.\r\n\r\nYeah, it's not clear to me either what the best thing would be here. As a strawman, consider having the uploader sign the set of reports and have the aggregators verify the signature. If the uploader *is* the collector, then this scheme implies a trust relationship between the collector and at least one aggregator. (In particular, the adversary could still do a Sybil attack.) For this to work, you'd want there to be some sort of organizational separation between the collector and uploader.",
          "createdAt": "2021-07-26T16:35:30Z",
          "updatedAt": "2021-07-26T17:01:58Z"
        },
        {
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "body": "Taking a step back, why do we need any sort of attestation _in this protocol_? Both (1) and (2) seem very deployment specific to me. In particular, if Sybil attacks are out of scope for the core protocol, then surely they should be addressed _outside_ of the core protocol, right? One can add attestation via Privacy Pass or whatever in the protocol that wraps PDA. ",
          "createdAt": "2021-07-26T17:19:08Z",
          "updatedAt": "2021-07-26T17:19:08Z"
        },
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "Ideally yes, but the question we're asking here is whether one would need to change our spec in order to accommodate a mechanism for (1) or (2).  ",
          "createdAt": "2021-07-26T17:21:00Z",
          "updatedAt": "2021-07-26T17:21:00Z"
        },
        {
          "author": "ekr",
          "authorAssociation": "COLLABORATOR",
          "body": "This seems like a great case for an extensible protocol, or as @chris-wood  suggests, a wrapper protocol.\r\n\r\nI think it's clear that one can have a PDA MVP without this.\r\n\r\n",
          "createdAt": "2021-07-26T17:23:31Z",
          "updatedAt": "2021-07-26T17:23:31Z"
        },
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "Looks like the consensus is to park this.",
          "createdAt": "2021-07-29T17:04:17Z",
          "updatedAt": "2021-07-29T17:04:17Z"
        }
      ]
    },
    {
      "number": 92,
      "id": "MDU6SXNzdWU5NTYwNzIxNjU=",
      "title": "Term \"sub-request\" is confusing",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/issues/92",
      "state": "CLOSED",
      "author": "cjpatton",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [
        "editorial"
      ],
      "body": "Aggregate and output share requests are specified in a way that allows the leader to \"batch\" multiple reports in the same request. Right now we avoid using the word \"batch\" to describe this, since batch refers to the set of reports used to compute an output. To disambiguate this, we use the term \"sub-request\" to refer to the input share and PDA-specific protocol message for each report. This is fairly awkward language and may lead to confusion. ",
      "createdAt": "2021-07-29T17:49:28Z",
      "updatedAt": "2022-05-11T15:19:41Z",
      "closedAt": "2022-05-11T15:19:40Z",
      "comments": [
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "Closed by #223.",
          "createdAt": "2022-05-11T15:19:40Z",
          "updatedAt": "2022-05-11T15:19:40Z"
        }
      ]
    },
    {
      "number": 95,
      "id": "MDU6SXNzdWU5NjA4MDIzMDg=",
      "title": "Have the leader encrypt its output share to the collector",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/issues/95",
      "state": "CLOSED",
      "author": "cjpatton",
      "authorAssociation": "COLLABORATOR",
      "assignees": [
        "tgeoghegan"
      ],
      "labels": [],
      "body": "Right now only the helper's output share for a batch of reports is encrypted to the collector. We previously agreed that all input shares should be encrypted to the corresponding aggregator (https://github.com/abetterinternet/prio-documents/issues/69). It makes sense to encrypt the leader's output share for the same reasons we discussed there.\r\n\r\nAlong the way, the message format should be made to accommodate multiple helpers, as we did for the input shares.",
      "createdAt": "2021-08-04T17:52:17Z",
      "updatedAt": "2021-08-23T20:36:59Z",
      "closedAt": "2021-08-23T20:34:45Z",
      "comments": [
        {
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "body": "Fixed in #103. Making \"the message format [...] accommodate multiple helpers\" is specifically tracked in #117 and resolved by #135.",
          "createdAt": "2021-08-23T20:36:59Z",
          "updatedAt": "2021-08-23T20:36:59Z"
        }
      ]
    },
    {
      "number": 98,
      "id": "MDU6SXNzdWU5NjU0MjI5NDY=",
      "title": "The wrapper-core protocol interface",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/issues/98",
      "state": "CLOSED",
      "author": "cjpatton",
      "authorAssociation": "COLLABORATOR",
      "assignees": [
        "cjpatton"
      ],
      "labels": [],
      "body": "On the last design call (2021/08/04) we decided to split our work into two (sets of) documents: one for the \"core\" cryptographic protocols (Prio, Hits, ...) and another for the \"wrapper\" protocol (basically the protocol bits we've been working on so far). The next step is to specify the \"interface\" between these (sets of) documents. This is our goal for this issue.\r\n\r\nSo far we've been reasoning about this core-wrapper interface by analogy of HPKE and its applications (ECH, OHTTP, etc.), which may indeed be an apt analogy, but it falls short of a precise definition. To that end, I'd like to suggest that the interface needs to accomplish two things.\r\n\r\n- (1) Specify the syntax of every PDA protocol. The syntax should cover:\r\n        - (1a) generation of input shares from a measurement;\r\n        - (1b) the state machine of the leader and helper and how they respond to messages (in the core protocol);\r\n        - (1c) accumulation of input shares into an output share; and\r\n        - (1d) combination of output shares into the output.\r\n- (2) Specify the security requirements of every PDA protocol. This has three main components:\r\n        - (2a) The expected _communication model_, which determines how much control over the network the adversary has. (This may be different from the communication model of the wrapper protocol, as discussed below.)\r\n        - (2b) A baseline notion of privacy in the expected communication model that allows any number of clients and all but one aggregator to be corrupted.\r\n        - (2c) A baseline notion of robustness in the expected communication that allows any number of corrupt clients to be corrupted, but requires all aggregators to be honest.\r\n\r\nMuch of what we need is already worked out, but there are some gaps that require us to make some decisions. Two such gaps are discussed below.\r\n\r\n## (2a) Communication model\r\n\r\nAs observed in #86, we've been considering attacks outside the formal model of either Prio or Hits (specifically Sybil and replay attacks). The communication model for the core protocol may therefore differ from (i.e., make stronger assumptions about the adversary than) the communication model for the wrapper protocol. I would argue that this is perfectly reasonable. In fact, the main job of the wrapper protocol should be to \"emulate\" whatever communication model is expected by the core protocol.\r\n\r\nWe are already well on our way here. The following mechanisms are used to provide properties that are implicit in the communication models of the papers:\r\n- HPKE encryption creates a confidential channel between the client and each honest aggregator.\r\n- The report's timestamp and jitter fields define a total ordering on reports, which the aggregators can use to ensure each report is counted in at most one batch.\r\n\r\nSome bits are still missing, however:\r\n- Who manages the report queue? It seems simplest if the core protocol can assume in-order, non-repeated reports. The wrapper protocol can then do this enforcement. \r\n- How are messages authenticated? Currently, the adversary can impersonate the leader since leader->helper messages are not leader authenticated. This may lead to an attack on robustness. We should probably address this in the wrapper protocol such that the core protocol can assume these messages are authenticated.\r\n\r\n## (2b) Baseline privacy goal\r\n\r\nIn Prio, the adversary learns nothing beyond the aggregate of the honest clients' inputs. In contrast, in Hits, the adversary doesn't just learn the heavy hitters (HHs); it may also learn the frequency of non-HH inputs that share a common prefix of a non-HH input with some HH. This leakage is inevitable because the aggregators learn each intermediate set of candidate prefixes at the start of each collect request.\r\n\r\nWe've observed that we can mitigate this leakage somewhat [with differential privacy (DP)](https://github.com/WICG/conversion-measurement-api/blob/main/AGGREGATE.md#privacy-budgeting). Thus, one way to address this gap between Prio and Hits may be to require that each PDA protocol provide DP. This is probably too high a cost, however, given that not all PDA tasks need it.\r\n\r\nA simpler alternative might be to limit the syntax so that a single collect request is in scope. This seems natural, since a single round of Hits provides basically the same security properties as Prio. DP could still be added, but this would merely augment whatever the baseline privacy goal aims to provide.\r\n",
      "createdAt": "2021-08-10T21:38:03Z",
      "updatedAt": "2021-12-30T17:17:26Z",
      "closedAt": "2021-12-30T17:17:26Z",
      "comments": []
    },
    {
      "number": 102,
      "id": "MDU6SXNzdWU5Njc1ODkxNjA=",
      "title": "Collector configuration endpoint",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/issues/102",
      "state": "OPEN",
      "author": "tgeoghegan",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [
        "parking-lot"
      ],
      "body": "PPM uses HPKE to achieve confidentiality and authenticity independently of the underlying transport. To that end, any server that receives messages in the protocol must provide an HPKE configuration to other entities so that messages can be encrypted.\r\n\r\nFor the leader and helper servers, this is achieved by the `leader_url` and `helper_url` fields (respectively) in `struct PPMParam`. Those servers' current HPKE configs can then be obtained from a well-defined HTTP endpoint relative to those URLs.\r\n\r\nFor the collector, we instead have `HpkeConfig collector_config` in `struct PPMParam`. The advantage of this approach is that it absolves the collector of needing to act as an HTTP server, since the collector otherwise is merely a client of the leader's `collect` endpoint. The downsides are that it's different from the other servers, which is a bit surprising and unappealing, and that it makes it impossible to rotate a collector's HPKE key without constructing and distributing a new `struct PPMParam` to all the participants, which includes the potentially numerous clients, in spite of the fact that none of them will ever need to encrypt messages to the collector.\r\n\r\nThis issue tracks improvements to collector configuration discovery. We should consider making collector HPKE configs discoverable the same way that leader and helper ones are, weighing that against the extra operational burden placed on collectors.",
      "createdAt": "2021-08-11T22:39:06Z",
      "updatedAt": "2021-08-11T22:58:50Z",
      "closedAt": null,
      "comments": [
        {
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "body": "Per today's design meeting, putting in the parking lot for now, as this doesn't need to block prototyping or other forward progress on the protocol.",
          "createdAt": "2021-08-11T22:39:35Z",
          "updatedAt": "2021-08-11T22:39:35Z"
        }
      ]
    },
    {
      "number": 104,
      "id": "MDU6SXNzdWU5Njk0ODYzMDg=",
      "title": "Does PPMParam need to be defined at all?",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/issues/104",
      "state": "CLOSED",
      "author": "ekr",
      "authorAssociation": "COLLABORATOR",
      "assignees": [
        "tgeoghegan"
      ],
      "labels": [],
      "body": "The current specification describes a PPMParam struct and defines a TaskID as SHA-256(PPMParam). However, because the PPMParam is never rendered on the wire. Rather it is just serialized in order to be fed into SHA-256. The parameters are provided to the endpoints out of band.\r\n\r\nConsider a client implementor who behaves as follows:\r\n\r\n- Create a JSON structure J that defines the parameters.\r\n- Translate J into PPAParam P.\r\n- Send the client the pair [J, TaskID = SHA-256(P)]\r\n\r\nYou'll note that the client never sees the PPAParam at all. As far as I can tell, this would be a completely conformant implementation. Similar comments apply to the aggregators as we also do not define how *they* are configured. So, similarly they could just be sent JSON and have a TaskID -> JSON lookup table. This isn't just a possible implementation, but it's likely to be a common one, because people have whatever central configuration system they have and don't necessarily want to carry around some binary blob.\r\n\r\nIn fact, the only reason people need to see the PPAParam structure at all as opposed to the information in it is to hash it to create TaskID (yes, i appreciate that I suggested the hashing thing).\r\n\r\nSo what I suggest is we merely make a list of the things that the client and the aggregators need to know respectively and not define any structure that contains that list. Then we can just pick the TaskID randomly.\r\n\r\nWhen we originally discussed hashing, the idea was to have parameters be transitively incorporated into the protocol to avoid situations where each side is using different parameters. It's not clear to me that this is that important. A malicious client can just lie and use its own parameters, and if there is a bug, then it's just as likely it involves misinterpreting the parameters.\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n",
      "createdAt": "2021-08-12T20:09:19Z",
      "updatedAt": "2021-09-15T20:20:51Z",
      "closedAt": "2021-09-15T20:20:51Z",
      "comments": [
        {
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "body": "I think our goal was to force clients to commit to a set of PPMParams, but you're right, nothing really ties the actual behavior of clients or aggregators to the PPMParams. We put a 16 byte nonce into PPMParam with the intention of guaranteeing that PPMTaskID would be unique, but I think we can just instead have PPMTaskID be that nonce. As for the sizes, we picked len(PPMTaskID) = 32 to match the length of a SHA-256, and len(PPMParam.nonce) == 16 to match a v4 UUID. If PPMTaskID is going to be randomly generated instead of derived, then 16 bytes should suffice.",
          "createdAt": "2021-08-12T21:28:34Z",
          "updatedAt": "2021-08-12T21:28:34Z"
        },
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "> So what I suggest is we merely make a list of the things that the client and the aggregators need to know respectively and not define any structure that contains that list. Then we can just pick the TaskID randomly.\r\n> \r\n> When we originally discussed hashing, the idea was to have parameters be transitively incorporated into the protocol to avoid situations where each side is using different parameters. It's not clear to me that this is that important. A malicious client can just lie and use its own parameters, and if there is a bug, then it's just as likely it involves misinterpreting the parameters.\r\n\r\nThe problem we're trying to solve by binding the PPM params to encryption has less to do with malicious clients than honest ones. Namely, it's meant to ensure that honest aggregators reject reports that were generated with incorrect parameters.\r\n\r\nAs to whether this binding is strictly necessary, I agree that it's not clear that there's an attack it prevents right now. This binding is conservative in the sense that it aims to mitigate attacks that may come up in the future, as the set of parameters evolve.\r\n\r\nAnother benefit of this binding is that it ensures the client knows what privacy-sensitive parameters are enforced by honest aggreagators. Namely, the batch size, minimum batch window, and, eventually, parameters for DP.\r\n\r\nTo conclude, there may not be a need to define a serialization format for PPM params, and it would be fine to just randomly the task ID. However, there should be some sort of binding between the params and HPKE encryption.\r\n\r\n",
          "createdAt": "2021-08-16T16:33:09Z",
          "updatedAt": "2021-08-16T16:33:09Z"
        },
        {
          "author": "ekr",
          "authorAssociation": "COLLABORATOR",
          "body": "You seem to be assuming a very specific implementation, but nothing in the spec requires that, as shown by my example above.\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n",
          "createdAt": "2021-08-16T18:30:18Z",
          "updatedAt": "2021-08-16T18:30:18Z"
        },
        {
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "body": "Based on our conversation in the call on 8/18, I think the consensus is\r\n\r\n- we should not define `struct Param` but instead informally list the parameters that all participants must agree on\r\n- `task_id` (which does appear in several on-the-wire messages) will become a randomly generated sequence of bytes instead of being a SHA-256 of the `Param`\r\n\r\nUnless someone objects (tagging @chris-wood to make sure he sees this issue as he hasn't participated yet) I'm going to make this doc change this week, after landing #135.",
          "createdAt": "2021-08-23T18:38:54Z",
          "updatedAt": "2021-08-23T18:38:54Z"
        },
        {
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "body": "#135 seems like it complicates this, since we'd have to spell out some way to sort aggregators. Do we want to land this change before that one?",
          "createdAt": "2021-08-23T19:15:01Z",
          "updatedAt": "2021-08-23T19:15:07Z"
        },
        {
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "body": "I want to land #135 first, since it's just about done. I don't think it'll be too hard to change references to `Param.aggregators` into references to an ordered list of aggregators.",
          "createdAt": "2021-08-23T20:26:11Z",
          "updatedAt": "2021-08-23T20:26:11Z"
        },
        {
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "body": "Sounds good!",
          "createdAt": "2021-08-23T20:32:00Z",
          "updatedAt": "2021-08-23T20:32:00Z"
        }
      ]
    },
    {
      "number": 105,
      "id": "MDU6SXNzdWU5NzA1NzU5MjE=",
      "title": "DefineMIME types for all of the things we are carrying over HTTP",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/issues/105",
      "state": "CLOSED",
      "author": "ekr",
      "authorAssociation": "COLLABORATOR",
      "assignees": [
        "chris-wood"
      ],
      "labels": [],
      "body": "",
      "createdAt": "2021-08-13T17:04:22Z",
      "updatedAt": "2021-08-19T16:21:11Z",
      "closedAt": "2021-08-19T16:21:11Z",
      "comments": []
    },
    {
      "number": 106,
      "id": "MDU6SXNzdWU5NzA1ODA1MjM=",
      "title": "Caching for HpkeConfig",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/issues/106",
      "state": "CLOSED",
      "author": "ekr",
      "authorAssociation": "COLLABORATOR",
      "assignees": [
        "chris-wood"
      ],
      "labels": [],
      "body": "It seems silly to have clients revalidating the HPKE key for each request, so we probably want some kind of caching. I'm not sure HTTP Caching is quite what we want, but something... \r\n\r\n@martinthomson @mnot recommendations?",
      "createdAt": "2021-08-13T17:11:13Z",
      "updatedAt": "2021-08-18T20:33:17Z",
      "closedAt": "2021-08-18T20:33:17Z",
      "comments": [
        {
          "author": "martinthomson",
          "authorAssociation": "CONTRIBUTOR",
          "body": "I'm going to need a little more context to provide good advice.\r\n\r\nIf we don't need key consistency (it doesn't appear so) and you only need correctness, then the client should just be able to talk directly to the collector and get keys periodically.  HTTP caching works fine for that purpose.\r\n\r\nThis would also need a rejection message so that the collector (or the leader on their behalf - the leader is more likely to learn about bad key identifiers before clients) can reject an out-of-date key in case the cache needs to be invalidated.",
          "createdAt": "2021-08-16T01:47:44Z",
          "updatedAt": "2021-08-16T01:47:44Z"
        },
        {
          "author": "ekr",
          "authorAssociation": "COLLABORATOR",
          "body": "We do not need key consistency.\r\n\r\nThe rejection message seems like a good idea.",
          "createdAt": "2021-08-16T02:06:52Z",
          "updatedAt": "2021-08-16T02:06:52Z"
        }
      ]
    },
    {
      "number": 107,
      "id": "MDU6SXNzdWU5NzA1ODgyNTI=",
      "title": "Redefine errors to line up with ACME",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/issues/107",
      "state": "CLOSED",
      "author": "ekr",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "ACME has a pretty well defined error structure, including RFC 8707 problem documents. We should look at adopting that.\r\n\r\n\r\n",
      "createdAt": "2021-08-13T17:23:55Z",
      "updatedAt": "2021-08-18T00:36:32Z",
      "closedAt": "2021-08-18T00:36:32Z",
      "comments": [
        {
          "author": "ekr",
          "authorAssociation": "COLLABORATOR",
          "body": "Fixed by #120 ",
          "createdAt": "2021-08-17T21:01:08Z",
          "updatedAt": "2021-08-17T21:01:08Z"
        }
      ]
    },
    {
      "number": 108,
      "id": "MDU6SXNzdWU5NzA1ODg2MDk=",
      "title": "What is the URL in errors?",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/issues/108",
      "state": "CLOSED",
      "author": "ekr",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "PPMAlert is:\r\n\r\n~~~\r\nstruct {\r\n  PPMTaskID task_id;\r\n  opaque payload<1..255>;\r\n} PPMAlert;\r\n~~~\r\n\r\nAnd the text says:\r\n\r\n> where `task` is the associated PPM task (this value is always known) and\r\n`payload` is the message. When sent by an aggregator in response to an HTTP\r\nrequest, the response status is 400. When sent in a request to an aggregator,\r\nthe URL is always `[aggregator]/error`, where `[aggregator]` is the URL of the\r\naggregator endpoint.\r\n\r\nWhere does the URL appear?",
      "createdAt": "2021-08-13T17:24:38Z",
      "updatedAt": "2021-08-17T21:32:15Z",
      "closedAt": "2021-08-17T21:32:15Z",
      "comments": [
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "The URL comes from the PPM parameters of the task.",
          "createdAt": "2021-08-16T16:36:02Z",
          "updatedAt": "2021-08-16T16:36:02Z"
        },
        {
          "author": "ekr",
          "authorAssociation": "COLLABORATOR",
          "body": "I mean where does it go. There is no slot in this structure for \"URL\"",
          "createdAt": "2021-08-16T17:04:01Z",
          "updatedAt": "2021-08-16T17:04:01Z"
        },
        {
          "author": "ekr",
          "authorAssociation": "COLLABORATOR",
          "body": "Fixed.",
          "createdAt": "2021-08-17T21:32:15Z",
          "updatedAt": "2021-08-17T21:32:15Z"
        }
      ]
    },
    {
      "number": 109,
      "id": "MDU6SXNzdWU5NzA3MjM4NzI=",
      "title": "Add structure in AggregateReq/Resp to reflect when you are processing the same sub-batch",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/issues/109",
      "state": "CLOSED",
      "author": "ekr",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "A batch of reports can be processed incrementally in a set of sub-batches. Each sub-batch may mean multiple RTs between leader and helper. Right now, this is hidden in the Prio or HH-specific pieces, but it probably should be manifest above.",
      "createdAt": "2021-08-13T21:37:06Z",
      "updatedAt": "2022-05-11T19:54:59Z",
      "closedAt": "2022-05-11T19:54:59Z",
      "comments": [
        {
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "body": "Yes, it seems to me that `AggregateResp` needs a boolean in it so that helper can indicate to leader whether more rounds are needed.",
          "createdAt": "2021-08-17T23:51:06Z",
          "updatedAt": "2021-08-17T23:51:06Z"
        },
        {
          "author": "divergentdave",
          "authorAssociation": "COLLABORATOR",
          "body": "I believe this has been resolved with PrepareStepResult (indicating \"continued\" or \"finished\").",
          "createdAt": "2022-05-11T19:54:59Z",
          "updatedAt": "2022-05-11T19:54:59Z"
        }
      ]
    },
    {
      "number": 110,
      "id": "MDU6SXNzdWU5NzA3Mjk4MTQ=",
      "title": "TODO: Fix the bounds for length-prefixed parameters in protocol messages",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/issues/110",
      "state": "OPEN",
      "author": "ekr",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": ".(E.g., `<23..479>` instead of `<1..2^16-1>`.)]",
      "createdAt": "2021-08-13T21:52:11Z",
      "updatedAt": "2021-08-13T21:52:11Z",
      "closedAt": null,
      "comments": []
    },
    {
      "number": 111,
      "id": "MDU6SXNzdWU5NzA3MzA2MTM=",
      "title": "Do something about long-running requests",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/issues/111",
      "state": "CLOSED",
      "author": "ekr",
      "authorAssociation": "COLLABORATOR",
      "assignees": [
        "chris-wood"
      ],
      "labels": [],
      "body": "It's easy to imagine that a request will take a long time, especially if you are using Collect and that has to trigger a bunch of work from the leader. We need some way of handling this.",
      "createdAt": "2021-08-13T21:54:07Z",
      "updatedAt": "2022-03-07T18:52:42Z",
      "closedAt": "2022-03-07T18:52:42Z",
      "comments": [
        {
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "body": "This intersects with something we were discussing last week, which is whether or not `struct PPMParam` should have `HpkeConfig collector_config` in it, or a URL from which collector config can be fetched dynamically. We decided on the former to spare collectors of running an online HTTP server. However, if we adopt an asynchronous model for collect requests, then we might need collectors to be an HTTP server anyway so that the leader can notify them that a collect request is complete, in which case we should make collectors have a `key_config` endpoint like the other servers.",
          "createdAt": "2021-08-17T23:38:01Z",
          "updatedAt": "2021-08-17T23:38:01Z"
        },
        {
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "body": "@cjpatton and I were talking about this today. We agree that `CollectReq`/`CollectResp` definitely needs to be made asynchronous since in the `poplar1` case, servicing a `CollectReq` will definitely incur lots of expensive work between the aggregators (this is less likely in the `prio3` case because the aggregators aren't blocked on obtaining the aggregation parameter from the collector in that VDAF).\r\n\r\nWhat I'm not sure if is whether we should make all the interactions between the aggregators during preparation and verification asynchronous, and I'm not sure how to decide. It seems like it should be possible for leaders to scope each aggregate requests to a small enough number of shares that each one can reasonably be serviced synchronously.",
          "createdAt": "2022-01-22T01:56:22Z",
          "updatedAt": "2022-01-22T01:56:22Z"
        },
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "For collect requests, I'd also note here that asynchronicity is probably going to be important for `prio3`, as it's possible that the aggregation flow will fall behind the upload flow. (Imagine the helper can only handle 1000 reports/sec, but the clients are uploading 1million reports/sec.)\r\n\r\nAs for aggregate requests, I would expect these to be able to be completed fairly quickly (in a matter of seconds, in the worst case). Based on our experience so far, the most expensive part appears to be interacting with long-term storage, which is required for anti-replay and, if we take #174, looking up report shares. I think we can hold off on making these requests asynchronous until we've gotten enough deployment experience to determine if this is going to be a problem.",
          "createdAt": "2022-01-22T02:37:22Z",
          "updatedAt": "2022-01-22T02:37:22Z"
        },
        {
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "body": "@martinthomson provided some interesting prior art that we should rely on when addressing this: https://mailarchive.ietf.org/arch/msg/ppm/dNf3eA-r6qGgeBZ9PhnHjJ1pSEc/",
          "createdAt": "2022-01-26T20:41:27Z",
          "updatedAt": "2022-01-26T20:41:27Z"
        }
      ]
    },
    {
      "number": 112,
      "id": "MDU6SXNzdWU5NzA3MzQ0NzQ=",
      "title": "Change PPMCollectResp to contain a list of shares",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/issues/112",
      "state": "CLOSED",
      "author": "ekr",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [
        "duplicate"
      ],
      "body": "We don't want to distinguish the helper from the leader and this will allow >1 helpers.\r\n\r\nWe can just force the leader to encrypt or have a cleartext version.",
      "createdAt": "2021-08-13T21:56:53Z",
      "updatedAt": "2021-09-08T02:33:11Z",
      "closedAt": "2021-09-08T02:33:10Z",
      "comments": [
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "Subsumed by #117?",
          "createdAt": "2021-08-16T23:51:47Z",
          "updatedAt": "2021-08-16T23:51:47Z"
        },
        {
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "body": "This was addressed in #135 ",
          "createdAt": "2021-09-08T02:33:10Z",
          "updatedAt": "2021-09-08T02:33:10Z"
        }
      ]
    },
    {
      "number": 113,
      "id": "MDU6SXNzdWU5NzA3Mzc4MDk=",
      "title": "Let's not call the random value \"jitter\"",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/issues/113",
      "state": "CLOSED",
      "author": "ekr",
      "authorAssociation": "COLLABORATOR",
      "assignees": [
        "chris-wood"
      ],
      "labels": [
        "editorial"
      ],
      "body": "Because you'll also want a \"jitter buffer\" on the receiver side and that means something different.\r\n\r\nInstead of having a random value, why not just have time be to a nanosecond clock and then lexically sort between collisions?",
      "createdAt": "2021-08-13T22:05:40Z",
      "updatedAt": "2021-08-18T00:10:23Z",
      "closedAt": "2021-08-18T00:10:23Z",
      "comments": [
        {
          "author": "ekr",
          "authorAssociation": "COLLABORATOR",
          "body": "Which will also help one remove duplicates.",
          "createdAt": "2021-08-13T22:05:51Z",
          "updatedAt": "2021-08-13T22:05:51Z"
        },
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "Yeah, this is a bad name :)",
          "createdAt": "2021-08-16T16:38:43Z",
          "updatedAt": "2021-08-16T16:38:43Z"
        }
      ]
    },
    {
      "number": 114,
      "id": "MDU6SXNzdWU5NzA3Mzg3OTA=",
      "title": "Double check that leader and helper have the same shares",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/issues/114",
      "state": "CLOSED",
      "author": "ekr",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "It's easy to see how this could get confused. Maybe we should have a hash over the input?",
      "createdAt": "2021-08-13T22:08:09Z",
      "updatedAt": "2021-08-26T15:17:07Z",
      "closedAt": "2021-08-26T15:17:07Z",
      "comments": [
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "Nominally, the helper doesn't have to remember any shares ... ideally it only has to remember the timestamp/jitter-value of the last report it consumed in a given batch window. I wonder if that's sufficient to mitigate the issue you're describing?",
          "createdAt": "2021-08-17T01:16:52Z",
          "updatedAt": "2021-08-17T01:16:52Z"
        },
        {
          "author": "ekr",
          "authorAssociation": "COLLABORATOR",
          "body": "Doesn't that just guarantee monotonicity?\r\n\r\nLike suppose we have this:\r\n\r\n```\r\nL->H: reports 1-10\r\nH->L: state1\r\nL->H: reports 11-20, state 1\r\nH->L: state 2\r\nL->H: reports 21-30, state 1\r\nH->L: state 2'\r\n```\r\n\r\nDoes something stop that?\r\n\r\n\r\n",
          "createdAt": "2021-08-17T01:22:31Z",
          "updatedAt": "2021-08-17T01:22:31Z"
        },
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "One way to detect if the state has been rewound is simply by using a counter to compute the nonce for encrypting the state.\r\n\r\n```\r\nL->H: reports 1-10\r\nH->L: decrypt state0 with nonce == 0, send state1 encrypted with nonce == 1\r\nL->H: reports 11-20, state 1\r\nH->L: decrypt state1 with nonce == 1; send state2 encrypted with nonce == 2\r\nL->H: reports 21-30, state 1\r\nH->L: attempt to decrypt state1 with nonce == 2, fail.\r\n```\r\n",
          "createdAt": "2021-08-17T01:32:59Z",
          "updatedAt": "2021-08-17T01:33:10Z"
        },
        {
          "author": "ekr",
          "authorAssociation": "COLLABORATOR",
          "body": "Maybe you could describe what state you think the helper has to keep generally.\r\n",
          "createdAt": "2021-08-17T01:37:05Z",
          "updatedAt": "2021-08-17T01:37:05Z"
        },
        {
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "body": "For some context, we ran into this problem this week in Prio v2: ISRG's counterpart server fell far enough behind while processing batches of input shares from New Mexico that the two servers had inconsistent views of which shares' proofs had been validated at the time of scheduling an aggregation task, and so the two servers aggregated over inconsistent lists of inputs, which yields garbage that can't be reassembled into an output.\r\n\r\nMy intuition is that leader gets an explicit ack from helper on each `AggregateSubReq`, and so leader should be able to ensure that it only aggregates over those inputs that were acked by helper? However I think this gets much more complicated if we do #117, because then leader has to take the intersection of the sets of inputs acked by each helper, and then instruct helpers to only collect those shares that were acked by _all_ participating helpers.",
          "createdAt": "2021-08-17T23:45:42Z",
          "updatedAt": "2021-08-17T23:45:42Z"
        },
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "Subsumed by https://github.com/abetterinternet/prio-documents/issues/141.",
          "createdAt": "2021-08-26T15:17:07Z",
          "updatedAt": "2021-08-26T15:17:07Z"
        }
      ]
    },
    {
      "number": 116,
      "id": "MDU6SXNzdWU5NzE5NTM0MjA=",
      "title": "Drop \"PPM\" prefix for all protocol messages",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/issues/116",
      "state": "CLOSED",
      "author": "chris-wood",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "Protocol messages are defined in the context of the PPM document, so the \"PPM\" seems redundant. I think we should just call things as they are, i.e., `TaskID` instead of `PPMTaskID`. ",
      "createdAt": "2021-08-16T17:31:33Z",
      "updatedAt": "2021-08-17T19:50:55Z",
      "closedAt": "2021-08-17T19:50:55Z",
      "comments": []
    },
    {
      "number": 117,
      "id": "MDU6SXNzdWU5NzIxODA0MzE=",
      "title": "Update protocol to generically allow >1 helper",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/issues/117",
      "state": "CLOSED",
      "author": "ekr",
      "authorAssociation": "COLLABORATOR",
      "assignees": [
        "tgeoghegan"
      ],
      "labels": [],
      "body": "",
      "createdAt": "2021-08-16T23:48:36Z",
      "updatedAt": "2021-08-26T22:31:56Z",
      "closedAt": "2021-08-26T22:31:56Z",
      "comments": [
        {
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "body": "This seems to be a dupe fo #68 -- can we close?",
          "createdAt": "2021-08-18T15:19:04Z",
          "updatedAt": "2021-08-18T15:19:04Z"
        },
        {
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "body": "Per discussion in the call today, I think this issue is about updating the various PDU definitions to allow for multiple helpers. For instance, `Param` currently has fields `Url leader_url` and `Url helper_url`, but it should instead have `Url aggregator_urls<1..lots>`. #68 is the more complex problem of extending the protocol to handle >1 helper, which probably involves more rounds of communication. I'm going to grab this issue because I ran into #133 which I think is related, so I'll fix both.",
          "createdAt": "2021-08-18T20:26:32Z",
          "updatedAt": "2021-08-18T20:26:32Z"
        }
      ]
    },
    {
      "number": 118,
      "id": "MDU6SXNzdWU5NzI5MzA2OTI=",
      "title": "Batch constraints are a bit funny",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/issues/118",
      "state": "CLOSED",
      "author": "ekr",
      "authorAssociation": "COLLABORATOR",
      "assignees": [
        "cjpatton"
      ],
      "labels": [],
      "body": "The current text has two batch constraints:\r\n\r\n```\r\n*  `batch_size`: The batch size, i.e., the minimum number of reports that are\r\n  aggregated into an output.\r\n* `batch_window`: The window of time covered by a batch, i.e., the maximum\r\n  interval between the oldest and newest report in a batch.\r\n```\r\n\r\nThis seems like it could have the result that collection is impossible. Suppose that we have:\r\n\r\n```\r\nbatch_size = 7200\r\nbatch_window = 3600\r\n```\r\n\r\nAnd reports come in at an average of 1/s. In this case it wouldn't be possible to satisfy these constraints because you would never be able to accumulate 7200 reports. More generally, it's not clear to me why ```batch_window``` should be a maximum rather than a minimum. How does that assist the helper/leader.\r\n\r\nISTM we should either have one constraint (probably ```batch_size```) or two but have them both be minimums. In either case, we probably want some way for the collector to learn when the limits are reached rather than having to poll.\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n",
      "createdAt": "2021-08-17T17:52:51Z",
      "updatedAt": "2021-09-09T14:12:05Z",
      "closedAt": "2021-09-09T14:12:05Z",
      "comments": [
        {
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "body": "> ISTM we should either have one constraint (probably batch_size) or two but have them both be minimums. In either case, we probably want some way for the collector to learn when the limits are reached rather than having to poll.\r\n\r\nHmm, I wonder if we can get away with a single constraint (batch_size) under the assumption that reports are totally ordered before aggregation? (Do we need to distinguish between intra- and inter-replay attacks in this case?) That would be simpler overall, I think.",
          "createdAt": "2021-08-17T21:20:59Z",
          "updatedAt": "2021-08-17T21:20:59Z"
        },
        {
          "author": "ekr",
          "authorAssociation": "COLLABORATOR",
          "body": "Excitingly, the glossary says:\r\n\r\n```\r\n   Batch window:  The minimum time difference between the oldest and\r\n      newest report in a batch (in seconds).\r\n```\r\n\r\nSo we need to decide which it is.",
          "createdAt": "2021-08-17T23:12:44Z",
          "updatedAt": "2021-08-17T23:12:44Z"
        },
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "Finishing up a PR For this now. Just to be clear, the intent was to enforce a *minimum* batch window, not a maximum. So I think the reference above is a typo.",
          "createdAt": "2021-08-20T01:11:28Z",
          "updatedAt": "2021-08-20T01:11:28Z"
        }
      ]
    },
    {
      "number": 130,
      "id": "MDU6SXNzdWU5NzM5MDkyMjM=",
      "title": "Cost implications of single leader model",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/issues/130",
      "state": "OPEN",
      "author": "hostirosti",
      "authorAssociation": "NONE",
      "assignees": [
        "tgeoghegan"
      ],
      "labels": [],
      "body": "Assuming `Aggregators` and `Servers` are running on distinct cloud providers / hosting environments there is an additional egress cost incurred using the `Leader` model where one `Aggregator` coordinates input validation and data collection from all clients and then forwards data shares  / batches to respective `Aggregators` that are part of the setup.\r\n\r\n As of 2021-08-18 there are the following network costs of major cloud providers. *No claim of 100% accuracy*\r\n\r\nTL;DR Assuming `Aggregators` / `Servers` running on distinct providers using the Leader model we can assume $50 - $230 / TB added cost for egress network traffic.\r\n\r\n//TODO add how many input shares per TB approx.\r\n\r\n# Network Cost Comparison across providers\r\n\r\n## Ingress Network Cost\r\n*>>cost incurred by clients sending data to `Aggregator(s)`<<*\r\n*all prices per GB*\r\n\r\nAWS | Azure | GCP \r\n----|-------|------\r\n free | free | free \r\n\r\n## Egress Network Cost\r\n*>>cost incurred by sending data out leaving the provider (e.g. server communication, leader aggregator sending data to other aggregators<<*\r\n*all prices per GB*\r\n\r\nAWS | Azure | GCP\r\n-----|-------|------\r\n$0.05-$0.154<sup>1</sup> |   $0.0875 - $0.181<sup>2</sup> |  $0.045 - $0.23<sup>3</sup>\r\n\r\n<sup>1</sup> Tiered discount 1GB free, 1GB-10TB, 10TB-50TB, 50TB-150TB, 150TB+ \r\n<sup>2</sup> Tiered discount 5GB free, 5GB-10TB, 10TB-50TB, 50TB-150TB, 150TB-500TB, 500TB+\r\n<sup>3</sup> Tiered discount 0-1TB, 1-10TB, 10+TB Premium Tier starts at $0.08, Standard Tier goes down to $0.045 Tiered 0-10TB, 10-150TB, 150-500TB\r\n\r\n## Intra-Provider Network Cost\r\n*>>cost incurred by sending data within a provider between different regions<<*\r\n\r\n### Intra-Continental\r\n*all prices per GB*\r\nRegion | AWS | Azure | GCP\r\n---- | ---- | ---- | ----\r\nNA | $0.01-$0.02  |  $0.02 | $0.01\r\nEurope | $0.02 |  $0.02 | $0.02\r\nAsia | $0.09 | $0.08 | $0.05\r\nOceania | $0.098 | $0.08 | $0.08\r\nMEAA | $0.1105-$0.147 | $0.08 | $0.08\r\nSouth America | $0.138 | $0.16 | $0.08\r\n\r\n### Inter-Continental\r\n*all prices per GB*\r\nRegion | AWS | Azure | GCP\r\n---- | ---- | ---- | ----\r\nNA -> * | $0.01-$0.02 |  $0.05 | $0.08-$0.15<sup>1</sup>\r\nEurope -> * | $0.02 |  $0.05 | $0.08-$0.15<sup>1</sup>\r\nAsia, Oceania, Africa -> * | $0.086-$0.098 | $0.08 | $0.08-$0.15<sup>1</sup>\r\nSouth America -> * | $0.138 | $0.16 | $0.08-$0.15<sup>1</sup>\r\n\r\n<sup>1</sup> from/to Indonesia or Oceania2 $0.15 for GCP\r\n\r\n\r\n",
      "createdAt": "2021-08-18T17:40:23Z",
      "updatedAt": "2022-01-05T03:13:54Z",
      "closedAt": null,
      "comments": [
        {
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "body": "Per today's design call, we agreed that we will stick with the leader model in the protocol for now. However, I am going to take a look at what the data egress costs are in Prio v2 relative to the amount of data we are moving, to provide some context on how much $$$ we are really talking about here. Further, I'm going to sketch out what a protocol variant that allows direct client to helper upload would look like, and how much cloud egress such a model would save, so that we have a better idea of how much money is saved.",
          "createdAt": "2021-08-18T18:04:03Z",
          "updatedAt": "2021-08-18T18:04:03Z"
        },
        {
          "author": "eriktaubeneck",
          "authorAssociation": "NONE",
          "body": "I would argue (in line with what I think is the current consensus) that having `Helpers` be minimal and stateless is preferable, however these egress costs will be significant. I propose we consider allowing the `Leader` run a `LeaderProxy` within each cloud provider, which could be specified by within the client, and could result in minimal egress costs. Here is a diagram (as best I could in ascii...), with the assumption that the `LeaderProxy` and `Helper` are within the same cloud, but top and bottom pairs are in different clouds:\r\n```\r\n                     +-------------+    +------------+\r\n            +-------->             |    |            |\r\n+--------+  |  +-----> LeaderProxy <---->   Helper   |\r\n|        |  |  |  +-->             |    |            |\r\n| Client +--|--+  |  +------^------+    +------------+\r\n|        |  |  |  |         |\r\n+--------+  |  |  |         |\r\n            |  |  |         |\r\n+--------+  |  |  |  +------v------+                    +-----------+\r\n|        |  |  |  |  |             |                    |           |\r\n| Client +--+  |  |  |    Leader   <--------------------> Collector |\r\n|        |  |  |  |  |             |                    |           |\r\n+--------+  |  |  |  +------^------+                    +-----------+\r\n            |  |  |         |\r\n+--------+  |  |  |         |\r\n|        |  |  |  |         |\r\n| Client +--|--|--+  +------v------+    +------------+\r\n|        |  |  |  +-->             |    |            |\r\n+--------+  |  +-----> LeaderProxy <---->   Helper   |\r\n            +-------->             |    |            |\r\n                     +-------------+    +------------+\r\n```\r\n\r\nOne added benefit of such an approach is the all of the egress cost is born by the leader, which further minimizes the responsibility and cost variance on the helpers.",
          "createdAt": "2021-11-12T23:44:41Z",
          "updatedAt": "2021-11-12T23:44:41Z"
        },
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "I've been working on an implementation of PPM instantiated with `prio3`. In order to make this discussion more concrete, I took some measurements of the communication cost for various data types.\r\n\r\nThe table below contains results for 1000 reports. The first column is the data type (see https://docs.rs/prio/latest/prio/vdaf/prio3); the second column is the total amount of data uploaded by clients to the leader; the third column is the amount of data sent from the leader to the helper; and the final column is the amount of data data sent from the helper to the leader. Data rates exclude HTTP request framing.\r\n\r\n| data type | bytes processed | bytes sent | bytes received | \r\n| ---------- | -----------| ------------- | ------------ |\r\n| Prio3Count64 | 423.8 KB | 276.5 KB | 82.1 KB |\r\n| Prio3Histogram64 (10 buckets) | 837.9 KB | 280.4 KB | 86.0 KB |\r\n| Prio3Sum64 (32 bits) | 2.2 MB | 280.4 KB | 86.0 KB |\r\n\r\nExtrapolating, aggregating 1 million reports results in at most 273.8MB of egress, or about $0.06 at $0.23/GB.\r\n\r\nThe main thing to note here is that the amount of data uploaded by clients depends on the data type, but the amount of data sent from the leader to helper does not. This is because in `prio3` the helper's input share is always constant size, but the leader's depends on the data type. For `hits` on the other hand, the size of each input share is going to be linear in the length of the inputs. This is likely makes the concrete cost much higher, but we should measure it.\r\n",
          "createdAt": "2022-01-03T19:12:20Z",
          "updatedAt": "2022-01-03T19:12:20Z"
        },
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "@eriktaubeneck wrote: \r\n> I propose we consider allowing the `Leader` run a `LeaderProxy` within each cloud provider, which could be specified by within the client, and could result in minimal egress costs. Here is a diagram (as best I could in ascii...), with the assumption that the `LeaderProxy` and `Helper` are within the same cloud, but top and bottom pairs are in different clouds: ...\r\n\r\nI'm not sure I see how this architecture helps with the state coordination problem. It seems like LeaderProxy just makes explicit a functionality that the Helper is going to have to implement it anyway. Why does making it explicit help?",
          "createdAt": "2022-01-03T19:24:53Z",
          "updatedAt": "2022-01-03T19:24:53Z"
        },
        {
          "author": "eriktaubeneck",
          "authorAssociation": "NONE",
          "body": "> I'm not sure I see how this architecture helps with the state coordination problem. \r\nAgreed, I don't believe it has an effect on state coordination. I'm only suggesting this in terms of minimizing cost.\r\n\r\nSuppose we have Agg1, Agg2, and Leader, which are in Cloud1, Cloud2, and Cloud3. If a message from Agg1 -> Agg2 needs to actually route through the Leader, i.e. Agg1 -> Leader -> Agg2, then that message would pay egress fees to both Cloud1 and Cloud2.\r\n\r\nIf instead we had a Leader Proxy running in Cloud1, the message could go from Agg1 -> Leader Proxy (Cloud 1) -> Agg2, which would only pay egress fees to Cloud1. It also has a nice site effect of consolidating all the egress fees onto the Leader.",
          "createdAt": "2022-01-04T18:49:14Z",
          "updatedAt": "2022-01-04T18:49:14Z"
        },
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "Right now we don't have a situation where Agg1 would send a message to Agg2. In fact, for the moment, we don't support more than one helper. In my opinion, addressing this is situation is a bit premature.",
          "createdAt": "2022-01-04T21:34:10Z",
          "updatedAt": "2022-01-04T21:34:10Z"
        },
        {
          "author": "eriktaubeneck",
          "authorAssociation": "NONE",
          "body": "Got it. I misunderstood the added cost concern in this issue. Agreed that this is a premature optimization under current constraints. ",
          "createdAt": "2022-01-05T03:13:53Z",
          "updatedAt": "2022-01-05T03:13:53Z"
        }
      ]
    },
    {
      "number": 131,
      "id": "MDU6SXNzdWU5NzM5MTg2NDE=",
      "title": "What happens if one of the shares is corrupt?",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/issues/131",
      "state": "CLOSED",
      "author": "ekr",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "We need some way for the helper to kick back an aggregate request with a bogus share without failing the entire batch.",
      "createdAt": "2021-08-18T17:53:21Z",
      "updatedAt": "2021-08-26T15:16:04Z",
      "closedAt": "2021-08-26T15:16:04Z",
      "comments": [
        {
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "body": "IMO this is the same as #114: we need to ensure that the leader and helper(s) are aggregating over the same set of reports. The leader already gets an `AggregateSubResp` from helper for each report (or doesn't), so it should be able to intersect the set of valid reports leader has with the set of valid report helper has and then issue an `OutputShareReq` that only references those reports. Currently `OutputShareReq` only has `batch_start` and `batch_end`. I think it needs either a list of report IDs, or perhaps a list of report IDs to exclude if that is more efficient. ",
          "createdAt": "2021-08-18T18:07:45Z",
          "updatedAt": "2021-08-18T18:07:45Z"
        },
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "+1 to this being a duplicate.\r\n\r\n@tgeoghegan's suggestion sounds a lot like what would be needed for the split-upload model that motivates #130. The main reason for the leader-only-upload model is that it avoids this cost by making the protocol simpler. The spec currently tries to solve this agreement problem by:\r\n1. Having the aggregators run an input-validation protocol.\r\n2. Having the leader hold the protocol state so that, at any given moment, it knows what set of reports are valid.\r\n3. Ensuring that each report is aggregated at most once by enforcing a total ordering on reports.\r\n\r\nWe can speculate about failure scenarios and whether these measure are sufficient --- as we already have done, quite a lot! --- but from where I stand it's not clear yet that there's a problem to solve here. I suggest that we hold off on specifying anything new until we're confident that it's necessary.",
          "createdAt": "2021-08-20T02:01:57Z",
          "updatedAt": "2021-08-20T02:01:57Z"
        },
        {
          "author": "ekr",
          "authorAssociation": "COLLABORATOR",
          "body": "Yes, now that I see there is an error, this seems like it should work OK.",
          "createdAt": "2021-08-20T02:38:07Z",
          "updatedAt": "2021-08-20T02:38:07Z"
        },
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "Shall we close this in favor of https://github.com/abetterinternet/prio-documents/issues/141?",
          "createdAt": "2021-08-26T00:53:12Z",
          "updatedAt": "2021-08-26T00:53:12Z"
        },
        {
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "body": "Seems like this, #141, and #114 all address the same problem.",
          "createdAt": "2021-08-26T02:00:33Z",
          "updatedAt": "2021-08-26T02:00:33Z"
        }
      ]
    },
    {
      "number": 133,
      "id": "MDU6SXNzdWU5NzQwMjgwMzk=",
      "title": "How does the leader know which `EncryptedInputShare` in a report is which?",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/issues/133",
      "state": "CLOSED",
      "author": "tgeoghegan",
      "authorAssociation": "COLLABORATOR",
      "assignees": [
        "tgeoghegan"
      ],
      "labels": [],
      "body": "We have this definition:\r\n```\r\nstruct {\r\n  TaskID task_id;\r\n  Time time;\r\n  uint64 nonce;\r\n  Extension extensions<4..2^16-1>;\r\n  EncryptedInputShare encrypted_input_shares<1..2^16-1>;\r\n} Report;\r\n<...>\r\n* `encrypted_input_shares` contains the encrypted input shares of each of the aggregators.\r\n```\r\nThe intent is to eventually allow an arbitrary number of aggregators, but how is the leader meant to know which `EncryptedInputShare` goes to which aggregator? Is share 0 understood to be the leader's, and share 1 is the helper's?",
      "createdAt": "2021-08-18T20:23:47Z",
      "updatedAt": "2021-08-26T22:32:12Z",
      "closedAt": "2021-08-26T22:32:12Z",
      "comments": [
        {
          "author": "ekr",
          "authorAssociation": "COLLABORATOR",
          "body": "Yeah, that's 0 and 1. But 3 and 4? LOL. \r\n\r\nMaybe we should do:\r\n\r\n```\r\nstruct {\r\n   AggregatorId aggregator;\r\n   EncryptedInputShare encrypted_input_shares<1..2^16-1>;\r\n} AnInputShare;\r\n```\r\n\r\nWhere ```AggregatorId``` is  TBD.\r\n",
          "createdAt": "2021-08-18T22:25:46Z",
          "updatedAt": "2021-08-18T22:25:46Z"
        },
        {
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "body": "Ooh, vectors of labeled tuples are much better than my idea of requiring consistent ordering of per-aggregator values across `Report`, `Param` and `CollectResp`",
          "createdAt": "2021-08-18T23:20:00Z",
          "updatedAt": "2021-08-18T23:20:00Z"
        },
        {
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "body": "This is (going to be) resolved by #135.",
          "createdAt": "2021-08-23T20:37:46Z",
          "updatedAt": "2021-08-23T20:37:46Z"
        }
      ]
    },
    {
      "number": 138,
      "id": "MDU6SXNzdWU5NzczMjcyNzU=",
      "title": "Aggregator roles and key diversification",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/issues/138",
      "state": "CLOSED",
      "author": "tgeoghegan",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [
        "parking-lot"
      ],
      "body": "Currently, the derivation of HPKE context entangles a constant for `server_role`, which is 0x01 for the leader and 0x00 for the helper. Some iterations of PR #135, which aimed to generalize message definitions to support more than one helper, introduced a notion of an aggregator ID or role, and then used that role in the key derivation. That notion wound up being a little more complicated than what needed to be addressed in that PR, but we should still consider whether and how we want to formalize the notion of an aggregator's role and whether it should be involved in encryption key derivation.",
      "createdAt": "2021-08-23T18:57:06Z",
      "updatedAt": "2022-05-11T18:59:27Z",
      "closedAt": "2022-05-11T18:59:27Z",
      "comments": [
        {
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "body": "I'm not sure if this should go in label parking-lot. The server role constants we have now are sufficient for the deployments that will realistically materialize in the near or medium term, and I think we could define server roles in the future in a manner that is compatible with the existing constants.",
          "createdAt": "2021-08-23T19:01:50Z",
          "updatedAt": "2021-08-23T19:01:50Z"
        },
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "I'm in favor of the generalization, but am fine with putting this in the parking lot.",
          "createdAt": "2021-08-26T00:51:51Z",
          "updatedAt": "2021-08-26T00:51:51Z"
        },
        {
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "body": "One important question we must address is the maximum number of aggregators in a protocol instantiation. We are already encountering places where [aggregators and clients must agree on the representation of the ID](https://github.com/abetterinternet/libprio-rs/pull/76).",
          "createdAt": "2021-09-14T21:23:50Z",
          "updatedAt": "2021-09-14T21:23:50Z"
        },
        {
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "body": "We've long since introduced a formal `Role` enumeration whose layout was chosen to allow adding more helpers in the future. Closing.",
          "createdAt": "2022-05-11T18:59:27Z",
          "updatedAt": "2022-05-11T18:59:27Z"
        }
      ]
    },
    {
      "number": 139,
      "id": "MDU6SXNzdWU5Nzg1NjkzNjk=",
      "title": "Clarify encoding, endianness of multi-byte values in HPKE application info and AAD strings",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/issues/139",
      "state": "CLOSED",
      "author": "tgeoghegan",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "We specify HPKE context construction and sealing like so:\r\n\r\n```\r\nenc, context = SetupBaseS(pk, \"pda input share\" || task_id || server_role)\r\npayload = context.Seal(time || nonce || extensions, input_share)\r\n```\r\n\r\nWe should be explicit about the encoding and endianness of these values. Since we use [TLS presentation language](https://datatracker.ietf.org/doc/html/rfc8446#section-3) on the wire, I think the natural thing is to use that encoding when constructing these strings. So `time` (which is a uint64 counting seconds since epoch start) should be big endian, `extensions` should be the TLS presentation language encoding of the `struct Extension`, and so on.",
      "createdAt": "2021-08-24T23:50:40Z",
      "updatedAt": "2021-12-30T00:54:23Z",
      "closedAt": "2021-12-30T00:54:23Z",
      "comments": [
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "TLS-syntax specifies the byte encoding of anything represented in it, including endianness.",
          "createdAt": "2021-12-29T22:15:04Z",
          "updatedAt": "2021-12-29T22:15:04Z"
        },
        {
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "body": "At the risk of being tediously pedantic: I think we should explicitly state that the TLS syntax encoding of various structs is what should go into application info and AAD strings, to rule out the possibility of implementations just `memcpy`ing a C struct in there, or a JSON string or something. I'm not sure what the IETF standard of pedantry is here though.",
          "createdAt": "2021-12-29T22:58:50Z",
          "updatedAt": "2021-12-29T22:58:50Z"
        },
        {
          "author": "ekr",
          "authorAssociation": "COLLABORATOR",
          "body": "I tend to think this is too pedantic, but if necessary, I would just say \"serialized\".",
          "createdAt": "2021-12-29T23:07:06Z",
          "updatedAt": "2021-12-29T23:07:06Z"
        },
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "I agree this is too pedantic, and I don't see a need to add the word \"serialized\".",
          "createdAt": "2021-12-29T23:25:08Z",
          "updatedAt": "2021-12-29T23:25:08Z"
        },
        {
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "body": "Fair enough, I am closing this issue then.",
          "createdAt": "2021-12-30T00:54:23Z",
          "updatedAt": "2021-12-30T00:54:23Z"
        }
      ]
    },
    {
      "number": 140,
      "id": "MDU6SXNzdWU5Nzg1ODI5NjU=",
      "title": "Specify how AEAD ciphertext and tag are represented in protocol messages",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/issues/140",
      "state": "CLOSED",
      "author": "tgeoghegan",
      "authorAssociation": "COLLABORATOR",
      "assignees": [
        "tgeoghegan"
      ],
      "labels": [],
      "body": "HPKE AEADs emit a ciphertext and a tag. HPKE doesn't specify for us how those two values should be represented, so we need to add some text explaining how the ciphertext and tag are combined into `EncryptedInputShare.payload` and `EncryptedOutputShare.encrypted_output_share` (we should probably also harmonize those field names because yuck).",
      "createdAt": "2021-08-25T00:20:40Z",
      "updatedAt": "2021-08-25T19:25:06Z",
      "closedAt": "2021-08-25T19:25:05Z",
      "comments": [
        {
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "body": "This is a non-issue: having re-read the HPKE spec as well as RFC5116 and RFC8439, there are unambiguous descriptions of how to represent `(ciphertext, tag)` for all the AEAD algorithms supported by HPKE ([AES-128-GCM and AES-256-GCM](https://datatracker.ietf.org/doc/html/rfc5116#section-5.1) and [ChaCha20Poly1305](https://datatracker.ietf.org/doc/html/rfc8439#section-2.8). So we do not need to specify it further at the PPM layer.",
          "createdAt": "2021-08-25T19:25:05Z",
          "updatedAt": "2021-08-25T19:25:05Z"
        }
      ]
    },
    {
      "number": 141,
      "id": "MDU6SXNzdWU5Nzk0NzMzODI=",
      "title": " Aggregate phase needs to end with both sides agreeing on which shares are valid",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/issues/141",
      "state": "OPEN",
      "author": "ekr",
      "authorAssociation": "COLLABORATOR",
      "assignees": [
        "chris-wood"
      ],
      "labels": [],
      "body": "Note from today's call: the CFRG documents need to specify that after the aggregate phase, the helper and leader need to agree to which shares are valid. Depending on the crypto, this may require the leader to tell the helper which ones were valid, if the helper doesn't get the proof result.",
      "createdAt": "2021-08-25T17:41:27Z",
      "updatedAt": "2021-10-12T20:22:53Z",
      "closedAt": null,
      "comments": [
        {
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "body": "I believe @cjpatton wants to address this.",
          "createdAt": "2021-08-25T18:05:23Z",
          "updatedAt": "2021-08-25T18:05:23Z"
        },
        {
          "author": "ekr",
          "authorAssociation": "COLLABORATOR",
          "body": "Yep, I was just making a note so we didn't forget.\n\nOn Wed, Aug 25, 2021 at 11:05 AM Tim Geoghegan ***@***.***>\nwrote:\n\n> I believe @cjpatton <https://github.com/cjpatton> wants to address this.\n>\n> \u2014\n> You are receiving this because you authored the thread.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/abetterinternet/prio-documents/issues/141#issuecomment-905757569>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/AAIPLIJSHEOWSCKNGDPVW2TT6UWG7ANCNFSM5CZUDJBA>\n> .\n> Triage notifications on the go with GitHub Mobile for iOS\n> <https://apps.apple.com/app/apple-store/id1477376905?ct=notification-email&mt=8&pt=524675>\n> or Android\n> <https://play.google.com/store/apps/details?id=com.github.android&utm_campaign=notification-email>\n> .\n>\n",
          "createdAt": "2021-08-25T18:14:51Z",
          "updatedAt": "2021-08-25T18:14:51Z"
        },
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "Wood and I spoke and decided he would be the best one to take this issue.",
          "createdAt": "2021-08-26T00:54:10Z",
          "updatedAt": "2021-08-26T00:54:10Z"
        },
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "Options discussed so far:\r\n1. Have the helper wait for an ACK from the leader before aggregating its output share\r\n2. If the helper fails to respond to the request for some reason, have the leader \"rewind\" the helpers state, either by replaying the previous helper state (may impact anti-replay) or with a special \"compensation request\", which has the helper deduct the last output share form the total (Robert's idea).\r\n3. Run the protocol with multiple sets of helpers so that, if a fault occurs in one run, another run can be used.",
          "createdAt": "2021-10-12T15:00:12Z",
          "updatedAt": "2021-10-12T15:00:12Z"
        },
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "@chris-wood pointed this out, which should be useful: https://en.wikipedia.org/wiki/Two-phase_commit_protocol",
          "createdAt": "2021-10-12T20:22:53Z",
          "updatedAt": "2021-10-12T20:22:53Z"
        }
      ]
    },
    {
      "number": 144,
      "id": "MDU6SXNzdWU5ODE1MzI5MzM=",
      "title": "Need LICENSE.md",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/issues/144",
      "state": "CLOSED",
      "author": "ekr",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "Right now this is empty. I propose that we do CC-0. Assuming people agree, I'll update LICENSE.md",
      "createdAt": "2021-08-27T19:25:48Z",
      "updatedAt": "2021-12-08T15:29:26Z",
      "closedAt": "2021-12-08T15:29:26Z",
      "comments": [
        {
          "author": "stpeter",
          "authorAssociation": "COLLABORATOR",
          "body": "CC0 seems fine, since the I-D will eventually just get licensed under IETF IPR rules anyway.",
          "createdAt": "2021-09-08T17:07:28Z",
          "updatedAt": "2021-09-08T17:07:28Z"
        },
        {
          "author": "stpeter",
          "authorAssociation": "COLLABORATOR",
          "body": "Or we could do something like this: https://github.com/yaronf/I-D/blob/main/LICENSE.md (however, I'm not sure what the best practice is, I don't see anything about it in RFC 8874, and even repositories like https://github.com/quicwg/base-drafts don't have a LICENSE.md file).",
          "createdAt": "2021-09-08T20:14:26Z",
          "updatedAt": "2021-09-08T20:14:26Z"
        },
        {
          "author": "ekr",
          "authorAssociation": "COLLABORATOR",
          "body": "What I'm trying to do here is have our initial submission actually have\nbroader terms than the IETF terms.\n\nOn Wed, Sep 8, 2021 at 1:14 PM Peter Saint-Andre ***@***.***>\nwrote:\n\n> Or we could do something like this:\n> https://github.com/yaronf/I-D/blob/main/LICENSE.md (however, I'm not sure\n> what the best practice is, I don't see anything about it in RFC 8874, and\n> even repositories like https://github.com/quicwg/base-drafts don't have a\n> LICENSE.md file).\n>\n> \u2014\n> You are receiving this because you authored the thread.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/abetterinternet/prio-documents/issues/144#issuecomment-915538252>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/AAIPLIL2Q2HQXP7XXRRSV6LUA6725ANCNFSM5C6EWILQ>\n> .\n> Triage notifications on the go with GitHub Mobile for iOS\n> <https://apps.apple.com/app/apple-store/id1477376905?ct=notification-email&mt=8&pt=524675>\n> or Android\n> <https://play.google.com/store/apps/details?id=com.github.android&referrer=utm_campaign%3Dnotification-email%26utm_medium%3Demail%26utm_source%3Dgithub>.\n>\n>\n",
          "createdAt": "2021-09-08T21:22:54Z",
          "updatedAt": "2021-09-08T21:22:54Z"
        },
        {
          "author": "stpeter",
          "authorAssociation": "COLLABORATOR",
          "body": "Makes sense. Some folks seem to think that CC0 / PD / Unlicense doesn't stick in certain locales because you have to assert copyright first. CC-BY feels weird, too, because the question is \"by whom\" (just the spec authors?). I'll ask someone at Mozilla about it.",
          "createdAt": "2021-09-08T21:36:56Z",
          "updatedAt": "2021-09-08T21:36:56Z"
        },
        {
          "author": "stpeter",
          "authorAssociation": "COLLABORATOR",
          "body": "If CC0 doesn't work, our resident expert at Mozilla suggested that we might consider WHATWG licensing (which is likely palatable to the relevant stakeholders):\r\n\r\n> This work is licensed under a Creative Commons Attribution 4.0 International License. To the extent portions of it are incorporated into source code, such portions in the source code are licensed under the BSD 3-Clause License instead.",
          "createdAt": "2021-09-09T16:17:22Z",
          "updatedAt": "2021-09-09T16:17:22Z"
        }
      ]
    },
    {
      "number": 146,
      "id": "MDU6SXNzdWU5ODMzNDU2NTc=",
      "title": "How should servers figure out which task a message pertains to?",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/issues/146",
      "state": "CLOSED",
      "author": "tgeoghegan",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [
        "parking-lot"
      ],
      "body": "Aggregators are expected to have an endpoint `hpke_config` from which they vend the HPKE public key and parameters so that clients may encrypt the contents of reports. There are no parameters to the `hpke_config` request, so there is no opportunity for an aggregator to provide a different config based on the task in play.\r\n\r\nNow, the `hpke_config` endpoint is relative to the aggregator's base endpoint URL, obtained from the per-task parameters, so an aggregator could simply provide base URLs that have the task ID in their path and use different key material on that basis. But all the other protocol messages like `Report` or `CollectReq` explicitly include task ID, suggesting that aggregators are supposed to be able to service multiple tasks from a single endpoint. Something feels inconsistent there.",
      "createdAt": "2021-08-31T01:24:49Z",
      "updatedAt": "2022-05-11T22:26:15Z",
      "closedAt": "2022-05-11T22:26:15Z",
      "comments": [
        {
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "body": "I think we could change the endpoint to `[aggregator]/hpke_config/<task_id>`. We would probably have to redefine task ID to make sure it's safe to use in URL construction (URL encoded byte strings look terrible).",
          "createdAt": "2021-08-31T01:26:36Z",
          "updatedAt": "2021-08-31T01:26:54Z"
        },
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "Good catch, and I like your suggested fix.",
          "createdAt": "2021-08-31T01:26:58Z",
          "updatedAt": "2021-08-31T01:26:58Z"
        },
        {
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "body": "I could swear we talked about this a long time ago. Anyway, I am putting this in `parking-lot` for now because I don't think any progress is blocked on it, and it strikes me as the kind of thing that we will go back and forth on a lot during the IETF process. ",
          "createdAt": "2021-08-31T01:40:18Z",
          "updatedAt": "2021-08-31T01:40:18Z"
        },
        {
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "body": "I think the real issue here is that when handling a message, collectors, leaders and helpers need to know which task it pertains to in order to select the appropriate HPKE context (among other parameters). We should decide whether the task ID appears in protocol messages or whether it can be inferred from the endpoint and be consistent about it. Retitling accordingly.",
          "createdAt": "2022-01-21T02:11:16Z",
          "updatedAt": "2022-01-21T02:11:29Z"
        },
        {
          "author": "BranLwyd",
          "authorAssociation": "COLLABORATOR",
          "body": "nit: IMO it would be more consistent to put the task ID in a `/hpke_config` request into the request body -- all other request/response pairs include the task ID in the request body, rather than including it in the request path.\r\n\r\n(There's no technical downside to putting the task ID in the path, this is only a \"consistency\" concern.)",
          "createdAt": "2022-04-01T04:09:16Z",
          "updatedAt": "2022-04-01T04:09:16Z"
        },
        {
          "author": "divergentdave",
          "authorAssociation": "COLLABORATOR",
          "body": "I think the issue with putting the task ID for a /hpke_config request in the body is that we have to switch from GET to POST, and lose cache-ability.",
          "createdAt": "2022-04-01T04:11:44Z",
          "updatedAt": "2022-04-01T04:11:44Z"
        },
        {
          "author": "BranLwyd",
          "authorAssociation": "COLLABORATOR",
          "body": "That's a good point -- it's still pretty unsatisfying that this one request/response pair will have to be structured in this way, while all other request/response pairs (Upload, Aggregate, AggregateShare, Collect) use a different structuring.\r\n\r\nHowever, given that some clients will literally be web browsers, where HTTP caching is \"free\", I think it's worthwhile to keep HTTP caching semantics working.",
          "createdAt": "2022-04-01T16:26:06Z",
          "updatedAt": "2022-04-01T16:26:06Z"
        },
        {
          "author": "BranLwyd",
          "authorAssociation": "COLLABORATOR",
          "body": "(FWIW, this would be a great place to use [HTTP QUERY](https://www.ietf.org/id/draft-ietf-httpbis-safe-method-w-body-02.html) which is \"GET but with a body\", except that (a) it's still not standardized and (b) even if it were, it's still new enough that many HTTP libraries won't have good support for it.)",
          "createdAt": "2022-04-01T17:25:37Z",
          "updatedAt": "2022-04-01T17:25:37Z"
        },
        {
          "author": "BranLwyd",
          "authorAssociation": "COLLABORATOR",
          "body": "One final thought for now: if we do stick to a GET request, we should consider putting the task ID for an `/hpke_config` request in a query parameter (e.g. `/hpke_config?task_id=foo`) rather than including it as part of the request path. Otherwise, every other request type will duplicate the task ID in both the request path & the request body.",
          "createdAt": "2022-04-01T20:56:57Z",
          "updatedAt": "2022-04-01T20:56:57Z"
        },
        {
          "author": "divergentdave",
          "authorAssociation": "COLLABORATOR",
          "body": "The `/hpke_config` endpoint has been changed to take the task ID as a query parameter, and all other messages include a task ID in the body. Should we close this out?",
          "createdAt": "2022-05-11T21:51:57Z",
          "updatedAt": "2022-05-11T21:51:57Z"
        },
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "Closed by #236 ",
          "createdAt": "2022-05-11T22:26:15Z",
          "updatedAt": "2022-05-11T22:26:15Z"
        }
      ]
    },
    {
      "number": 148,
      "id": "MDU6SXNzdWU5OTIyOTUyNzA=",
      "title": "rename this repository",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/issues/148",
      "state": "CLOSED",
      "author": "bdaehlie",
      "authorAssociation": "NONE",
      "assignees": [],
      "labels": [],
      "body": "I think we should rename this repository since we aren't using the term Prio to describe it any more. Consistent naming of resources helps with internal and external communication about this work.",
      "createdAt": "2021-09-09T14:26:33Z",
      "updatedAt": "2021-09-09T19:39:39Z",
      "closedAt": "2021-09-09T19:39:39Z",
      "comments": [
        {
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "body": "@chris-wood suggested `ppm-specification`. If nobody objects I will rename this repository this afternoon.",
          "createdAt": "2021-09-09T15:40:06Z",
          "updatedAt": "2021-09-09T15:40:06Z"
        },
        {
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "body": "Done!",
          "createdAt": "2021-09-09T19:39:39Z",
          "updatedAt": "2021-09-09T19:39:39Z"
        }
      ]
    },
    {
      "number": 150,
      "id": "I_kwDOFEJYQs47dnPe",
      "title": "Can `AggregateReq`/`VerifyReq`s span multiple batch windows, and what is the scope of a `helper_state` blob?",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/issues/150",
      "state": "CLOSED",
      "author": "tgeoghegan",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "Section 4.3 discusses the `helper_state` opaque blob, which is carried across successive `AggregateReq/Resp` messages as well as `OutputShareReq`. However we don't discuss the scope of a helper state blob. I think the only way it makes sense is if the leader maintains a helper state blob for each PPM task, but the text should be explicit about this. ",
      "createdAt": "2021-09-16T00:04:22Z",
      "updatedAt": "2022-05-11T18:57:54Z",
      "closedAt": "2022-05-11T18:57:54Z",
      "comments": [
        {
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "body": "@ekr points out that we need to think about parallelism here. If, as I asserted, `helper_state` is per-task, then that means leader needs to guarantee that at most one `AggregateReq` is in flight for any task, to prevent concurrent modifications to the helper's state blob. We might want to constrain the aggregate protocol in a way that enables finer-grained state blobs to permit multiple aggregate protocol runs to occur in parallel. ekr's suggestion is to require that an `AggregateReq` only contain reports from a single batch interval, at which point the scope of a helper state blob can be (task, batch interval) which enables much greater parallelism.",
          "createdAt": "2021-09-23T00:47:26Z",
          "updatedAt": "2021-09-23T00:47:26Z"
        },
        {
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "body": "`helper_state` is gone as of #185, and aggregation job IDs provide more obvious answers for parallelizing input preparation.",
          "createdAt": "2022-05-11T18:57:54Z",
          "updatedAt": "2022-05-11T18:57:54Z"
        }
      ]
    },
    {
      "number": 153,
      "id": "I_kwDOFEJYQs48NCFj",
      "title": "Clarify need for client-provided timestamps & replay protection",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/issues/153",
      "state": "CLOSED",
      "author": "BranLwyd",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "Clients in the PPM send a client-generated `(timestamp, nonce)` tuple with their upload requests, and encrypt their reports using a nonce that is derived from this `(timestamp, nonce)` tuple. [section 4.2.2]\r\n\r\nThe aggregators use the `(timestamp, nonce)` tuple as a unique identifier for an individual report, to enable an \"anti-replay\" mechanism described in section 4.4.2. The reasoning for this anti-replay mechanism is described as:\r\n\r\n> Using a report multiple times within a single batch, or using the same report in multiple batches, is considered a privacy violation.\r\n\r\nI argue that this mechanism does not practically stop any of the actors from submitting some arbitrary report multiple times in a single batch (i.e. \"ballot-stuffing\"): malicious clients can effectively replay any of their reports by re-submitting the report content re-encrypted with a new `(timestamp, nonce)` tuple; malicious servers can effectively pose as a client and perform the described \"malicious client\" attack themselves.\r\n\r\nBut per discussion with timg@, the purpose of the anti-replay mechanism is not to stop a malicious client/server from doing arbitrary ballot-stuffing; it is to protect a malicious leader from using the same legitimate *client-provided* report multiple times, which could enable certain attacks on client privacy.\r\n\r\nSeparately, there is currently nothing in the spec placing any requirements or server validations on the timestamp value. A misconfigured or malicious client could send a \"poisoned\" report with a timestamp of `MAX_UINT64`. As the leader must send reports to the helper ordered by `(timestamp, nonce)` [sections 4.3.1, 4.4.2], once this report was sent to the helper as part of an aggregation request the leader would no longer be able to submit any additional reports (and if it tried, the helper would silently filter them).\r\n\r\nSeparately (again), message deduplication based on a total ordering of message timestamps will lead to messages that are received in a delayed fashion being dropped, since the leader will no longer be able to include them in aggregation requests. (The same effect would be seen if a misconfigured/malicious client sent a message timestamped forward to the end of the current batch; this is very similar to the \"poisoned report\" issue above, but somewhat more inherent to the ordering-based deduplication mechanism.)\r\n\r\nProposals:\r\n* Update the explanation of the anti-replay mechanism to describe the intended protection more explicitly, i.e. that it covers only replay of messages sent by a client, with replay attempted by the server (I think).\r\n* Think through and add server validation on the client-submitted timestamp. For example, we might decide that only reports in the current batch, or a previous batch falling within a \"grace window\", are allowed. (I am unsure if this would be acceptable for Heavy Hitters or other PPM algorithms that require a more \"online\" query capability.)\r\n* Consider switching away from an ordering-based deduplication system entirely, as it depends on ordering information that cannot be reliably provided by the clients & because it will cause delayed messages to be dropped. Whatever replaces the ordering-based deduplication mechanism will likely require more storage than the ordering-based mechanism, but this might be mitigated by bounding what reports can be accepted by a time or `batch_id` window.\r\n* Consider switching clients from reporting a timestamp to reporting a `batch_id` counter. The current timestamp-based report could be mapped to a batch ID by something like `timestamp / batch_window_duration` (though using a counter opens up the possibility of other methods of determining the current `batch_id`). Reports should still be deduplicated by the `(batch_id, nonce)` tuple. (The ordering-based deduplication mechanism would no longer work.)\r\n",
      "createdAt": "2021-09-28T18:00:13Z",
      "updatedAt": "2021-10-25T19:54:13Z",
      "closedAt": "2021-10-25T19:54:13Z",
      "comments": [
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "I like how the linked PR solves this. Before closing this issue, however, we might consider being a bit more prescriptive, along the lines of https://datatracker.ietf.org/doc/html/rfc8446#section-8.2 (thanks @ekr for the link)",
          "createdAt": "2021-10-06T16:31:06Z",
          "updatedAt": "2021-10-06T16:31:06Z"
        }
      ]
    },
    {
      "number": 155,
      "id": "I_kwDOFEJYQs48Vf9H",
      "title": "Authenticate collect/output share request parameters from collector to helper",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/issues/155",
      "state": "OPEN",
      "author": "tgeoghegan",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "During execution of the collect protocol, the leader is responsible for relaying some parameters of the collect request to the helper, represented by the opaque `output_param` in `CollectReq` and `OutputShareReq` messages introduced by #154. That parameter will always be null/empty/absent for Priov3, but in Hits, it would contain the string prefixes that the collector wants a count of in the result set (and who knows what else in yet-undefined VDAFs).\r\n\r\nIt's currently possible for the leader (or any actor that can tamper with messages on the network) to insert arbitrary `output_param` into `OutputShareReq` messages. @cjpatton reckons [this is a threat to soundness](https://github.com/abetterinternet/ppm-specification/pull/154#discussion_r718917818). We should think about whether this enables the leader to undermine soundness in any ways beyond the capabilities the threat model already grants it, and if so, introduce collector->helper authentication+integrity. ~Confidentiality~Privacy may not be needed on here because the `output_param` should be identical for helper and leader.",
      "createdAt": "2021-09-30T14:43:08Z",
      "updatedAt": "2021-10-08T20:05:52Z",
      "closedAt": null,
      "comments": [
        {
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "body": "Note that we already protect helper->collector messages with HPKE. Since both sides already advertise HPKE configs, one solve here would be to use that to tunnel a mutually authenticated channel through the leader.",
          "createdAt": "2021-09-30T14:44:46Z",
          "updatedAt": "2021-09-30T14:44:46Z"
        },
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "This is misrepresenting the problem slightly. I think the key points are:\r\n1. For soundness we assume both aggregators are honest. Regardless, a network attacker can currently impersonate the leader to the helper because the leader is not authenticated and violate soundness. This is outside of the model for VDAF, but is one of our security considerations for the PPM protocol. This needs to be addressed.\r\n2. For privacy (note that this is not the same thing as confidentiality) we assume just one of the aggregators is honest. The dishonest aggregator may act arbitrarily, including forging the output parameter or the helper's encrypted input share itself. Authentication of the channel can't help us here.\r\n\r\nAs far as the mechanism for leader authentication: auth-mode for HPKE is a promising direction. One thing we need to think through is whether KCI attacks matter for our setting, since HPKE auth-mode is vulnerable to these: https://www.ietf.org/archive/id/draft-irtf-cfrg-hpke-12.html#sec-properties\r\n\r\n",
          "createdAt": "2021-09-30T15:10:53Z",
          "updatedAt": "2021-09-30T17:28:28Z"
        },
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "Another option for leader authentication is client certificates for TLS.",
          "createdAt": "2021-09-30T17:29:09Z",
          "updatedAt": "2021-09-30T17:29:09Z"
        },
        {
          "author": "ekr",
          "authorAssociation": "COLLABORATOR",
          "body": "The text implies that we are doing mutual authentication, but it should be hoisted into the protocol definition\r\n```faithfully as specified. The system also assumes that servers communicate over\r\nsecure and mutually authenticated channels. In practice, this can be done by TLS\r\nor some other form of application-layer authentication.\r\n```",
          "createdAt": "2021-10-08T20:05:52Z",
          "updatedAt": "2021-10-08T20:05:52Z"
        }
      ]
    },
    {
      "number": 158,
      "id": "I_kwDOFEJYQs484ixL",
      "title": "Diagrams",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/issues/158",
      "state": "OPEN",
      "author": "coopdanger",
      "authorAssociation": "CONTRIBUTOR",
      "assignees": [],
      "labels": [],
      "body": "To make this document more understandable for those uninitiated in the IETF community, it would be helpful to add some ladder diagrams or a state machine diagram or something early in the document to show the overall flow of exchanges between the different entities involved.",
      "createdAt": "2021-10-08T20:55:06Z",
      "updatedAt": "2021-10-08T20:55:06Z",
      "closedAt": null,
      "comments": []
    },
    {
      "number": 161,
      "id": "I_kwDOFEJYQs497hbc",
      "title": "Rotation of shared secrets in PPM task parameters",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/issues/161",
      "state": "OPEN",
      "author": "tgeoghegan",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "The [VDAF spec](https://datatracker.ietf.org/doc/html/draft-patton-cfrg-vdaf-00) describes how to generate `verify_params` for aggregators in `prio3` and `poplar1`. The verification parameters MUST be kept secret from other clients, which means that they may need to be rotated either if some aggregator's verification parameter is exposed or if a sufficient number of inputs are processed under some verification parameter (this would take a huge number of inputs to be a problem).",
      "createdAt": "2021-10-28T22:49:33Z",
      "updatedAt": "2022-04-15T18:52:01Z",
      "closedAt": null,
      "comments": [
        {
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "body": "It may suffice to discuss this abstractly in security considerations and otherwise declare rotation of task parameters to be out-of-band with the PPM protocol, as we already do for initial parameter establishment.",
          "createdAt": "2021-10-28T22:50:27Z",
          "updatedAt": "2021-10-28T22:50:27Z"
        },
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "I think this is going to need to be specified. If it's done incorrectly, it could become an attack vector.\r\n\r\nBoth Prio v1 [[CGB17]] and Poplar [[BBCGGI21]] require per-report randomness for validating the recovered output shares. For robustness, it is important that the aggregators agree on fresh randomness that is unpredictable to the client. Otherwise it might be possible for a malicious client to garble the aggregate result.\r\n\r\nFor privacy the picture is murkier. The key question is whether a malicious aggregator can, by controlling the random input the helper consumes, cause the helper to leak information about the measurement. It's possible that the answer depends on the protocol:\r\n- For Prio v1 [[CGB17]], it seems to be just fine for the leader to just pick the randomness and send it to the helper. (See [[CGB17], Section 4.2, Step 3a].)\r\n- For Poplar [[BBCGGI21]], the process by which the shared randomness is established is unspecified (See [[BBCGGI21], Appendix C.4.].) It may be OK for the leader to just pick it, but this is not guaranteed.\r\n- For schemes based on techniques in [[BBCGGI19]], including `prio3` in the VDAF draft, as well as the code running in ENPA, the situation is similar: The distributed ZKP system described in [[BBCGGI19], Section 6.2] makes use of an \"ideal coin-flipping functionality\" (see Definition 6.3), which in practice would have to be realized by an actual protocol. Incidentally, I believe ENPA effectively realizes this ideal coin-flipping functionality by having a third party choose the randomness. (Can you confirm, @tgeoghegan?)\r\n\r\nFor PPM we know we'll need a procedure for establishing a shared secret among the aggregators, which will be used to derive per-report randomness by the VDAF. What's not clear right now is what security properties this procedure needs to have in order for PPM to meet its privacy goals. Either (1) the procedure is irrelevant to privacy, i.e., the share secret may be chosen by the adversary, or (2) we need a protocol that realizes the ideal coin flipping functionality described in [[BBCGGI19], Definition 6.3]. Or, perhaps there's something in between.\r\n\r\nIf (1), then we could just have the leader run the VDAF setup procedure and send the shared secret to the helper over a secure channel. If (2), then we'll have to do something more sophisticated. [[BBCGGI19], Section 6.1] points to some papers we can explore. As a straw man, could it be as simple as having each aggregator commit to some initial key material, then derive the shared secret from key material provided by each aggregator? (Something along the lines of https://en.wikipedia.org/wiki/Commitment_scheme#Bit-commitment_in_the_random_oracle_model?)\r\n\r\ncc/ @henrycg in case you have thoughts here or can point us in the right direction.\r\ncc/ @chris-wood since we spoke about this recently.\r\n\r\n[CGB17]: https://crypto.stanford.edu/prio/paper.pdf\r\n[BBCGGI19]: https://eprint.iacr.org/2019/188.pdf\r\n[BBCGGI21]: https://eprint.iacr.org/2021/017.pdf",
          "createdAt": "2021-12-30T02:07:34Z",
          "updatedAt": "2022-01-11T17:40:04Z"
        },
        {
          "author": "henrycg",
          "authorAssociation": "COLLABORATOR",
          "body": "The commit-then-open coin-flipping protocol you mention is pretty simple and is general enough to cover the randomness needs of Prio, Heavy Hitters, and probably any future schemes as well. The only downside is that it adds another round of interaction between the servers.\r\n\r\nIf you want the leader to be able to unilaterally pick the randomness, let me know and I can check back through the Heavy Hitters paper to make sure that that would be safe in the HH context. I suspect it would be fine, but I would want to check carefully.",
          "createdAt": "2021-12-31T10:08:23Z",
          "updatedAt": "2021-12-31T10:08:23Z"
        },
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "I think my preference would be to take (2), since it's more conservative. However, it would be great to know if (1) is a possibility. We'd be much obliged if you could take a careful look at the HH paper and see if this will work. While at it, it would be great to know if [[BBCGGI19](https://eprint.iacr.org/2019/188), Theorem 6.6] falls apart if we replace the ideal coin-flipping functionality with the leader choosing the randomness unilaterally.",
          "createdAt": "2021-12-31T16:28:54Z",
          "updatedAt": "2021-12-31T16:28:54Z"
        },
        {
          "author": "henrycg",
          "authorAssociation": "COLLABORATOR",
          "body": "Okay, I will add this to my queue. It may take a week or two, but I will follow up once I have taken a closer look.",
          "createdAt": "2022-01-01T09:05:47Z",
          "updatedAt": "2022-01-01T09:05:47Z"
        },
        {
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "body": "> Incidentally, I believe ENPA effectively realizes this ideal coin-flipping functionality by having a third party choose the randomness.\r\n\r\nIn ENPA, a random value is chosen for each report by the ingestion servers that get input shares from clients and batch them up to be forwarded to aggregators.",
          "createdAt": "2022-01-03T20:56:52Z",
          "updatedAt": "2022-01-03T20:56:52Z"
        },
        {
          "author": "henrycg",
          "authorAssociation": "COLLABORATOR",
          "body": "I just read back through the Poplar (S&P'21) and BBCGGI19 papers and chatted with my co-authors. The bottom line, barring and bugs in our thinking, is:\r\n\r\n- For Poplar, the situation is as with Prio v1: the leader can choose the randomness and this has no effect on the zero-knowledge property of the proof system.\r\n- For BBCGGI19, if you are using the proof system of Example 5.6 with the compiler of Section 6.2, then again the leader can safely choose the randomness used to check the proof. (If you use some other base proof system\u2014not the one from Example 5.6 nor the ones like it\u2014then it might not be safe for the leader to choose the randomness.)\r\n\r\nYuval Ishai, a co-author on both of these papers, pointed out that the Fiat-Shamir trick (see Section 6.2.3 of BBCGGI19) applies to all three of these proof systems: Prio v1, Poplar, and BBCGGI19. So, you could potentially use Fiat-Shamir to avoid the need for the leader or anyone else to choose the randomness. The Fiat-Shamir trick only works if you have set up the underlying proof system to have soundness error ~2^{-128}, so if you are using a 64-bit modulus then Fiat-Shamir may not be useful.",
          "createdAt": "2022-01-11T14:05:15Z",
          "updatedAt": "2022-01-11T14:05:15Z"
        },
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "> * For BBCGGI19, if you are using the proof system of Example 5.6 with the compiler of Section 6.2, then again the leader can safely choose the randomness used to check the proof. (If you use some other base proof system\u2014not the one from Example 5.6 nor the ones like it\u2014then it might not be safe for the leader to choose the randomness.)\r\n\r\nI'm fairly certain what we've implemented meets this criterion, but I want to be really careful here, since what we've implemented diverges somewhat from what's in the paper. (@henrycg, you and I spoke over email about the differences.) Let me spell this out so we're all on the same page.\r\n\r\nThe prio3 VDAF is designed to work with any [1.5-round, public-coin IOP](https://cjpatton.github.io/vdaf/draft-patton-cfrg-vdaf.html#name-fully-linear-proof-flp-syst). We refer to this primitive simply as an FLP (\"Fully Linear Proof\") system in the VDAF spec. [Our concrete FLP implementation](https://docs.rs/prio/latest/prio/pcp/index.html) is based on Theorem 4.3 and includes a couple generalizations. Namely:\r\n\r\n* The validity circuit takes an optional random input, which admits constructions like the SIMD circuit of Theorem 5.3. (The random input is called the \"joint randomness\" in the VDAF spec. It is generated by applying the Fiat-Shamir trick of Section 6.2.3.)\r\n* The validity circuit may contain multiple gadgets as suggested in Remark 4.5.\r\n\r\nIncidentally, while these changes were already suggested by BBCGGI19, they are significant enough to warrant a fresh security proof. Note that this FLP is not yet specified in the VDAF draft -- I plan to do so in the coming weeks. That way we'll have a concrete target for analysis.\r\n\r\n \r\n> Yuval Ishai, a co-author on both of these papers, pointed out that the Fiat-Shamir trick (see Section 6.2.3 of BBCGGI19) applies to all three of these proof systems: Prio v1, Poplar, and BBCGGI19. So, you could potentially use Fiat-Shamir to avoid the need for the leader or anyone else to choose the randomness. The Fiat-Shamir trick only works if you have set up the underlying proof system to have soundness error ~2^{-128}, so if you are using a 64-bit modulus then Fiat-Shamir may not be useful.\r\n\r\nIn the prio3 VDAF, we already do the Fiat-Shamir trick for the joint randomness in order to avoid interaction between the client and aggregators during the upload phase. It's a nice observation that we could extend this to also encompass the randomness used by the aggregators. (We call this the \"query randomness\" in the VDAF spec.) However, it may not be worth the extra computational cost for the client, since it doesn't save latency in the aggregation phase.\r\n\r\nIncidentally, we have not yet implemented a large enough field: See https://github.com/abetterinternet/libprio-rs/issues/106.\r\n\r\nCan you say a bit more about how this would work for Poplar? My understanding is that, since the client doesn't know in advance what candidate prefixes will be used to query its IDPF shares, it has know way of generating the challenge randomness that will be used for the secure sketch.\r\n ",
          "createdAt": "2022-01-11T21:00:35Z",
          "updatedAt": "2022-01-11T21:54:57Z"
        },
        {
          "author": "henrycg",
          "authorAssociation": "COLLABORATOR",
          "body": "> Can you say a bit more about how this would work for Poplar? My understanding is that, since the client doesn't know in advance what candidate prefixes will be used to query its IDPF shares, it has know way of generating the challenge randomness that will be used for the secure sketch.\r\n\r\nThe idea for Poplar (roughly) is that the servers would derive the randomness used in the sketch by hashing their shares of the client's submission. Since the sketch-verification process does not require the servers to interact with the client, I think it's okay that the client does not know at the time of submission exactly which vector the servers will sketch. It is certainly possible that I m missing something here.\r\n\r\nI agree that using Fiat-Shamir here may not be worth the extra cost and complexity.",
          "createdAt": "2022-01-12T08:19:48Z",
          "updatedAt": "2022-01-12T08:19:48Z"
        },
        {
          "author": "schoppmp",
          "authorAssociation": "NONE",
          "body": "@cjpatton and I have been discussing this in cjpatton/vdaf#18, and I think we should review carefully whether it would make sense to rotate `verify_params` more often. More concretely, I believe it would be good to generate the verification randomness only *after* a set of client shares to verify has been agreed on, and to re-generate it for every such set of shares.\r\n\r\nThe reason is that in a real deployment, it might be easier to ensure that the right code is being run (i.e., the aggregation server behaves semi-honestly), than to ensure confidentiality of the aggregation server's state. Now if we fix the verification randomness in advance, an attacker learning it could then create a malicious client share that would pass the verification.",
          "createdAt": "2022-01-28T12:02:38Z",
          "updatedAt": "2022-01-28T12:02:38Z"
        },
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "I agree that PPM needs to make sure that frequent key rotation for VDAFs needs to be as ergonomic as possible.",
          "createdAt": "2022-01-28T15:59:06Z",
          "updatedAt": "2022-01-28T15:59:06Z"
        },
        {
          "author": "BranLwyd",
          "authorAssociation": "COLLABORATOR",
          "body": "We should resolve rotation of `verify_param` for PPM soon, now that we are moving forward with implementation. AFAICT there is currently no specification-compliant way for `verify_param` to be rotated.\r\n\r\nSpecifically, given that we are working in a distributed environment, we would need to support multiple versions of `verify_params` live at once for a single `task`. There are two basic strategies for rotating secrets in a distributed environment that I have encountered before, but I have concerns with both of them:\r\n\r\n1) Include a \"`verify_param` version identifier\" value that determines which \"version\" of the `verify_param` to use. AFAICT nothing like this is currently specified anywhere in PPM or VDAF. This would be a simple/straightforward solution, but would increase communication costs somewhat & would need to be specified.\r\n\r\n2) Try all of the `verify_param`s we know about. However, given the way that `verify_param` is used as part of `prep_init` to transform an input share into an initial preparation state, I'm not sure this is feasible: a helper would not know if the `verify_param` it chose was correct until after the next round of communication with the leader, since \"correct\" in this case means \"the same as the `verify_param` chosen by the leader\". And if the helper chose an incorrect `verify_param`, I believe this would lead to a transition to an `INVALID` state in the leader's state machine, so the helper couldn't try another `verify_param`.\r\n\r\nBarring a third option (or an error in analysis of the two options above), I think this needs to be addressed at the specification level.",
          "createdAt": "2022-04-15T18:43:53Z",
          "updatedAt": "2022-04-15T18:43:53Z"
        },
        {
          "author": "BranLwyd",
          "authorAssociation": "COLLABORATOR",
          "body": "> @cjpatton and I have been discussing this in [cjpatton/vdaf#18](https://github.com/cjpatton/vdaf/issues/18), and I think we should review carefully whether it would make sense to rotate `verify_params` more often. More concretely, I believe it would be good to generate the verification randomness only _after_ a set of client shares to verify has been agreed on, and to re-generate it for every such set of shares.\r\n\r\nThere is currently some text in the VDAF spec that suggests that `public_param` held by the clients needs to match with the `verify_param`:\r\n\r\n> CP The public_param is intended to allow for protocols that require the Client to use a public key for sharding its measurement. When rotating the verify_param for such a scheme, it would be necessary to also update the public_param with which the clients are configured. For PPM it would be nice if we could rotate the verify_param without also having to update the clients. We should consider dropping this at some point. See https://github.com/cjpatton/vdaf/issues/19.\r\n\r\nI think this is incompatible with the suggestion to generate `verify_params` after receiving the client report. But, if we want to go this way, perhaps the right answer is to drop the `public_param`? It's not used by either `prio3` or `poplar1`; and from the perspective of PPM, it would make things easier by allowing rotation of `verify_params` without coordination with the clients.",
          "createdAt": "2022-04-15T18:52:00Z",
          "updatedAt": "2022-04-15T18:52:00Z"
        }
      ]
    },
    {
      "number": 163,
      "id": "I_kwDOFEJYQs4-XTJo",
      "title": "Aggregators should inform collector of contribution count in collect response",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/issues/163",
      "state": "CLOSED",
      "author": "tgeoghegan",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "Collectors will want to know how many inputs are included in the aggregations they receive, for a number of reasons: they may wish to compute a mean over a privately aggregated sum, or track metrics on how many clients are providing inputs. struct `CollectResp` should include a count of how many contributions went into an aggregation.",
      "createdAt": "2021-11-05T22:55:01Z",
      "updatedAt": "2022-03-04T22:18:05Z",
      "closedAt": "2022-03-04T22:18:05Z",
      "comments": []
    },
    {
      "number": 166,
      "id": "I_kwDOFEJYQs4-u8xP",
      "title": "Consider making the Leader a non-aggregator",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/issues/166",
      "state": "CLOSED",
      "author": "eriktaubeneck",
      "authorAssociation": "NONE",
      "assignees": [],
      "labels": [],
      "body": "In section 2.1: \"The leader is responsible for coordinating the protocol. It receives the encrypted shares, distributes them to the helpers, and orchestrates the process of computing the final measurement as requested by the collector.\"\r\n\r\nThen, in section 6.1.3: \"The leader is also an aggregator, and so all the assets, capabilities and mitigations available to aggregators also apply to the leader.\"\r\n\r\nFor a given _Measurement API_, which is implemented by a client provider, we assume that the client provider will need provide some sets of approved _aggregators_, which are trusted to be non-colluding. By requiring the _leader_ to be an _aggregator_, we limit who can actually be a leader.\r\n\r\nConsider a _Measurement API_ implemented by a web browser. In that case, I could imagine both the following scenarios:\r\n\r\n1. The site itself wants to act as the leader, collecting the encrypted reports themselves.\r\n2. The site delegates to a service provider, collecting the encrypted reports on that sites behalf (similar to current analytics tools.)\r\n\r\nFor scenario 1, it seems very unlikely that any site which wishes to act as a _leader_ for themselves would be able to be approved, as that would be a huge undertaking.\r\n\r\nFor scenario 2, this seems like it would limit competition in this space and potentially give a great deal of benefit to early approved services.\r\n\r\nGiven this, I propose downgrading the responsibility of the leader to just the storage and coordination role, and not imposing the currently required trust into the _leader_. This would be a fairly significant change to the current draft of the proposal, so before undertaking such changes and providing a PR, I'd like to first what the reaction to this idea is.",
      "createdAt": "2021-11-13T00:25:29Z",
      "updatedAt": "2022-01-21T23:54:03Z",
      "closedAt": "2022-01-21T23:54:03Z",
      "comments": [
        {
          "author": "martinthomson",
          "authorAssociation": "CONTRIBUTOR",
          "body": "I think that this worth considering.  The current formulation of roles is a little bit biased toward having a single entity that does most of the functions, with a secondary that performs only the necessary additional steps required to avoid collusion.\r\n\r\nThe current model has:\r\n* a leader that gathers inputs, coordinates aggregation, and assembles the results\r\n* a helper (or helpers) that participate in aggregation\r\n\r\nErik is describing a model where there is a less trusted entity that gathers inputs and assembles results, but does not participate in aggregation.  That entity might coordinate the aggregation process also, though I don't know if that is necessary, depending on what that coordination entails.  If the aggregation functions can talk amongst themselves, that might be more efficient.  Moreover, it might be more trustworthy that way as the (untrusted) coordination function does not need to see intermediate values; in Hits at least, that would leak some information.\r\n\r\nUnfortunately, this creates a different set of protocols than what is in the current draft.  You could cut things differently and avoid some (or most) of the complication by allowing this untrusted entity to gather reports and pass them to a leader for aggregation.  That leaves a few unnecessary redundancies in the proposed model.  For instance, you don't need the added complexity of encrypting the output shares toward the collector, because you can rely on TLS instead.\r\n\r\n@eriktaubeneck, I think that when you say \"storage\" you refer only to the phase where individual submissions are gathered prior to running the aggregation protocol.  There is another storage component to this system, which is the anti-replay or budgeting component that ensures that single measurements can't be used too many times.  That part can't be given to an untrusted entity.",
          "createdAt": "2021-11-15T00:38:52Z",
          "updatedAt": "2021-11-15T00:38:52Z"
        },
        {
          "author": "ekr",
          "authorAssociation": "COLLABORATOR",
          "body": "> Unfortunately, this creates a different set of protocols than what is in the current draft. You could cut things differently and avoid some (or most) of the complication by allowing this untrusted entity to gather reports and pass them to a leader for aggregation. That leaves a few unnecessary redundancies in the proposed model. For instance, you don't need the added complexity of encrypting the output shares toward the collector, because you can rely on TLS instead.\r\n\r\nI don't believe that this is correct. The idea here is to avoid any entity other than the collector learning the true value. I don't see how the architectuer Erik proposes would remove that need.",
          "createdAt": "2021-11-15T00:42:04Z",
          "updatedAt": "2021-11-15T00:42:04Z"
        },
        {
          "author": "martinthomson",
          "authorAssociation": "CONTRIBUTOR",
          "body": "I understand the goal.  I wanted to maintain that goal.\r\n\r\nIf you consider an entity that is coordinating and collecting, the shares of the result can be sent to that entity directly rather than using HPKE and routing them via a leader (which at this point is just an unnecessary intermediary).",
          "createdAt": "2021-11-15T00:49:46Z",
          "updatedAt": "2021-11-15T00:49:54Z"
        },
        {
          "author": "ekr",
          "authorAssociation": "COLLABORATOR",
          "body": "That puts way more complexity and need for real-time activity on that entity than with the current model, so I think this would be a regression.\r\n",
          "createdAt": "2021-11-15T00:57:24Z",
          "updatedAt": "2021-11-15T00:58:06Z"
        },
        {
          "author": "eriktaubeneck",
          "authorAssociation": "NONE",
          "body": "There are three different issues being discussed here:\r\n\r\n1. What are the properties of the party (currently the leader) who collects the data from the client?\r\n2. What party(s) maintain state for anti-reply and DP budgeting?\r\n3. How are results delivered to the collector so that no other party learns the true value.\r\n\r\nI'm primarily proposing a change for (1), as @martinthomson suggests. Thanks for clarifying. Collecting real time data from clients at scale is a non-trivial task, and it seems preferable to have as much flexibility and optionality for eventual collectors who are using this API. Removing the need for trust in the party promotes more competition, and thus more options for pricing, up time, robustness, etc. Dropping data from a client would result in unrecoverable measurement loss (whereas a failed PPM measurement could likely be rerun.)\r\n\r\n(2) is worth its own issue, though if we are comfortable with a single party managing the longer term state, that could still be compatible with this architecture. The functionality for (1) could be separated out, and called something like \"consumer\".\r\n\r\nFor (3), I generally agree with @ekr that minimizing complexity for the aggregators is preferable. Compared to the rest of the protocol, wrapping the result in a HPKE doesn't add a great deal of overhead. In general, it seems ideal to shift as much cost onto the leader (wrt the economics I mention above), and this also plays into egress costs, as described in #130.\r\n\r\nEDIT: does add overhead > doesn't add overhead.",
          "createdAt": "2021-11-15T03:30:27Z",
          "updatedAt": "2021-11-15T16:23:07Z"
        },
        {
          "author": "ekr",
          "authorAssociation": "COLLABORATOR",
          "body": "Erik: I don't understand your point (3).\r\n\r\nFirst, in any situation where one party stores the reports prior to doling them out to the aggregators, they need to be HPKE encrypted, which means that the aggregators need to be able to do HPKE. Any given aggregation will require far more reports than the aggregate value and so wrapping the result in HPKE will be a very small fraction of the HPKEs that the aggregator does. What's the additional overhead here?\r\n\r\nSecond, I think it's potentially reasonable to introduce *another* entity which orchestrates the computation (as the leader does now), without having the cryptographic keys, but: (1) we certainly want to preserve the ability of a service to offer the same model as now in which the collector issues requests and gets answers without participating in the protocol (2) It's not actually clear to me what the security and privacy properties of this entity would be. At minimum, it seems likely that it would be able to cause the system to produce false results.\r\n\r\n\r\n\r\n\r\n\r\n\r\n",
          "createdAt": "2021-11-15T12:39:18Z",
          "updatedAt": "2021-11-15T12:39:18Z"
        },
        {
          "author": "eriktaubeneck",
          "authorAssociation": "NONE",
          "body": "> Erik: I don't understand your point (3).\r\n\r\nUgh, typo. It *doesn't add* a great deal of overhead. I agree it's better to route through the leader, vs having aggregators connect directly to the collector, as @martinthomson suggested.\r\n\r\n> (1) we certainly want to preserve the ability of a service to offer the same model as now in which the collector issues requests and gets answers without participating in the protocol\r\n\r\nAgreed. In general, I don't see any limits on a single party participating in the protocol in more than role, so long as there are multiple non-colluding parties participating as aggregators.\r\n\r\n> (2) It's not actually clear to me what the security and privacy properties of this entity would be. At minimum, it seems likely that it would be able to cause the system to produce false results.\r\n\r\nI will take an attempt at describing this in more detail on this issue. My goal would be to design it such that the collector needs to trust this new _consumer_ entity, since they could affect the robustness of the result, but that the clients wouldn't need to trust the _consumer_ because they can't violate the client/end-user privacy.",
          "createdAt": "2021-11-15T16:18:13Z",
          "updatedAt": "2021-11-15T16:18:28Z"
        },
        {
          "author": "csharrison",
          "authorAssociation": "CONTRIBUTOR",
          "body": "I just saw this issue from Erik's email on the list. I wanted to point to a similar discussion (https://github.com/abetterinternet/ppm-specification/issues/64) we had a while back on allowing this via considering an intermediary aggregator as another \"client\" and supporting batch uploads to the leader / aggregators. I think these issues could probably be merged since they are addressing the same underlying goal.\r\n",
          "createdAt": "2022-01-19T17:13:59Z",
          "updatedAt": "2022-01-19T17:13:59Z"
        },
        {
          "author": "eriktaubeneck",
          "authorAssociation": "NONE",
          "body": "Thanks for linking @csharrison. Agreed that these seem to be addressing the same underlying goal. #64 is closed, but its outcome is unclear to me. Do you think it's still worth working on achieving this underlying goal?",
          "createdAt": "2022-01-19T17:34:32Z",
          "updatedAt": "2022-01-19T17:34:32Z"
        },
        {
          "author": "csharrison",
          "authorAssociation": "CONTRIBUTOR",
          "body": "> Thanks for linking @csharrison. Agreed that these seem to be addressing the same underlying goal. #64 is closed, but its outcome is unclear to me. Do you think it's still worth working on achieving this underlying goal?\r\n\r\nThe issue isn't closed (just the PR https://github.com/abetterinternet/ppm-specification/pull/78). I still agree on the goal.\r\n\r\ncc @cjpatton ",
          "createdAt": "2022-01-19T17:59:24Z",
          "updatedAt": "2022-01-19T17:59:24Z"
        },
        {
          "author": "eriktaubeneck",
          "authorAssociation": "NONE",
          "body": "> The issue isn't closed (just the PR #78). I still agree on the goal.\r\n\r\nWhoops, misread! ",
          "createdAt": "2022-01-19T18:36:49Z",
          "updatedAt": "2022-01-19T18:36:58Z"
        },
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "FWIW, I don't think anyone strongly objects to allowing multiple reports per upload request. This is where we left it previously: https://github.com/abetterinternet/ppm-specification/pull/78#issuecomment-880096898\r\n\r\n",
          "createdAt": "2022-01-19T21:31:08Z",
          "updatedAt": "2022-01-19T21:31:08Z"
        },
        {
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "body": "In the current text, the closest we get to discussing anything like the _consumer_ is [this section](https://github.com/abetterinternet/ppm-specification/blob/main/draft-gpew-priv-ppm.md#anonymizing-proxies-anon-proxy) where we suggest using [OHTTP](https://datatracker.ietf.org/doc/draft-ietf-ohai-ohttp/) to put a server between clients and the aggregators. Besides stripping identifying information like IP addresses, such a server could also do any number of things that are useful in a specific deployment but can't or shouldn't be specified in PPM, like verifying vendor specific attestations from clients to increase confidence that reports are genuine.\r\n\r\nAs I recall, the goal was to avoid explicitly prescribing how such a server should work in PPM, just to reduce the complexity of the protocol. I still hope OHTTP/OHAI are good answers here, but I also don't think there's anything in the protocol that precludes arbitrary proxy solutions from being deployed. So long as the PPM leader is receiving well-formed reports from the proxy, then the protocol spoken between the proxy and the client can be anything. The exception of course is that the individual reports should be encrypted to the aggregators' HPKE keys by the real clients, but I don't think there's any way for PPM aggregators to prevent a proxy from transcrypting reports (of course, the threat model already concedes that a malicious client can leak its own inputs, and transmitting them in the clear to a proxy counts as leaking).\r\n\r\nAnyway, my opinion here is that we should formalize the notion of allowing multiple reports per upload requests to allow efficient batching of reports in client proxies and that we should discuss and illustrate but perhaps not specify how client proxies would be involved in PPM.",
          "createdAt": "2022-01-19T23:39:36Z",
          "updatedAt": "2022-01-19T23:53:32Z"
        },
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "+1 to @tgeoghegan, with one caveat: It may be useful for aggregators to do some sort of attestation of the clients, potentially even through an ingestor proxy. (See https://github.com/abetterinternet/ppm-specification/issues/89.) But this is out-of-scope of the core protocol right now. We included \"upload extensions\" with the report in order to enable this (see section {{upload-extensions}}), which may or may not be sufficient.",
          "createdAt": "2022-01-19T23:52:17Z",
          "updatedAt": "2022-01-19T23:52:17Z"
        },
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "@eriktaubeneck given the recent discussion on the list, I'm wondering if it's possible to close this and open an issue for tracking the various deployment scenarios folks are considering. Besides that, is there anything else still unresolved in this thread?",
          "createdAt": "2022-01-21T17:44:43Z",
          "updatedAt": "2022-01-21T17:44:43Z"
        },
        {
          "author": "eriktaubeneck",
          "authorAssociation": "NONE",
          "body": "@cjpatton that sounds like a good plan to me. I will close this now and open up a new thread next week.",
          "createdAt": "2022-01-21T23:54:03Z",
          "updatedAt": "2022-01-21T23:54:03Z"
        }
      ]
    },
    {
      "number": 173,
      "id": "I_kwDOFEJYQs5AvW_R",
      "title": "addressing collusion",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/issues/173",
      "state": "OPEN",
      "author": "npdoty",
      "authorAssociation": "NONE",
      "assignees": [],
      "labels": [],
      "body": "The privacy guarantees that motivate this protocol work require non-collusion: if servers collude, all the individual data can be retrieved. As was raised by a few folks at the BOF, methods for addressing collusion or providing users some confidence about non-collusion will be important for evaluating the utility for privacy of this work.\r\n\r\nWe might want to adjust the charter to not exclude discovery/selection, as that might benefit from hooks to help users choose servers operated by different parties. Or, we might include in the scope some group discussion or recommendation of ways to provide user confidence in non-collusion, even if that won't be defined in the protocol. Or, if there's an implied dependency on some other project to establish co-operative but non-colluding servers, we should make that explicit. Finally, it might be useful to describe a threat model and the implications of colluding servers, to make it easier to evaluate these proposals against alternatives that rely on trusting a server to minimize collected data.",
      "createdAt": "2021-12-21T19:21:50Z",
      "updatedAt": "2022-01-03T22:12:07Z",
      "closedAt": null,
      "comments": [
        {
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "body": "> We might want to adjust the charter to not exclude discovery/selection, as that might benefit from hooks to help users choose servers operated by different parties. \r\n\r\nI think it might be interesting for the PPM WG to eventually consider this, but I don't think it should be in scope for the PPM RFC. My worry is that there's a huge number of ways for a client to agree on PPM task parameters with an aggregator and then authenticate for subsequent API interactions, and trying to describe them would dilute the focus of the PPM RFC. Discovery, especially, is a thorny problem, and I think we'd quickly end up reinventing the X.500 directory. To be clear, it'd be really nice to have something like the X.500 directory out there, but even if it's possible or a good idea to build that, I think it's outside of the scope of the PPM WG and protocol.\r\n\r\n> Or, we might include in the scope some group discussion or recommendation of ways to provide user confidence in non-collusion, even if that won't be defined in the protocol. Or, if there's an implied dependency on some other project to establish co-operative but non-colluding servers, we should make that explicit.\r\n\r\nI think it's important to remember that the point of PPM isn't to increase a user's confidence that any individual server will comply with the protocol. The point is to reduce the probability of compromise by increasing the number of participants who must defect and collude for privacy to be compromised. So in fact PPM concedes that it's not practical to get guarantees about the behavior of a remote server.\r\n\r\nLet's suppose there did exist some scheme that lets a client have confidence in the behavior of a remote server. Then I wouldn't need an algorithm like Prio at all: I would simply apply the scheme to a conventional telemetry system and have it prove to users that it never leaks information (I should credit this observation to Mariana Raykova, who explained it to me when I suggested specifying just the kind of mechanism you're suggesting).\r\n\r\nFurther, attestation schemes usually rely on some kind of trusted computing base (TCB) outside of the system being measured, like a TPM, ARM TrustZone or Intel SGX. Besides the degree to which these complicate the trust model (e.g., if TrustZone is used, I now have to trust ARM, the SoC manufacturer and the OEM that fused a software signing key into the SoC -- and we haven't thought about multi-tenant virtualization yet), I don't think we want to impose such hardware requirements on PPM implementations.\r\n\r\nFinally, I'm not convinced that there are yet any standards for attestation mature enough to be used in a protocol like PPM. What schemes exist today are usually intended to allow a vendor's backend to trust devices manufactured by a vendor, which is a very different proposition than allowing end users to trust an arbitrary remote server. I am aware that there's an [IETF working group](https://datatracker.ietf.org/wg/rats/about/) working in this space. Once that standard becomes mature, I think it'd be worth mentioning, but it's use in PPM implementations would be orthogonal to the PPM protocol itself: attestation tokens or bindings, just like any other kind of authentication, could be included in the HTTP requests in the PPM protocol, or provided to the helper in the [upload extensions](https://github.com/abetterinternet/ppm-specification/blob/main/draft-gpew-priv-ppm.md#upload-extensions-upload-extensions).\r\n\r\n> Finally, it might be useful to describe a threat model and the implications of colluding servers, to make it easier to evaluate these proposals against alternatives that rely on trusting a server to minimize collected data.\r\n\r\nWe do have a [threat model](https://github.com/abetterinternet/ppm-specification/blob/main/draft-gpew-priv-ppm.md#threat-model) section in the document which includes a section discussing [aggregator collusion](https://github.com/abetterinternet/ppm-specification/blob/main/draft-gpew-priv-ppm.md#aggregator-collusion), though all it says is that if all servers collude, the system provides no privacy at all. We could mention that adding more aggregators helps to mitigate these threats (because more aggregators means more servers have to collude), but the protocol is currently only designed to support exactly two aggregators.",
          "createdAt": "2021-12-29T20:52:05Z",
          "updatedAt": "2021-12-29T20:52:05Z"
        },
        {
          "author": "npdoty",
          "authorAssociation": "NONE",
          "body": "> I think it's important to remember that the point of PPM isn't to increase a user's confidence that any individual server will comply with the protocol. The point is to reduce the probability of compromise by increasing the number of participants who must defect and collude for privacy to be compromised. So in fact PPM concedes that it's not practical to get guarantees about the behavior of a remote server.\r\n> \r\n> Let's suppose there did exist some scheme that lets a client have confidence in the behavior of a remote server. Then I wouldn't need an algorithm like Prio at all: I would simply apply the scheme to a conventional telemetry system and have it prove to users that it never leaks information (I should credit this observation to Mariana Raykova, who explained it to me when I suggested specifying just the kind of mechanism you're suggesting).\r\n> \r\n> Further, attestation schemes usually rely on some kind of trusted computing base (TCB) outside of the system being measured, like a TPM, ARM TrustZone or Intel SGX. Besides the degree to which these complicate the trust model (e.g., if TrustZone is used, I now have to trust ARM, the SoC manufacturer and the OEM that fused a software signing key into the SoC -- and we haven't thought about multi-tenant virtualization yet), I don't think we want to impose such hardware requirements on PPM implementations.\r\n\r\nMy understanding is that the privacy advantage of PPM schemes is that it provides privacy without attestation of server behavior *by* splitting up the computation to servers that are known to be operated by different parties. So I'm not suggesting that we include in scope or rely on some perfect attestation of server behavior (I agree, it would make the PPM protocol unnecessary) but that we do consider mechanisms for choosing servers operated by different parties.\r\n\r\nIf there's no reason at all for a user to believe that the PPM system is operated by multiple non-colluding parties, then I don't see how it's different for the user than relying on the trustworthiness of a single telemetry server.",
          "createdAt": "2021-12-29T22:42:48Z",
          "updatedAt": "2021-12-29T22:42:48Z"
        },
        {
          "author": "ekr",
          "authorAssociation": "COLLABORATOR",
          "body": "I am opposed to any work to define server selection or discovery at this time. All of the applications I am aware of that people actually intend to deploy involve software vendors selecting (or filtering) the servers, so this doesn't seem helpful.\r\n\r\nThe reason that it's different for the user is that they can *see* which servers the client is using and make their own decision about whether that's good enough. As a general matter, this is the kind of assurance users have about the behavior of any software they run.\r\n\r\n\r\n\r\n\r\n",
          "createdAt": "2021-12-29T23:10:31Z",
          "updatedAt": "2021-12-29T23:14:55Z"
        },
        {
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "body": "> If there's no reason at all for a user to believe that the PPM system is operated by multiple non-colluding parties, then I don't see how it's different for the user than relying on the trustworthiness of a single telemetry server.\r\n\r\nOooh, that's an interesting point and I see now how it is distinct from a server attesting to the measurements of its code. We do require clients to connect to aggregators over HTTPS, which means they get a server identity in the form of the TLS certificate. At the risk of being glib, I'd say that if the web PKI hasn't figured out a better solution than OV and EV certs to prove to clients that `foo.com` and `bar.com` aren't the same real-world entity, then I don't know if we can do better.",
          "createdAt": "2021-12-29T23:12:11Z",
          "updatedAt": "2021-12-29T23:12:11Z"
        },
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": " I agree with Tim and EKR that working on server selection is premature at this time.",
          "createdAt": "2021-12-29T23:49:25Z",
          "updatedAt": "2021-12-29T23:49:25Z"
        },
        {
          "author": "npdoty",
          "authorAssociation": "NONE",
          "body": "Implementer pre-selection or filtering of servers, transparency and authentication of servers, and audits based on that transparency -- these are indeed ways to address the threat of collusion.\r\n\r\nIf there's agreement among potential implementers that selection/discovery won't be used (at least for now), then it's fine to exclude that from WG scope. But I would suggest that we should discuss the ways collusion will be addressed, in case it has impacts on the protocol design.",
          "createdAt": "2022-01-03T22:12:07Z",
          "updatedAt": "2022-01-03T22:12:07Z"
        }
      ]
    },
    {
      "number": 176,
      "id": "I_kwDOFEJYQs5BMBlP",
      "title": "\"Heavy Hitters\" is now \"Poplar\"",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/issues/176",
      "state": "CLOSED",
      "author": "cjpatton",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "@henrycg has informed me that the authors of [[BBCGGI21](https://eprint.iacr.org/2021/017.pdf)] have given their protocol a proper name so as to avoid confusing conflating the protocol with the problem it solves. We ought to adopt the name in the PPM and [VDAF](https://github.com/cjpatton/vdaf) specs. ",
      "createdAt": "2022-01-04T19:06:37Z",
      "updatedAt": "2022-01-06T18:48:37Z",
      "closedAt": "2022-01-06T18:48:37Z",
      "comments": []
    },
    {
      "number": 180,
      "id": "I_kwDOFEJYQs5B0TPi",
      "title": "Aggregators required to store nonce sets indefinitely",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/issues/180",
      "state": "OPEN",
      "author": "cjpatton",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "Since #169, aggregators are required to store report nonces for batch intervals that have not yet been collected. This is necessary in order to prevent replay attacks. The problem is that nothing guarantees that a batch interval will be collected in a timely manner: In theory, it's possible that aggregators will have to store nonce sets indefinitely. To prevent this, there needs to be a way for the aggregators to agree on when to stop accepting reports for a given batch interval.\r\n\r\nThe strawman solution is to allow each aggregator to, at its own discretion, ignore a report if it can't confirm if the report was replayed or not. The problem is that this potentially leads to unnecessary data loss.",
      "createdAt": "2022-01-15T00:13:29Z",
      "updatedAt": "2022-01-19T00:42:32Z",
      "closedAt": null,
      "comments": []
    },
    {
      "number": 183,
      "id": "I_kwDOFEJYQs5CEUiE",
      "title": "Interaction of anti-replay and flexibility",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/issues/183",
      "state": "OPEN",
      "author": "ekr",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "Reading through the latest changes on anti-replay it seems like we are foregoing a bunch of flexibility that we may want.\r\n\r\nHere's a simple example:\r\nSuppose that I have a measurement that i want to slice by geographic regions. At the moment this is impossible because the anti-replay mechanism requires only one set of aggregations for a given time window. As @cjpatton pointed out to me privately, you can have a different task for each region, but:\r\n\r\n1. This is going to be a pain if you want to change your slicing policy later\r\n2. It mostly precludes crosstabs and drilldown \r\n\r\nAt minimum, I think we want an anti-replay design to guarantee that any given input share is aggregated at most once but that allows overlapping windows. Eventually, I expect we're going to want to allow multiple aggregation but in restricted ways (otherwise drilldown and crosstabs are hard).",
      "createdAt": "2022-01-19T18:33:08Z",
      "updatedAt": "2022-01-22T00:57:27Z",
      "closedAt": null,
      "comments": [
        {
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "body": "I agree that flexibility is generally useful, but we need to be careful to not allow any sort of overlapping windows to violate report privacy. We need a better way to reason about what's permissible and what's not here. ",
          "createdAt": "2022-01-19T22:58:03Z",
          "updatedAt": "2022-01-19T22:58:03Z"
        },
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "I agree that the ability to filter aggregates by some attribute (region, user agent, etc.) is a useful feature, and I agree that protocol changes will likely be needed to support it. I'm not sure what this has to do with anti-replay, however:\r\n\r\n> At minimum, I think we want an anti-replay design to guarantee that any given input share is aggregated at most once but that allows overlapping windows. Eventually, I expect we're going to want to allow multiple aggregation but in restricted ways (otherwise drilldown and crosstabs are hard).\r\n\r\nA collect request may specify any batch interval the collector wants, so long as the conditions in {{batch-parameter-validation}}. This allows one to \"drill down\" on clients with certain attributes while still maintaining some privacy invariants.\r\n\r\nBut to emphasize @chris-wood's point, these conditions may not be sufficient. A more careful analysis is needed (especially for applications that use DP).",
          "createdAt": "2022-01-19T23:47:19Z",
          "updatedAt": "2022-01-19T23:47:19Z"
        },
        {
          "author": "ekr",
          "authorAssociation": "COLLABORATOR",
          "body": ">  I'm not sure what this has to do with anti-replay, however:\r\n\r\nThe following text forbids overlapping batches, which are necessary for both drilldown and crosstabs\r\n\r\n> In addition, for any report whose nonce contains a timestamp that falls in a batch interval for which it has completed at least one aggregate-share request (see Section 4.3.2), the helper MUST send an error messsage in response rather than its next VDAF message. Note that this means leaders cannot interleave a sequence of aggregate and aggregate-share requests for a single batch.\r\n\r\n",
          "createdAt": "2022-01-19T23:50:59Z",
          "updatedAt": "2022-01-19T23:50:59Z"
        },
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "Ah, indeed it does. In fact, this seems like it prevents any report from being aggregated more than once (even as required for protocols like Poplar). This needs to be fixed regardless.",
          "createdAt": "2022-01-19T23:57:08Z",
          "updatedAt": "2022-01-19T23:57:08Z"
        },
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "So I think the following is what we want. the check needs to be enforced by both the leader and helper (though at different times), so I'll try to speak in terms of a generic aggregator.\r\n\r\nBefore it processes a report share, the aggregator first checks if the report pertains to a batch that has already been collected.  This is the case if the aggregator is the leader and has completed a collect request for a batch containing the report, or if the aggregator is a helper and has completed an aggregate-share request for a batch containing the report (see {{aggregate-share-request}}). It also checks if the report has been \"observed\". This is the case if the report was used in a previous aggregate request.\r\n                               \r\n* If the report has not yet been observed but is contained by a batch that has   been collected, then the aggregator returns an error rather than process the report share further. This prevents additional reports from being aggregated after its batch has already been collected.              \r\n                               \r\n* If the report has been observed but has not been collected, then it returns an error rather than continue processing. This  prevents a report from being used more than once in a batch.\r\n\r\nIn particular, we *only* process a report if either it has been observed *and* has been collected *or* it has never been observed and is not contained by a batch that has been collected.\r\n\r\nI believe this allows overlapping batches to be collected without interfering with anti-replay.",
          "createdAt": "2022-01-21T22:02:25Z",
          "updatedAt": "2022-01-22T00:57:27Z"
        }
      ]
    },
    {
      "number": 185,
      "id": "I_kwDOFEJYQs5COzIl",
      "title": "Replace helper state blob with an aggregation job UUID",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/issues/185",
      "state": "CLOSED",
      "author": "tgeoghegan",
      "authorAssociation": "COLLABORATOR",
      "assignees": [
        "chris-wood"
      ],
      "labels": [],
      "body": "@cjpatton and I were debating the [helper state blob](https://abetterinternet.github.io/ppm-specification/draft-gpew-priv-ppm.html#name-helper-state). Now that helpers have to store all the report nonces and are also likely to be expected to store their own report shares, I argue that we should get rid of it: we don't need it and it entails a bunch of complicated security considerations. Helpers need to encrypt their state so leaders can't see it, need to protect themselves against leaders replaying old state blobs and they need to version it so that a helper can deal with a blob constructed by an older version of itself.\r\n\r\nChris' rebuttal is that even if you don't use the blob to store something like a set of nonces or a counter or a partial aggregate share, it's still useful as a key into the storage where the helper keeps its state. This is helpful for a helper running on something like a Cloudflare Worker, where ephemeral servers are launched in response to incoming messages, and so a different helper instance might handle the sequence of `AggregateInit` and `Aggregate` requests.\r\n\r\nWe agreed that we don't need an arbitrarily large opaque blob shipped back and forth between leader and helper to solve that problem. All you need is a unique value like a UUID so that a stateless helper can recover context from storage. This will let us delete a whole bunch of SHOULD and MAY discussion from the spec.",
      "createdAt": "2022-01-22T01:48:38Z",
      "updatedAt": "2022-05-10T14:21:24Z",
      "closedAt": "2022-05-10T14:21:24Z",
      "comments": [
        {
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "body": "I think we also owe a definition of an \"aggregation job\", which is evolving in #179 ",
          "createdAt": "2022-01-22T01:55:35Z",
          "updatedAt": "2022-01-22T01:55:35Z"
        },
        {
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "body": "Some discussion of the implications of helper state to parallelism is in #150.",
          "createdAt": "2022-04-29T00:55:19Z",
          "updatedAt": "2022-04-29T00:55:19Z"
        }
      ]
    },
    {
      "number": 187,
      "id": "I_kwDOFEJYQs5CV14J",
      "title": "Make sure error codes are enumerated in errors table",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/issues/187",
      "state": "CLOSED",
      "author": "tgeoghegan",
      "authorAssociation": "COLLABORATOR",
      "assignees": [
        "tgeoghegan"
      ],
      "labels": [],
      "body": "We have some error codes like `staleReport` that aren't enumerated in the table in `Message Transport.Errors`. We should bring that table up to date. While we're in there, I think `outdatedConfig` and `staleReport` aren't the right types, since outdatedness or staleness aren't the only reasons that an HPKE config or report, respectively, could be rejected.",
      "createdAt": "2022-01-24T18:58:00Z",
      "updatedAt": "2022-05-11T18:57:19Z",
      "closedAt": "2022-05-11T18:57:19Z",
      "comments": [
        {
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "body": "The error table was brought up to date by #233.",
          "createdAt": "2022-05-11T18:57:19Z",
          "updatedAt": "2022-05-11T18:57:19Z"
        }
      ]
    },
    {
      "number": 188,
      "id": "I_kwDOFEJYQs5Cbc57",
      "title": "Consider allowing clients to upload mulitple reports in a single message to aggregators",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/issues/188",
      "state": "CLOSED",
      "author": "tgeoghegan",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "Right now, an upload message from a client to an aggregator contains a single report (or two shares of a single report, in #174). I suspect there will be cases where a client will want to upload multiple reports in one HTTP transaction, especially deployments that use an intermediate client/client proxy/batching client. I believe we will need to define a PPM protocol message that allows multiple reports to support this.",
      "createdAt": "2022-01-26T00:21:01Z",
      "updatedAt": "2022-01-26T20:38:08Z",
      "closedAt": "2022-01-26T20:38:07Z",
      "comments": [
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "This sounds like a duplicate of https://github.com/abetterinternet/ppm-specification/issues/64?",
          "createdAt": "2022-01-26T02:10:00Z",
          "updatedAt": "2022-01-26T02:10:00Z"
        },
        {
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "body": "You're right, it is! I should have searched for existing issues before writing up a new one.",
          "createdAt": "2022-01-26T20:38:07Z",
          "updatedAt": "2022-01-26T20:38:07Z"
        }
      ]
    },
    {
      "number": 189,
      "id": "I_kwDOFEJYQs5DBlJI",
      "title": "fix VDAF reference",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/issues/189",
      "state": "CLOSED",
      "author": "bdaehlie",
      "authorAssociation": "NONE",
      "assignees": [
        "cjpatton"
      ],
      "labels": [],
      "body": "Would be helpful to readers if this reference was fixed in the Editor's Copy:\r\n\r\n[I-D.draft-cfrg-patton-vdaf]\r\n    \"*** BROKEN REFERENCE ***\". ",
      "createdAt": "2022-02-04T18:21:20Z",
      "updatedAt": "2022-04-27T22:02:55Z",
      "closedAt": "2022-04-27T22:02:55Z",
      "comments": []
    },
    {
      "number": 190,
      "id": "I_kwDOFEJYQs5DBmFO",
      "title": "reconsider reliance on strict ordering",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/issues/190",
      "state": "OPEN",
      "author": "bdaehlie",
      "authorAssociation": "NONE",
      "assignees": [],
      "labels": [],
      "body": "The PPM specification relies on strictly enforced ordering in a couple of places:\r\n\r\nExample 1: \"aggregator_endpoints: A list of URLs relative to which an aggregator's API endpoints can be found. Each endpoint's list MUST be in the same order. The leader's endpoint MUST be the first in the list.\"\r\n\r\nExample 2: \"encrypted_input_shares contains the encrypted input shares of each of the aggregators. The order in which the encrypted input shares appear MUST match the order of the task's aggregator_endpoints (i.e., the first share should be the leader's, the second share should be for the first helper, and so on).\"\r\n\r\nThis technically solves the intended problem just fine as far as I can tell but it's a scheme that's prone to implementation mistakes, and if a mistake is made it'll be harder to spot than it probably needs to be. I would consider some kind of explicit tagging of resources rather than relying on consistent ordering in lists.",
      "createdAt": "2022-02-04T18:26:05Z",
      "updatedAt": "2022-02-04T18:26:05Z",
      "closedAt": null,
      "comments": []
    },
    {
      "number": 191,
      "id": "I_kwDOFEJYQs5DBzok",
      "title": "reconsider empty body requirement for status 200 responses",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/issues/191",
      "state": "OPEN",
      "author": "bdaehlie",
      "authorAssociation": "NONE",
      "assignees": [],
      "labels": [],
      "body": "Section 4.2.2:\r\n\r\n\"Clients SHOULD NOT upload the same measurement value in more than one report if the leader responds with status 200 and an empty body.\u201d\"\r\n\r\nIs a non-empty body understood to signal an error condition based on some other context?\r\n\r\nWhat if the client got status 200 from the leader but a non-empty body? Should the client retry as this text suggests?\r\n\r\nI don't know enough about HTTP semantics to know for sure, but it seems like specifying an empty body here is unnecessary. It seems fine to specify that the leader should *send* an empty body for 200, but maybe be less strict on the consumption side and drop the empty body requirement?",
      "createdAt": "2022-02-04T19:34:22Z",
      "updatedAt": "2022-02-04T19:34:22Z",
      "closedAt": null,
      "comments": []
    },
    {
      "number": 192,
      "id": "I_kwDOFEJYQs5DB2Mk",
      "title": "standardize HTTP response wording",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/issues/192",
      "state": "CLOSED",
      "author": "bdaehlie",
      "authorAssociation": "NONE",
      "assignees": [],
      "labels": [],
      "body": "All of the following are currently used to refer to 200 responses:\r\n\r\n* status 200\r\n* HTTP 200 OK\r\n* HTTP status 200\r\n* HTTP status 200 OK\r\n\r\nWould be nice to pick one and use it consistently.",
      "createdAt": "2022-02-04T19:48:23Z",
      "updatedAt": "2022-05-12T20:28:52Z",
      "closedAt": "2022-05-12T20:28:52Z",
      "comments": []
    },
    {
      "number": 195,
      "id": "I_kwDOFEJYQs5FFuP-",
      "title": "Collect requirements",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/issues/195",
      "state": "OPEN",
      "author": "chris-wood",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "Let's start with an overview of the problem as I understand it. Currently, batch management is dealt with by dividing the time into a contiguous list of batch windows, each of size min_batch_duration epochs. This is illustrated below (T denotes the T\u2019th batch window):\r\n\r\n~~~\r\n|...| T - 1 |  T  | T + 1 |...|\r\n~~~\r\n\r\nEach report indicates an epoch that places it uniquely into one batch window. \r\n\r\nWhen Collectors request the aggregate shares for a batch window, they indicate the interval of time they are interested in collecting aggregate results. This request is constrained in that the interval must be a multiple of the batch window size (min_batch_duration), though it can exceed more than one batch window. For example, a Collector can request aggregate shares for a single batch window T (marked with asterisks), as follows:\r\n\r\n~~~\r\n|...| T - 1 |  T  | T + 1 |...|\r\n            *******\r\n~~~\r\n\r\nA Collector can also request aggregate shares for multiple, consecutive batch windows T and T+1 as follows:\r\n\r\n~~~\r\n|...| T - 1 |  T  | T + 1 |...|\r\n            ***************\r\n~~~\r\n\r\nFor privacy, each collect request must correspond to some minimum number of measurements, called the min_batch_size. If the aggregators do not have enough report shares to satisfy the request, they must respond with an error. \r\n\r\nIntiuitively, this requirement is meant to esnure that the collect requests cannot be abused to learn individual measurements contributed to an aggregate output. However, the current batch scheme doesn't abide by this requirement. To see why, assume there exists a batch window T in which min_batch_size reports fall. Moreover, assume that there exists only one report in the T+1 window. Assume further the Collector makes the following pair of requests:\r\n\r\n1. out1 = Collect(T, T+1)\r\n2. out2 = Collect(T)\r\n\r\nThis would be a reasonable sequence of requests if, for example, the Collector wanted to drill down to get data for a more fine-grained batch window. However, if both requests were satisfied given the current set of reports, the delta between out1 and out2 would allow the Collector to learn the value of the single individual report in the window T+1. In general, the protocol should prohibit privacy violations of this form.\r\n\r\nOne way to rule out such privacy violations is to require that each batch window covered by a collect request contain at least min_batch_size reports. (In the example above, the first collect request above would be prohibited because T+1 has just one report.) However, this is perhaps overly restrictive. We want queries to be flexible enough to allow one to slice batches differently, but this needs to be done such that privacy violations cannot occur. \r\n\r\nGiven the above, here\u2019s an attempt to formalize the batch query constraint requirement. Let Ci = Collect(Ti,..., Tn), i <= n denote a collect request for the batch interval Ti,...,Tn. For each Ci there exists a unique Si = {r | Ti,...,Tn} where |Si| >= B. That is, Si is the set of reports included in the aggregate covered by the interval Ti,...,Tn, and its size is at least B, where B is min_batch_size.\r\n\r\nBased on this, the requirement can simply be stated as follows. Given Ci,...,Cq collect requests, it must not be possible for the collector to reconstruct an aggregate of over a report set S* such that |S*| < B . The Collector can run any number set operations, including intersection, union, and difference, using the output sets Si,...,Sq.\r\n\r\nThere's a number of questions that might follow from this:\r\n\r\n- Is this the right requirement? If not, how should it be tweaked?\r\n- If so, should the protocol specify how to enforce it, or defer that to the implementations? If we assume that collect requests will always agree on their aggregate inputs, then maybe we can simply rely on this and each aggregator's own \"collect request validation implementation\" to ensure the batch constraints aren't violated. \r\n- If we do decide to specify its enforcement, how should aggregators check collect requests for correctness while supporting query flexibility? For example, as in #183, what if one wanted to include a \"space dimension\" with a query, e.g., \"give me the aggregate for all reports in time Ti,..,Tj for this given User-Agent\" or whatever, then one shouldn't be able to abuse this to violate the requirement above.\r\n\r\nThere may be other questions that fall out of this as well, but hopefully this gets the ball rolling.",
      "createdAt": "2022-03-04T00:59:18Z",
      "updatedAt": "2022-05-31T19:14:17Z",
      "closedAt": null,
      "comments": [
        {
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "body": "Currently, we have a task parameter `max_batch_lifetime` defined as:\r\n> The maximum number of times a batch of reports may be\r\n>  used in collect requests.\r\n\r\nIn a task where `max_batch_lifetime` (which I prefer to think of as a privacy budget) is 1, the `(out1, out2)` attack is defeated because after doing `Collect(T, T+1)`, the aggregators will refuse to service `Collect(T)`, since the `max_batch_lifetime` for `T` has been consumed. However I'm not sure if that works for tasks where `max_batch_lifetime > 1`, as will be the case for poplar1 (which successive rounds of prefix queries are made by the collector).\r\n\r\nWhat if we require that once a batch window has been included in a collect request over `Ti...Tn`, it can only appear in later collect requests over supersets of `Ti...Tn`. i.e., after doing `Collect(T, T+1)`, `Collect(T, T+1, T+2)` is permitted, but `Collect(T)` is not. This would make the state tracking quite a bit more complicated for the aggregators, though.",
          "createdAt": "2022-03-04T23:06:55Z",
          "updatedAt": "2022-03-04T23:06:55Z"
        },
        {
          "author": "divergentdave",
          "authorAssociation": "COLLABORATOR",
          "body": "Tim: Requiring that later collect requests to be either a superset or disjoint to each prior collect request wouldn't be sufficient to meet the requirement, as a privacy-attacking collector could just order their requests differently. If T had `min_batch_size` reports in it, and T+1 had one report, they could issue `Collect(T)`, followed by `Collect(T, T+1)`, and then take the difference to isolate the value of the lone report in T+1. While no aggregator under any rule would allow `Collect(T+1)`, we will have to apply more strict conditions to avoid this difference-of-aggregates attack.\r\n\r\nI have an intuitive argument that deciding whether a set of collect requests could produce an aggregate over S* such that |S*| < B could be computationally hard. If the VDAF in use is prio3, we can represent each collect request with a pair of vectors, one vector of the additive aggregates in the result, and one vector (\"hot encoded\") that signifies which epoch the results came from. Let the report vector have dimension equal to the number of epochs in the time period we're analyzing, (call it N) and each element will be 0 if the corresponding epoch isn't part of the collect request, or equal to the number of reports in the epoch if it is included, |{r | Ti}|. The total number of reports in a collect request is equal to the element-wise sum of this report vector, which is the taxicab metric. We know that for each report vector, this sum is greater than or equal to B, `min_batch_size`. A privacy-attacking collector can take a linear combination of the additive aggregate results from the collect requests, and we can take the same linear combination of the corresponding report vectors to track which reports are included, and with which multiplicity. Now, our requirement begins to look like a lattice problem. We start with a set of the report vectors with taxicab norm >= B, and we want to know whether the lattice they generate has any vectors with taxicab norm < B.\r\n\r\n(Caveats: I don't know whether lattice problems are as hard with the taxicab metric as with the typical length norm. If the attacker somehow arrives at the aggregate for 2\\*Ti, they could divide by a small multiple to recover it, and the lattice view of the problem would be insufficient. I'm not sure whether there exists a combination of collect requests for which an attacker could reconstruct 2\\*Ti but not Ti, or some other small multiple. These report vectors have a fairly restrictive structure, as they each have only one consecutive run of nonzero elements; this may make the lattice problem easier than the general case.)\r\n\r\nMoreover, here's a pathological example to consider: Let B=10, and let N=100. Say that T0 has one report, and T1 through T99 each have B reports. Our attacker first issues `Collect(T0, T1)`, `Collect(T1, T2)`, `Collect(T2, T3)`, ... `Collect(T98, T99)`. Each successive request covers either B+1 or 2B reports. While the one-sided set difference of `Collect(T0, T1)` and `Collect(T1, T2)` is only one report, the attacker can't recover a `prio3` aggregate of the lone report in T0, as it's confounded by the influence of T2. This continues through the rest of the collect requests on two epochs. Now, the collector issues a request `Collect(T99)`. If the aggregators do not reject this request, the collector will be able to violate privacy by back-calculating the value of the aggregate of `Collect(T0)`, with only one report, which should not be permitted.\r\n\r\nWith this pathological example in mind, defining a collect request acceptance rule that only checks over some fixed time horizon could be troublesome. And, since we have to consider differences of collect requests, each additional collect request we include in our analysis could up to double the number of subsets we look at. (no good if the number of collect requests considered can be arbitrarily large) I think we will have to make some trade-off to be less-than-maximally permissive in what sorts of patterns of collect requests we allow, so we can preserve privacy of reports in sparse epochs, while making the on-line decision to allow or reject a collect request simpler.\r\n\r\nOne simple rule that we could adopt: Every collect request must either not overlap any previous non-aborted collect requests, or have an identical start time and interval to all overlapping non-aborted collect requests. This would allow for what I imagine to be normal operation, continuously collecting over the minimum interval, and then retrying with longer intervals if incoming reports dip below `min_batch_size`. However, it would prohibit any attempts to \"temporally drill down\" in situations that would otherwise not violate privacy. Are there use cases which would be better served by that than collecting over smaller intervals and summarizing aggregates? Do we contemplate VDAFs which cannot be re-aggregated, like percentile calculations? (`poplar1` counts from separate aggregations could be combined, though they may miss some results that are just under the threshold in each interval, but would have been above in a combined interval)",
          "createdAt": "2022-03-11T18:56:07Z",
          "updatedAt": "2022-03-11T18:56:07Z"
        },
        {
          "author": "BranLwyd",
          "authorAssociation": "COLLABORATOR",
          "body": "Is there a use case for partially-overlapping collection intervals? As Tim notes, `prio3` doesn't allow this due to allowing only a single collect request for any given minimal batch window; my (possibly-incorrect) understanding of `poplar1` is that the repeated collect requests would in practice be done over an identical interval.\r\n\r\nThat is, could we get away with something like this (the same as what David suggests, IIUC): all collection intervals containing a given minimal batch window must be identical.\r\n\r\nThis disallows drilling down. In `prio3` we could mitigate this by keeping the minimal batch window as small as possible. I am not sure if we need drilling down for `poplar1`, and of course we don't know what VDAFs are coming.",
          "createdAt": "2022-03-14T17:07:16Z",
          "updatedAt": "2022-03-14T17:07:16Z"
        },
        {
          "author": "simon-friedberger",
          "authorAssociation": "NONE",
          "body": "Would it be a good middle-ground to always split the client space into disjoint sets? That would simplify the computation of what is allowed, as David described above, but would still allow some flexibility to drill-down into results, as long as the disjoint sets don't get too small.\r\n\r\nThe reasoning is that, given two sets A and B, with A \u2286 B, and \u03a3B = X, \u03a3A = Y, clearly the difference B\\A  has \u03a3B\\A = X-Y. So, to keep the privacy requirements, B\\A must have `min_batch_size` elements as well.\r\n\r\n(Edit: Note that drill-down would necessarily mean that aggregators have to store which sets they have used and to disable all sets containing a nonce when pruning old nonces.)",
          "createdAt": "2022-04-12T12:31:40Z",
          "updatedAt": "2022-04-18T10:54:00Z"
        },
        {
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "body": "I was thinking about collect requirements for [Prio3Aes128Histogram](https://cfrg.github.io/draft-irtf-cfrg-vdaf/draft-irtf-cfrg-vdaf.html#name-prio3aes128histogram), and I'm now wondering if the definition and enforcement of collect protocol privacy requirements might depend on the VDAF in use, and thus some portion of this will have be defined at the VDAF layer.\r\n\r\nOur thinking thus far is that DAP aggregators would have to enforce a minimum number of contributions within a collect request's batch interval. The appeal of this approach is that it can be applied generically regardless of the VDAF in use and depends on a single shared parameter that's easy to apply. But suppose someone deploys Prio3Aes128Histogram, picks a reasonable minimum batch size, but happens to choose their bucket boundaries such that one of the buckets always contains a single contribution. Does that violate the privacy of the individual who reported that value?\r\n\r\nA straightforward fix here would be to say that an aggregator should refuse to release a Prio3Aes128Histogram aggregate share unless each bucket has either zero contributions or enough contributions to meet some a privacy threshold. But introducing special cases for VDAFs at the DAP layer seems wrong, so perhaps the enforcement of this kind of thing should be specified in the VDAF's [`out_shares_to_agg_share`](https://cfrg.github.io/draft-irtf-cfrg-vdaf/draft-irtf-cfrg-vdaf.html#name-aggregation-2) function, which would now optionally return an error if privacy requirements aren't met?",
          "createdAt": "2022-05-31T17:50:19Z",
          "updatedAt": "2022-05-31T17:50:19Z"
        },
        {
          "author": "simon-friedberger",
          "authorAssociation": "NONE",
          "body": "I think this has to be handled not just at the VDAF side of things but in the task definition. The impact of the collected information on privacy and the leakage of the specific aggregration function are task specific and need to be be handled there.\r\n\r\nI am not sure how straightforward your fix would be, given that aggregators don't see how many entries there are in a bucket. So this would be another validation step. But actually a post-aggregation validation step might be a useful extension. \ud83e\udd14",
          "createdAt": "2022-05-31T19:03:22Z",
          "updatedAt": "2022-05-31T19:03:22Z"
        },
        {
          "author": "BranLwyd",
          "authorAssociation": "COLLABORATOR",
          "body": "If we do view this as a privacy violation, it's a rather sticky one: as Simon points out, the collector is the first entity that would be able to determine how many reports any given bucket contains (since it unshards the aggregate shares into an aggregate result). But once the collector has computed the aggregate result it has exposed itself to the privacy-violating measurement, and we must trust that the collector will act unilaterally to do the right thing. In contrast, the other privacy protections such as `min_batch_size` are implemented by both the leader & the helper aggregators (i.e. two separate, non-colluding entities) and are implemented without revealing the privacy-violating measurements.",
          "createdAt": "2022-05-31T19:14:17Z",
          "updatedAt": "2022-05-31T19:14:17Z"
        }
      ]
    },
    {
      "number": 202,
      "id": "I_kwDOFEJYQs5FjMSe",
      "title": "Do not require parsing aggregation messages before authenticating",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/issues/202",
      "state": "CLOSED",
      "author": "BranLwyd",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "The interop target PR (#179) currently specifies that messages must be cryptographcially authenticated before they are interpreted:\r\n\r\n> The last 32 bytes of each message is an HMAC-SHA256 tag computed over the serialized message excluding the tag field itself. The key that is used is the agg_auth_key shared by the aggregators and configured for the given task.\r\n> \r\n> Upon receiving an AggregateReq message, an aggregator MUST verify the tag before interpreting the message's contents. If verification fails, it MUST abort and alert its peer with error \"invalidHmac\".\r\n\r\nThe HMAC key to use to perform verification is based on the task; the task is identified by an ID contained in the message. Therefore, currently the message must be interpreted before it can be authenticated. This is a problem because implementations both cannot follow the letter of the specification, and because requiring interpretation of message bytes before verification makes it more likely that implementations will be exposed to attacks from unauthenticated attackers based on bugs in the message parsing code.\r\n\r\nImplementations should not have to parse authenticated messages before performing authentication.\r\n\r\n\r\nDiscussing with @cjpatton, @chris-wood, & @divergentdave, two strawman solutions were identified:\r\n\r\n1) Include the task ID as an HTTP header. This is a relatively simple strategy, but would either move the task ID out of the message itself (losing binding of the message to a task), or duplicate the task ID in both the message & the header (increasing the amount of overhead per request).\r\n\r\n2) Ensure that the task ID is at a specific byte offset in all authenticated messages, similar to the current arrangement that the authentication tag is the last 32 bytes of each message. For example, the task ID could be arranged to be the first 32 bytes of the message. Then authentication would be: read the task ID as the first 32 bytes and retrieve the HMAC key; verify the content based on the tag as the last 32 bytes & the retrieved key; if successful, parse the message. This strategy allows the message to keep its binding to the task without requiring duplication of information, but is somewhat more complex to specify & implement.",
      "createdAt": "2022-03-11T20:42:41Z",
      "updatedAt": "2022-04-12T19:06:09Z",
      "closedAt": "2022-04-12T19:06:08Z",
      "comments": [
        {
          "author": "divergentdave",
          "authorAssociation": "COLLABORATOR",
          "body": "Here's a third proposal for how to handle HMAC authentication. I propose the following structure definitions:\r\n\r\n```\r\nstruct {\r\n  AggregationJobID job_id;\r\n  opaque agg_param<0..2^16-1>;\r\n  ReportShare seq<1..2^16-1>;\r\n} AggregateInitReq;\r\n\r\nstruct {\r\n  AggregationJobID job_id;\r\n  Transition seq<1..2^16-1>;\r\n} AggregateContinueReq;\r\n\r\nstruct {\r\n  AggregateReqType msg_type;\r\n  select (msg_type) {\r\n    agg_init_req:  AggregateInitReq;\r\n    agg_cont_req:  AggregateContinueReq;\r\n  }\r\n} AggregateReqInner;\r\n\r\nstruct {\r\n  TaskID task_id;\r\n  opaque inner<0..2^16-1>;\r\n  opaque tag[32];\r\n} AggregateReqOuter;\r\n\r\nstruct {\r\n  Transition seq<1..2^16-1>;\r\n} AggregateRespInner;\r\n\r\nstruct {\r\n  opaque inner<0..2^16-1>;\r\n  opaque tag[32];\r\n} AggregateRespOuter;\r\n\r\nstruct {\r\n  Interval batch_interval;\r\n  uint64 report_count;\r\n  opaque checksum[32];\r\n} AggregateShareReqInner;\r\n\r\nstruct {\r\n  TaskID task_id;\r\n  opaque inner<0..2^16-1>;\r\n  opaque tag[32];\r\n} AggregateShareReqOuter;\r\n\r\nstruct {\r\n  HpkeCiphertext encrypted_aggregate_share;\r\n} AggregateShareResp;\r\n\r\nstruct {\r\n  opaque inner<0..2^16-1>;\r\n  opaque tag[32];\r\n} AggregateShareRespOuter;\r\n```\r\n\r\nThe specification text would say in each case that the HMAC tag is over the encoding of the preceding (one or two) structure elements, and the HMAC key is selected based on the `TaskID` in either the request structure itself, or the request corresponding to the response. The byte string contained by `AggregateReqOuter.inner` encodes a message of type `AggregateReqInner`, same with `AggregateRespOuter.inner` and `AggregateRespInner`, `AggregateShareReqOuter.inner` and `AggregateShareReqInner`, `AggregateShareRespOuter.inner` and `AggregateShareRespInner`.\r\n\r\nDownsides: This way, the specification is a bit more verbose, messages will be two bytes longer for the additional length field, and various fields will have their effective length limits reduced slightly.\r\nUpsides: The text \"MUST verify the tag before interpreting the message's contents\" will be much easier to follow, and we could get more specific, stating that the contents of `opaque inner<0..2^16-1>` must not be interpreted before verifying the tag over it and (sometimes) the task ID. There is no interaction with the HTTP layer request or response (aside from its body).",
          "createdAt": "2022-03-11T22:39:03Z",
          "updatedAt": "2022-03-11T22:39:03Z"
        },
        {
          "author": "BranLwyd",
          "authorAssociation": "COLLABORATOR",
          "body": "The interop target now specifies request messages in a way that allows the task ID to be extracted without parsing the entire application-specific message -- the task ID is now always the first 32 bytes, which matches strawman solution (2) above.\r\n\r\nWe might still consider moving authentication parameters to the HTTP Authentication header later, but as far as I'm concerned that's a \"nice-to-have\" & is definitely not necessary for the interop pilot. I'm closing this bug as, as far as I'm concerned, the issue is resolved.",
          "createdAt": "2022-04-12T19:06:08Z",
          "updatedAt": "2022-04-12T19:06:08Z"
        }
      ]
    },
    {
      "number": 209,
      "id": "I_kwDOFEJYQs5GVdU3",
      "title": "Alignment with RFC 7807 Problem Details",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/issues/209",
      "state": "OPEN",
      "author": "divergentdave",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "Some of the requirements and recommendations in section 3.1 conflict with the spirit of RFC 7807, which it references.\r\n\r\nThere is presently a requirement that:\r\n\r\n> The \"instance\" value MUST be the endpoint to which the request was targeted.\r\n\r\nThe \"instance\" key is defined as one of the standard members in RFC 7807, and it says:\r\n\r\n> \"instance\" (string) - A URI reference that identifies the specific occurrence of the problem.  It may or may not yield further information if dereferenced.\r\n\r\nAs a consequence of the current text, PPM aggregators would always provide the same URI in the \"instance\" field. I would recommend that we remove the MUST requirement here. Alternately, we could define a new extension member (say, \"endpoint\") and put the aggregator's endpoint in that member, if we still wish to have it as part of the problem details. (For what it's worth, RFC 7807 allows the \"type\" and \"instance\" members to be relative URIs, so there is already a baked-in assumption that problem detail consumers retain the request URL associated with a JSON document)\r\n\r\nSecond, there's a SHOULD recommendation that the \"detail\" field be populated, and no mention of the \"title\" field. These are both standard members, defined as follows:\r\n\r\n> \"title\" (string) - A short, human-readable summary of the problem type.  It SHOULD NOT change from occurrence to occurrence of the problem, except for purposes of localization (e.g., using proactive content negotiation; see [[RFC7231], Section 3.4](https://www.rfc-editor.org/rfc/rfc7231#section-3.4)).\r\n> \"detail\" (string) - A human-readable explanation specific to this occurrence of the problem.\r\n\r\nI think we should add a recommendation that, when one of the error types from Table 1 is used, the accompanying description from the table (or a localization thereof) should be provided in the \"title\" member. The \"detail\" member could then provide more particularized information, for example, a message mentioning the old and new configuration IDs involved in an `urn:ietf:params:ppm:error:outdatedConfig` error.\r\n\r\nThird, there is currently the following requirement for a PPM-specific extension member:\r\n\r\n> The problem document MUST also include a \"taskid\" member which contains the associated PPM task ID (this value is always known, see {{task-configuration}}).\r\n\r\nAssuming that an aggregator services multiple PPM tasks at one HTTP endpoint, there are edge cases where we may want to use `urn:ietf:params:ppm:error:unrecognizedMessage`, but not know the task ID, for example, if a request body is too short to encode a task ID. With the present text, I think aggregators would have to respond with a non-PPM error type, or just a 400 Bad Request response with an empty body.\r\n\r\nAs \"taskid\" is the only extension member we define on our problem types, I think we should clarify the MUST requirement here, and only require it when the \"type\" is one of the error types in the PPM URN namespace.\r\n\r\nFor the edge cases where \"taskid\" is not known we could relax the MUST requirement, and only require a \"taskid\" member when the PPM Task ID is known. Alternately, we could suggest that the error in such error cases be of type `about:blank` (the default type, indicating no additional semantics beyond that of the HTTP status code) and with an appropriate status line, like \"400 Bad Request\".",
      "createdAt": "2022-03-24T20:38:31Z",
      "updatedAt": "2022-03-24T20:38:31Z",
      "closedAt": null,
      "comments": []
    },
    {
      "number": 210,
      "id": "I_kwDOFEJYQs5GYNsz",
      "title": "DP: Bound contribution from a single client",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/issues/210",
      "state": "OPEN",
      "author": "martinthomson",
      "authorAssociation": "CONTRIBUTOR",
      "assignees": [],
      "labels": [],
      "body": "Seeing @chris-wood present on this made it clear that there are no mechanisms that might prevent a single client from contributing to aggregates multiple times.  This is problematic for the application of DP, as the contribution of any client needs to be bounded in order to place a finite bound on the DP noise.\r\n\r\nThere is currently a fixation on having fixed-sized duration for tasks and batch limits, but neither of these help.",
      "createdAt": "2022-03-25T12:45:04Z",
      "updatedAt": "2022-04-12T13:36:05Z",
      "closedAt": null,
      "comments": [
        {
          "author": "simon-friedberger",
          "authorAssociation": "NONE",
          "body": "Given that clients don't want to break their own privacy, how is this different from the Sybil attacks discussed in #211 ?",
          "createdAt": "2022-04-12T13:36:04Z",
          "updatedAt": "2022-04-12T13:36:04Z"
        }
      ]
    },
    {
      "number": 211,
      "id": "I_kwDOFEJYQs5GYP5u",
      "title": "Sybil attack distinction",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/issues/211",
      "state": "CLOSED",
      "author": "chris-wood",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "From dkg in Vienna: \r\n\r\n> maybe distinguish between the two kinds of sybil attacks as a sybil attack against the collector (stats poisoning), vs. a sybil attack against a reporting client (privacy violation)\r\n\r\n",
      "createdAt": "2022-03-25T12:54:51Z",
      "updatedAt": "2022-05-10T14:22:57Z",
      "closedAt": "2022-05-10T14:22:56Z",
      "comments": [
        {
          "author": "martinthomson",
          "authorAssociation": "CONTRIBUTOR",
          "body": "It seems like there are a bunch of assumptions about Sybil attacks generally that are not well articulated yet.  This would certainly help.",
          "createdAt": "2022-03-25T13:40:22Z",
          "updatedAt": "2022-03-25T13:40:22Z"
        }
      ]
    },
    {
      "number": 215,
      "id": "I_kwDOFEJYQs5Hor_e",
      "title": "OHAI proxy instead of null shares",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/issues/215",
      "state": "CLOSED",
      "author": "simon-friedberger",
      "authorAssociation": "NONE",
      "assignees": [],
      "labels": [],
      "body": "It has already been mentioned that whether a client submits reports leaks. Section 6.1.2.3.4 suggests submitting \"null\" reports to mask this fact. \r\n\r\nWouldn't it be easier to use an anonymizing proxy to hide client participation?\r\n\r\nAlso, in the case of a VDAF like heavy hitters the \"null\" shares would either be very obvious (random string) or create computational effort and distort the result (a semi-common prefix).",
      "createdAt": "2022-04-12T13:25:17Z",
      "updatedAt": "2022-05-06T06:49:23Z",
      "closedAt": "2022-05-06T06:49:23Z",
      "comments": [
        {
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "body": "Our goal has been to support but not to require the use of an OHAI proxy, or any other kind of server that sits between the clients and the aggregators. There are many deployments that will want an ingestion server or a proxy for reasons ranging from client anonymization to authentication to availability, but other deployments won't want or need this.\r\n\r\nYou raise a good point about what it means to upload a null or empty report in a VDAF like Poplar1, though.",
          "createdAt": "2022-04-19T21:17:46Z",
          "updatedAt": "2022-04-19T21:17:46Z"
        },
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "I think we should continue to support both, though the \"null\" report idea is a bit underspecified right now. For Poplar1, why send a random string? I would think that some fixed string (say, the all-zero string) would make more sense.",
          "createdAt": "2022-04-26T01:09:57Z",
          "updatedAt": "2022-04-26T01:09:57Z"
        },
        {
          "author": "simon-friedberger",
          "authorAssociation": "NONE",
          "body": "If you pick all-zero that string will probably always end up in your result and will have to be part of every round of the computationally-expensive protocol.\r\n\r\nBut I agree that it's probably not a huge problem even if we have to define what the null shares are for each VDAF.",
          "createdAt": "2022-05-06T06:49:23Z",
          "updatedAt": "2022-05-06T06:49:23Z"
        }
      ]
    },
    {
      "number": 216,
      "id": "I_kwDOFEJYQs5HqSsO",
      "title": "PPM should consider specifying the acceptable HPKE parameters",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/issues/216",
      "state": "OPEN",
      "author": "BranLwyd",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "HPKE is parameterized by several different configuration choices (defined in https://www.rfc-editor.org/rfc/rfc9180.pdf, section 4): a \"key encapsulation method\", a \"key derivation function\", and an \"AEAD encryption algorithm\". The specification goes on to define several options for each of these choices in section 7.\r\n\r\nPPM currently does not constrain these values, so a specification-compliant PPM implementation may use any set of choices for these values. Different implementations will succeed at interop only if they share a common set of supported HPKE configuration values. This may lead general implementations to support as wide a variety of HPKE parameters as possible, leading to code bloat -- this is especially important in a Web setting.\r\n\r\nQuestions:\r\n* Should PPM seek to specify HPKE configuration parameters at all?\r\n* If so, what are the right parameters to specify? (The best solution might be something like \"minimally-compliant PPM implementations must support HPKE configurations X, Y, and Z; implementations may support other HPKE configurations as they wish\")",
      "createdAt": "2022-04-12T18:58:35Z",
      "updatedAt": "2022-05-12T14:38:00Z",
      "closedAt": null,
      "comments": [
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "\r\n> PPM currently does not constrain these values, so a specification-compliant PPM implementation may use any set of choices for these values. Different implementations will succeed at interop only if they share a common set of supported HPKE configuration values. This may lead general implementations to support as wide a variety of HPKE parameters as possible, leading to code bloat -- this is especially important in a Web setting.\r\n\r\nAnother word for \"code bloat\" here is \"cryptographic agility\". Agility is problematic for the reasons you mention, as well as others. However it's also often necessary in many cases. For example, lots of TLS implementations prefer X25519 for the key exchange because it's the fastest option, but some deployments are stuck using P-256 for various reasons.\r\n\r\nThat said, you're right that we don't know if we'll need this sort of agility for PPM.\r\n \r\n> Questions:\r\n> \r\n>     * Should PPM seek to specify HPKE configuration parameters at all?\r\n\r\nMy $0.02: We probably will need to eventually.\r\n\r\n>     * If so, what are the right parameters to specify? (The best solution might be something like \"minimally-compliant PPM implementations must support HPKE configurations X, Y, and Z; implementations may support other HPKE configurations as they wish\")\r\n\r\nThere is a notion in IETF standards known as \"mandatory to implement (MTI)\" ciphersuites. We might consider defining MTI suites for HPKE, but I don't think this is particularly pressing. Plus, we're likely to have wildly different opinions about what suites are MTI.\r\n\r\nTaking a step back, it's completely reasonable for a given implementation of the protocol to have only limited agility or no agility at all. It does impact interop, but in practice there are likely to be a small set of suites that 99% of people implement. For PPM, I would suspect that everyone is going to have (X25519, HKDF-SHA256, AES-GCM).\r\n",
          "createdAt": "2022-04-26T01:07:07Z",
          "updatedAt": "2022-04-26T01:07:07Z"
        },
        {
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "body": "I would recommend specifying a MTI suite while allowing other suites as needed for particular deployments, just [as we did for ECH](https://tlswg.org/draft-ietf-tls-esni/draft-ietf-tls-esni.html#name-compliance-requirements).",
          "createdAt": "2022-05-12T14:38:00Z",
          "updatedAt": "2022-05-12T14:38:00Z"
        }
      ]
    },
    {
      "number": 217,
      "id": "I_kwDOFEJYQs5HvhGi",
      "title": "Drop ordering requirement on successive Aggregate requests",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/issues/217",
      "state": "CLOSED",
      "author": "BranLwyd",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "Currently, the successive aggregate requests in an aggregation job are required to include client report data (report shares/transitions) in a consistent order.\r\n\r\nExample language from the spec:\r\n> The sequence of Transition messages corresponds to the ReportShare sequence of the AggregateInitReq. The order of these sequences MUST be the same (i.e., the nonce of the first Transition MUST be the same as first ReportShare and so on).\r\n\r\n> Next, the helper processes the Transition messages from the leader. If any message appears out of order or has an unrecognized nonce, or if any two messages have the same nonce, then the helper MUST abort with error \"unrecognizedMessage\".\r\n\r\n\r\nThe justification I have heard for this requirement is that requiring ordering saves implementations from needing to do an `O(n lg n)` sort, where `n` is the number of client reports being processed. However, even without ordering, no sort or other `O(n lg n)` operation would be required from implementations. Specifically, the aggregator can construct a hashmap from report nonce to report share/transition (requiring `O(n)` time total); then, when matching report shares/transitions to stored state, do an `O(1)` map lookup per report, for a total of `O(n)` time spent doing lookups.\r\n\r\n\r\nAn upside to dropping the ordering requirement is a simpler specification which permits a simpler implementation with fewer error modes.\r\n\r\n\r\nA downside to dropping the ordering requirement is that, even though both ordered and non-ordered implementations can do matching of request parts to stored state in `O(n)` time, I suspect that the unordered implementation will take more wallclock time (e.g. have \"larger constants hidden by the big-O\") due to the hashmap operations. [Not measured yet.]\r\n\r\n\r\nQuestions:\r\n* Is there a justification other than avoiding an `O(n lg n)` sort to requiring consistency of ordering in aggregate requests?",
      "createdAt": "2022-04-13T18:23:59Z",
      "updatedAt": "2022-06-13T19:39:34Z",
      "closedAt": "2022-06-13T19:39:34Z",
      "comments": [
        {
          "author": "BranLwyd",
          "authorAssociation": "COLLABORATOR",
          "body": "(this is a consideration post-interop-pilot, most likely--unless all parties think a change is a good idea, I think the interop pilot keeping the ordering requirement is fine)",
          "createdAt": "2022-04-13T18:29:18Z",
          "updatedAt": "2022-04-13T18:29:18Z"
        },
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "You're right that O(n) is not hard to achieve. However, not all implementors necessarily have a geneirc HashMap structure (or even a generic quicksort algorithm) on hand. For example, imagine you were implementing this in C and couldn't use stdlib. The naive algorithm for matching a request to a response would take O(n^2) time, and that's might what you go with if you never expect n to be huge.\r\n\r\nThe current text follows this design principle: Do your best to avoid design choices that permit bad (i.e., inefficient) implementations. In particular, the goal of the current spec is to only allow one \"natural\" matching algorithm. Perhaps it would be helpful to spell this algorithm out.\r\n\r\nFWIW, this exact problem came up in the design of Encrypted Client Hello. (See https://github.com/tlswg/draft-ietf-tls-esni/issues/378.) There the motivation was to reduce the risk of bad implementations becoming DoS vectors. Here the risk is even more pronounced, since the number of reports (n) processed in a single run of the aggregation sub-protocol might be 100s or even 1000s. After all, this flow is about bulk processing of large numbers of reports.\r\n\r\n\r\n",
          "createdAt": "2022-05-04T18:37:40Z",
          "updatedAt": "2022-05-04T18:46:48Z"
        },
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "Here's how we ended up solving the problem in ECH: https://github.com/davidben/draft-ietf-tls-esni/commit/f8e9df6c475f9268b3f0b9054c14f76ca9cbe9d7#",
          "createdAt": "2022-05-04T18:46:05Z",
          "updatedAt": "2022-05-04T18:46:05Z"
        },
        {
          "author": "BranLwyd",
          "authorAssociation": "COLLABORATOR",
          "body": "Closing this for now -- this is a minor request, and I think the arguments for keeping the ordering requirement are good. We can reopen if this question comes up again.",
          "createdAt": "2022-06-13T19:39:34Z",
          "updatedAt": "2022-06-13T19:39:34Z"
        }
      ]
    },
    {
      "number": 218,
      "id": "I_kwDOFEJYQs5H8C3a",
      "title": "Aggregation set agreement underspecified",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/issues/218",
      "state": "OPEN",
      "author": "simon-friedberger",
      "authorAssociation": "NONE",
      "assignees": [],
      "labels": [],
      "body": "It seems to me we are not entirely clear on how aggregators determine which set of reports to aggregate over.\r\n\r\nThe spec currently uses a checksum to verify that the sets are the same but isn't very specific about how the set is defined. If I understand correctly this is done using the `batch_interval` argument which only supports time as a selection parameter.\r\n\r\nI see a few issues here:\r\n1. We should define how aggregators agree on a set in case the checksum fails.\r\n2. `batch_interval` should probably be a `batch_filter` so it can also depend on version information, location, etc. (Of course it is difficult to define which information can be metadata and how much of a privacy concern it creates.) See #27 .\r\n3. `batch_filter` would have to be part of the `CollectReq` to support the drill-down feature discussed in other issues, e.g. #183 .",
      "createdAt": "2022-04-18T10:45:39Z",
      "updatedAt": "2022-04-26T00:58:11Z",
      "closedAt": null,
      "comments": [
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "Hi Simon!\r\n\r\n> 1. We should define how aggregators agree on a set in case the checksum fails.\r\nRight now we treat this case as a fatal error. Doing more than can get complicated. For example, one could imagine a scheme whereby the aggregators try to determine the union of their two sets and exclude reports not in the union. \r\n\r\nBefore we get into attempting to recover data, I think we should first try to get a sense of how likely this error is to occur in a typical deployment.\r\n\r\n> 2. `batch_interval` should probably be a `batch_filter` so it can also depend on version information, location, etc. (Of course it is difficult to define which information can be metadata and how much of a privacy concern it creates.) See #27 .\r\n> 3. `batch_filter` would have to be part of the `CollectReq` to support the drill-down feature discussed in other issues, e.g. #183 .\r\n\r\nWe definitely want to support this feature, however I think solving #195 would be a prerequisite.\r\n\r\n\r\n",
          "createdAt": "2022-04-26T00:58:10Z",
          "updatedAt": "2022-04-26T00:58:10Z"
        }
      ]
    },
    {
      "number": 221,
      "id": "I_kwDOFEJYQs5IIsg9",
      "title": "Usage of HPKE `info` and `aad` fields (was \"HPKE: do not use both application_info & AAD.\")",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/issues/221",
      "state": "CLOSED",
      "author": "BranLwyd",
      "authorAssociation": "COLLABORATOR",
      "assignees": [
        "BranLwyd"
      ],
      "labels": [],
      "body": "Per https://www.rfc-editor.org/rfc/rfc9180.pdf section 8.1:\r\n> Applications that only use the single-shot APIs described in Section 6 should use the Setup info parameter for specifying auxiliary authenticated information. Implementations which only expose single-shot APIs should not allow applications to use both Setup info and Context aad or exporter_context auxiliary information parameters.\r\n\r\n\r\nPPM effectively uses the single-shot APIs; we should consider refactoring PPM's usage of HPKE to use only one of application_info & AAD. Following the advice of the HPKE RFC, we would want to use application_info.\r\n\r\nThis would permit slightly simpler implementations. I am not sure how much it would simplify the HPKE computations.",
      "createdAt": "2022-04-20T21:41:18Z",
      "updatedAt": "2022-05-21T10:57:14Z",
      "closedAt": "2022-05-21T10:57:14Z",
      "comments": [
        {
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "body": "Should we then formally use the single shot HPKE APIs from [HPKE section 6.1](https://www.rfc-editor.org/rfc/rfc9180#name-encryption-and-decryption-2)?",
          "createdAt": "2022-04-20T21:57:04Z",
          "updatedAt": "2022-04-20T21:57:04Z"
        },
        {
          "author": "BranLwyd",
          "authorAssociation": "COLLABORATOR",
          "body": "That would be my recommendation (though, somewhat confusingly given the advice quoted above, those APIs still allow specifying both application info & AAD).\r\n\r\nImplementations can & do already use the single-shot APIs, so I strongly suspect specifying the single-shot APIs will be feasible. [See [here](https://github.com/divviup/janus/blob/8ad7d31b3bded508ed31e65ee8782088fdfe719c/janus_server/src/hpke.rs#L197) & [here](https://github.com/divviup/janus/blob/8ad7d31b3bded508ed31e65ee8782088fdfe719c/janus_server/src/hpke.rs#L306).]",
          "createdAt": "2022-04-20T22:25:49Z",
          "updatedAt": "2022-04-20T22:26:20Z"
        },
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "+1 to using single-shot APIs, though I'm not sure I agree that using either info or add (but not both) is simpler. What's the reasoning?",
          "createdAt": "2022-04-21T01:08:58Z",
          "updatedAt": "2022-04-21T01:08:58Z"
        },
        {
          "author": "BranLwyd",
          "authorAssociation": "COLLABORATOR",
          "body": "The reasoning is:\r\na) it follows the advice of the HPKE spec (quoted above)\r\nb) AFAICT, in a single-shot setting, application info & AAD serve exactly the same purpose, so using both is arbitrary/confusing/a potential source of mistakes. (in a multi-shot setting, application info is bound to all encryptions/decryptions done by the same context; AAD is bound to a single encryption/decryption)",
          "createdAt": "2022-04-22T16:12:55Z",
          "updatedAt": "2022-04-22T16:12:55Z"
        },
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "TBH I'm not sure I agree with the quoted guidance here. There is a concept in protocol design known as \"domain separation\", the goal of which is to provide some kind of binding of long-term secret key operations to the context in which they were used. Imagine, for example, that someone used an HPKE secret key for PPM and some other protocol. Suppose further that both are using the empty string for `info`. Then the security of our PPM deployment depends on how the other protocol uses the derived AEAD key, since in both protocols  may end up deriving the same AEAD key. One way to avoid creating this attack surface is to pick an `info` string that no other application is likely to choose so that derived keys are guaranteed to not collide (except with some negligible probability).\r\n\r\nThat said, I'd go for changing how we use `info` and `aad`. Something like this might be simpler:\r\n* Let `info` be a fixed string that identifies the protocol. It would be good if this string were relatively long, say the SHA-256 hash of \"ppm-00\".\r\n* Let `aad` encode the task ID, sender/receiver roles, etc.\r\n\r\n",
          "createdAt": "2022-04-22T16:50:29Z",
          "updatedAt": "2022-04-22T16:54:54Z"
        },
        {
          "author": "BranLwyd",
          "authorAssociation": "COLLABORATOR",
          "body": "I definitely agree that application info should include information allowing domain separation, for the reasons you mention. (Indeed, the current PPM spec includes the strings \"ppm input share\" or \"ppm aggregate share\" in its application infos, presumably for this purpose.)\r\n\r\nBut I think that's orthogonal to the question of whether we should also use AAD, since the application info could also include information other than the \"domain separation parameter\". Picking one example to make things concrete, a client upload request sets its application info to `Report.task_id || \"ppm input share\" || 0x01 || server_role` and its AAD to `Report.nonce || Report.extensions`. But it could just as easily set the application info to `Report.task_id || \"ppm input share\" || 0x01 || server_role || Report.nonce || Report.extensions` (i.e. the concatenation of the two previous strings) and not use AAD. (Or alternatively, it could place that string in the AAD and not use application info.)\r\n\r\nMy argument is that it's simpler to use only one of the parameters, since in the single-shot setting that PPM is using HPKE, the two parameters serve exactly the same purpose (i.e. including additionally-authenticated data).",
          "createdAt": "2022-04-22T17:59:46Z",
          "updatedAt": "2022-04-22T18:00:40Z"
        },
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "As I see it, our goal is to make sure that decryption only succeeds if the sender and receiver agree on the \"context\", i.e., the task ID, sender/receiver role, nonce, extensions, and so on. This way a MITM cannot force the aggregator to interpret an input share incorrectly. Does this sound reasonable to you?\r\n\r\nFrom the point of view of this threat model, I don't think it's immediately clear that sticking the context in `info` or `aad` is equivalent. For example, if we stuff the context in `info`, then it influences the derivation of the AEAD key; but depending on the AEAD, it might be feasible for an attacker to find a find two keys that decrypt the same ciphertext. (See https://eprint.iacr.org/2020/1153.pdf.) More analysis will be needed to say for sure whether this weakness in the AEAD amounts to an attack against our protocol. In the meantime, sticking the \"context\" in `aad` seems like a more conservative choice to me.",
          "createdAt": "2022-04-22T18:22:33Z",
          "updatedAt": "2022-04-22T18:22:33Z"
        },
        {
          "author": "BranLwyd",
          "authorAssociation": "COLLABORATOR",
          "body": "Given your concern, your approach SGTM. It sounds like this may be a concern worth raising with the folks working on the HPKE spec, given the advice to \"use the Setup info parameter for specifying auxiliary authenticated information\", but I'm not going to chase this down currently.",
          "createdAt": "2022-04-22T20:02:02Z",
          "updatedAt": "2022-04-22T20:02:02Z"
        },
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "So I think there's two tasks for this issue:\r\n* Move task ID from `info` to `aad`\r\n* Use single-shot APIs for HPKE\r\n\r\nAnything else?",
          "createdAt": "2022-04-26T00:50:40Z",
          "updatedAt": "2022-04-26T00:50:40Z"
        },
        {
          "author": "BranLwyd",
          "authorAssociation": "COLLABORATOR",
          "body": "Yep, I think that's it.",
          "createdAt": "2022-04-26T16:14:59Z",
          "updatedAt": "2022-04-26T16:14:59Z"
        },
        {
          "author": "BranLwyd",
          "authorAssociation": "COLLABORATOR",
          "body": "(reopening for now as the fix PR has been reverted temporarily)",
          "createdAt": "2022-05-13T16:54:30Z",
          "updatedAt": "2022-05-13T16:54:30Z"
        }
      ]
    },
    {
      "number": 226,
      "id": "I_kwDOFEJYQs5IgPYh",
      "title": "Aggregation idempotency",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/issues/226",
      "state": "OPEN",
      "author": "chris-wood",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "From @tgeoghegan:\r\n\r\nSuppose we have a task with max_batch_lifetime = 1. Consider:\r\n\r\n1. Leader makes an AggregateShareReq for some batch interval.\r\n2. Helper services the request, and marks that batch interval as having been collected once.\r\n3. Helper attempts to transmit an AggregateShareResp to leader, but the message is truncated.\r\n\r\nNow, if the leader retries its AggregateShareReq, the helper will refuse the request because the batch interval's lifetime has been consumed. So, to allow the leader to retry this request, the helper has to be willing to resend previously computed aggregate shares.\r\n\r\nIssue from #223.",
      "createdAt": "2022-04-26T19:55:29Z",
      "updatedAt": "2022-05-02T18:56:00Z",
      "closedAt": null,
      "comments": [
        {
          "author": "BranLwyd",
          "authorAssociation": "COLLABORATOR",
          "body": "This issue also affects the aggregation process: if an aggregation step fails in a similar way, the helper might believe it has \"stepped\" a VDAF preparation to step `N+1` while the leader still believes it is at step `N`.\r\n\r\nOne strawman solution would be having the helper store the \"current\" aggregation step & the \"previous\" aggregation step, then updating the PPM specification to have the leader indicate which \"step number\" it is on when sending aggregate requests (since VDAF does not & I suppose should not have to carry this information). I think this would make the aggregation steps effectively idempotent. The downsides are the increased storage cost to the helper & the increased communication cost -- can we do better?",
          "createdAt": "2022-05-02T18:54:40Z",
          "updatedAt": "2022-05-02T18:56:00Z"
        }
      ]
    },
    {
      "number": 228,
      "id": "I_kwDOFEJYQs5IlwRs",
      "title": "Message serialization doesn't seeem fully specified",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/issues/228",
      "state": "CLOSED",
      "author": "cjpatton",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "The only language I can find in the document that prescribes serialization is in Section 1.2 (please point out if I missed anything):\r\n\r\n> This document uses the presentation language of [[RFC8446](https://datatracker.ietf.org/doc/html/rfc8446)].\r\n\r\nWe intend this statement to be prescriptive, i.e., encoding/decoding of messages is as defined in RFC8446. Another valid interpretation might be \"we define the fields of each message following the conventions of RFC8446, but leaving encoding/decoding unspecified\".\r\n\r\nI think it would help to refine this statement a bit. WDYTA:\r\n\r\n> This document uses the presentation language of RFC8446 to define messages in the PPM protocol. Encoding and decoding of these messages as byte strings also follows RFC8446.",
      "createdAt": "2022-04-27T20:36:22Z",
      "updatedAt": "2022-04-28T17:45:54Z",
      "closedAt": "2022-04-28T17:45:54Z",
      "comments": [
        {
          "author": "BranLwyd",
          "authorAssociation": "COLLABORATOR",
          "body": "SGTM FWIW (this was our interpretation, and I think it makes sense to clarify)",
          "createdAt": "2022-04-27T23:41:41Z",
          "updatedAt": "2022-04-27T23:41:41Z"
        },
        {
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "body": "Yeah, this seems like a fine clarification. I don't think it was under specified before, but more information for those unfamiliar with TLS-style encoding doesn't hurt. ",
          "createdAt": "2022-04-28T16:37:38Z",
          "updatedAt": "2022-04-28T16:37:38Z"
        }
      ]
    },
    {
      "number": 230,
      "id": "I_kwDOFEJYQs5IqG1-",
      "title": "Separate report shares from aggregation parameters",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/issues/230",
      "state": "OPEN",
      "author": "chris-wood",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "Currently, the aggregation process begins by the leader sending report shares and aggregation parameters _together_ to each helper. @ekr observes that this is not strictly necessary, as the verification process should discard any reports that are invalid in the end, and the leader can cause each helper to store bogus report shares indefinitely anyway. Splitting up sharing report shares and aggregation parameters might help some implementations, e.g., by allowing the leader to stream report shares to each aggregator before initiating aggregation. For Prio3, this isn't much helpful since aggregation can begin without the collector's input. For Poplar, this might be very useful. ",
      "createdAt": "2022-04-28T16:41:37Z",
      "updatedAt": "2022-05-04T18:23:53Z",
      "closedAt": null,
      "comments": [
        {
          "author": "ekr",
          "authorAssociation": "COLLABORATOR",
          "body": "Maybe I'm confused. How is `agg_param` computed? I had thought it was constant for a given instance, because this document does not seem to define it as an output.\r\n",
          "createdAt": "2022-04-28T16:58:59Z",
          "updatedAt": "2022-04-28T16:58:59Z"
        },
        {
          "author": "divergentdave",
          "authorAssociation": "COLLABORATOR",
          "body": "`agg_param` is chosen by the collector, and sent to the leader in a `CollectReq`. For the case of Prio3, this parameter is the unit type, but for Poplar1, it will be a candidate prefix.\r\n\r\nSplitting up how report shares and aggregation parameters are sent will have an additional benefit for the Poplar1 case, in that it would allow the leader to send report shares to the helper only once, for reuse in multiple different aggregations with different candidate prefixes. This would be a significant bandwidth win.",
          "createdAt": "2022-04-28T17:05:01Z",
          "updatedAt": "2022-04-28T17:05:01Z"
        },
        {
          "author": "ekr",
          "authorAssociation": "COLLABORATOR",
          "body": "I'm not against splitting them up, but I was just making a much more trivial point, which was that the leader can send the shares to the helper prior to locally initializing. I thought there was some text here that said that, but now I can't find it so maybe I misread or maybe it changed.\r\n",
          "createdAt": "2022-04-28T17:14:28Z",
          "updatedAt": "2022-04-28T17:14:28Z"
        },
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "> I'm not against splitting them up, but I was just making a much more trivial point, which was that the leader can send the shares to the helper prior to locally initializing. I thought there was some text here that said that, but now I can't find it so maybe I misread or maybe it changed.\r\n\r\nSure, but the helper will only be able to decrypt them. It won't be able to begin processing them until it knows `agg_param` (at least in general). I suppose it might be useful to permit the helper to decrypt immediately to reduce the chance of the HPKE config getting rotated before it has a chance to decrypt.\r\n\r\nIn any case, I think this change is a good idea for the reason mentioned by @divergentdave.\r\n\r\n",
          "createdAt": "2022-05-04T18:23:53Z",
          "updatedAt": "2022-05-04T18:23:53Z"
        }
      ]
    },
    {
      "number": 237,
      "id": "I_kwDOFEJYQs5JN3WZ",
      "title": "Decide which Task parameters might be mutable.",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/issues/237",
      "state": "OPEN",
      "author": "BranLwyd",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "Tasks are defined with a number of parameters; eventually, it might be helpful to determine which might be mutated (and any restrictions on how they might be mutated).\r\n\r\nOne initial thought is that any of the parameters that end up distributed to clients are likely effectively immutable, if only due to the challenge of updating all of the clients.\r\n\r\n[This fell out of a discussion on https://github.com/divviup/janus/pull/142.]",
      "createdAt": "2022-05-06T20:48:18Z",
      "updatedAt": "2022-05-06T20:48:18Z",
      "closedAt": null,
      "comments": []
    },
    {
      "number": 239,
      "id": "I_kwDOFEJYQs5JZo6U",
      "title": "Provide error handling guidance",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/issues/239",
      "state": "OPEN",
      "author": "tgeoghegan",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "The draft defines a list of problem document types to represent conditions such as an aggregate share request being rejected because it would violate privacy requirements. Some of these are fatal but in some cases, the sender of a request can try again. For instance, if a `CollectReq` is rejected because its `batch_interval` does not contain enough reports, then the collector could either wait a while for more reports to arrive or try again immediately with a bigger `batch_interval`. We should add guidance on which errors are non-fatal and what implementations can try to do when they encounter them.",
      "createdAt": "2022-05-10T17:14:05Z",
      "updatedAt": "2022-05-10T17:14:17Z",
      "closedAt": null,
      "comments": [
        {
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "body": "Some discussion [here](https://github.com/ietf-wg-ppm/ppm-specification/pull/233#discussion_r861403548).",
          "createdAt": "2022-05-10T17:14:17Z",
          "updatedAt": "2022-05-10T17:14:17Z"
        }
      ]
    },
    {
      "number": 240,
      "id": "I_kwDOFEJYQs5JZqZ7",
      "title": "Clarify or remove MUST requirement for leader to buffer reports",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/issues/240",
      "state": "CLOSED",
      "author": "tgeoghegan",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "@chris-wood observes that we have an awkward MUST requirement on leaders buffering received reports: https://github.com/ietf-wg-ppm/ppm-specification/pull/233#discussion_r869306691",
      "createdAt": "2022-05-10T17:17:30Z",
      "updatedAt": "2022-05-11T19:27:25Z",
      "closedAt": "2022-05-11T19:27:25Z",
      "comments": []
    },
    {
      "number": 241,
      "id": "I_kwDOFEJYQs5JZsY-",
      "title": "Allow leader to explicitly cancel aggregate jobs",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/issues/241",
      "state": "OPEN",
      "author": "tgeoghegan",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "It's possible for a leader to abandon an aggregate job before it's finished, and the helper never gets to find out. For instance, suppose leader sends `AggregateInitReq`, then helper responds with a malformed `AggregateResp`, maybe just because there is a bug in the client's message encoding routine. Upon receipt of the malformed message, the leader will cease preparation of the reports in that aggregate job. From the helper's point of view, there will forever be an unfinished aggregate job, awaiting the next `AggregateReq` from leader.\r\n\r\nThis introduces an ambiguity when helper handles `AggregateShareReq`. It's possible that the helper might have some abandoned aggregate jobs whose reports would have contributed to the `AggregateShareReq`. We might want the helper to abort here, because this could indicate that the leader has jumped the gun on starting the collect protocol, but we can't, because there's no way for the helper to know whether any of those jobs were intentionally abandoned by the leader.\r\n\r\nThis could be fixed by having the leader explicitly send an aggregate job cancellation message to the helper if it sees an `AggregateResp` it doesn't like.\r\n",
      "createdAt": "2022-05-10T17:25:33Z",
      "updatedAt": "2022-05-10T17:26:20Z",
      "closedAt": null,
      "comments": [
        {
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "body": "This is a special case or at least related to #141.\r\n\r\nAt the moment, the protocol includes report counts and a checksum in aggregate shares, which aims to let us detect how bad this problem is. We can decide whether it's worth introducing this based on what we learn from running the protocol.",
          "createdAt": "2022-05-10T17:26:20Z",
          "updatedAt": "2022-05-10T17:26:20Z"
        }
      ]
    },
    {
      "number": 248,
      "id": "I_kwDOFEJYQs5Jj_EX",
      "title": "No negotiation for HPKE Configs",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/issues/248",
      "state": "OPEN",
      "author": "ekr",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "The server only supplies one config, so what happens if the server would support X22519 and P-256? We can fix this by having the server supply multiple configs.",
      "createdAt": "2022-05-12T15:38:26Z",
      "updatedAt": "2022-05-12T15:38:26Z",
      "closedAt": null,
      "comments": []
    },
    {
      "number": 255,
      "id": "I_kwDOFEJYQs5J3GMe",
      "title": "Consider specifying aggregator behavior on message-deserialization failures.",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/issues/255",
      "state": "OPEN",
      "author": "BranLwyd",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "The DAP specification defines a number of error modes, which ultimately end up mapped to error codes defined in section 3.1.\r\n\r\nCurrently, the specified behavior does not describe how to treat message-deserialization failures, in any of client-aggregator, aggregator-aggregator, or collector-aggregator communications. We should consider specifying this.\r\n\r\nInitial thoughts:\r\n* Moving to `FAILED` (with a new error code?) or `INVALID` makes sense to me, for deserialization errors during the aggregation process.\r\n* It'd be very nice if one \"bad\" client report didn't fail the entire aggregation job, e.g. we should probably specify behavior that limits the \"blast radius\" of a badly-serialized message.\r\n* We could leave this unspecified; I suppose the risk is that different implementations might treat this error mode with different semantics (e.g. some will fail a single report, some will fail the entirety of the aggregation job).",
      "createdAt": "2022-05-17T21:34:17Z",
      "updatedAt": "2022-05-17T21:37:47Z",
      "closedAt": null,
      "comments": [
        {
          "author": "BranLwyd",
          "authorAssociation": "COLLABORATOR",
          "body": "(This fell out of discussion on https://github.com/divviup/janus/pull/167; FWIW, Janus will currently transition a report aggregation to `INVALID` if it fails to decode a message, though of course that's just one implementation's choice.)",
          "createdAt": "2022-05-17T21:37:47Z",
          "updatedAt": "2022-05-17T21:37:47Z"
        }
      ]
    },
    {
      "number": 259,
      "id": "I_kwDOFEJYQs5J78Wa",
      "title": "Checking `batch-collected` at time of aggregate initalization is insufficient",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/issues/259",
      "state": "OPEN",
      "author": "divergentdave",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "I think that there is a hole in our anti-replay requirements, for tasks with `max_batch_lifetime > 1`. The issue is that currently, we only require that aggregators check if reports fall in intervals that have already been collected during the leader and helper aggregate initialization, see section `input-share-batch-validation`. We need a similar check either when handling aggregation continuations or the collect flow.\r\n\r\nAs an example of what we should be disallowing, consider a task with `min_batch_size = 10, max_batch_lifetime = 2`. Let's say that all aggregations are done with the same aggregation parameter, whatever it is.\r\n\r\n- The leader sends out an AggregateInitializeReq for its first job, with ten reports.\r\n  - The input share validation checks succeed, as there have been no collect reqeusts yet.\r\n- The leader sends out an AggregateInitializeReq for its second job, with one report. This succeeds as well.\r\n- The leader sends an AggregateContinueReq for its first job, with `finished` transitions.\r\n- The leader sends an AggregateShareReq for an interval that covers all reports in both jobs.\r\n- The leader sends an AggregateContinueReq for its second job, with `finished` transitions.\r\n  - Note that we do not require the helper to do any checks against collect requests when handling aggregation continuations. (see `agg-continue-flow`)\r\n- The leader sends a second AggregateShareReq, identical to the previous request.\r\n  - Note that the checks in `batch-parameter-validation` pass.\r\n    - The batch includes eleven reports, so `min_batch_size` is satisfied.\r\n    - We assumed `max_batch_lifetime = 2`, and each report has been collected zero or one times thus far.\r\n  - Aside from the `max_batch_lifetime` condition, the `collect-aggregate` section does not impose any other checks or conditions requiring the helper to consider previous AggregateShareReq requests when deciding if a request is valid, nor does it require that identical requests always get the same response.\r\n\r\nAfter receiving the two aggregate shares produced above, the collector could compute the aggregate function over both the first ten reports and all eleven reports. For many functions, this would allow recovery of the eleventh input, breaking our privacy goal.\r\n\r\nThere is a paragraph that says:\r\n\r\n> After issuing an aggregate-share request for a given batch interval, it is an error for the leader to issue any more aggregate or aggregate-init requests for additional reports in the batch interval. These reports will be rejected by helpers as described {{agg-init}}.\r\n\r\nHowever, the referenced section only covers the \"aggregate-init\" part, and not aggregate continuation.",
      "createdAt": "2022-05-18T19:58:46Z",
      "updatedAt": "2022-05-18T19:58:46Z",
      "closedAt": null,
      "comments": []
    },
    {
      "number": 260,
      "id": "I_kwDOFEJYQs5KCmAM",
      "title": "Clarify the domain in which aggregation job IDs must be unique",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/issues/260",
      "state": "OPEN",
      "author": "BranLwyd",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [
        "draft-01"
      ],
      "body": "The current DAP specification says (section 4.3.1.1):\r\n```\r\nGenerate a fresh AggregationJobID. This ID MUST be unique within the context of the corresponding DAP task.\r\n```\r\n...which implies that the domain of uniqueness for aggregation job IDs is at least as large as all aggregation job IDs for the related task.\r\n\r\nBut then, the aggregate continue request definition is (section 4.3.2.1):\r\n```\r\nstruct {\r\n  AggregationJobID job_id;\r\n  PrepareStep prepare_shares<1..2^16-1>;\r\n} AggregateContinueReq;\r\n```\r\n... which implies that aggregation job IDs must be unique over all aggregation jobs (on any task), since the `task_id` is omitted.\r\n\r\nDepending on intent, I suggest one of the following edits:\r\n* Update section 4.3.1.1 to state that aggregation job IDs must be unique over all aggregation jobs (for any task the aggregator knows about).\r\n* Update section 4.3.2.1 to include a `TaskId` in the `AggregateContinueReq` message.",
      "createdAt": "2022-05-19T18:56:41Z",
      "updatedAt": "2022-05-26T16:20:39Z",
      "closedAt": null,
      "comments": [
        {
          "author": "BranLwyd",
          "authorAssociation": "COLLABORATOR",
          "body": "My two cents: I really like keeping separate tasks isolated as much as possible, so I like the idea of requiring aggregation job IDs to be unique only over the domain of aggregation jobs for the related task. OTOH, this would require sending extra bytes with every `AggregateContinueReq`, which folks certainly might find unpalatable.\r\n\r\nedit: If we make aggregation job IDs globally unique, this would also make aggregation jobs the only thing other than tasks that are not identified per-task -- client reports are effectively identified by (task_id, report_nonce) currently. IMO this is another point in favor of explicitly maintaining that aggregation job IDs are unique only up to the task. This might be especially important for \"large\" implementations that may wish to shard over tasks -- if aggregation job IDs are globally unique, all shards must know about all aggregation job IDs, even those pertaining to tasks they don't know about. (edit: or, to put it another way, a sharded-by-task implementation would have to have a component that knows how to map aggregation job IDs to task IDs, which would require knowledge of all aggregation job IDs & their related tasks; IMO it'd be nicer if we shaped things so that implementations can shard over _something_, and sharding by task makes sense to me)",
          "createdAt": "2022-05-19T19:01:19Z",
          "updatedAt": "2022-05-19T22:01:22Z"
        },
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "I agree this needs to be fixed and I prefer your second suggestion.",
          "createdAt": "2022-05-24T18:28:41Z",
          "updatedAt": "2022-05-24T18:28:41Z"
        }
      ]
    },
    {
      "number": 261,
      "id": "I_kwDOFEJYQs5KDCyc",
      "title": "Aggregate{Initialize,Continue}Resp should not include the aggregation job ID",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/issues/261",
      "state": "OPEN",
      "author": "BranLwyd",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [
        "draft-01"
      ],
      "body": "`Aggregate{Initialize,Continue}Resp` both include the relevant aggregation job ID; but in both cases, the `Aggregate{Initialize,Continue}Req` includes the aggregation job ID, the response will always reflect the aggregation job ID that was included in the request, and a request is always paired with a response by means of being part of the same HTTP request/response. This looks to be unnecessary communication overhead--if that's accurate, I think we can just drop these fields.",
      "createdAt": "2022-05-19T20:49:20Z",
      "updatedAt": "2022-05-26T16:20:03Z",
      "closedAt": null,
      "comments": [
        {
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "body": "I wonder if a better design is to pull the aggregation job ID out of the DAP structure and make it a query parameter for the URL, e.g., `[aggregator]/aggregate?aggregate-job-id=...`, for two reasons: (1) the URL isn't echoed in the response, achieving the desired property of this change, and (2) this avoids any caching headaches, since different each aggregate init request would have a different URL. Thoughts?",
          "createdAt": "2022-05-19T21:18:34Z",
          "updatedAt": "2022-05-19T21:18:34Z"
        },
        {
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "body": "I think caching is a non-issue, because requests to `/aggregate` are POSTs, and POSTs are not required to be idempotent (hence not cacheable). That said I kind of like the idea of hoisting the aggregation job ID into the request URL. However, I think it'd be appropriate to put the aggregation job ID in the path (i.e., `[aggregator]/aggregation_jobs/<base64urlencoded job ID>`), since the job ID is part of the resource being acted on.\r\n\r\nAt that point, I think we might want to revisit all the DAP endpoints. Currently, we have `/upload`, `/aggregate` and `/collect`, which are all verbs. HTTP urges us to think about [resources](https://datatracker.ietf.org/doc/html/rfc7231#section-2), which ought to be nouns, and we should let the HTTP method be the verb.\r\n\r\nSo instead of POST to `[leader]/upload`, maybe we want POST to `[leader]/reports/<report_nonce>`, and instead of `[helper]/aggregate`, we want `[helper]/aggregation_jobs/<aggregation job ID>` and so on. However all of that is far beyond the scope of this issue.",
          "createdAt": "2022-05-19T21:50:26Z",
          "updatedAt": "2022-05-19T21:50:26Z"
        },
        {
          "author": "BranLwyd",
          "authorAssociation": "COLLABORATOR",
          "body": "I'm not so sure about the proposed benefit to caching -- the relevant requests are `POST`s, so they shouldn't be cached. And if we ever encounter an HTTP client that does cache `POST` requests, I don't including the IDs as query params will help: the `/aggregate` endpoint is used for all aggregation messages (initialization and continue), so we'd still run into potential caching headaches on aggregate continue requests since they'd be using identical URLs to the aggregate initialization requests.\r\n\r\nThat said, perhaps this change is desirable from the perspective of fitting HTTP semantics more closely. A few thoughts:\r\n1. Almost all messages include all relevant data in the HTTP body, rather than using the query parameter. We'd probably want to decide on a rule for what goes into query parameters vs the body, and apply it to all messages for consistency.\r\n2. The one place in the DAP spec that doesn't place all request information in the body is the `/hpke_config` request, which places the task ID as a query parameter. This is done because we want to use HTTP caching for these requests, which implies using `GET`, and `GET` can't reliably transmit a body. (IMO, if/when the HTTP `QUERY` verb is standardized+practically usable, it would be preferable to move the `/hpke_config` parameters to the request body, for consistency.)\r\n3. For aggregate initialization/continue messages specifically, IMO we'd want to move the task ID to the query parameter, too, since the task ID is effectively another part of the aggregation job identifier. (...depending on how the discussion in #260 goes.)\r\n4. Placing this ID in the body allows it to be transmitted raw/unencoded. Placing the ID in the query parameters would require some URL-safe encoding, such as base64url, which would cost a small but non-negligible number of bytes.\r\n\r\nAll that said, IMO I kinda like keeping all of the request parameters together in one place, and IMO the body is a slightly nicer place to put the request parameters than the URL query parameter (since we can transmit with whatever encoding we want, saving a few bytes).",
          "createdAt": "2022-05-19T21:52:26Z",
          "updatedAt": "2022-05-19T21:52:26Z"
        },
        {
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "body": "Yeah, sorry, I forgot these were POSTs. ",
          "createdAt": "2022-05-19T21:53:01Z",
          "updatedAt": "2022-05-19T21:53:01Z"
        },
        {
          "author": "BranLwyd",
          "authorAssociation": "COLLABORATOR",
          "body": "I like Tim's idea of making the IDs part of the URL path if we move the IDs out of the request body, but also agree that a larger refactoring of the URL layout is beyond the scope of this issue.",
          "createdAt": "2022-05-19T21:55:36Z",
          "updatedAt": "2022-05-19T21:55:36Z"
        }
      ]
    },
    {
      "number": 264,
      "id": "I_kwDOFEJYQs5KP_-i",
      "title": "Consider unifying the top-level media type used for DAP messages.",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/issues/264",
      "state": "OPEN",
      "author": "BranLwyd",
      "authorAssociation": "COLLABORATOR",
      "assignees": [
        "BranLwyd"
      ],
      "labels": [
        "draft-01"
      ],
      "body": "Currently, DAP uses the following media types (defined in section 7.1):\r\n* `application/dap-hpke-config`\r\n* `message/dap-report`\r\n* `message/dap-aggregate-initialize-req`\r\n* `message/dap-aggregate-initialize-resp`\r\n* `message/dap-aggregate-continue-req`\r\n* `message/dap-aggregate-continue-resp`\r\n* `message/dap-aggregate-share-req`\r\n* `message/dap-aggregate-share-resp`\r\n* `message/dap-collect-req`\r\n* `message/dap-collect-resp`\r\n\r\nNote that the first uses the `application` top-level type, while the remainder use the `message` top-level type. For consistency, I suggest we use the same top-level type for all messages.\r\n\r\nWhich type is more appropriate? Per [RFC 2046](https://www.rfc-editor.org/rfc/rfc2046.html):\r\n* `application` is for \"either uninterpreted binary data or information to be processed by an application\"\r\n* `message` is for \"an encapsulated message\"; all of the motivating examples (see section 5.2) are around encaspulating one message format inside another, or fragmenting a message into multiple chunks. [RFC 6838](https://www.rfc-editor.org/rfc/rfc6838.html) provides further guidance that \"multipart and message are composite types; that is, they provide a means of encapsulating zero or more objects, each one a separate media type.\"\r\n\r\nGiven that DAP messages are not a method of encapsulating a message of a different type, I suggest that `application` is the more appropriate top-level type to use. This is also supported by the rather large number of `application` media types vs the relatively tiny number of `message` media types in [IANA's media types list](https://www.iana.org/assignments/media-types/media-types.xhtml).\r\n\r\n(this issue fell out of discussion on https://github.com/divviup/janus/pull/183)",
      "createdAt": "2022-05-23T21:20:22Z",
      "updatedAt": "2022-05-26T16:20:20Z",
      "closedAt": null,
      "comments": [
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "Agreed, `application` seems better.",
          "createdAt": "2022-05-24T18:30:36Z",
          "updatedAt": "2022-05-24T18:30:36Z"
        },
        {
          "author": "divergentdave",
          "authorAssociation": "COLLABORATOR",
          "body": "The `message/` types were chosen in PR #128 on a tentative basis, and marked with \"OPEN ISSUE: Solicit review of these allocations from domain experts.\"\r\n\r\nBased on the encapsulation reasoning, I agree that `application` be most appropriate for our media types.",
          "createdAt": "2022-05-24T19:03:49Z",
          "updatedAt": "2022-05-24T19:03:49Z"
        }
      ]
    },
    {
      "number": 266,
      "id": "I_kwDOFEJYQs5KfhBk",
      "title": "Align spec with vdaf-01",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/issues/266",
      "state": "OPEN",
      "author": "cjpatton",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [
        "draft-01"
      ],
      "body": "The next VDAF draft is out. It includes some minor changes that we'll need to adopt here.\r\nhttps://datatracker.ietf.org/doc/draft-irtf-cfrg-vdaf/01/\r\n",
      "createdAt": "2022-05-26T16:19:19Z",
      "updatedAt": "2022-05-26T16:19:52Z",
      "closedAt": null,
      "comments": []
    },
    {
      "number": 267,
      "id": "I_kwDOFEJYQs5Kpdhx",
      "title": "Specify handling of agg_param",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/issues/267",
      "state": "OPEN",
      "author": "simon-friedberger",
      "authorAssociation": "NONE",
      "assignees": [],
      "labels": [],
      "body": "There is an agg_param in AggregateInitializeReq and in CollectReq and in AggregateShareReq.\r\nIIUC CollectReq.agg_param may need to be forwarded as AggregateInitializeReq.agg_param or - depending on the VDAF - later as AggregateShareReq.agg_param.\r\n\r\nISTM the logic needs to be specified to implement DAP correctly.",
      "createdAt": "2022-05-30T08:29:30Z",
      "updatedAt": "2022-05-31T16:12:58Z",
      "closedAt": null,
      "comments": [
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "Yes, both the agg_param and batch_interval need to match. Is there anything that needs to change in order to make this so?",
          "createdAt": "2022-05-31T15:16:49Z",
          "updatedAt": "2022-05-31T15:16:49Z"
        },
        {
          "author": "simon-friedberger",
          "authorAssociation": "NONE",
          "body": "Well, if the agg_param in all three (CollectReq, AggregateInitializeReq, AggregateShareReq) must be the same the leader cannot start aggregating before the collector sends the request. Which is an optimization that was requested, right?\r\n\r\nI think there are two valid scenarios:\r\n1. AggregateInitializeReq.agg_param can be determined by the leader, e.g. because it is empty. In this case the leader can start aggregating ahead of time, without a request. Later AggregateShareReq.agg_param will be set to CollectReq.agg_param.\r\n2. AggregateInitializeReq.agg_param does need information from the collector. So it is set to CollectReq.agg_param. Presumably AggregateShareReq.agg_param can then be empty.\r\n\r\n",
          "createdAt": "2022-05-31T15:29:50Z",
          "updatedAt": "2022-05-31T15:29:50Z"
        },
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "Right, these are the two valid scenarios. For (2.) the current use case is Prio3, where the agg_param is always \"\" and aggregation can begin prior to receiving a collect request. For (1.) the envisioned use case is Poplar1, where the agg parameter encodes a set of candidate prefixes. In general these cannot be known until the agg result for a previous Poplar1 evaluation has been collected.",
          "createdAt": "2022-05-31T16:01:17Z",
          "updatedAt": "2022-05-31T16:01:42Z"
        },
        {
          "author": "simon-friedberger",
          "authorAssociation": "NONE",
          "body": "So we need a flag in the Task to determine which scenario applies, right?",
          "createdAt": "2022-05-31T16:05:40Z",
          "updatedAt": "2022-05-31T16:05:40Z"
        },
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "Unless this impacts interop, I don't think the spec needs normative text to address this. I think the text we have in the overview is sufficient.",
          "createdAt": "2022-05-31T16:12:58Z",
          "updatedAt": "2022-05-31T16:12:58Z"
        }
      ]
    },
    {
      "number": 270,
      "id": "I_kwDOFEJYQs5Ls3zt",
      "title": "Consider specifying problem type for \"unrecognized aggregation job\"",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/issues/270",
      "state": "OPEN",
      "author": "BranLwyd",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "Similarly to the \"unrecognizedTask\" error token, a request might reference a nonexistent/unknown aggregation job. It may be useful to specify an \"unrecognizedAggregationJob\" or similar error token for this case.",
      "createdAt": "2022-06-13T23:04:34Z",
      "updatedAt": "2022-06-13T23:04:34Z",
      "closedAt": null,
      "comments": []
    },
    {
      "number": 271,
      "id": "I_kwDOFEJYQs5L1mLK",
      "title": "Consider enforcing min_batch_size check in aggregator",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/issues/271",
      "state": "OPEN",
      "author": "wangshan",
      "authorAssociation": "NONE",
      "assignees": [],
      "labels": [],
      "body": "`min_batch_size` as part of task parameters is distributed out of band by aggregators. At the moment there's no protocol level support to guarantee `min_batch_size` is not maliciously reduced by a dishonest leader. For use cases that work with central differential privacy, the `min_batch_size` is chosen based on an epsilon-dp guarantee over a certain batch. A dishonest leader can send a smaller `min_batch_size` to helper to break a strong dp guarantee.\r\n \r\nOne possible solution is to include parameters like `min_batch_size` (and other privacy parameters, for eg. epsilons in differential privacy) in `Extension`, which will become part of AAD therefore avoid tempering, and enforcing aggregators to check the out-of-band `min_batch_size` matches the ones included in every `Extension` field for the same task. Aggregator can also implement a one-off calculation on the task parameters to verify the `min_batch_size` is reasonable with other provided privacy parameters. For example, given a local differential privacy epsilon e_0, target central differential privacy epsilon e_c, and a min_batch_size N,  we can calculate whether e_c can be achieved  by aggregating e_0 over N reports, by using various shuffling amplification analysis.",
      "createdAt": "2022-06-15T14:41:02Z",
      "updatedAt": "2022-06-17T09:11:00Z",
      "closedAt": null,
      "comments": [
        {
          "author": "BranLwyd",
          "authorAssociation": "COLLABORATOR",
          "body": "`min_batch_size` is distributed out-of-band, which means that the helper and leader are considered to both have the value configured separately (i.e. without a chance for one of the aggregators modify the value that is configured for the other aggregator).\r\n\r\n`min_batch_size` is also evaluated separately and independently by each aggregator for each collect operation. The leader's check is specified in [Collection Initialization](https://ietf-wg-ppm.github.io/draft-ietf-ppm-dap/draft-ietf-ppm-dap.html#name-collection-initialization) & the helper's check is specified in [Collection Aggregation](https://ietf-wg-ppm.github.io/draft-ietf-ppm-dap/draft-ietf-ppm-dap.html#name-collection-aggregation). (In both cases, the relevant section refers to the [Validating Batch Parameters](https://ietf-wg-ppm.github.io/draft-ietf-ppm-dap/draft-ietf-ppm-dap.html#name-validating-batch-parameters) section which specifies the `min_batch_size` check directly.)\r\n\r\nGiven the above, I believe a malicious leader cannot reduce `min_batch_size`, either at time of task initialization or at time of collection. (A malicious leader can certainly skip its own `min_batch_size` check, but as long as the helper does not collude, a small batch will still be caught by the helper's check.)\r\n\r\n> Aggregator can also implement a one-off calculation on the task parameters to verify the `min_batch_size` is reasonable with other provided privacy parameters.\r\n\r\nThis is an interesting idea & worthy of consideration IMO -- AFAIK, the DAP spec currently does not speak to what values of `min_batch_size` are reasonable.",
          "createdAt": "2022-06-16T18:11:03Z",
          "updatedAt": "2022-06-16T18:11:03Z"
        },
        {
          "author": "wangshan",
          "authorAssociation": "NONE",
          "body": "I think the problem is DAP doesn't specify how task parameters are distributed out-of-band. If the task parameters is sent to helper from a malicious leader before task initialisation, then the helper would check against a wrong `min_batch_size` later.\r\n\r\nHaving said that, my above suggestion of checking against a `min_batch_size` in AAD also assumes client have the right task parameters.\r\n\r\nOn the other hand, I see there is an open issue in [Differential privacy](https://ietf-wg-ppm.github.io/draft-ietf-ppm-dap/draft-ietf-ppm-dap.html#name-differential-privacy):\r\n```\r\n[OPEN ISSUE: While parameters configuring the differential privacy noise (like specific distributions / variance) can be agreed upon out of band by the aggregators and collector, there may be benefits to adding explicit protocol support by encoding them into task parameters.]\r\n```\r\nThese DP parameters will face the same problem: how do we guarantee they are configured honestly.\r\n\r\nI agree we should consider adding `min_batch_size` calculation from epsilon-dp parameters. There are well researched paper about calculating `min_batch_size` based on local DP from each client and a desired central DP on the batch. This _may_ need to be VDAF specific though.",
          "createdAt": "2022-06-16T20:10:04Z",
          "updatedAt": "2022-06-16T20:10:04Z"
        },
        {
          "author": "simon-friedberger",
          "authorAssociation": "NONE",
          "body": "Regarding the values of `min_batch_size`, there is an explicit statement in \"[6.4 Batch Parameters](https://ietf-wg-ppm.github.io/draft-ietf-ppm-dap/draft-ietf-ppm-dap.html#name-batch-parameters)\":\r\n\r\n> This document does not specify how to choose minimum batch sizes.\r\n\r\nI think there also used to be a somewhat obvious statement that if `min_batch_size` is 1 there is no privacy but I cannot find it anymore.\r\n\r\nI assume specification is avoided because there might be corner cases where low values make sense, e.g. some tasks might have a batch size of 2 because plausible deniability is enough. I would also like to see some guidance/examples on this but probably in the VDAF spec.",
          "createdAt": "2022-06-17T09:11:00Z",
          "updatedAt": "2022-06-17T09:11:00Z"
        }
      ]
    },
    {
      "number": 272,
      "id": "I_kwDOFEJYQs5L20ft",
      "title": "Increase Ciphertext size limit",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/issues/272",
      "state": "OPEN",
      "author": "wangshan",
      "authorAssociation": "NONE",
      "assignees": [],
      "labels": [],
      "body": "Current HPKE Ciphertext size is limited to 2 bytes, about 65KB, many use cases will need more than this, Prio for eg. doesn't have this limit. Can we change this to 4 bytes  so the size can be `<1..2^32-1>`?\r\n\r\n```\r\nstruct {\r\n  HpkeConfigId config_id;    // config ID\r\n  opaque enc<1..2^16-1>;     // encapsulated HPKE key\r\n  opaque payload<1..2^16-1>; // ciphertext\r\n} HpkeCiphertext;\r\n```",
      "createdAt": "2022-06-15T19:48:27Z",
      "updatedAt": "2022-06-15T19:48:27Z",
      "closedAt": null,
      "comments": []
    },
    {
      "number": 273,
      "id": "I_kwDOFEJYQs5L6ZxK",
      "title": "Collect without interval",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/issues/273",
      "state": "OPEN",
      "author": "wangshan",
      "authorAssociation": "NONE",
      "assignees": [],
      "labels": [],
      "body": "If the collector is not interested in time and interval, but simply want to collect aggregation in a batch that meets `min_batch_size`. Then can the protocol support a 'batch-based collection' instead of current interval-based?\r\n\r\nConsider a Prio usecase, when `max_batch_lifetime == 1`, collector will only need to collect the aggregation so far, with a batch size B >= `min_batch_size`. This can be orchestrated by the leader, which can implement a counting service to track batch size for a task, once it reaches `min_batch_size`, leader sends AggregateShareReq to collect helper's `aggregate_share` and return to collector.\r\n\r\nThis requires a new id to tie agg-flow with agg-share-flow. For example, in addition to `agg_job_id`, leader can send a unique `batch_id` in every AggregateReq. At collect time, leader use the same `batch_id` to collect `output_share` in helper (helper can still proactively aggregate output_shares to `aggregate_share`, since there are no more batch windows, helper can store `aggregate_share` by `agg_job_id`, or accumulate all aggregation jobs' `output_share` to one `aggregate_share`, and store it with `batch_id`). Illustrated as following:\r\n\r\n```\r\n|<------------------------ batch_id1 ----------------->| <== AggregationShareReq\r\n|    agg_job_id1     |   agg_job_id2   |   agg_job_id3 | <== AggregateReq\r\nT0                                                    Tm <== Time\r\n```\r\nHere [T0, Tm] is the time takes to aggregate `min_batch_size` number of reports, it has no relationship with `min_batch_duration` or collector interval.\r\n\r\nAs this issue pointed out: https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/issues/195, to avoid privacy leak, each batch window must contain at least `min_batch_size` reports, otherwise attacker can find ways to slice intervals to break privacy guarantee. But if the protocol does require each batch window meets `min_batch_size`, then the collect interval itself is no longer useful, since the duration that takes to meet `min_batch_size` is the smallest duration that can be queried. Therefore, it seems to make sense to base collection entirely on batch size, not interval.\r\n",
      "createdAt": "2022-06-16T13:55:49Z",
      "updatedAt": "2022-06-17T12:35:45Z",
      "closedAt": null,
      "comments": [
        {
          "author": "wangshan",
          "authorAssociation": "NONE",
          "body": "In this case the aggregators no longer need to worry about `min_batch_duration`. Leader can store last know Tm to filter out late arrivals if needed.",
          "createdAt": "2022-06-16T13:59:51Z",
          "updatedAt": "2022-06-16T13:59:51Z"
        },
        {
          "author": "simon-friedberger",
          "authorAssociation": "NONE",
          "body": "This seems similar to my suggestion in #218 of having a `batch_filter` to allow more flexible specification of subsets of reports.",
          "createdAt": "2022-06-17T08:29:29Z",
          "updatedAt": "2022-06-17T08:29:29Z"
        },
        {
          "author": "wangshan",
          "authorAssociation": "NONE",
          "body": "Yes, `batch_filter` sounds like a more generic name that can incorporate both batch interval and batch id. \r\n\r\nBut I think allowing advanced filter can open up privacy concerns. When slicing the batches, one not only have to make sure the sliced batch meets all privacy guarantees, but also all the deltas with previously slices. We may find a way to do this with time intervals, but adding other metadata like region will make it extremely hard. These metadata will likely be related to client measurements, so I think it's better to encode such information in the measurement, or designing different tasks for them. \r\n\r\nThere are use cases where drill down or fine-grained filtering is not needed, usr simply want aggregate results with privacy guarantee.",
          "createdAt": "2022-06-17T12:01:23Z",
          "updatedAt": "2022-06-17T12:01:23Z"
        },
        {
          "author": "simon-friedberger",
          "authorAssociation": "NONE",
          "body": "Agreed, previous discussion on this topic is mainly here: #195 ",
          "createdAt": "2022-06-17T12:35:45Z",
          "updatedAt": "2022-06-17T12:35:45Z"
        }
      ]
    },
    {
      "number": 274,
      "id": "I_kwDOFEJYQs5L6jUI",
      "title": "Consider supporting coarse-grained timestamp in Nonce",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/issues/274",
      "state": "OPEN",
      "author": "wangshan",
      "authorAssociation": "NONE",
      "assignees": [],
      "labels": [],
      "body": "Not sure if DAP enforces precision of `Nonce.Time`:\r\n\r\n```\r\nTime uint64; /* seconds elapsed since start of UNIX epoch */\r\n```\r\n\r\nBut with fine-grained timestamp, it is easier for attacker to associate a report with the user sent that report. For example, if timestamp is accurate to second, and leader is compromised, attacker can compare users that uploaded at a given second (perhaps from a routing server) and reports' timestamp, then figure out if a particular user has contributed to a task. With a coarse-grained timestamp, however, we can minimise this threat with a secure routing server. Anti-replay can still be satisfied with the UUID part of Nonce.\r\n\r\n\r\n",
      "createdAt": "2022-06-16T14:25:47Z",
      "updatedAt": "2022-06-22T18:41:36Z",
      "closedAt": null,
      "comments": [
        {
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "body": "This is a valid concern. One reasonable change would be to modify the report timestamp to align with the batch window start (min_batch_duration), and then bump the size of the nonce to offset the increase change of collisions. Specifically, this would mean we update the Nonce like so:\r\n\r\n~~~\r\nstruct {\r\n  Time time; // set to min_batch_duration for current batch window\r\n  uint8 rand[32]; // or 16 bytes, whatever we're comfortable with for the sake of minimizing collisions\r\n} Nonce;\r\n~~~\r\n\r\n@wangshan, would this work? @ekr, @tgeoghegan, @cjpatton, thoughts?",
          "createdAt": "2022-06-22T18:41:35Z",
          "updatedAt": "2022-06-22T18:41:35Z"
        }
      ]
    },
    {
      "number": 276,
      "id": "I_kwDOFEJYQs5MFYra",
      "title": "Add metadata definition",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/issues/276",
      "state": "OPEN",
      "author": "simon-friedberger",
      "authorAssociation": "NONE",
      "assignees": [],
      "labels": [],
      "body": "It would be convenient for testing purposes if we could just collect some random data and also send that data as metadata for comparison.\r\n\r\nSince we already discussed that we might need other metadata for slicing I think it would be good to add a definition for it. Could probably be as simple as saying \"there are `n` opaque metadata bytes with `n`, it's meaning and usage defined by the task\".",
      "createdAt": "2022-06-20T07:18:20Z",
      "updatedAt": "2022-06-20T07:18:20Z",
      "closedAt": null,
      "comments": []
    }
  ],
  "pulls": [
    {
      "number": 2,
      "id": "MDExOlB1bGxSZXF1ZXN0NTc4OTQxNzU0",
      "title": "Describe the cryptographic dependencies for the candidate protocol",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/pull/2",
      "state": "MERGED",
      "author": "cjpatton",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "Solves #1.\r\n\r\nThis adds a high level description of the current candidate for our version of Prio. (Note that this is subject to change as the threat \r\nmodel and system requirements evolve.) \r\n\r\nIt then enumerates the cryptographic primitives with which the protocol could be instantiated, including the FF parameters, KEM, and PRG.",
      "createdAt": "2021-02-24T03:29:56Z",
      "updatedAt": "2021-06-17T21:15:37Z",
      "baseRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "baseRefName": "main",
      "baseRefOid": "ca9cebcfd164db7f0c0963d4fa7458de0e35976e",
      "headRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "headRefName": "cjpatton/primitives",
      "headRefOid": "18a82ef4412443cc378b71e3c2e82ccd4e9b9f31",
      "closedAt": "2021-02-27T03:20:02Z",
      "mergedAt": "2021-02-27T03:20:02Z",
      "mergedBy": "chris-wood",
      "mergeCommit": {
        "oid": "2b46fe7cdab7bd6f15fd467c4da4e526d28bec31"
      },
      "comments": [],
      "reviews": [
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTk3Nzg4Njc0",
          "commit": {
            "abbreviatedOid": "43ae90e"
          },
          "author": "acmiyaguchi",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-02-24T18:21:19Z",
          "updatedAt": "2021-02-24T19:03:28Z",
          "comments": [
            {
              "originalPosition": 26,
              "body": "Will s-way secret sharing be a vital feature of the v3 API? Neither libprio nor libprio-rs have implemented a system with more than two parties.",
              "createdAt": "2021-02-24T18:21:19Z",
              "updatedAt": "2021-02-27T02:45:07Z"
            },
            {
              "originalPosition": 86,
              "body": "Be explicit about what state is (input-shares vs accumulated shares):\r\n\r\n```suggestion\r\n   without needing to maintain input-shares from the previous step.\r\n```",
              "createdAt": "2021-02-24T18:39:12Z",
              "updatedAt": "2021-02-27T02:45:07Z"
            },
            {
              "originalPosition": 88,
              "body": "```suggestion\r\n**Minimizing bandwidth overhead.**\r\n```",
              "createdAt": "2021-02-24T18:41:23Z",
              "updatedAt": "2021-02-27T02:45:07Z"
            },
            {
              "originalPosition": 114,
              "body": "To clarify, does the size of the field affect the performance of the polynomial operations? I would guess that fields that aren't powers of 2 will be less performant than those that are, unless the p in the next section can be chosen carefully to address this.",
              "createdAt": "2021-02-24T18:45:30Z",
              "updatedAt": "2021-02-27T02:45:07Z"
            },
            {
              "originalPosition": 118,
              "body": "The numbers in this list are all 1. ",
              "createdAt": "2021-02-24T18:46:58Z",
              "updatedAt": "2021-02-27T02:45:07Z"
            },
            {
              "originalPosition": 152,
              "body": "Is this how libprio-rs handles the exchange of the shared PRG secret now ([via ECIES](https://github.com/abetterinternet/libprio-rs/blob/61efbcc10f4ece6f3403edb7c49de3f9c479a1d7/src/encrypt.rs#L72-L76))?",
              "createdAt": "2021-02-24T18:52:24Z",
              "updatedAt": "2021-02-27T02:45:07Z"
            },
            {
              "originalPosition": 133,
              "body": "What do the bits refer to?",
              "createdAt": "2021-02-24T18:57:28Z",
              "updatedAt": "2021-02-27T02:45:07Z"
            },
            {
              "originalPosition": 114,
              "body": "Does arbitrary sized finite fields imply the use of bignums? Will the field sizes be carefully chosen for performance (e.g. recommended EC primes of 256, 384, etc)?",
              "createdAt": "2021-02-24T19:03:05Z",
              "updatedAt": "2021-02-27T02:45:07Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTk4MDk0NzYw",
          "commit": {
            "abbreviatedOid": "43ae90e"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-02-25T02:02:48Z",
          "updatedAt": "2021-02-25T02:02:48Z",
          "comments": [
            {
              "originalPosition": 26,
              "body": "In my view, it's worth adding in this flexibility now in case we end up needing it later. Depending on our security considerations and how address resilience, it may end up being useful to have 3 or more aggregators.",
              "createdAt": "2021-02-25T02:02:48Z",
              "updatedAt": "2021-02-27T02:45:07Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTk4MDk1MzU2",
          "commit": {
            "abbreviatedOid": "43ae90e"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-02-25T02:04:22Z",
          "updatedAt": "2021-02-25T02:04:23Z",
          "comments": [
            {
              "originalPosition": 86,
              "body": "Changed \"maintain state\" to \"keep around the input share\".",
              "createdAt": "2021-02-25T02:04:22Z",
              "updatedAt": "2021-02-27T02:45:07Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTk4MDk5ODM4",
          "commit": {
            "abbreviatedOid": "43ae90e"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-02-25T02:16:08Z",
          "updatedAt": "2021-02-25T02:16:09Z",
          "comments": [
            {
              "originalPosition": 114,
              "body": "I don't think we should try to support arbitrary fields; instead, we should pick a few fields of different sizes and develop optimized versions of each. I suspect that generic bignum libraries would be too slow. (That said, a coworker of mine developed some pretty fast code that works for any prime field of size < 2^126. We'll be open sourcing this very soon.) As far as using off-the-shelf code for ECC fields. My sense is that he design criteria for ECC are quite different from ours. Hence, I'm not sure that this would be suitable. Worth looking into, though.\r\n",
              "createdAt": "2021-02-25T02:16:09Z",
              "updatedAt": "2021-02-27T02:45:07Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTk4MTAwMzMz",
          "commit": {
            "abbreviatedOid": "43ae90e"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-02-25T02:17:15Z",
          "updatedAt": "2021-02-25T02:17:15Z",
          "comments": [
            {
              "originalPosition": 118,
              "body": "Most Markdown renderers turn these into an ascending sequence, i.e., \"1.\", \"2.\", \"3.\", and so on. This just indicates that I want an enumerated list.",
              "createdAt": "2021-02-25T02:17:15Z",
              "updatedAt": "2021-02-27T02:45:07Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTk4MTAxMDI5",
          "commit": {
            "abbreviatedOid": "43ae90e"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-02-25T02:19:07Z",
          "updatedAt": "2021-02-25T02:19:07Z",
          "comments": [
            {
              "originalPosition": 152,
              "body": "No, since ECIES is full blown encryption.\r\n\r\nNote that we may end up wanting full-blown encryption, depending on our security considerations. If we do, then HPKE would still provide it.",
              "createdAt": "2021-02-25T02:19:07Z",
              "updatedAt": "2021-02-27T02:45:07Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTk4MTAxOTM4",
          "commit": {
            "abbreviatedOid": "43ae90e"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-02-25T02:21:30Z",
          "updatedAt": "2021-02-25T02:21:30Z",
          "comments": [
            {
              "originalPosition": 133,
              "body": "\"bits\" indicates the size of the prime, i.e., the prime is roughly 2^bits. E.g, log2(3221225473) \\approx 31.58. I added a note to clarify.",
              "createdAt": "2021-02-25T02:21:30Z",
              "updatedAt": "2021-02-27T02:45:07Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTk4MTA5MTAz",
          "commit": {
            "abbreviatedOid": "4c1024f"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "\ud83d\udea2 great start!",
          "createdAt": "2021-02-25T02:29:44Z",
          "updatedAt": "2021-02-25T02:52:06Z",
          "comments": [
            {
              "originalPosition": 51,
              "body": "Should we mark this consensus protocol (for both leader and r selection) as a dependency?",
              "createdAt": "2021-02-25T02:29:44Z",
              "updatedAt": "2021-02-27T02:45:07Z"
            },
            {
              "originalPosition": 49,
              "body": "Out of curiosity, why use separate functions to denote the extension of K for each type? Is it not the case that `n = p(n) = u(n) = v(n)`?",
              "createdAt": "2021-02-25T02:31:03Z",
              "updatedAt": "2021-02-27T02:45:07Z"
            },
            {
              "originalPosition": 64,
              "body": "```suggestion\r\nobtain the final result.\r\n\r\n[[OPEN ISSUE: sketch out the b=1 path]]\r\n```",
              "createdAt": "2021-02-25T02:31:48Z",
              "updatedAt": "2021-02-27T02:45:07Z"
            },
            {
              "originalPosition": 52,
              "body": "```suggestion\r\ndesignate one of the aggregators as the leader.\r\n\r\n[[OPEN ISSUE: specify consensus protocol.]]\r\n\r\nThe protocol proceeds as\r\n```",
              "createdAt": "2021-02-25T02:32:22Z",
              "updatedAt": "2021-02-27T02:45:07Z"
            },
            {
              "originalPosition": 70,
              "body": "What is the core protocol? (Ideally this doc would be self-contained, so the core should be sketched here or somewhere nearby.)",
              "createdAt": "2021-02-25T02:33:11Z",
              "updatedAt": "2021-02-27T02:45:07Z"
            },
            {
              "originalPosition": 79,
              "body": "```suggestion\r\n   encrypts each (input, proof) share under the public key of the share's\r\n```",
              "createdAt": "2021-02-25T02:33:49Z",
              "updatedAt": "2021-02-27T02:45:07Z"
            },
            {
              "originalPosition": 86,
              "body": "```suggestion\r\n   without needing to cache the input share from the previous step.\r\n```",
              "createdAt": "2021-02-25T02:34:39Z",
              "updatedAt": "2021-02-27T02:45:07Z"
            },
            {
              "originalPosition": 117,
              "body": "Can we mark as an open issue to parameterize this (as HCG provided)?",
              "createdAt": "2021-02-25T02:36:25Z",
              "updatedAt": "2021-02-27T02:45:07Z"
            },
            {
              "originalPosition": 135,
              "body": "How did we generate these primes? ",
              "createdAt": "2021-02-25T02:40:40Z",
              "updatedAt": "2021-02-27T02:45:07Z"
            },
            {
              "originalPosition": 147,
              "body": "```suggestion\r\npublic key encryption and cryptographically secure pseudorandom number generation (CSPRNG). The combination of\r\n```",
              "createdAt": "2021-02-25T02:42:39Z",
              "updatedAt": "2021-02-27T02:45:07Z"
            },
            {
              "originalPosition": 147,
              "body": "(common form in IETF standards)",
              "createdAt": "2021-02-25T02:43:13Z",
              "updatedAt": "2021-02-27T02:45:07Z"
            },
            {
              "originalPosition": 154,
              "body": "```suggestion\r\nthese primitives that we use here allows us to make an additional\r\nsimplification. However, we assume users and leaders communicate over a secure,\r\nauthenticated channel, such as TLS. As a result, we only need to encrypt\r\nCSPRNG seeds, which requires only a key-encapsulation mechanism (KEM) \r\nrather than full-blown encryption.\r\n```",
              "createdAt": "2021-02-25T02:47:42Z",
              "updatedAt": "2021-02-27T02:45:07Z"
            },
            {
              "originalPosition": 171,
              "body": "```suggestion\r\nvariety of languages.\r\n\r\n[[OPEN ISSUE: specify how HPKE can implement Encaps and Decaps above.]]\r\n```",
              "createdAt": "2021-02-25T02:48:57Z",
              "updatedAt": "2021-02-27T02:45:07Z"
            },
            {
              "originalPosition": 183,
              "body": "```suggestion\r\nK, then map each chunk of l bytes to an element of K in the natural way.\r\n\r\n[[OPEN ISSUE: determine if more than k*l byes are needed to deal with bias for each element.]]\r\n```",
              "createdAt": "2021-02-25T02:51:50Z",
              "updatedAt": "2021-02-27T02:45:07Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTk5NzQ5OTQz",
          "commit": {
            "abbreviatedOid": "4c1024f"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-02-26T16:41:16Z",
          "updatedAt": "2021-02-26T16:41:16Z",
          "comments": [
            {
              "originalPosition": 51,
              "body": "This is something we'll have to figure out once we have picked a threat model. I'll mark it as an open issue for now. ",
              "createdAt": "2021-02-26T16:41:16Z",
              "updatedAt": "2021-02-27T02:45:07Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTk5NzU3MDg0",
          "commit": {
            "abbreviatedOid": "4c1024f"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-02-26T16:49:31Z",
          "updatedAt": "2021-02-26T16:49:31Z",
          "comments": [
            {
              "originalPosition": 49,
              "body": "Actually \"K^n\" is meant to denote the set of vectors over K of length n. :grimacing: I added this notation to the \"Notation\" paragraph above.\r\n\r\nTo your question: in general, the length of the proof, verification message, and joint randomness is a function of the length of length of the input. For example, for an input length of n, the corresponding proof might be p(n) = a*n + b for some constants a, b.",
              "createdAt": "2021-02-26T16:49:31Z",
              "updatedAt": "2021-02-27T02:45:07Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTk5NzU5Mzgw",
          "commit": {
            "abbreviatedOid": "4c1024f"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-02-26T16:52:08Z",
          "updatedAt": "2021-02-26T16:52:08Z",
          "comments": [
            {
              "originalPosition": 70,
              "body": "The 'core protocol\" is the input-validation protocol described in the previous section.",
              "createdAt": "2021-02-26T16:52:08Z",
              "updatedAt": "2021-02-27T02:45:07Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTk5NzYwMDY3",
          "commit": {
            "abbreviatedOid": "4c1024f"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-02-26T16:52:56Z",
          "updatedAt": "2021-02-26T16:52:57Z",
          "comments": [
            {
              "originalPosition": 79,
              "body": "Done, here and elsewhere.",
              "createdAt": "2021-02-26T16:52:56Z",
              "updatedAt": "2021-02-27T02:45:07Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTk5NzczNTc3",
          "commit": {
            "abbreviatedOid": "4c1024f"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-02-26T17:08:51Z",
          "updatedAt": "2021-02-26T17:08:51Z",
          "comments": [
            {
              "originalPosition": 117,
              "body": "Done.",
              "createdAt": "2021-02-26T17:08:51Z",
              "updatedAt": "2021-02-27T02:45:07Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTk5NzkyNTYx",
          "commit": {
            "abbreviatedOid": "4c1024f"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-02-26T17:32:05Z",
          "updatedAt": "2021-02-26T17:32:05Z",
          "comments": [
            {
              "originalPosition": 135,
              "body": "Added an explanation below.",
              "createdAt": "2021-02-26T17:32:05Z",
              "updatedAt": "2021-02-27T02:45:07Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTk5NzkzOTgw",
          "commit": {
            "abbreviatedOid": "4c1024f"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-02-26T17:33:51Z",
          "updatedAt": "2021-02-26T17:33:51Z",
          "comments": [
            {
              "originalPosition": 135,
              "body": "(Also updated one of the primes.)",
              "createdAt": "2021-02-26T17:33:51Z",
              "updatedAt": "2021-02-27T02:45:07Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTk5Nzk4NTY1",
          "commit": {
            "abbreviatedOid": "4c1024f"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-02-26T17:39:39Z",
          "updatedAt": "2021-02-26T17:39:40Z",
          "comments": [
            {
              "originalPosition": 183,
              "body": "Great point! Done.",
              "createdAt": "2021-02-26T17:39:40Z",
              "updatedAt": "2021-02-27T02:45:07Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTk5ODI2MzIw",
          "commit": {
            "abbreviatedOid": "e6082ce"
          },
          "author": "aaomidi",
          "authorAssociation": "NONE",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-02-26T18:16:25Z",
          "updatedAt": "2021-02-26T18:16:26Z",
          "comments": [
            {
              "originalPosition": 92,
              "body": "How does the public key of the other recipients get advertised? ",
              "createdAt": "2021-02-26T18:16:25Z",
              "updatedAt": "2021-02-27T02:45:07Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTk5ODMyMzQ1",
          "commit": {
            "abbreviatedOid": "e6082ce"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-02-26T18:24:33Z",
          "updatedAt": "2021-02-26T18:24:34Z",
          "comments": [
            {
              "originalPosition": 92,
              "body": "That's TBD. I was thinking the user would simply make an HTTP request to each aggregator, but there might be a better way.\r\n\r\nAdded a TODO below.",
              "createdAt": "2021-02-26T18:24:34Z",
              "updatedAt": "2021-02-27T02:45:07Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjAwMDMzNTAz",
          "commit": {
            "abbreviatedOid": "f326c44"
          },
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-02-26T23:51:41Z",
          "updatedAt": "2021-02-27T00:24:38Z",
          "comments": [
            {
              "originalPosition": 3,
              "body": "```suggestion\r\n## Terminology\r\n```\r\n\r\nGlossaries are super important in a design doc like this, so I suggest promoting this to a main section of the doc",
              "createdAt": "2021-02-26T23:51:41Z",
              "updatedAt": "2021-02-27T02:45:07Z"
            },
            {
              "originalPosition": 11,
              "body": "We should make a distinction between the _client_ and the _user_ of the client (e.g., a web browser and the human using that web browser) since they are distinct actors.",
              "createdAt": "2021-02-26T23:53:53Z",
              "updatedAt": "2021-02-27T02:45:07Z"
            },
            {
              "originalPosition": 31,
              "body": "nit: would be nice to have a link to some reference material on \"standard\" linear secret sharing for folks like me who aren't as up to date on the literature.",
              "createdAt": "2021-02-26T23:57:29Z",
              "updatedAt": "2021-02-27T02:45:07Z"
            },
            {
              "originalPosition": 44,
              "body": "I have concerns about the leader performing the verification on behalf of all the other aggregations. However the onus is on me to develop a plausible attack the leader can execute if it can lie to aggregators about share validity, so this is fine for now.",
              "createdAt": "2021-02-26T23:59:55Z",
              "updatedAt": "2021-02-27T02:45:07Z"
            },
            {
              "originalPosition": 111,
              "body": "I'm a bit confused by `in` vs. `x` in this paragraph. Is `in` meant to be the input before being split into the vector `{x}`? If so, should line 116 read \"Let in be an element of...\"?",
              "createdAt": "2021-02-27T00:04:46Z",
              "updatedAt": "2021-02-27T02:45:08Z"
            },
            {
              "originalPosition": 183,
              "body": "Users (/clients) communicate with each aggregator, not just the leader, right?",
              "createdAt": "2021-02-27T00:07:09Z",
              "updatedAt": "2021-02-27T02:45:08Z"
            },
            {
              "originalPosition": 192,
              "body": "Should this be `Decaps(sk, c)`?",
              "createdAt": "2021-02-27T00:10:18Z",
              "updatedAt": "2021-02-27T02:45:08Z"
            },
            {
              "originalPosition": 28,
              "body": "I think it's worth clarifying that `{x:i}` is itself an element of `K^n` (right?)",
              "createdAt": "2021-02-27T00:14:12Z",
              "updatedAt": "2021-02-27T02:45:08Z"
            },
            {
              "originalPosition": 65,
              "body": "I think this should say something like \"Once all of the inputs have been validated and a sufficient number of input shares have been aggregated, the aggregators send their aggregate shares to the leader...\", to make it clear that aggregators aren't disclosing individual input shares to the leader.",
              "createdAt": "2021-02-27T00:17:32Z",
              "updatedAt": "2021-02-27T02:45:08Z"
            },
            {
              "originalPosition": 152,
              "body": "For what it's worth, I think ECIES as used in Prio v2 is overkill for v3 for two reasons:\r\n\r\n1. Prio v2 needs to tunnel a confidential+authenticated channel from mobile devices to aggregators through Apple or Google servers, so we couldn't rely on TLS. In v3, if clients send shares directly to aggregators, we don't have that problem.\r\n2. In v2, clients will generate an ephemeral ECDSA key and do ECDH with the aggregator's long term public key to make a fresh symmetric for every single datum moving through the system. We were constrained there by the fact that the mobile OS vendors had already built and shipped their clients and were reluctant to make changes to them, but I think we could reuse symmetric keys for >1 datum.",
              "createdAt": "2021-02-27T00:24:38Z",
              "updatedAt": "2021-02-27T02:45:08Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjAwMDQ0ODI4",
          "commit": {
            "abbreviatedOid": "f326c44"
          },
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "state": "CHANGES_REQUESTED",
          "body": "Thanks for getting the ball rolling!",
          "createdAt": "2021-02-27T00:27:29Z",
          "updatedAt": "2021-02-27T00:27:29Z",
          "comments": []
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjAwMDUwNjMy",
          "commit": {
            "abbreviatedOid": "f326c44"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-02-27T00:52:14Z",
          "updatedAt": "2021-02-27T00:52:14Z",
          "comments": [
            {
              "originalPosition": 11,
              "body": "Here I mean \"client\". Will fix.",
              "createdAt": "2021-02-27T00:52:14Z",
              "updatedAt": "2021-02-27T02:45:08Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjAwMDUzMDUy",
          "commit": {
            "abbreviatedOid": "f326c44"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-02-27T01:01:46Z",
          "updatedAt": "2021-02-27T01:01:47Z",
          "comments": [
            {
              "originalPosition": 31,
              "body": "Done.",
              "createdAt": "2021-02-27T01:01:47Z",
              "updatedAt": "2021-02-27T02:45:08Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjAwMDU0NDE0",
          "commit": {
            "abbreviatedOid": "f326c44"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-02-27T01:07:13Z",
          "updatedAt": "2021-02-27T01:07:13Z",
          "comments": [
            {
              "originalPosition": 191,
              "body": "```suggestion\r\n1. k := Decaps(sk, c) denotes decapsulation of symmetric key k under the\r\n```",
              "createdAt": "2021-02-27T01:07:13Z",
              "updatedAt": "2021-02-27T02:45:08Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjAwMDU0NTg1",
          "commit": {
            "abbreviatedOid": "f326c44"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-02-27T01:08:08Z",
          "updatedAt": "2021-02-27T01:08:08Z",
          "comments": [
            {
              "originalPosition": 183,
              "body": "I think, in this proposed design, clients communicate only with the leader, who mediates all things. @cjpatton?",
              "createdAt": "2021-02-27T01:08:08Z",
              "updatedAt": "2021-02-27T02:45:08Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjAwMDU0ODY0",
          "commit": {
            "abbreviatedOid": "f326c44"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-02-27T01:09:35Z",
          "updatedAt": "2021-02-27T01:09:36Z",
          "comments": [
            {
              "originalPosition": 111,
              "body": "```suggestion\r\nLet x be an element of K^n for some n. Suppose we split x into {x} by choosing\r\n{x:1}, ..., {x:s-1} at random and letting {x:s} = x - ({x:1} + ... + {x:s-1}).\r\n```",
              "createdAt": "2021-02-27T01:09:35Z",
              "updatedAt": "2021-02-27T02:45:08Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjAwMDU1MTU3",
          "commit": {
            "abbreviatedOid": "25787f2"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-02-27T01:11:22Z",
          "updatedAt": "2021-02-27T01:11:22Z",
          "comments": [
            {
              "originalPosition": 44,
              "body": "The threat model for Prio --- as it's described in the original paper and [BBC+19] --- considers **either** a malicious client (attacking soundness) **or** a malicious subset of aggregators (attacking privacy). In particular, soundness isn't guaranteed if any one of the aggregators is malicious; in theory it may be possible for a malicious client and aggregator to collude and break soundness.\r\n\r\nThere are techniques described in [BBC+19] that address the stronger threat model in which a malicious client may collude with a malicious aggregator. I think it's worth exploring how practical these techniques are. Meanwhile, thinking about attacks is a great idea.",
              "createdAt": "2021-02-27T01:11:22Z",
              "updatedAt": "2021-02-27T02:45:08Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjAwMDU1MTcz",
          "commit": {
            "abbreviatedOid": "25787f2"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-02-27T01:11:30Z",
          "updatedAt": "2021-02-27T01:11:30Z",
          "comments": [
            {
              "originalPosition": 28,
              "body": "`{x:i}` is a share of `x`, so it's just an element of `K`. ",
              "createdAt": "2021-02-27T01:11:30Z",
              "updatedAt": "2021-02-27T02:45:08Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjAwMDU1MjQx",
          "commit": {
            "abbreviatedOid": "25787f2"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-02-27T01:11:49Z",
          "updatedAt": "2021-02-27T01:11:49Z",
          "comments": [
            {
              "originalPosition": 28,
              "body": "```suggestion\r\n{x:s}, where {x:i} is the share held by the i-th party and an element of K. We write {x} as\r\n```",
              "createdAt": "2021-02-27T01:11:49Z",
              "updatedAt": "2021-02-27T02:45:08Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjAwMDU1NTcy",
          "commit": {
            "abbreviatedOid": "25787f2"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-02-27T01:13:32Z",
          "updatedAt": "2021-02-27T01:13:33Z",
          "comments": [
            {
              "originalPosition": 44,
              "body": "Maybe just flag this as an open issue?\r\n```suggestion\r\n   whether the input is deemed valid. This algorithm is run by the leader.\r\n   \r\n[[OPEN ISSUE: what can go wrong when the leader is responsible for verifying everything on behalf of all aggregators?]]\r\n```",
              "createdAt": "2021-02-27T01:13:32Z",
              "updatedAt": "2021-02-27T02:45:08Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjAwMDYwMTY1",
          "commit": {
            "abbreviatedOid": "25787f2"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-02-27T01:35:18Z",
          "updatedAt": "2021-02-27T01:35:19Z",
          "comments": [
            {
              "originalPosition": 59,
              "body": "```suggestion\r\n1. Each aggregator i runs {vf:i} := Query({x:i}, {pf:i}, r) and sends {vf:i} to\r\n```",
              "createdAt": "2021-02-27T01:35:19Z",
              "updatedAt": "2021-02-27T02:45:08Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjAwMDY2MTM2",
          "commit": {
            "abbreviatedOid": "a7c9df8"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-02-27T02:26:24Z",
          "updatedAt": "2021-02-27T02:26:24Z",
          "comments": [
            {
              "originalPosition": 111,
              "body": "Oops, typo: s/in/x/.",
              "createdAt": "2021-02-27T02:26:24Z",
              "updatedAt": "2021-02-27T02:45:08Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjAwMDY2MzUx",
          "commit": {
            "abbreviatedOid": "a7c9df8"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-02-27T02:28:06Z",
          "updatedAt": "2021-02-27T02:28:06Z",
          "comments": [
            {
              "originalPosition": 183,
              "body": "I envision the client sending its encrypted shares to the leader. However, it does need to speak to the aggregators prior to the input-validation protocol to get their public keys.",
              "createdAt": "2021-02-27T02:28:06Z",
              "updatedAt": "2021-02-27T02:45:08Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjAwMDY2Mzk5",
          "commit": {
            "abbreviatedOid": "a7c9df8"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-02-27T02:28:33Z",
          "updatedAt": "2021-02-27T02:28:34Z",
          "comments": [
            {
              "originalPosition": 192,
              "body": "Yup, good catch!",
              "createdAt": "2021-02-27T02:28:34Z",
              "updatedAt": "2021-02-27T02:45:08Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjAwMDY2NTEx",
          "commit": {
            "abbreviatedOid": "a7c9df8"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-02-27T02:29:36Z",
          "updatedAt": "2021-02-27T02:29:36Z",
          "comments": [
            {
              "originalPosition": 28,
              "body": "Yes, done.",
              "createdAt": "2021-02-27T02:29:36Z",
              "updatedAt": "2021-02-27T02:45:08Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjAwMDY2NjE4",
          "commit": {
            "abbreviatedOid": "a7c9df8"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-02-27T02:30:41Z",
          "updatedAt": "2021-02-27T02:30:41Z",
          "comments": [
            {
              "originalPosition": 65,
              "body": "Changed to \"Once a sufficient number of shares have been ...\"",
              "createdAt": "2021-02-27T02:30:41Z",
              "updatedAt": "2021-02-27T02:45:08Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjAwMDY4MTc5",
          "commit": {
            "abbreviatedOid": "18a82ef"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-02-27T02:45:21Z",
          "updatedAt": "2021-02-27T02:45:21Z",
          "comments": [
            {
              "originalPosition": 44,
              "body": "Added this to \"Thread model\".",
              "createdAt": "2021-02-27T02:45:21Z",
              "updatedAt": "2021-02-27T02:45:21Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjAwMDY5NzM2",
          "commit": {
            "abbreviatedOid": "18a82ef"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-02-27T02:54:09Z",
          "updatedAt": "2021-02-27T02:54:09Z",
          "comments": [
            {
              "originalPosition": 183,
              "body": "Does it? Why can't the client get these keys from the leader?",
              "createdAt": "2021-02-27T02:54:09Z",
              "updatedAt": "2021-02-27T02:54:09Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjAwMDcwNzE2",
          "commit": {
            "abbreviatedOid": "98eb939"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-02-27T03:02:16Z",
          "updatedAt": "2021-02-27T03:02:16Z",
          "comments": [
            {
              "originalPosition": 183,
              "body": " The leader is incentivized to break privacy... it could just hand the client fake public keys for which it knows the secret keys and decrypt all of the shares.",
              "createdAt": "2021-02-27T03:02:16Z",
              "updatedAt": "2021-02-27T03:02:16Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjAwMDcyNTI0",
          "commit": {
            "abbreviatedOid": "18a82ef"
          },
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "",
          "createdAt": "2021-02-27T03:18:02Z",
          "updatedAt": "2021-02-27T03:18:02Z",
          "comments": []
        }
      ]
    },
    {
      "number": 3,
      "id": "MDExOlB1bGxSZXF1ZXN0NTc5NTU0MzI2",
      "title": "Start system overview and requirements.",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/pull/3",
      "state": "MERGED",
      "author": "chris-wood",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "Imperfect, incomplete, maybe even inaccurate! Starting to get some stuff down. ",
      "createdAt": "2021-02-24T19:36:30Z",
      "updatedAt": "2021-12-30T02:09:36Z",
      "baseRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "baseRefName": "main",
      "baseRefOid": "2b46fe7cdab7bd6f15fd467c4da4e526d28bec31",
      "headRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "headRefName": "caw/start-overview",
      "headRefOid": "397417aabbea73fa910ccb3a5b47fd0446c7c1a6",
      "closedAt": "2021-03-02T18:28:23Z",
      "mergedAt": "2021-03-02T18:28:23Z",
      "mergedBy": "chris-wood",
      "mergeCommit": {
        "oid": "fee74dacf41e8e333c5fbef4d860dfdfbc435c50"
      },
      "comments": [],
      "reviews": [
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTk5ODAyOTc0",
          "commit": {
            "abbreviatedOid": "d63afcb"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "Good start. The main thing is that this needs to be aligned with the candidate protocol in #2. Let's merge that PR, then rebase this.",
          "createdAt": "2021-02-26T17:45:20Z",
          "updatedAt": "2021-02-26T17:58:35Z",
          "comments": [
            {
              "originalPosition": 9,
              "body": "```suggestion\r\ninput. An aggregation function F is one that computes an output y = F(x[1],x[2],...) for inputs\r\nx[i]. In general, Prio supports any aggregation function whose inputs can be encoded in a \r\n```",
              "createdAt": "2021-02-26T17:45:20Z",
              "updatedAt": "2021-03-02T18:23:37Z"
            },
            {
              "originalPosition": 14,
              "body": "[[OPEN ISSUE: It's possible to estimate quantiles such as the median. How practical is this?]]",
              "createdAt": "2021-02-26T17:46:40Z",
              "updatedAt": "2021-03-02T18:23:37Z"
            },
            {
              "originalPosition": 16,
              "body": "```suggestion\r\n- Data structures, like Bloom filters, counting Bloom filters, and count-min sketches, that approximately represent (multi-)sets of strings.\r\n```",
              "createdAt": "2021-02-26T17:49:13Z",
              "updatedAt": "2021-03-02T18:23:37Z"
            },
            {
              "originalPosition": 23,
              "body": "```suggestion\r\nor aggregators, run a protocol that validates each input x[1], x[2], ... and computes the final output y. The final collector  \r\n```\r\n\r\n(\"invoke multi-party computation\" sounds like we're doing general purpose MPC.)",
              "createdAt": "2021-02-26T17:52:41Z",
              "updatedAt": "2021-03-02T18:23:37Z"
            },
            {
              "originalPosition": 48,
              "body": "Pretty! Though I think we need to align this with the candidate protocol #2. In particular, I would remove the wires going from the client to the top and bottom aggregators, and I would rename the middle aggregator to \"Leader'.",
              "createdAt": "2021-02-26T17:53:55Z",
              "updatedAt": "2021-03-02T18:23:37Z"
            },
            {
              "originalPosition": 56,
              "body": "Needs alignment with the candidate protocol of #2.",
              "createdAt": "2021-02-26T17:55:06Z",
              "updatedAt": "2021-03-02T18:23:37Z"
            },
            {
              "originalPosition": 66,
              "body": "```suggestion\r\nclients. In doing so, the adversary can provide malicious (yet truthful) inputs to the aggregation \r\n```\r\nAlso, what does \"yet truthful\" mean here?",
              "createdAt": "2021-02-26T17:56:15Z",
              "updatedAt": "2021-03-02T18:23:37Z"
            },
            {
              "originalPosition": 100,
              "body": "What does \"f^\" mean?",
              "createdAt": "2021-02-26T17:57:50Z",
              "updatedAt": "2021-03-02T18:23:37Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjAwMDU3MjU1",
          "commit": {
            "abbreviatedOid": "6c84653"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-02-27T01:18:55Z",
          "updatedAt": "2021-02-27T01:18:55Z",
          "comments": [
            {
              "originalPosition": 14,
              "body": "```suggestion\r\n- Simple statistics, including sum, mean, min, max, variance, and standard deviation; [[OPEN ISSUE: It's possible to estimate quantiles such as the median. How practical is this?]]\r\n\r\n\r\n```",
              "createdAt": "2021-02-27T01:18:55Z",
              "updatedAt": "2021-03-02T18:23:37Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjAwMDY3MzQw",
          "commit": {
            "abbreviatedOid": "7f81949"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "",
          "createdAt": "2021-02-27T02:37:28Z",
          "updatedAt": "2021-02-27T02:37:28Z",
          "comments": []
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjAxMjUxODkz",
          "commit": {
            "abbreviatedOid": "733132f"
          },
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-03-01T23:10:49Z",
          "updatedAt": "2021-03-02T15:36:42Z",
          "comments": [
            {
              "originalPosition": 12,
              "body": "\"a particular way\" is tantalizingly vague. Is this referring to affine-aggregatable encodings as discussed in the '17 paper?",
              "createdAt": "2021-03-01T23:10:50Z",
              "updatedAt": "2021-03-02T18:23:37Z"
            },
            {
              "originalPosition": 58,
              "body": "I don't think clients would be aware of data batching--they would just continuously upload data as they generate it right? It's only the aggregators that need to be aware of batches so they can withhold aggregation parts from the leader or collector until the batch size threshold is met.",
              "createdAt": "2021-03-01T23:40:22Z",
              "updatedAt": "2021-03-02T18:23:37Z"
            },
            {
              "originalPosition": 60,
              "body": "This design where clients only talk to the leader requires that we establish some kind of authenticated+encrypted tunnel through the leader. It might be simpler to have clients send shares directly to aggregators, because then we could use TLS to protect that channel. I think @cjpatton has argued elsewhere that there needs to be some kind of secure channel between clients and each aggregator no matter what, so that clients can discover each aggregator's encryption keys (i.e., we can't let the leader advertise parameters on behalf of the other aggregators). ",
              "createdAt": "2021-03-01T23:42:54Z",
              "updatedAt": "2021-03-02T18:23:37Z"
            },
            {
              "originalPosition": 100,
              "body": "I'm guessing this is in reference to f-privacy and f^-privacy as discussed in section 2/page 3 of the 2017 paper. I certainly need to learn more about the information theory around privacy and what it means to quantify information leakage.",
              "createdAt": "2021-03-02T00:15:04Z",
              "updatedAt": "2021-03-02T18:23:37Z"
            },
            {
              "originalPosition": 88,
              "body": "The 2017 paper's section 2 discusses _anonymity_ alongside privacy and robustness. However I'm not sure how to draw a clear distinction between anonymity and privacy in this context so maybe it's not worth discussing in this doc.",
              "createdAt": "2021-03-02T15:33:38Z",
              "updatedAt": "2021-03-02T18:23:37Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjAxOTk0ODMz",
          "commit": {
            "abbreviatedOid": "733132f"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-03-02T16:09:02Z",
          "updatedAt": "2021-03-02T16:09:02Z",
          "comments": [
            {
              "originalPosition": 12,
              "body": "Indeed -- and the mechanism is described later on in this doc, so I figured best to keep it high level here.",
              "createdAt": "2021-03-02T16:09:02Z",
              "updatedAt": "2021-03-02T18:23:37Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjAxOTk1NTI1",
          "commit": {
            "abbreviatedOid": "733132f"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-03-02T16:09:38Z",
          "updatedAt": "2021-03-02T16:09:38Z",
          "comments": [
            {
              "originalPosition": 58,
              "body": "That's a good point! I'll move this batch cutoff to the leader step.",
              "createdAt": "2021-03-02T16:09:38Z",
              "updatedAt": "2021-03-02T18:23:37Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjAxOTk3MjYx",
          "commit": {
            "abbreviatedOid": "733132f"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-03-02T16:11:07Z",
          "updatedAt": "2021-03-02T16:11:08Z",
          "comments": [
            {
              "originalPosition": 88,
              "body": "Indeed. I suggest we leave this as-is for now.",
              "createdAt": "2021-03-02T16:11:08Z",
              "updatedAt": "2021-03-02T18:23:37Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjAyMDAxODky",
          "commit": {
            "abbreviatedOid": "733132f"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-03-02T16:15:19Z",
          "updatedAt": "2021-03-02T16:15:19Z",
          "comments": [
            {
              "originalPosition": 60,
              "body": "That's one possibility, sure, but I don't think that's necessary. The leader could package up signed keys that it collects from aggregators and send them to the client. Clients could also fetch them directly from aggregators (if they knew what aggregators to fetch from). From a client perspective, the former seems simpler, since it would allow us to punt on aggregator discovery.",
              "createdAt": "2021-03-02T16:15:19Z",
              "updatedAt": "2021-03-02T18:23:37Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjAyMDc5NDQ5",
          "commit": {
            "abbreviatedOid": "733132f"
          },
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-03-02T17:27:55Z",
          "updatedAt": "2021-03-02T17:27:55Z",
          "comments": [
            {
              "originalPosition": 60,
              "body": "The leader could vend signed keys on behalf of aggregators, but the client still needs to discover a trusted public key for each aggregator to then verify the signed keys. I think you have to bootstrap trust between the client and each participating aggregator independently from the leader, or the leader can impersonate aggregators and defeat the system's privacy guarantees.",
              "createdAt": "2021-03-02T17:27:55Z",
              "updatedAt": "2021-03-02T18:23:37Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjAyMTAzMzk2",
          "commit": {
            "abbreviatedOid": "733132f"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-03-02T17:53:40Z",
          "updatedAt": "2021-03-02T17:53:40Z",
          "comments": [
            {
              "originalPosition": 100,
              "body": "To resolve this, please add a reference to the paper.",
              "createdAt": "2021-03-02T17:53:40Z",
              "updatedAt": "2021-03-02T18:23:37Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjAyMTA0NDMz",
          "commit": {
            "abbreviatedOid": "733132f"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-03-02T17:54:54Z",
          "updatedAt": "2021-03-02T17:54:55Z",
          "comments": [
            {
              "originalPosition": 60,
              "body": "IMO it's better to avoid creating a new PKI and just have aggregators distribute their own encryption keys. I'm open to being wrong, however :)",
              "createdAt": "2021-03-02T17:54:55Z",
              "updatedAt": "2021-03-02T18:23:37Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjAyMTA1NDc3",
          "commit": {
            "abbreviatedOid": "733132f"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-03-02T17:56:04Z",
          "updatedAt": "2021-03-02T17:56:04Z",
          "comments": [
            {
              "originalPosition": 60,
              "body": "I'm not suggesting a new PKI for this.",
              "createdAt": "2021-03-02T17:56:04Z",
              "updatedAt": "2021-03-02T18:23:37Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjAyMTA1ODA2",
          "commit": {
            "abbreviatedOid": "733132f"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-03-02T17:56:24Z",
          "updatedAt": "2021-03-02T17:56:24Z",
          "comments": [
            {
              "originalPosition": 88,
              "body": "I would resolve this by adding a refereence to the paper. ",
              "createdAt": "2021-03-02T17:56:24Z",
              "updatedAt": "2021-03-02T18:23:37Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjAyMTA1OTY3",
          "commit": {
            "abbreviatedOid": "733132f"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-03-02T17:56:34Z",
          "updatedAt": "2021-03-02T17:56:34Z",
          "comments": [
            {
              "originalPosition": 60,
              "body": ">  but the client still needs to discover a trusted public key for each aggregator to then verify the signed keys.\r\n\r\nYes, it does, and I'm suggesting this can be done by asking the leader to provide the signed keys. ",
              "createdAt": "2021-03-02T17:56:34Z",
              "updatedAt": "2021-03-02T18:23:37Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjAyMTA2NjQw",
          "commit": {
            "abbreviatedOid": "733132f"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-03-02T17:57:18Z",
          "updatedAt": "2021-03-02T17:57:18Z",
          "comments": [
            {
              "originalPosition": 100,
              "body": "Can you please leave what you're looking for as a suggestion? (There is a reference -- \"HCG's paper\" -- no?)",
              "createdAt": "2021-03-02T17:57:18Z",
              "updatedAt": "2021-03-02T18:23:37Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjAyMTMyMzQ5",
          "commit": {
            "abbreviatedOid": "397417a"
          },
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "",
          "createdAt": "2021-03-02T18:26:12Z",
          "updatedAt": "2021-03-02T18:26:12Z",
          "comments": []
        }
      ]
    },
    {
      "number": 6,
      "id": "MDExOlB1bGxSZXF1ZXN0NTgyNTc1NDA1",
      "title": "Add an initial section on system constraints",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/pull/6",
      "state": "MERGED",
      "author": "acmiyaguchi",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "This PR adds a draft of system constraints. I had difficulty finding example documents to lend structure here, so apologies if the style or ideas are off the rails.\r\n\r\nI've added three constraints that should be relevant to future discussions: data resolution, timeliness, and integrity. I'm likely missing others. Some of the text involves services or applications that implement/use Prio -- I'm not sure if it's appropriate for this document. ",
      "createdAt": "2021-03-02T00:52:49Z",
      "updatedAt": "2021-03-03T17:57:07Z",
      "baseRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "baseRefName": "main",
      "baseRefOid": "2b46fe7cdab7bd6f15fd467c4da4e526d28bec31",
      "headRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "headRefName": "system-constraints",
      "headRefOid": "235f5a9563155602eb98f3790e9adb20d40a20c8",
      "closedAt": "2021-03-03T17:55:11Z",
      "mergedAt": "2021-03-03T17:55:11Z",
      "mergedBy": "acmiyaguchi",
      "mergeCommit": {
        "oid": "83c4ad39a101c17dcfc2421353996297aa503506"
      },
      "comments": [
        {
          "author": "stpeter",
          "authorAssociation": "COLLABORATOR",
          "body": "> Nice work! Beyond @cjpatton's comments, my only blocking point here is on the notion of a \"deadline\", and what that means in a distributed system. I've suggested relaxing this to be soft.\r\n\r\nIn certain use cases (e.g., click measurement), most of the data might need to be passed along within a certain timeframe (say, 1 hour). That's not quite a deadline, but a constraint that we'll want to keep in mind.",
          "createdAt": "2021-03-02T21:43:17Z",
          "updatedAt": "2021-03-02T21:43:17Z"
        },
        {
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "body": "> That's not quite a deadline, but a constraint that we'll want to keep in mind.\r\n\r\nYeah, that's a fine thing to note. I was just trying to stress that any tightly synchronized version of a deadline (\"all nodes stop collecting the batch at time X\") would be quite hard to implement.",
          "createdAt": "2021-03-02T22:04:26Z",
          "updatedAt": "2021-03-02T22:04:35Z"
        }
      ],
      "reviews": [
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjAxMzY3MTgx",
          "commit": {
            "abbreviatedOid": "34efd33"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "This looks good, minor comments only. ",
          "createdAt": "2021-03-02T03:07:43Z",
          "updatedAt": "2021-03-02T03:27:39Z",
          "comments": [
            {
              "originalPosition": 15,
              "body": "Instead of \"proportional to the verification circuit's size\" I would suggest \"related to the circuit's complexity\". The size of the proof, and the time complexity of generating and verifying it, can be reduced significantly if the circuit has a lot of redundancy. ",
              "createdAt": "2021-03-02T03:07:43Z",
              "updatedAt": "2021-03-03T00:13:17Z"
            },
            {
              "originalPosition": 30,
              "body": "```suggestion\r\ncomputational budget. Meeting these deadlines will require efficient\r\n```",
              "createdAt": "2021-03-02T03:08:22Z",
              "updatedAt": "2021-03-03T00:13:17Z"
            },
            {
              "originalPosition": 32,
              "body": "What's meant by \"binary serialization\"? ",
              "createdAt": "2021-03-02T03:08:42Z",
              "updatedAt": "2021-03-03T00:13:17Z"
            },
            {
              "originalPosition": 45,
              "body": "```suggestion\r\ninaccuracies in the aggregates. An example data integrity constraint is that\r\n```\r\nDefinitely an important constraint :)",
              "createdAt": "2021-03-02T03:10:11Z",
              "updatedAt": "2021-03-03T00:13:17Z"
            },
            {
              "originalPosition": 52,
              "body": "Invalid shares are always a problem if they go undetected. It sounds like this paragraph is more about DoS mitigation? I.e., regardless of their validity, the aggregators need to be able to detect if they're being flooded by inputs?",
              "createdAt": "2021-03-02T03:17:37Z",
              "updatedAt": "2021-03-03T00:13:17Z"
            },
            {
              "originalPosition": 58,
              "body": "This is good stuff. I feel like we're definitely gonna expand this paragraph as we implement this :)",
              "createdAt": "2021-03-02T03:18:51Z",
              "updatedAt": "2021-03-03T00:13:17Z"
            },
            {
              "originalPosition": 46,
              "body": "```suggestion\r\nevery share must be processed exactly once by all aggregators. Data integrity\r\n```",
              "createdAt": "2021-03-02T03:27:16Z",
              "updatedAt": "2021-03-03T00:13:17Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjAxODg3MDUy",
          "commit": {
            "abbreviatedOid": "34efd33"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "Nice work! Beyond @cjpatton's comments, my only blocking point here is on the notion of a \"deadline\", and what that means in a distributed system. I've suggested relaxing this to be soft. (Other comments and suggestions around additional content can be addressed in a followup PR.)",
          "createdAt": "2021-03-02T14:38:27Z",
          "updatedAt": "2021-03-02T14:52:07Z",
          "comments": [
            {
              "originalPosition": 13,
              "body": "What is the throughput of the system? How many inputs/second can be processed?\r\n\r\nTaking a step back: Should we have a section where we discuss this and other key performance indicators that we're trying to be mindful of? (Time between batch start and batch end, where the aggregate is available, comes to mind, for example.)",
              "createdAt": "2021-03-02T14:38:27Z",
              "updatedAt": "2021-03-03T00:13:17Z"
            },
            {
              "originalPosition": 14,
              "body": "```suggestion\r\nrelated to the verification circuit's complexity and the rate of verifications\r\n```",
              "createdAt": "2021-03-02T14:38:51Z",
              "updatedAt": "2021-03-03T00:13:17Z"
            },
            {
              "originalPosition": 17,
              "body": "```suggestion\r\nApplications that utilize proofs with a large number of multiplication gates or a high\r\n```",
              "createdAt": "2021-03-02T14:39:09Z",
              "updatedAt": "2021-03-03T00:13:17Z"
            },
            {
              "originalPosition": 8,
              "body": "```suggestion\r\n### Data resolution limitations\r\n```",
              "createdAt": "2021-03-02T14:39:41Z",
              "updatedAt": "2021-03-03T00:13:17Z"
            },
            {
              "originalPosition": 25,
              "body": "```suggestion\r\nA soft real-time system should produce a response within a deadline in order to be useful. This\r\n```\r\n\r\nAny sort of time synchronization or deadline enforcement here seems challenging, given the nature of the distributed system. I'd suggest relaxing this text a bit to say that deadlines are soft, and missing a deadline just means that the output has lesser value.",
              "createdAt": "2021-03-02T14:47:02Z",
              "updatedAt": "2021-03-03T00:13:17Z"
            },
            {
              "originalPosition": 23,
              "body": "```suggestion\r\n### Aggregation utility and soft batch deadlines\r\n```",
              "createdAt": "2021-03-02T14:47:27Z",
              "updatedAt": "2021-03-03T00:13:17Z"
            },
            {
              "originalPosition": 28,
              "body": "```suggestion\r\nAn example of a soft real-time constraint is the expectation that input data can be\r\n```",
              "createdAt": "2021-03-02T14:48:07Z",
              "updatedAt": "2021-03-03T00:13:17Z"
            },
            {
              "originalPosition": 32,
              "body": "```suggestion\r\nrequests or utilize more efficient serialization to improve throughput.\r\n```",
              "createdAt": "2021-03-02T14:48:46Z",
              "updatedAt": "2021-03-03T00:13:17Z"
            },
            {
              "originalPosition": 38,
              "body": "```suggestion\r\nto produce a response within a soft deadline.\r\n```",
              "createdAt": "2021-03-02T14:49:15Z",
              "updatedAt": "2021-03-03T00:13:17Z"
            },
            {
              "originalPosition": 57,
              "body": "```suggestion\r\nrequests and controls the schedule for signaling the end of the aggregation\r\n```",
              "createdAt": "2021-03-02T14:50:39Z",
              "updatedAt": "2021-03-03T00:13:17Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjAyMjc2Nzg1",
          "commit": {
            "abbreviatedOid": "34efd33"
          },
          "author": "acmiyaguchi",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-03-02T21:12:19Z",
          "updatedAt": "2021-03-02T22:00:03Z",
          "comments": [
            {
              "originalPosition": 32,
              "body": "The example I had in mind was using something like Avro over JSON+base64 in cases where string parsing takes up more time than it should. ",
              "createdAt": "2021-03-02T21:12:19Z",
              "updatedAt": "2021-03-03T00:13:17Z"
            },
            {
              "originalPosition": 52,
              "body": "I mean for this paragraph to distinguish between normal and unusual. In my day-to-day work, I've trawled through garbage coming through public ingestion endpoint (a lot of fuzzers and malformed data). I think some error is tolerable and normal. A large number of invalid inputs could be attributed to misconfigured application, and not necessarily an explicit denial of service. I did have DoS in mind too; I'll be more specific. ",
              "createdAt": "2021-03-02T21:20:09Z",
              "updatedAt": "2021-03-03T00:13:17Z"
            },
            {
              "originalPosition": 15,
              "body": "I'm interested in learning more about the optimizations at some point after overcoming my admittedly weak understanding of arithmetic circuits. ",
              "createdAt": "2021-03-02T21:30:08Z",
              "updatedAt": "2021-03-03T00:13:17Z"
            },
            {
              "originalPosition": 13,
              "body": "I think inputs/second is a reasonable definition of throughput, which is dependent on input parameters and the resources allocated for work. I guess \"rate of work\" would do here too. \r\n\r\nUsing a maybe not so great physics analogy to explain in a different frame:\r\n* verifying input is work\r\n* throughput is power (rate of work)\r\n* compute-time is energy (capacity for work)\r\n* the amount of data that can be processed is constrained by throughput and available compute-time\r\n\r\n> Should we have a section where we discuss this and other key performance indicators that we're trying to be mindful of?\r\n\r\nIt's probably a good idea. Maybe something to consider in the requirements or a separate performance section. I imagine an implementation would also want to monitor some of these things (e.g time to completion, error counts).  This section could also be expanded for discussion.\r\n",
              "createdAt": "2021-03-02T21:59:51Z",
              "updatedAt": "2021-03-03T00:13:17Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjAyMzI2NTE1",
          "commit": {
            "abbreviatedOid": "73184c6"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-03-02T22:21:22Z",
          "updatedAt": "2021-03-02T22:21:22Z",
          "comments": [
            {
              "originalPosition": 13,
              "body": "> It's probably a good idea. Maybe something to consider in the requirements or a separate performance section. I imagine an implementation would also want to monitor some of these things (e.g time to completion, error counts). This section could also be expanded for discussion.\r\n\r\nBoth seem fine. Maybe just mark an OPEN ISSUE here for us to resolve later?",
              "createdAt": "2021-03-02T22:21:22Z",
              "updatedAt": "2021-03-03T00:13:17Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjAyMzI2NzQ3",
          "commit": {
            "abbreviatedOid": "73184c6"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "",
          "createdAt": "2021-03-02T22:21:44Z",
          "updatedAt": "2021-03-02T22:21:44Z",
          "comments": []
        }
      ]
    },
    {
      "number": 11,
      "id": "MDExOlB1bGxSZXF1ZXN0NTg0MjM4OTg4",
      "title": "add link to Crypto 19 paper",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/pull/11",
      "state": "MERGED",
      "author": "stpeter",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "",
      "createdAt": "2021-03-03T20:20:42Z",
      "updatedAt": "2021-12-30T02:09:38Z",
      "baseRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "baseRefName": "main",
      "baseRefOid": "83c4ad39a101c17dcfc2421353996297aa503506",
      "headRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "headRefName": "crypto19",
      "headRefOid": "91e42f265d682f38b8a0c96dcb4975662078a596",
      "closedAt": "2021-03-04T03:34:46Z",
      "mergedAt": "2021-03-04T03:34:46Z",
      "mergedBy": "chris-wood",
      "mergeCommit": {
        "oid": "a9efe7d10647ac9fa2a93d5930f932155ef96052"
      },
      "comments": [],
      "reviews": [
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjAzNjc0ODQ0",
          "commit": {
            "abbreviatedOid": "91e42f2"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "",
          "createdAt": "2021-03-04T03:33:59Z",
          "updatedAt": "2021-03-04T03:33:59Z",
          "comments": []
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjAzNjc1MTAz",
          "commit": {
            "abbreviatedOid": "91e42f2"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "",
          "createdAt": "2021-03-04T03:34:43Z",
          "updatedAt": "2021-03-04T03:34:43Z",
          "comments": []
        }
      ]
    },
    {
      "number": 12,
      "id": "MDExOlB1bGxSZXF1ZXN0NTg0NDYzODM1",
      "title": "Add \"collector\" to terminology and fix some typos",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/pull/12",
      "state": "MERGED",
      "author": "cjpatton",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "Solves #10.\r\n\r\nThe collector is the endpoint that receives the final aggregate and defines the \"parameters of the protocol\". I'm being intentionally vague about the latter. I envision the parameters including the following:\r\n1. Who are the aggregators, and who is the leader;\r\n2. What type of data is being collected;\r\n3. How many inputs are aggregated in a given window (or, how long is a data collection window);\r\n4. and cryptographic parameters.",
      "createdAt": "2021-03-04T03:49:24Z",
      "updatedAt": "2021-06-17T21:15:35Z",
      "baseRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "baseRefName": "main",
      "baseRefOid": "a9efe7d10647ac9fa2a93d5930f932155ef96052",
      "headRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "headRefName": "cjpatton/collector",
      "headRefOid": "afb81f9b00c119d56c33b3bf530c0067ff6c4637",
      "closedAt": "2021-03-04T03:52:36Z",
      "mergedAt": "2021-03-04T03:52:36Z",
      "mergedBy": "chris-wood",
      "mergeCommit": {
        "oid": "5dd000153dc8c7136c271b14499b43a64316fbaf"
      },
      "comments": [],
      "reviews": [
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjAzNjgxODQ2",
          "commit": {
            "abbreviatedOid": "afb81f9"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "",
          "createdAt": "2021-03-04T03:52:33Z",
          "updatedAt": "2021-03-04T03:52:33Z",
          "comments": []
        }
      ]
    },
    {
      "number": 13,
      "id": "MDExOlB1bGxSZXF1ZXN0NTg1MDM1NTg0",
      "title": "Update field parameters",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/pull/13",
      "state": "MERGED",
      "author": "cjpatton",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "@ekr and others have discussed using an 80 bit field in some application. This PR adds one. It also removes the smallest field (unlikely to ever be used) and renumbers the table.",
      "createdAt": "2021-03-04T18:50:04Z",
      "updatedAt": "2021-06-17T21:15:34Z",
      "baseRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "baseRefName": "main",
      "baseRefOid": "5dd000153dc8c7136c271b14499b43a64316fbaf",
      "headRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "headRefName": "cjpatton/fields",
      "headRefOid": "c20b7839e8182811cd13d910217139ae08e9ae8e",
      "closedAt": "2021-03-19T15:56:46Z",
      "mergedAt": "2021-03-19T15:56:46Z",
      "mergedBy": "cjpatton",
      "mergeCommit": {
        "oid": "f63c8fd340e1befa5db524602eb4dd7f802613f9"
      },
      "comments": [
        {
          "author": "ekr",
          "authorAssociation": "COLLABORATOR",
          "body": "@henrycg would love to get your input here.",
          "createdAt": "2021-03-04T18:57:10Z",
          "updatedAt": "2021-03-04T18:57:10Z"
        },
        {
          "author": "ekr",
          "authorAssociation": "COLLABORATOR",
          "body": "As far as I can tell, this accurately subsets the previous fields. I have no opinion on the substance.",
          "createdAt": "2021-03-04T18:57:57Z",
          "updatedAt": "2021-03-04T18:57:57Z"
        },
        {
          "author": "ekr",
          "authorAssociation": "COLLABORATOR",
          "body": "Oh, I see the 72 bit field. No idea if that one is right :)",
          "createdAt": "2021-03-04T18:58:58Z",
          "updatedAt": "2021-03-04T18:58:58Z"
        },
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "@ekr, #3 is the roughly 80-bit field. It's actually just under 80 bits; that way we can represent field elements using 10 bytes.\r\n@henrycg, we would especially like your input on our criteria for choosing the parameters. These criteria are listed above.",
          "createdAt": "2021-03-04T19:30:03Z",
          "updatedAt": "2021-03-04T19:30:19Z"
        },
        {
          "author": "henrycg",
          "authorAssociation": "COLLABORATOR",
          "body": "> - It might be a good idea to explain somewhere that soundness error (probability that the servers accept a false proof) is `2n/(p-n)` when carrying out all arithmetic modulo `p` and with input size `n`. As written, the \"bits\" column in the parameters table might give the impression that using modulus 1 gives ~31 bits of security, when it could actually give only ~15 bits of security when used with inputs of size 2^16.\r\n\r\nAdded the bound to the \"Field size\" criterion, and changed \"bits\" to \"size\". That column now says how many bits are needed to represent field elements.\r\n\r\n> - Nit: In this table and in the preceding discussion on [Finite field arithmetic](https://github.com/abetterinternet/prio-documents/blob/main/design-document.md#finite-field-arithmetic), it might make sense to use a symbol other than `n`, since `n` is used to mean something else in the earlier section on [Cryptographic Components](https://github.com/abetterinternet/prio-documents/blob/main/design-document.md#cryptographic-components).\r\n\r\nGood call! Changed `n` to ~`s`.~ `b`.",
          "createdAt": "2021-03-04T23:40:18Z",
          "updatedAt": "2021-03-05T16:26:12Z"
        },
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "\r\n> Good call! Changed `n` to `s`.\r\n\r\nOof, this is supposed to be `b` instead of `s`. Edited above.\r\n",
          "createdAt": "2021-03-05T16:25:40Z",
          "updatedAt": "2021-03-05T16:25:40Z"
        },
        {
          "author": "tlepoint",
          "authorAssociation": "NONE",
          "body": "Out of curiosity, why do you need to hardcode prime numbers rather than making the whole system more flexible and accept any prime that would respect the constraints?",
          "createdAt": "2021-03-08T21:41:01Z",
          "updatedAt": "2021-03-08T21:41:01Z"
        },
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "> Out of curiosity, why do you need to hardcode prime numbers rather than making the whole system more flexible and accept any prime that would respect the constraints?\r\n\r\nIt seems sensible to settle on a handful of primes and develop optimized implementations of the arithmetic for each field. Initially, however, we plan to have generic arithmetic: see https://github.com/abetterinternet/libprio-rs/issues/10.",
          "createdAt": "2021-03-18T21:24:57Z",
          "updatedAt": "2021-03-18T21:24:57Z"
        },
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "Rebased and squahsed.",
          "createdAt": "2021-03-19T15:56:36Z",
          "updatedAt": "2021-03-19T15:56:36Z"
        }
      ],
      "reviews": [
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjE1OTQ5ODYy",
          "commit": {
            "abbreviatedOid": "129d0ce"
          },
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "I'm well out of my depth on the math here but one typo that this PR didn't even introduce aside, this LGTM.",
          "createdAt": "2021-03-18T23:21:14Z",
          "updatedAt": "2021-03-18T23:32:12Z",
          "comments": [
            {
              "originalPosition": 5,
              "body": "```suggestion\r\n   needs to be in order to effectively detect malicious clients. Typically the\r\n```",
              "createdAt": "2021-03-18T23:21:14Z",
              "updatedAt": "2021-03-19T15:56:32Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjE2NTQ3OTMz",
          "commit": {
            "abbreviatedOid": "00bba6d"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "",
          "createdAt": "2021-03-19T15:50:31Z",
          "updatedAt": "2021-03-19T15:52:07Z",
          "comments": [
            {
              "originalPosition": 5,
              "body": "Why \"typically\"? Is this not an upper bound?",
              "createdAt": "2021-03-19T15:50:31Z",
              "updatedAt": "2021-03-19T15:56:32Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjE2NTUyMDc2",
          "commit": {
            "abbreviatedOid": "00bba6d"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-03-19T15:54:46Z",
          "updatedAt": "2021-03-19T15:54:46Z",
          "comments": [
            {
              "originalPosition": 5,
              "body": "It's going to depend on the circuit.",
              "createdAt": "2021-03-19T15:54:46Z",
              "updatedAt": "2021-03-19T15:56:32Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjE2NTUzMzY3",
          "commit": {
            "abbreviatedOid": "00bba6d"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-03-19T15:56:07Z",
          "updatedAt": "2021-03-19T15:56:07Z",
          "comments": [
            {
              "originalPosition": 5,
              "body": "Will it be higher? Lower?",
              "createdAt": "2021-03-19T15:56:07Z",
              "updatedAt": "2021-03-19T15:56:32Z"
            }
          ]
        }
      ]
    },
    {
      "number": 16,
      "id": "MDExOlB1bGxSZXF1ZXN0NTg3MzE5MTIw",
      "title": "design document: threat model",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/pull/16",
      "state": "MERGED",
      "author": "tgeoghegan",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "Initial threat model, enumerating the system's actors and their\r\ncapabilities, as well as current or hypothetical mitigations.",
      "createdAt": "2021-03-09T02:42:35Z",
      "updatedAt": "2021-12-30T00:53:19Z",
      "baseRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "baseRefName": "main",
      "baseRefOid": "5dd000153dc8c7136c271b14499b43a64316fbaf",
      "headRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "headRefName": "timg/threat-model",
      "headRefOid": "d4fb63bc5773f9c9e8b8e55ff0ea03500408f290",
      "closedAt": "2021-03-29T20:59:21Z",
      "mergedAt": "2021-03-29T20:59:21Z",
      "mergedBy": "chris-wood",
      "mergeCommit": {
        "oid": "1fbcac5a3b4e779716a6687adccc2671ee49467f"
      },
      "comments": [],
      "reviews": [
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjA5MDEwNDY2",
          "commit": {
            "abbreviatedOid": "511977a"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "CHANGES_REQUESTED",
          "body": "This is a great start! I think my only blocking comment is around the network adversary.",
          "createdAt": "2021-03-10T18:01:17Z",
          "updatedAt": "2021-03-16T13:43:38Z",
          "comments": [
            {
              "originalPosition": 55,
              "body": "Is this an attack on Prio, or the client shooting itself in the foot? It seems the like the latter, so maybe we just say something like, \"Clients can leak their data and compromise their own privacy. This does not affect the privacy of others in the system.\"",
              "createdAt": "2021-03-10T18:01:17Z",
              "updatedAt": "2021-03-26T21:58:30Z"
            },
            {
              "originalPosition": 77,
              "body": "Indeed -- I'd mark it as out of scope.",
              "createdAt": "2021-03-10T18:01:53Z",
              "updatedAt": "2021-03-26T21:58:30Z"
            },
            {
              "originalPosition": 93,
              "body": "I think this is trying to say that if a client reveals identifying information to users, such as via client auth, then aggregators have this capability. Is that right?",
              "createdAt": "2021-03-10T18:03:48Z",
              "updatedAt": "2021-03-26T21:58:30Z"
            },
            {
              "originalPosition": 104,
              "body": "Clarifying question: Is this suggesting or recommending that aggregators should somehow secret-share data before storing it? If so, I might mark this as out of scope. (Perhaps by saying that state persistence for each aggregator is assumed secure? Clearly if aggregators make their data public then things go wrong.)",
              "createdAt": "2021-03-10T18:14:08Z",
              "updatedAt": "2021-03-26T21:58:30Z"
            },
            {
              "originalPosition": 94,
              "body": "```suggestion\r\n   system by revealing that a particular client contributed data to the system.\r\n   Moreover, aggregators may choose to selectively drop or omit data from certain \r\n   clients.\r\n```",
              "createdAt": "2021-03-16T01:34:35Z",
              "updatedAt": "2021-03-26T21:58:30Z"
            },
            {
              "originalPosition": 105,
              "body": "I might omit this one, since it seems *somewhat* orthogonal to protocol or deployment mitigations.",
              "createdAt": "2021-03-16T01:36:46Z",
              "updatedAt": "2021-03-26T21:58:30Z"
            },
            {
              "originalPosition": 152,
              "body": "```suggestion\r\n1. Aggregators should refuse shared parameters that are trivially insecure\r\n```",
              "createdAt": "2021-03-16T01:39:35Z",
              "updatedAt": "2021-03-26T21:58:30Z"
            },
            {
              "originalPosition": 35,
              "body": "What about the network in general? That is, the attacker that is not a client, aggregator, or collector? You could imagine, for example, a network attacker forcing clients to use certain aggregators by making others appear to be unavailable. \ud83e\udd37 ",
              "createdAt": "2021-03-16T01:41:49Z",
              "updatedAt": "2021-03-26T21:58:30Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjEzNzA1MDYw",
          "commit": {
            "abbreviatedOid": "511977a"
          },
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-03-16T20:42:18Z",
          "updatedAt": "2021-03-16T20:42:18Z",
          "comments": [
            {
              "originalPosition": 55,
              "body": "I'm making a distinction between the user and the client here (I think my use of \"individual\" is confusing). I'm imagining a scenario where an application vendor might adopt Prio to elicit trust from users, but ship client software that covertly leaks user data over some non-Prio channel. \r\n\r\nI'm not sure we can do anything about it, unless the model is extended to include a trusted OS that a client runs in, which could attest to various properties of the client (e.g., measurements of reproducible builds, or attest to a log of the client's network activity so that external observers can verify that there are no unexpected connections to `secret-cleartext-metrics.appvendor.com`).\r\n\r\nI'm going to reword this to explicitly separate the case of an individual user/client disclosing their own data (which as you say does not compromise anyone else's privacy) and the case of a client used by many users leaking data (which is out of scope in the current model).",
              "createdAt": "2021-03-16T20:42:18Z",
              "updatedAt": "2021-03-26T21:58:30Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjEzNzE4OTk5",
          "commit": {
            "abbreviatedOid": "511977a"
          },
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-03-16T20:59:45Z",
          "updatedAt": "2021-03-16T20:59:45Z",
          "comments": [
            {
              "originalPosition": 105,
              "body": "I agree that this one isn't specific to Prio but rather would apply to any distributed computing system, so I'll strike it.",
              "createdAt": "2021-03-16T20:59:45Z",
              "updatedAt": "2021-03-26T21:58:30Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjEzNzIwMzU4",
          "commit": {
            "abbreviatedOid": "511977a"
          },
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-03-16T21:01:29Z",
          "updatedAt": "2021-03-16T21:01:30Z",
          "comments": [
            {
              "originalPosition": 104,
              "body": "The point of Prio, as I see it, is that you need to subvert all of the aggregators in order to defeat privacy. But if all the aggregators are using the same cloud storage vendor, then the attacker no longer needs to subvert _n_ different aggregators -- they just need to subvert a single cloud vendor. So users are back to hoping that a single entity will not have any breaches, will not get any national security letters and will consistently comply with its own privacy policy, which I think undermines Prio.\r\n\r\nReading this back, I don't like the sentence \"Prio deployments should ensure that aggregators' security do not have a common point of failure.\". I'll try to find a better way to express this.\r\n",
              "createdAt": "2021-03-16T21:01:29Z",
              "updatedAt": "2021-03-26T21:58:30Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjEzNzM2NjQw",
          "commit": {
            "abbreviatedOid": "511977a"
          },
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-03-16T21:23:21Z",
          "updatedAt": "2021-03-16T21:23:21Z",
          "comments": [
            {
              "originalPosition": 77,
              "body": "I'm not so sure, because at least one mitigation could be applied within the Prio protocol: requiring client identities. If clients had to authenticate to aggregators (or to a trusted authenticator who would then relay anonymized data shares to aggregators), then the system could detect clients sending excessive contributions and reject them.",
              "createdAt": "2021-03-16T21:23:21Z",
              "updatedAt": "2021-03-26T21:58:30Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjEzNzM4MTg0",
          "commit": {
            "abbreviatedOid": "511977a"
          },
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-03-16T21:25:37Z",
          "updatedAt": "2021-03-16T21:25:37Z",
          "comments": [
            {
              "originalPosition": 93,
              "body": "I would phrase it as \"if a client reveals identifying information to aggregators, such as via client auth, then aggregators have this capability\".",
              "createdAt": "2021-03-16T21:25:37Z",
              "updatedAt": "2021-03-26T21:58:30Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjEzNzQzMDQ0",
          "commit": {
            "abbreviatedOid": "511977a"
          },
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-03-16T21:32:28Z",
          "updatedAt": "2021-03-16T21:32:29Z",
          "comments": [
            {
              "originalPosition": 35,
              "body": "I think you're right that there should be a section for an attacker on the network. However I find it hard to reason about a threat like the one in your example because we haven't yet sketched out how aggregator discovery works. But certainly we can already call out the necessity of confidential and mutually authenticated links between participating servers.",
              "createdAt": "2021-03-16T21:32:28Z",
              "updatedAt": "2021-03-26T21:58:30Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjE1OTA5Mzc5",
          "commit": {
            "abbreviatedOid": "702f11c"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "This is super useful, thank you for getting this started. My only high-level comment is that this analysis doesn't completely settle the question of whether we care if a malicious server colludes with a malicious client in order to corrupt the final output. As I mention below, this threat model is only briefly considered in [BBC+19] (and not at all in the original Prio paper, [GB17]); and because a malicious aggregator could always submit a bogus aggregation share, this model doesn't seem (to me anyway) relevant for our deployment.\r\n\r\nI think this PR should explicitly remove this threat model from scope. We should assume that aggregators do their very best to validate and accumulate data shares correctly. That said, we should make it a goal to detect misbehaving aggregators. However, the target there needs to be detecting bogus aggregation shares.",
          "createdAt": "2021-03-18T22:01:15Z",
          "updatedAt": "2021-03-24T01:53:33Z",
          "comments": [
            {
              "originalPosition": 8,
              "body": "^ I've been the terms \"input\" and \"input share\" instead of \"data\" and \"data share\" respectively. I prefer \"input\" because the term \"data\" might also be used to describe the output aggregate.",
              "createdAt": "2021-03-18T22:01:16Z",
              "updatedAt": "2021-03-26T21:58:30Z"
            },
            {
              "originalPosition": 11,
              "body": "^ Elsewhere in this doc, the term \"invalid input\" refers to an input whose shares have been deemed invalid by the aggregators in their run of the input-validation protocol. I would use the term \"malformed\" to describe un-encodable input.",
              "createdAt": "2021-03-24T00:43:56Z",
              "updatedAt": "2021-03-26T21:58:30Z"
            },
            {
              "originalPosition": 3,
              "body": "I suggest keeping this list of terms in alphabetical order.",
              "createdAt": "2021-03-24T00:45:45Z",
              "updatedAt": "2021-03-26T21:58:30Z"
            },
            {
              "originalPosition": 17,
              "body": "The problem with using \"aggregation\" is that the same term applies to the task of aggregating inputs. I think a better term would be \"output\" or \"aggregate\".",
              "createdAt": "2021-03-24T00:46:53Z",
              "updatedAt": "2021-03-26T21:58:30Z"
            },
            {
              "originalPosition": 27,
              "body": "To my thinking, \"anonymity\" is implied by \"privacy\". I suggest removing this.",
              "createdAt": "2021-03-24T00:47:50Z",
              "updatedAt": "2021-03-26T21:58:30Z"
            },
            {
              "originalPosition": 60,
              "body": "```suggestion\r\n       clients do besides uploading data shares. Accordingly, such attacks\r\n```",
              "createdAt": "2021-03-24T00:51:10Z",
              "updatedAt": "2021-03-26T21:58:30Z"
            },
            {
              "originalPosition": 71,
              "body": "```suggestion\r\n1. The input-validation protocol executed by the aggregators prevents either individual\r\n```",
              "createdAt": "2021-03-24T00:54:10Z",
              "updatedAt": "2021-03-26T21:58:30Z"
            },
            {
              "originalPosition": 98,
              "body": "```suggestion\r\n   to emit aggregation shares.\r\n```",
              "createdAt": "2021-03-24T00:55:41Z",
              "updatedAt": "2021-03-26T21:58:30Z"
            },
            {
              "originalPosition": 104,
              "body": "```suggestion\r\n   is preserved as long as at least one aggregator is does not reveal its data shares.\r\n```",
              "createdAt": "2021-03-24T00:57:11Z",
              "updatedAt": "2021-03-26T21:58:30Z"
            },
            {
              "originalPosition": 113,
              "body": "^ I agree, but the design here is tricky. I would add a [[TODO]] here that reminds us to flesh this out.",
              "createdAt": "2021-03-24T00:58:03Z",
              "updatedAt": "2021-03-26T21:58:30Z"
            },
            {
              "originalPosition": 119,
              "body": "^ Does this defeat the bogus aggregation share attack? I'm not sure anything does. There may be other, more subtle attacks it detects, but given how easy it is for an aggregator to submit a bogus aggregation share, I don't think it matters much. (See comment in \"Future work and possible extensions\".)\r\n\r\nHowever, detecting bad aggregators is a really good idea. We'll need to flesh this out later.",
              "createdAt": "2021-03-24T01:08:08Z",
              "updatedAt": "2021-03-26T21:58:30Z"
            },
            {
              "originalPosition": 129,
              "body": "This capability is only marginally stronger than the bogus aggregation share attack, IMO.",
              "createdAt": "2021-03-24T01:09:41Z",
              "updatedAt": "2021-03-26T21:58:30Z"
            },
            {
              "originalPosition": 127,
              "body": "Another capability to call out: The leader can try to shrink the anonymity set by requesting aggregation shares early (cf. https://github.com/abetterinternet/prio-documents/issues/15).",
              "createdAt": "2021-03-24T01:12:08Z",
              "updatedAt": "2021-03-26T21:58:30Z"
            },
            {
              "originalPosition": 137,
              "body": "I think what's meant by this is that the aggregators could exchange verification shares so that each aggregator can run the decision algorithm locally. Is that right?\r\n\r\nI agree that this would help mitigate the leader's additional capabilities. However, doing so would require a secure channel between each pair of aggregators. I think this cost is too high.",
              "createdAt": "2021-03-24T01:17:06Z",
              "updatedAt": "2021-03-26T21:58:30Z"
            },
            {
              "originalPosition": 147,
              "body": "In [BBC+19] (and hence libprio-rs) the concept of \"polynomial identity test\" is generalized to distributed evaluation of a PCP over joint randomness. Hence, I would use the term \"joint randomness\" instead of \"polynomial identity test values\".\r\n\r\nTo your point: We haven't yet decided how the joint randomness is chosen. It could very well be the collector, but this is TBD. (See \"Consensus protocol\" below.) Also, I would add \"designation the leader role\" to this list.\r\nBut ",
              "createdAt": "2021-03-24T01:21:57Z",
              "updatedAt": "2021-03-26T21:58:30Z"
            },
            {
              "originalPosition": 149,
              "body": "```suggestion\r\n   shares submitted by aggregators.\r\n```",
              "createdAt": "2021-03-24T01:22:14Z",
              "updatedAt": "2021-03-26T21:58:30Z"
            },
            {
              "originalPosition": 154,
              "body": "The parameters need to be authenticated and enforced by each aggregator, but I think it's up to the collector to choose how large the anonymity set should be.",
              "createdAt": "2021-03-24T01:23:12Z",
              "updatedAt": "2021-03-26T21:58:30Z"
            },
            {
              "originalPosition": 180,
              "body": "The size of the input is a function of the data type, not the data itself. In particular, all clients will submit the same amount of data for a given aggregation job.",
              "createdAt": "2021-03-24T01:26:25Z",
              "updatedAt": "2021-03-26T21:58:30Z"
            },
            {
              "originalPosition": 194,
              "body": "Aggregation isn't well-defined if input lengths vary, so I think the first part of this mitigation is irrelevant.",
              "createdAt": "2021-03-24T01:27:52Z",
              "updatedAt": "2021-03-26T21:58:30Z"
            },
            {
              "originalPosition": 213,
              "body": "```suggestion\r\nfalse data in order to spoil aggregations. Deployments could require client\r\nauthentication. For example,\r\n```",
              "createdAt": "2021-03-24T01:29:05Z",
              "updatedAt": "2021-03-26T21:58:30Z"
            },
            {
              "originalPosition": 219,
              "body": "Another authentication mechanism: The leader might just require the user to login beforehand.\r\n\r\nI'm curious how whitebox crypto might be used here?",
              "createdAt": "2021-03-24T01:30:33Z",
              "updatedAt": "2021-03-26T21:58:30Z"
            },
            {
              "originalPosition": 226,
              "body": "```suggestion\r\nsome other channel which compromises privacy. If we introduce the\r\n```\r\n\r\nAs I mentioned above, privacy implies anonymity as the terms are defined above. (You may disagree?)",
              "createdAt": "2021-03-24T01:32:15Z",
              "updatedAt": "2021-03-26T21:58:30Z"
            },
            {
              "originalPosition": 203,
              "body": "An attacker capability explicitly considered in [BBC+19], but not in [GB17], is that a coalition of verifiers may attempt to convince the honest verifiers that an invalid data is valid. This doesn't matter much in our setting, since the bogus aggregation share attack descrbed above is equally effective and much easier to pull off. It would matter, however, if the aggregator were divided into two entities: one which validates input shares (the verifier); and another that accumulates them and emits the aggregation share. I think it's worth noting this somewhere, probably here.",
              "createdAt": "2021-03-24T01:36:43Z",
              "updatedAt": "2021-03-26T21:58:30Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjIxNDM2OTgx",
          "commit": {
            "abbreviatedOid": "702f11c"
          },
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-03-25T18:10:31Z",
          "updatedAt": "2021-03-25T18:10:31Z",
          "comments": [
            {
              "originalPosition": 8,
              "body": "That's a good idea. I keep finding myself writing \"original data\" or \"unshared data\" to disambiguate, so I'll adopt your \"input\" instead.",
              "createdAt": "2021-03-25T18:10:31Z",
              "updatedAt": "2021-03-26T21:58:30Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjIxNDY4ODgy",
          "commit": {
            "abbreviatedOid": "702f11c"
          },
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-03-25T18:45:59Z",
          "updatedAt": "2021-03-25T18:45:59Z",
          "comments": [
            {
              "originalPosition": 11,
              "body": "My phrasing here was based on a misreading of the 2017 paper. I'll rewrite this to make it plain that invalid data is simply data for which the validity predicate does not hold.",
              "createdAt": "2021-03-25T18:45:59Z",
              "updatedAt": "2021-03-26T21:58:30Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjIxNDcyNTI0",
          "commit": {
            "abbreviatedOid": "702f11c"
          },
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-03-25T18:50:10Z",
          "updatedAt": "2021-03-25T18:50:11Z",
          "comments": [
            {
              "originalPosition": 27,
              "body": "The [2017 paper](https://crypto.stanford.edu/prio/paper.pdf) calls out privacy and anonymity as distinct security properties (section 2). Anonymity is the adversary not knowing which client submitted which input, privacy is the adversary not knowing what the inputs are. The reason I added anonymity to this list is because I think that in the setting where aggregators talk directly to clients, privacy is preserved but client anonymity is weakened since the aggregator can identify clients e.g. by IP. Further we can sketch out a mitigation -- an anonymizing proxy -- so I think it's worth discussing the anonymity property.",
              "createdAt": "2021-03-25T18:50:11Z",
              "updatedAt": "2021-03-26T21:58:30Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjIxNDczNjQ3",
          "commit": {
            "abbreviatedOid": "702f11c"
          },
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-03-25T18:51:31Z",
          "updatedAt": "2021-03-25T18:51:31Z",
          "comments": [
            {
              "originalPosition": 129,
              "body": "Plus, HCG clarified for us yesterday that any aggregator, leader or not, can collude with malicious clients to achieve the same thing. I'll rewrite this.",
              "createdAt": "2021-03-25T18:51:31Z",
              "updatedAt": "2021-03-26T21:58:30Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjIxNTU5MjM5",
          "commit": {
            "abbreviatedOid": "702f11c"
          },
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-03-25T20:40:03Z",
          "updatedAt": "2021-03-25T20:40:03Z",
          "comments": [
            {
              "originalPosition": 17,
              "body": "Good point! I chose \"output\" for symmetry with your other good suggestion of \"input\".",
              "createdAt": "2021-03-25T20:40:03Z",
              "updatedAt": "2021-03-26T21:58:30Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjIxNTg0Nzg3",
          "commit": {
            "abbreviatedOid": "702f11c"
          },
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-03-25T21:14:15Z",
          "updatedAt": "2021-03-25T21:14:15Z",
          "comments": [
            {
              "originalPosition": 113,
              "body": "I think this isn't something we'd tackle in an initial deployment of Prio anyway, so I wrote up #22 on this topic, and will move this mitigation into future work and possible extensions.",
              "createdAt": "2021-03-25T21:14:15Z",
              "updatedAt": "2021-03-26T21:58:30Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjIxNTkwMjA5",
          "commit": {
            "abbreviatedOid": "702f11c"
          },
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-03-25T21:22:04Z",
          "updatedAt": "2021-03-25T21:22:04Z",
          "comments": [
            {
              "originalPosition": 219,
              "body": "The notion with whitebox is that you could use it to distribute a shared secret to all \"legitimate\" instances of your client, and so having a message HMACed with a whiteboxed key gives you some kind of assurance on the provenance of the message. But thinking about it further, I've never been a big fan of whitebox, and mentioning it here isn't particularly helpful to explaining Prio, so I'll just strike it.",
              "createdAt": "2021-03-25T21:22:04Z",
              "updatedAt": "2021-03-26T21:58:30Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjIxNTk1MDM5",
          "commit": {
            "abbreviatedOid": "702f11c"
          },
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-03-25T21:29:12Z",
          "updatedAt": "2021-03-25T21:29:13Z",
          "comments": [
            {
              "originalPosition": 203,
              "body": "I think the leader in our design is the verifier you describe, no? What HCG argued to us on 3/24 was that a verifier colluding with a malicious client doesn't have any capability that isn't already available to any aggregator colluding with a malicious client. I think what you're sketching out is a further variation where the leader is _only_ a verifier and not an aggregator?",
              "createdAt": "2021-03-25T21:29:12Z",
              "updatedAt": "2021-03-26T21:58:30Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjIxNTk4OTM4",
          "commit": {
            "abbreviatedOid": "702f11c"
          },
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-03-25T21:35:08Z",
          "updatedAt": "2021-03-25T21:35:09Z",
          "comments": [
            {
              "originalPosition": 180,
              "body": "For any individual aggregation, yes, but imagine if a client supports dozens or hundreds of individual aggregations, and users can opt out of any of them. If the client only transmits input shares for the aggregations the client has opted into, then the volume of traffic observable by the adversary would change. Hence I argue that a client should always transmit the same amount of data, regardless of which aggregations a user has consented to.",
              "createdAt": "2021-03-25T21:35:09Z",
              "updatedAt": "2021-03-26T21:58:30Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjIxNjAwOTk3",
          "commit": {
            "abbreviatedOid": "702f11c"
          },
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-03-25T21:38:23Z",
          "updatedAt": "2021-03-25T21:38:23Z",
          "comments": [
            {
              "originalPosition": 154,
              "body": "I agree, but the intent here is that aggregators should implement basic checks independent of the configuration of any aggregation to prevent abuse.",
              "createdAt": "2021-03-25T21:38:23Z",
              "updatedAt": "2021-03-26T21:58:30Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjIxNjAxOTQ3",
          "commit": {
            "abbreviatedOid": "702f11c"
          },
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-03-25T21:39:55Z",
          "updatedAt": "2021-03-25T21:39:55Z",
          "comments": [
            {
              "originalPosition": 137,
              "body": "HCG convinced us (or at least me!) that it's OK to have a designated proof verifier because the verifier is no more powerful than any aggregator that colludes with a malicious client, so I'm going to remove this item.",
              "createdAt": "2021-03-25T21:39:55Z",
              "updatedAt": "2021-03-26T21:58:30Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjIyNDg2ODI3",
          "commit": {
            "abbreviatedOid": "f090834"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "LGTM modulo editorial things.",
          "createdAt": "2021-03-26T19:48:11Z",
          "updatedAt": "2021-03-26T21:07:52Z",
          "comments": [
            {
              "originalPosition": 6,
              "body": "```suggestion\r\n   not truthful. For example, if the data being gathered is whether or not users have\r\n```",
              "createdAt": "2021-03-26T19:48:11Z",
              "updatedAt": "2021-03-26T21:58:30Z"
            },
            {
              "originalPosition": 31,
              "body": "```suggestion\r\n1. Privacy. The aggregators and collector learn only the output of F computed over all client inputs, \r\n```",
              "createdAt": "2021-03-26T19:49:50Z",
              "updatedAt": "2021-03-26T21:58:30Z"
            },
            {
              "originalPosition": 34,
              "body": "```suggestion\r\n1. Robustness. As long as the aggregators execute the input-validation protocol correctly, a malicious client can skew the output of F only by reporting false \r\n```",
              "createdAt": "2021-03-26T19:50:24Z",
              "updatedAt": "2021-03-26T21:58:30Z"
            },
            {
              "originalPosition": 138,
              "body": "```suggestion\r\n1. Shrinking the anonymity set. The leader instructs aggregators to construct\r\n```",
              "createdAt": "2021-03-26T20:58:14Z",
              "updatedAt": "2021-03-26T21:58:30Z"
            },
            {
              "originalPosition": 180,
              "body": "Works for me.",
              "createdAt": "2021-03-26T21:00:15Z",
              "updatedAt": "2021-03-26T21:58:30Z"
            },
            {
              "originalPosition": 203,
              "body": "> I think the leader in our design is the verifier you describe, no? \r\n\r\nNo. Here I'm imagining if any aggregator were split into two services: one which validates input shares and another that accumulates them.\r\n\r\nIn any case, the point here is moot I think. We will assume that the aggregators execute the input-validation correctly (this is setting I of [BBC+19].)\r\n",
              "createdAt": "2021-03-26T21:03:49Z",
              "updatedAt": "2021-03-26T21:58:30Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjIzNjQ0Nzgy",
          "commit": {
            "abbreviatedOid": "d4fb63b"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "",
          "createdAt": "2021-03-29T20:58:52Z",
          "updatedAt": "2021-03-29T20:58:52Z",
          "comments": []
        }
      ]
    },
    {
      "number": 17,
      "id": "MDExOlB1bGxSZXF1ZXN0NTg4NTUwNjk1",
      "title": "Add batch size constraint and aggregator count constraint to the design document",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/pull/17",
      "state": "CLOSED",
      "author": "aaomidi",
      "authorAssociation": "NONE",
      "assignees": [],
      "labels": [],
      "body": "Introduces two new sections under `System constraints`",
      "createdAt": "2021-03-09T20:03:35Z",
      "updatedAt": "2021-12-30T02:09:39Z",
      "baseRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "baseRefName": "main",
      "baseRefOid": "5dd000153dc8c7136c271b14499b43a64316fbaf",
      "headRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "headRefName": "amir/constrants/batch_aggregator",
      "headRefOid": "4ad6e66911b5a600027152024d101f62479a55ea",
      "closedAt": "2021-07-01T01:51:57Z",
      "mergedAt": null,
      "mergedBy": null,
      "mergeCommit": null,
      "comments": [
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "I believe the intention of this change is now subsumed by #59. Can we close this?",
          "createdAt": "2021-07-01T01:48:52Z",
          "updatedAt": "2021-07-01T01:48:52Z"
        }
      ],
      "reviews": [
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjEzNTg5NjQx",
          "commit": {
            "abbreviatedOid": "4ad6e66"
          },
          "author": "acmiyaguchi",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-03-16T18:26:00Z",
          "updatedAt": "2021-03-16T18:30:42Z",
          "comments": [
            {
              "originalPosition": 13,
              "body": "This paragraph conflates two separate instances of content size. It's reasonable for the leader to validate incoming shares based on their length, which is some function of aggregation parameters (e.g., it should be cheap to filter data for a 10-bit encoding that looks like it's 1000-bits). These would get rejected during the verification process anyways. At the same time, the leader should also be aware that aggregators may only accept up to a certain number of messages at a time. \r\n\r\nThe burden should be on the leader to ensure that the clients are behaving with respect to batch constraint since the client (a single device/user) has limited awareness about the batch it's part of.",
              "createdAt": "2021-03-16T18:26:00Z",
              "updatedAt": "2021-03-16T18:30:42Z"
            },
            {
              "originalPosition": 22,
              "body": "Might be useful to include an approach of how to resolve one of the issues that arises in this context (e.g., ensuring redundancy of some kind). ",
              "createdAt": "2021-03-16T18:28:33Z",
              "updatedAt": "2021-03-16T18:30:42Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjE5MjQyMzg3",
          "commit": {
            "abbreviatedOid": "4ad6e66"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "I don't think the aggregators should be able to enforce minimum batch sizes. IMO this should be a parameter chosen by the collector.",
          "createdAt": "2021-03-24T02:00:54Z",
          "updatedAt": "2021-03-24T02:07:31Z",
          "comments": [
            {
              "originalPosition": 18,
              "body": "```suggestion\r\nThe collector may opt into using\r\n```\r\n(Not sure if this is what you mean ... see \"Terminology\" above.)",
              "createdAt": "2021-03-24T02:00:54Z",
              "updatedAt": "2021-03-24T02:07:31Z"
            }
          ]
        }
      ]
    },
    {
      "number": 23,
      "id": "MDExOlB1bGxSZXF1ZXN0NjAxODc0MzY1",
      "title": "EKR pass 1.",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/pull/23",
      "state": "MERGED",
      "author": "ekr",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "- Try to keep things concrete. We always send things to the leader\r\n  so just say so.\r\n\r\n- Move the \"System Constraints\" section to the end and rename it.\r\n  This will remove forward refs when the rest of the doc is\r\n  written.\r\n\r\nOther editorial.",
      "createdAt": "2021-03-26T20:03:56Z",
      "updatedAt": "2021-03-29T21:02:12Z",
      "baseRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "baseRefName": "main",
      "baseRefOid": "f63c8fd340e1befa5db524602eb4dd7f802613f9",
      "headRepository": "ekr/ppm-specification",
      "headRefName": "ekr_comments",
      "headRefOid": "4fc2641189ae683255e191b07618624db64ee408",
      "closedAt": "2021-03-29T21:02:12Z",
      "mergedAt": "2021-03-29T21:02:12Z",
      "mergedBy": "cjpatton",
      "mergeCommit": {
        "oid": "1457f9ba189dfd70a18393c6b6af6459e3ab78fd"
      },
      "comments": [],
      "reviews": [
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjIyNTYxMjA1",
          "commit": {
            "abbreviatedOid": "4fc2641"
          },
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-03-26T22:04:13Z",
          "updatedAt": "2021-03-26T22:09:13Z",
          "comments": [
            {
              "originalPosition": 134,
              "body": "The most recent consensus is that aggregators will decrypt proof+input shares received from clients, forward the proof shares to the leader (while keeping input shares secret), and the leader is responsible for validating the proof and instructing aggregators to include an input in an aggregation.\r\n\r\nA further nit: the proof proves that the input is _valid_ (#16 adds a definition of invalid input to the glossary). Prio can't say anything useful about the correctness or truthfulness of the input.",
              "createdAt": "2021-03-26T22:04:14Z",
              "updatedAt": "2021-03-26T22:09:13Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjIzNjQ0Mjk0",
          "commit": {
            "abbreviatedOid": "4fc2641"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "\ud83d\udea2 ",
          "createdAt": "2021-03-29T20:58:13Z",
          "updatedAt": "2021-03-29T20:58:13Z",
          "comments": []
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjIzNjQ2Nzg0",
          "commit": {
            "abbreviatedOid": "4fc2641"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "",
          "createdAt": "2021-03-29T21:01:29Z",
          "updatedAt": "2021-03-29T21:01:29Z",
          "comments": []
        }
      ]
    },
    {
      "number": 25,
      "id": "MDExOlB1bGxSZXF1ZXN0NjA0NTQxNDI0",
      "title": "Beef up the introduction and add an outline for the document structure",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/pull/25",
      "state": "MERGED",
      "author": "cjpatton",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "Solves #24. ",
      "createdAt": "2021-03-30T22:20:48Z",
      "updatedAt": "2021-06-17T21:15:33Z",
      "baseRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "baseRefName": "main",
      "baseRefOid": "67c276d22919506d2a949a35a4937eedcbef2408",
      "headRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "headRefName": "cjpatton-pass-1",
      "headRefOid": "724e42ed9f77346d5bb8f19ea0f48082168acb99",
      "closedAt": "2021-03-30T23:03:41Z",
      "mergedAt": "2021-03-30T23:03:41Z",
      "mergedBy": "cjpatton",
      "mergeCommit": {
        "oid": "bd54726bf0a5af09d58548a06a9df31faefebbd1"
      },
      "comments": [],
      "reviews": [
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjI0NzYzNTY3",
          "commit": {
            "abbreviatedOid": "fdc6a35"
          },
          "author": "ekr",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "This is a huge improvement. Once you land this, I have some thoughts on how to bridge to the crypto section.",
          "createdAt": "2021-03-30T22:47:49Z",
          "updatedAt": "2021-03-30T22:52:40Z",
          "comments": [
            {
              "originalPosition": 93,
              "body": "```suggestion\r\nx[1,1] + x[1,2] modulo some value p.  For convenience, we will omit the \"mod p\" in the rest of this section. It then uploads x[1,1] to one server x[1,2] to the other. The\r\n```",
              "createdAt": "2021-03-30T22:47:49Z",
              "updatedAt": "2021-03-30T23:03:11Z"
            },
            {
              "originalPosition": 91,
              "body": "This seems like an example where we actually have to invoke modular arithmetic, because obviously if x[,] are just integers then we know that x[1] < x[1,1] and x[1] < x[1,2].\r\n\r\n",
              "createdAt": "2021-03-30T22:49:22Z",
              "updatedAt": "2021-03-30T23:03:11Z"
            },
            {
              "originalPosition": 103,
              "body": "```suggestion\r\nbecause addition is commutative. i.e., \r\n```",
              "createdAt": "2021-03-30T22:51:22Z",
              "updatedAt": "2021-03-30T23:03:11Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjI0NzY5Mjg1",
          "commit": {
            "abbreviatedOid": "fdc6a35"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-03-30T23:00:27Z",
          "updatedAt": "2021-03-30T23:00:27Z",
          "comments": [
            {
              "originalPosition": 91,
              "body": "I took your suggestion above, which should make it clear.",
              "createdAt": "2021-03-30T23:00:27Z",
              "updatedAt": "2021-03-30T23:03:11Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjI0NzY5NzA4",
          "commit": {
            "abbreviatedOid": "fdc6a35"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-03-30T23:01:24Z",
          "updatedAt": "2021-03-30T23:01:24Z",
          "comments": [
            {
              "originalPosition": 103,
              "body": "Done.",
              "createdAt": "2021-03-30T23:01:24Z",
              "updatedAt": "2021-03-30T23:03:11Z"
            }
          ]
        }
      ]
    },
    {
      "number": 26,
      "id": "MDExOlB1bGxSZXF1ZXN0NjA0Njc3NDkz",
      "title": "Try to make the on-ramp to the crypto easier and clean up a bit of no\u2026",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/pull/26",
      "state": "MERGED",
      "author": "ekr",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "\u2026tation to make it more friendly to comsec types",
      "createdAt": "2021-03-31T00:15:12Z",
      "updatedAt": "2021-04-07T20:46:33Z",
      "baseRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "baseRefName": "main",
      "baseRefOid": "bd54726bf0a5af09d58548a06a9df31faefebbd1",
      "headRepository": "ekr/ppm-specification",
      "headRefName": "crypto_bridge",
      "headRefOid": "0c45dd2a02bc854ea385232a4e55032a734ef409",
      "closedAt": "2021-04-07T20:46:33Z",
      "mergedAt": "2021-04-07T20:46:33Z",
      "mergedBy": "cjpatton",
      "mergeCommit": {
        "oid": "89cc97e283500263c82024d784cdfcd78f5926c0"
      },
      "comments": [],
      "reviews": [
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjI0ODA1MTQ5",
          "commit": {
            "abbreviatedOid": "ec93aa3"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "CHANGES_REQUESTED",
          "body": "",
          "createdAt": "2021-03-31T00:34:29Z",
          "updatedAt": "2021-03-31T00:43:46Z",
          "comments": [
            {
              "originalPosition": 27,
              "body": "s/break/split/",
              "createdAt": "2021-03-31T00:34:29Z",
              "updatedAt": "2021-04-07T20:46:06Z"
            },
            {
              "originalPosition": 46,
              "body": "s/Where/Above,/",
              "createdAt": "2021-03-31T00:35:01Z",
              "updatedAt": "2021-04-07T20:46:06Z"
            },
            {
              "originalPosition": 25,
              "body": "I understand the intention of this paragraph, however I think it's a bit confusing as it is. For instance, you say that a client wishes to report a \"set of inputs\", whereas above we think of each clients sending exactly one input, and we refer to the inputs of the aggregation function collectively as the \"set of inputs\"\r\n\r\nWDYTA:\r\n> Each run of the Prio protocol is parameterized by a finite field, which we will call K, and an integer n. Each client encodes its input as a length-n vector of element of K. The length of the vector depends on the type of data being collected. A single field element may be sufficient for some applications, whereas more sophisticated measurements will require larger encodings.",
              "createdAt": "2021-03-31T00:43:32Z",
              "updatedAt": "2021-04-07T20:46:06Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjI0ODEzNDA4",
          "commit": {
            "abbreviatedOid": "ec93aa3"
          },
          "author": "ekr",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-03-31T00:59:47Z",
          "updatedAt": "2021-03-31T00:59:47Z",
          "comments": [
            {
              "originalPosition": 25,
              "body": "Perhaps this is just me being confused. When you and I talked the other day, what I thought I heard was that if I wanted to report, say, \"number of urls\" and \"number of clicks\", I would turn that into a single 2-length vector of integers rather then sending two entirely different 1-length vectors and proofs.' Is that not correct?\r\n\r\n",
              "createdAt": "2021-03-31T00:59:47Z",
              "updatedAt": "2021-04-07T20:46:06Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjI0ODIzNzA4",
          "commit": {
            "abbreviatedOid": "ec93aa3"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-03-31T01:30:10Z",
          "updatedAt": "2021-03-31T01:30:11Z",
          "comments": [
            {
              "originalPosition": 25,
              "body": "That's correct. My point is that, in the language of this doc, the \"input\" in this case is the pair (number_of_urls, number_of_clicks). I'm trying to be precise about the language. In particular, I want to be clear that \"set of inputs\" refers to the collection of user inputs. Each input is a datum of some type, e.g., a pair of integers, a single integer, a widget, what have you.\r\n",
              "createdAt": "2021-03-31T01:30:10Z",
              "updatedAt": "2021-04-07T20:46:06Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjI0ODI0NjA3",
          "commit": {
            "abbreviatedOid": "ec93aa3"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "",
          "createdAt": "2021-03-31T01:32:42Z",
          "updatedAt": "2021-03-31T01:32:53Z",
          "comments": [
            {
              "originalPosition": 27,
              "body": "```suggestion\r\nIn order to share x between s servers, we split it up into s shares\r\n```",
              "createdAt": "2021-03-31T01:32:42Z",
              "updatedAt": "2021-04-07T20:46:06Z"
            },
            {
              "originalPosition": 46,
              "body": "```suggestion\r\nAbove, p(n), u(n), and v(n) are functions that we specify later.\r\n```",
              "createdAt": "2021-03-31T01:32:50Z",
              "updatedAt": "2021-04-07T20:46:06Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjMwNTY1Nzk5",
          "commit": {
            "abbreviatedOid": "ec93aa3"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-04-07T20:45:07Z",
          "updatedAt": "2021-04-07T20:45:08Z",
          "comments": [
            {
              "originalPosition": 25,
              "body": "Taking my suggestion.",
              "createdAt": "2021-04-07T20:45:07Z",
              "updatedAt": "2021-04-07T20:46:06Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjMwNTY3ODk0",
          "commit": {
            "abbreviatedOid": "0c45dd2"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "",
          "createdAt": "2021-04-07T20:46:16Z",
          "updatedAt": "2021-04-07T20:46:16Z",
          "comments": []
        }
      ]
    },
    {
      "number": 28,
      "id": "MDExOlB1bGxSZXF1ZXN0NjE0ODEzMTMw",
      "title": "More background",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/pull/28",
      "state": "MERGED",
      "author": "ekr",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "",
      "createdAt": "2021-04-13T23:04:33Z",
      "updatedAt": "2021-04-14T17:08:14Z",
      "baseRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "baseRefName": "main",
      "baseRefOid": "89cc97e283500263c82024d784cdfcd78f5926c0",
      "headRepository": "ekr/ppm-specification",
      "headRefName": "more_background",
      "headRefOid": "d381c284c332121d51e55a217f5a7d7c5516c485",
      "closedAt": "2021-04-14T17:08:14Z",
      "mergedAt": "2021-04-14T17:08:14Z",
      "mergedBy": "chris-wood",
      "mergeCommit": {
        "oid": "d868f8cae34f07b1acf902832f4aa627f56925cd"
      },
      "comments": [],
      "reviews": [
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjM1ODAxNTA1",
          "commit": {
            "abbreviatedOid": "e968c27"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": ":boat: ",
          "createdAt": "2021-04-14T16:05:03Z",
          "updatedAt": "2021-04-14T16:05:38Z",
          "comments": [
            {
              "originalPosition": 132,
              "body": "```suggestion\r\n{{CITE}} describes how to encode measurements for each statistic.\r\n```",
              "createdAt": "2021-04-14T16:05:03Z",
              "updatedAt": "2021-04-14T16:32:16Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjM1ODA0MDM3",
          "commit": {
            "abbreviatedOid": "e968c27"
          },
          "author": "ekr",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-04-14T16:07:29Z",
          "updatedAt": "2021-04-14T16:07:29Z",
          "comments": [
            {
              "originalPosition": 132,
              "body": "I think this is actually going to be a cross-reference to some to-be-written section of this doc.",
              "createdAt": "2021-04-14T16:07:29Z",
              "updatedAt": "2021-04-14T16:32:16Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjM1ODI2MjEz",
          "commit": {
            "abbreviatedOid": "e968c27"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-04-14T16:29:51Z",
          "updatedAt": "2021-04-14T16:29:52Z",
          "comments": [
            {
              "originalPosition": 60,
              "body": "```suggestion\r\nmeasurements of all clients. In this case, the protocol input is a single measurement consisting of \r\na single positive integer; no additional encoding is done. Given this input, the first client splits its\r\nmeasurement x[1] with additive secret-sharing into a pair of integers x[1,1] and x[1,2] for which \r\nx[1] = x[1,1] + x[1,2] modulo a prime p. (For convenience, we will omit the\r\n```",
              "createdAt": "2021-04-14T16:29:51Z",
              "updatedAt": "2021-04-14T16:32:16Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjM1ODUzNjg1",
          "commit": {
            "abbreviatedOid": "d381c28"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-04-14T16:58:52Z",
          "updatedAt": "2021-04-14T16:58:53Z",
          "comments": [
            {
              "originalPosition": 132,
              "body": "Indeed. \"{{CITE}}\" the way we've been writing this.",
              "createdAt": "2021-04-14T16:58:53Z",
              "updatedAt": "2021-04-14T16:58:53Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjM1ODYwNzE1",
          "commit": {
            "abbreviatedOid": "d381c28"
          },
          "author": "ekr",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-04-14T17:06:39Z",
          "updatedAt": "2021-04-14T17:06:39Z",
          "comments": [
            {
              "originalPosition": 132,
              "body": "That's not going to be ideal if/when we want to turn this into an IETF draft, b/c it will cause the formatter to choke.",
              "createdAt": "2021-04-14T17:06:39Z",
              "updatedAt": "2021-04-14T17:06:39Z"
            }
          ]
        }
      ]
    },
    {
      "number": 29,
      "id": "MDExOlB1bGxSZXF1ZXN0NjE2MTc5MTUx",
      "title": "Add a disclaimer",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/pull/29",
      "state": "MERGED",
      "author": "cjpatton",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "",
      "createdAt": "2021-04-15T16:09:53Z",
      "updatedAt": "2021-06-17T21:15:31Z",
      "baseRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "baseRefName": "main",
      "baseRefOid": "d868f8cae34f07b1acf902832f4aa627f56925cd",
      "headRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "headRefName": "cjpatton/wip",
      "headRefOid": "fe93b6cf74f50244e1fe09e409789c9d5879f5aa",
      "closedAt": "2021-04-15T16:15:56Z",
      "mergedAt": "2021-04-15T16:15:56Z",
      "mergedBy": "chris-wood",
      "mergeCommit": {
        "oid": "934b48a1119acfb264b213180437794b8241fdc4"
      },
      "comments": [],
      "reviews": [
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjM2ODc2NDAw",
          "commit": {
            "abbreviatedOid": "fe93b6c"
          },
          "author": "ekr",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "LGTM",
          "createdAt": "2021-04-15T16:14:33Z",
          "updatedAt": "2021-04-15T16:14:33Z",
          "comments": []
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjM2ODc3NzA1",
          "commit": {
            "abbreviatedOid": "fe93b6c"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "",
          "createdAt": "2021-04-15T16:15:53Z",
          "updatedAt": "2021-04-15T16:15:53Z",
          "comments": []
        }
      ]
    },
    {
      "number": 31,
      "id": "MDExOlB1bGxSZXF1ZXN0NjIwNzExMzY3",
      "title": "Specify the ingestion flow",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/pull/31",
      "state": "CLOSED",
      "author": "cjpatton",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "Specifies the ingestion flow, including parameter discovery, uploading of shares, and validating of the shares. The same flow applies to both Prio and heavy hitters (\"Hits\"). The protocol-specific messages are left unspecified. (We will specify them in future PRs.)\r\n\r\nNote that I decided to go with TLS syntax for this PR. This was done only because I'm familiar with this style and it was easy for me to write quickly. I'm happy to completely re-do message encoding, but let's do so in a future PR.\r\n\r\nIssues addressed by this change:\r\n* Closes #4: In this design, the leader specifies any number of helpers. For each helper, the client initiates a run of the protocol with the leader and the helper. This allows the a helper to drop out without impacting data processing later on. However, the leader cannot drop out. (This seems OK, since this is the same up-time requirement as usual.)\r\n* Addresses #8. In this design, the joint randomness needed for a run of the protocol is picked by the leader and sent to the helpers in the `PAVerifyStartReq` message.\r\n* Closes #9. In this design, the leader tells the client the URL of each helper. The client gets each helper's public key by making an HTTP request.\r\n* Addresses #18. This PR specifies a high-level flow that should fit the input-validation protocol for heavy hitters.\r\n* Closes #21. Any protocol-specific parameters are carried by the `PAClientParam` message.\r\n* Addresses #22. In this design, multiple protocol runs are used to add resilience to aggregator drop-out. We still don't know whether we can use threshold secret sharing (i.e., Shamir) for the same purpose. (In any case, this design disallows it.) We should think about whether this works before closing that issue.",
      "createdAt": "2021-04-22T02:32:50Z",
      "updatedAt": "2021-04-27T15:38:01Z",
      "baseRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "baseRefName": "main",
      "baseRefOid": "934b48a1119acfb264b213180437794b8241fdc4",
      "headRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "headRefName": "cjpatton/ingestion",
      "headRefOid": "0e672cbdc5cdb3e7e29373bb13c4590ec12f72c8",
      "closedAt": "2021-04-27T15:33:08Z",
      "mergedAt": null,
      "mergedBy": null,
      "mergeCommit": null,
      "comments": [
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "Be advised: I changed the first client->leader request to a POST. That way the leader can \"challenge\" the client (e.g., give it a random nonce), which may be needed for some protocols",
          "createdAt": "2021-04-23T14:42:19Z",
          "updatedAt": "2021-04-23T14:42:19Z"
        },
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "@chris-wood has some major revisions (restructuring the doc, mostly) so I'll be closing this PR and opening a new one. I'm also making the following changes:\r\n- Remove \"resend_shares\" flag\r\n- Add an \"upload ID\" to PAClientParam.",
          "createdAt": "2021-04-27T15:33:08Z",
          "updatedAt": "2021-04-27T15:33:08Z"
        }
      ],
      "reviews": [
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjQyNTkwODEz",
          "commit": {
            "abbreviatedOid": "620c88f"
          },
          "author": "ekr",
          "authorAssociation": "COLLABORATOR",
          "state": "CHANGES_REQUESTED",
          "body": "I got about half-way through this and left some comments, but I think it probably needs a fair amount of rework before it's ready for detailed review. In particular, it's pretty informal about the HTTP mechanics. There's a lot of prior art in how to describe this. I would suggest imitating ACME (RFC 8555) which will also help with the client auth if you don't want to do TLS client auth.",
          "createdAt": "2021-04-22T19:26:44Z",
          "updatedAt": "2021-04-22T19:36:42Z",
          "comments": [
            {
              "originalPosition": 35,
              "body": "This just uses TLS, right? If so, we usually just assume the WebPKI and wave at 6125.",
              "createdAt": "2021-04-22T19:26:45Z",
              "updatedAt": "2021-04-23T21:13:14Z"
            },
            {
              "originalPosition": 59,
              "body": "Can you reorder these so we don't have a forward reference?",
              "createdAt": "2021-04-22T19:27:16Z",
              "updatedAt": "2021-04-23T21:13:14Z"
            },
            {
              "originalPosition": 57,
              "body": "This is kind of a confused thing in TLS, but based on 8446, I believe you want:\r\n\r\n```\r\nopaque<0..255> URl;\r\n```\r\n\r\nWith that said, you also want 0..2^16-1;",
              "createdAt": "2021-04-22T19:29:11Z",
              "updatedAt": "2021-04-23T21:13:14Z"
            },
            {
              "originalPosition": 55,
              "body": "You need to explain these structs.",
              "createdAt": "2021-04-22T19:30:03Z",
              "updatedAt": "2021-04-23T21:13:14Z"
            },
            {
              "originalPosition": 45,
              "body": "You usually need a length field here so that you can extent his to new protos",
              "createdAt": "2021-04-22T19:30:19Z",
              "updatedAt": "2021-04-23T21:13:14Z"
            },
            {
              "originalPosition": 74,
              "body": "A GET? A POST? [ACME](https://www.rfc-editor.org/rfc/rfc8555.html) does a pretty good job of describing how to talk to this kind of HTTP services server.\r\n\r\n",
              "createdAt": "2021-04-22T19:32:29Z",
              "updatedAt": "2021-04-23T21:13:14Z"
            },
            {
              "originalPosition": 87,
              "body": "This seems redundant.",
              "createdAt": "2021-04-22T19:32:46Z",
              "updatedAt": "2021-04-23T21:13:14Z"
            },
            {
              "originalPosition": 85,
              "body": "With an OK or...? What's the content type.",
              "createdAt": "2021-04-22T19:33:18Z",
              "updatedAt": "2021-04-23T21:13:14Z"
            },
            {
              "originalPosition": 107,
              "body": "How does this interact with the related structs in ECH?",
              "createdAt": "2021-04-22T19:35:05Z",
              "updatedAt": "2021-04-23T21:13:14Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjQyNjAwODAz",
          "commit": {
            "abbreviatedOid": "620c88f"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "Good start! Lots of ways we can do this, and I'm happy to just iterate going forward.",
          "createdAt": "2021-04-22T19:39:47Z",
          "updatedAt": "2021-04-22T20:00:12Z",
          "comments": [
            {
              "originalPosition": 110,
              "body": "This is unused -- did you mean to include in the key config?",
              "createdAt": "2021-04-22T19:39:48Z",
              "updatedAt": "2021-04-23T21:13:14Z"
            },
            {
              "originalPosition": 162,
              "body": "```suggestion\r\n} PAUpload;\r\n```",
              "createdAt": "2021-04-22T19:42:19Z",
              "updatedAt": "2021-04-23T21:13:14Z"
            },
            {
              "originalPosition": 165,
              "body": "Should the config_id be in this struct? The leader doesn't need to parse it upon receipt of the PAUpload message, right?",
              "createdAt": "2021-04-22T19:43:33Z",
              "updatedAt": "2021-04-23T21:13:14Z"
            },
            {
              "originalPosition": 146,
              "body": "How? With what AAD? ",
              "createdAt": "2021-04-22T19:43:48Z",
              "updatedAt": "2021-04-23T21:13:14Z"
            },
            {
              "originalPosition": 131,
              "body": "Why one message for each helper? Can then not be sent in a single message? (Also, isn't there just one helper, per the list above^?)",
              "createdAt": "2021-04-22T19:44:19Z",
              "updatedAt": "2021-04-23T21:13:15Z"
            },
            {
              "originalPosition": 162,
              "body": "Maybe we can rearrange this like so? The leader then just copies the contents from the end of this message and sends them to the right helper along with the `PATask`.\r\n\r\n```\r\nstruct {\r\n   PATask task;\r\n   PALeaderShare leader_share;\r\n   Url helper_url;\r\n   struct {\r\n      uint8 helper_key_config_id;\r\n      opaque enc<0..2^16-1>;\r\n      opaque payload<0..2^24-1>;\r\n   } PAHelperUpload;\r\n} PALeaderUpload;",
              "createdAt": "2021-04-22T19:46:53Z",
              "updatedAt": "2021-04-23T21:13:15Z"
            },
            {
              "originalPosition": 178,
              "body": "Should it wait to send \"200 OK\" until the helper confirms that the upload is well formed? (That is, it can decrypt the share?)",
              "createdAt": "2021-04-22T19:48:01Z",
              "updatedAt": "2021-04-23T21:13:15Z"
            },
            {
              "originalPosition": 185,
              "body": "Why would we not relay this signal to clients? It could mean that their configuration information is out of date, or something else. Would that be important for monitoring purposes?",
              "createdAt": "2021-04-22T19:49:02Z",
              "updatedAt": "2021-04-23T21:13:15Z"
            },
            {
              "originalPosition": 194,
              "body": "We should probably say that the leader buckets up uploads based on matching task IDs and helper config IDs above. (It's listed below.)",
              "createdAt": "2021-04-22T19:50:10Z",
              "updatedAt": "2021-04-23T21:13:15Z"
            },
            {
              "originalPosition": 212,
              "body": "How can `PAVerifyStartReq.shares` carry protocol-specific information if it only includes `enc` and `payload`? Is `payload` the share encryption and then other goop? (Reading on, that does seem to be the case. I'm not sure how we'd  clarify that now.)",
              "createdAt": "2021-04-22T19:51:58Z",
              "updatedAt": "2021-04-23T21:13:15Z"
            },
            {
              "originalPosition": 217,
              "body": "What happens if this is not the case? Would it be better to just have a list of (share, payload) tuple in `PAVerifyStartReq`?",
              "createdAt": "2021-04-22T19:53:10Z",
              "updatedAt": "2021-04-23T21:13:15Z"
            },
            {
              "originalPosition": 262,
              "body": "It also requires the leader to maintain a mapping between shares and messages it sent to the helper. That sort of state seems error prone to manage. Hmm... could this message indicate specifically which shares should be re-sent, if any?\r\n\r\nAlso, I wonder if we should even make this an option. State management is hard enough as-is, so perhaps requiring just one entity to do it is better than possibly allowing others to do it?",
              "createdAt": "2021-04-22T19:55:56Z",
              "updatedAt": "2021-04-23T21:13:15Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjQyNjg5NTMy",
          "commit": {
            "abbreviatedOid": "620c88f"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-04-22T21:40:04Z",
          "updatedAt": "2021-04-22T21:40:04Z",
          "comments": [
            {
              "originalPosition": 35,
              "body": "Yup. Changed to \"The client and leader can establish a leader-authenticated TLS channel.\"",
              "createdAt": "2021-04-22T21:40:04Z",
              "updatedAt": "2021-04-23T21:13:15Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjQyNjkwMDU0",
          "commit": {
            "abbreviatedOid": "620c88f"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-04-22T21:40:55Z",
          "updatedAt": "2021-04-22T21:40:56Z",
          "comments": [
            {
              "originalPosition": 59,
              "body": "What's a \"forward reference\"?",
              "createdAt": "2021-04-22T21:40:56Z",
              "updatedAt": "2021-04-23T21:13:15Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjQyNzA0Mzgz",
          "commit": {
            "abbreviatedOid": "620c88f"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-04-22T21:53:13Z",
          "updatedAt": "2021-04-22T21:53:14Z",
          "comments": [
            {
              "originalPosition": 87,
              "body": "It is, removed.",
              "createdAt": "2021-04-22T21:53:13Z",
              "updatedAt": "2021-04-23T21:13:15Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjQyNzA1ODEw",
          "commit": {
            "abbreviatedOid": "620c88f"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-04-22T21:54:31Z",
          "updatedAt": "2021-04-22T21:54:31Z",
          "comments": [
            {
              "originalPosition": 107,
              "body": "It's not the same struct, so they're not related. We (Cloudflare) wouldn't use our ECHConfig for this purpose, if that's what you're asking. ",
              "createdAt": "2021-04-22T21:54:31Z",
              "updatedAt": "2021-04-23T21:13:15Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjQyNzMzNDI5",
          "commit": {
            "abbreviatedOid": "620c88f"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-04-22T22:14:12Z",
          "updatedAt": "2021-04-22T22:14:12Z",
          "comments": [
            {
              "originalPosition": 74,
              "body": "I think it should be a GET here. Specified this here and elsewhere.",
              "createdAt": "2021-04-22T22:14:12Z",
              "updatedAt": "2021-04-23T21:13:15Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjQyNzM0MzA4",
          "commit": {
            "abbreviatedOid": "620c88f"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-04-22T22:14:39Z",
          "updatedAt": "2021-04-22T22:14:40Z",
          "comments": [
            {
              "originalPosition": 85,
              "body": "200. Specified here and elsewhere.",
              "createdAt": "2021-04-22T22:14:39Z",
              "updatedAt": "2021-04-23T21:13:15Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjQyNzM1Nzgy",
          "commit": {
            "abbreviatedOid": "620c88f"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-04-22T22:15:39Z",
          "updatedAt": "2021-04-22T22:15:39Z",
          "comments": [
            {
              "originalPosition": 45,
              "body": "Didn't seem necessary here, but I don't mind adding it.",
              "createdAt": "2021-04-22T22:15:39Z",
              "updatedAt": "2021-04-23T21:13:15Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjQyNzM5ODMz",
          "commit": {
            "abbreviatedOid": "620c88f"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-04-22T22:22:26Z",
          "updatedAt": "2021-04-22T22:22:27Z",
          "comments": [
            {
              "originalPosition": 110,
              "body": "Good catch, added AEAD code point to key config",
              "createdAt": "2021-04-22T22:22:26Z",
              "updatedAt": "2021-04-23T21:13:15Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjQyNzQ0NDY5",
          "commit": {
            "abbreviatedOid": "620c88f"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-04-22T22:31:59Z",
          "updatedAt": "2021-04-22T22:32:00Z",
          "comments": [
            {
              "originalPosition": 165,
              "body": "Ah, good call.",
              "createdAt": "2021-04-22T22:31:59Z",
              "updatedAt": "2021-04-23T21:13:15Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjQyNzQ1MjQ2",
          "commit": {
            "abbreviatedOid": "620c88f"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-04-22T22:33:36Z",
          "updatedAt": "2021-04-22T22:33:37Z",
          "comments": [
            {
              "originalPosition": 165,
              "body": "Actually it's better if the config id is not in the `PAHelperShare`. This struct is reused in the `PAVerifyStartReq` message, and there a single config id is used for several helper shares.",
              "createdAt": "2021-04-22T22:33:36Z",
              "updatedAt": "2021-04-23T21:13:15Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjQyNzQ2Mjgw",
          "commit": {
            "abbreviatedOid": "620c88f"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-04-22T22:35:50Z",
          "updatedAt": "2021-04-22T22:35:51Z",
          "comments": [
            {
              "originalPosition": 146,
              "body": "As we discussed today, some PA protocols (like Prio) might derive an HPKE context, export a PRG seed, and use that seed for secret sharing. Others (like HH) might secret share first, then encrypt.",
              "createdAt": "2021-04-22T22:35:51Z",
              "updatedAt": "2021-04-23T21:13:15Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjQyNzQ3MDc5",
          "commit": {
            "abbreviatedOid": "620c88f"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-04-22T22:37:16Z",
          "updatedAt": "2021-04-22T22:37:17Z",
          "comments": [
            {
              "originalPosition": 131,
              "body": "I suppose the PAUploads could be sent in the same POST request. This seemed easier to implement. Besides, the leader will never share state between the individual runs.",
              "createdAt": "2021-04-22T22:37:16Z",
              "updatedAt": "2021-04-23T21:13:15Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjQyNzQ5NTQ0",
          "commit": {
            "abbreviatedOid": "620c88f"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-04-22T22:42:35Z",
          "updatedAt": "2021-04-22T22:42:35Z",
          "comments": [
            {
              "originalPosition": 178,
              "body": "Hmm, that's an interesting suggestion. I'm leaning towards \"no\" because the leader is permitted to batch a bunch of verify-start requests. This might cause latency that the client would notice. Besides, there's no reason to wait, since the client doesn't care if its shares were deemed valid.",
              "createdAt": "2021-04-22T22:42:35Z",
              "updatedAt": "2021-04-23T21:13:15Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjQyNzU0MTMw",
          "commit": {
            "abbreviatedOid": "620c88f"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-04-22T22:52:49Z",
          "updatedAt": "2021-04-22T22:52:50Z",
          "comments": [
            {
              "originalPosition": 162,
              "body": "~Done, but I called the inner struct `PAHelperShare`.~ Eh, actually I want to keep it as-is. For this 'cut-and-paste' trick to work, you need to stick the key config id in the helper share. But in the verify start request message, there are a bunch of helper shares that all correspond to the same key config id.",
              "createdAt": "2021-04-22T22:52:49Z",
              "updatedAt": "2021-04-23T21:13:15Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjQyNzY4Mzk3",
          "commit": {
            "abbreviatedOid": "620c88f"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-04-22T23:21:30Z",
          "updatedAt": "2021-04-22T23:21:30Z",
          "comments": [
            {
              "originalPosition": 194,
              "body": "Done.",
              "createdAt": "2021-04-22T23:21:30Z",
              "updatedAt": "2021-04-23T21:13:15Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjQyNzY5OTE5",
          "commit": {
            "abbreviatedOid": "0780ef2"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-04-22T23:25:38Z",
          "updatedAt": "2021-04-22T23:25:39Z",
          "comments": [
            {
              "originalPosition": 185,
              "body": "Done.",
              "createdAt": "2021-04-22T23:25:38Z",
              "updatedAt": "2021-04-23T21:13:15Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjQyNjY0MDU2",
          "commit": {
            "abbreviatedOid": "620c88f"
          },
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-04-22T21:01:57Z",
          "updatedAt": "2021-04-22T23:26:47Z",
          "comments": [
            {
              "originalPosition": 35,
              "body": "The client also needs a root certificate that can authenticate all the helpers, so that the HPKE parameters can be fetched.",
              "createdAt": "2021-04-22T21:01:57Z",
              "updatedAt": "2021-04-23T21:13:15Z"
            },
            {
              "originalPosition": 65,
              "body": "```suggestion\r\n[[NOTE: `PAParameters.task.id` is a 64-bit integer because it may be useful for\r\n```",
              "createdAt": "2021-04-22T21:07:18Z",
              "updatedAt": "2021-04-23T21:13:15Z"
            },
            {
              "originalPosition": 74,
              "body": "Presumably a single leader could be participating in many different deployments using different parameters, so this request needs a task ID (as in, `PAParam.task.id`) parameter (which could be an HTTP header or a query or path fragment in the URI) to specify which deployment is being asked about.",
              "createdAt": "2021-04-22T21:10:27Z",
              "updatedAt": "2021-04-23T21:13:15Z"
            },
            {
              "originalPosition": 117,
              "body": "```suggestion\r\nset up a base-mode HPKE context to use to derive symmetric keys with which to protect the shares sent to the helper\r\nvia the leader.\r\n```",
              "createdAt": "2021-04-22T21:14:09Z",
              "updatedAt": "2021-04-23T21:13:15Z"
            },
            {
              "originalPosition": 122,
              "body": "Does this specifically refer to when the client does an HTTP GET to obtain HPKE parameters from the helper?",
              "createdAt": "2021-04-22T21:16:53Z",
              "updatedAt": "2021-04-23T21:13:15Z"
            },
            {
              "originalPosition": 131,
              "body": "+1 to this. It also helps with idempotency if clients can upload all the input shares in a single HTTP request as opposed to having to track retries across _n_ requests to _n_ helpers.",
              "createdAt": "2021-04-22T21:21:11Z",
              "updatedAt": "2021-04-23T21:13:15Z"
            },
            {
              "originalPosition": 33,
              "body": "There should be a definition of \"helper\" in the glossary.",
              "createdAt": "2021-04-22T21:51:42Z",
              "updatedAt": "2021-04-23T21:13:15Z"
            },
            {
              "originalPosition": 37,
              "body": "What is the scope of an HPKE key pair? Does the helper use a single HPKE key for all deployments it participates in, or one per `PATask`?\r\n\r\nIf a helper has a single HPKE key pair across all `PATask`s (which makes sense to me if we think of the HPKE pub as analogous to a TLS server's certificate), then I think we should specify that `PAParam.task.id` gets used as a label in the HPKE KDF to ensure keys aren't re-used across `PATask`s.",
              "createdAt": "2021-04-22T22:00:16Z",
              "updatedAt": "2021-04-23T21:13:15Z"
            },
            {
              "originalPosition": 97,
              "body": "Similarly to `[leader]/parameters` this needs a parameter for task ID.",
              "createdAt": "2021-04-22T22:02:02Z",
              "updatedAt": "2021-04-23T21:13:15Z"
            },
            {
              "originalPosition": 49,
              "body": "```suggestion\r\n} PAServerParam;\r\n```\r\nfor symmetry with `PAClientParam`.",
              "createdAt": "2021-04-22T22:09:41Z",
              "updatedAt": "2021-04-23T21:13:15Z"
            },
            {
              "originalPosition": 105,
              "body": "What value should be used when not encrypting helper shares (e.g. the Prio case where HPKE is used only to derive a PRNG seed shared between client and helper)? [`0xFFFF`/Export Only?](https://www.ietf.org/archive/id/draft-irtf-cfrg-hpke-08.html#section-7.3)",
              "createdAt": "2021-04-22T22:20:25Z",
              "updatedAt": "2021-04-23T21:13:15Z"
            },
            {
              "originalPosition": 103,
              "body": "Should this be \"Used by client to decide if it recognizes this config\"? Does this identifier refer to some list of well known HPKEKeyConfigs?",
              "createdAt": "2021-04-22T22:23:42Z",
              "updatedAt": "2021-04-23T21:13:15Z"
            },
            {
              "originalPosition": 124,
              "body": "```suggestion\r\n* the key config specifies a KEM, KDF or AEAD algorithm the client doesn't recognize.\r\n```",
              "createdAt": "2021-04-22T22:24:09Z",
              "updatedAt": "2021-04-23T21:13:15Z"
            },
            {
              "originalPosition": 103,
              "body": "Oh I get it now -- the client is meant to echo this value back into `PAUpload` so that helper can later reject shares that use algos helper doesn't recognize. I think this comment could be made more clear.",
              "createdAt": "2021-04-22T22:26:03Z",
              "updatedAt": "2021-04-23T21:13:15Z"
            },
            {
              "originalPosition": 167,
              "body": "IIUC, in the Prio case, there won't be an encrypted share because the helper's shares are recomputed from a PRNG seed derived from the HPKE context. So what goes in this message field in that case? Empty string?",
              "createdAt": "2021-04-22T22:28:32Z",
              "updatedAt": "2021-04-23T21:13:15Z"
            },
            {
              "originalPosition": 178,
              "body": "I think the answer is no, because we expect the leader to be getting _lots_ of input submissions from clients (e.g., millions, billions of installations of Firefox or Chrome periodically uploading telemetry). If helpers are on the hot path of input submission, then helpers are subject to the same availability and performance requirements as leaders, which I think negates one of the main advantages of the leader design.",
              "createdAt": "2021-04-22T22:32:45Z",
              "updatedAt": "2021-04-23T21:13:15Z"
            },
            {
              "originalPosition": 198,
              "body": "Farther down, we state\r\n>Note that a well-formed message contains as many payloads as shares\r\n\r\nSo should both `shares` and `payloads` be `0..2^24-1` (or `0..2^16-1`)?",
              "createdAt": "2021-04-22T22:34:36Z",
              "updatedAt": "2021-04-23T21:13:15Z"
            },
            {
              "originalPosition": 40,
              "body": "We should have a reference to https://tools.ietf.org/html/rfc8446#section-3 somewhere in here",
              "createdAt": "2021-04-22T22:39:54Z",
              "updatedAt": "2021-04-23T21:13:15Z"
            },
            {
              "originalPosition": 137,
              "body": "include a reference to https://www.ietf.org/archive/id/draft-irtf-cfrg-hpke-08.html#name-encryption-to-a-public-key, where I assume `SetupBaseS` comes from",
              "createdAt": "2021-04-22T22:45:08Z",
              "updatedAt": "2021-04-23T21:13:15Z"
            },
            {
              "originalPosition": 193,
              "body": "Is the entire `PATask` structure needed here or just the unique identifier so that helpers can look it up in the list of tasks they know about?",
              "createdAt": "2021-04-22T22:57:10Z",
              "updatedAt": "2021-04-23T21:13:15Z"
            },
            {
              "originalPosition": 198,
              "body": "The use of \"payload\" here is confusing. Aren't the shares the payload? I'm also not clear on why there is a unique `{Prio|Hits}VerifyStartReq` for each `PAHelperShare`. Would `PrioVerifyStartReq` contain the random value used for the polynomial identity test?",
              "createdAt": "2021-04-22T23:03:57Z",
              "updatedAt": "2021-04-23T21:13:15Z"
            },
            {
              "originalPosition": 210,
              "body": "\"share\" vs. \"payload\" is confusing in these lines.",
              "createdAt": "2021-04-22T23:05:21Z",
              "updatedAt": "2021-04-23T21:13:15Z"
            },
            {
              "originalPosition": 224,
              "body": "Looks where? I think the idea is that each helper maintains a list of `PAParam`s it is aware of and participating in?",
              "createdAt": "2021-04-22T23:06:18Z",
              "updatedAt": "2021-04-23T21:13:15Z"
            },
            {
              "originalPosition": 44,
              "body": "Is there a 1:1 relationship between `PAParam` and `PATask`? I think yes, since participants need to be able to use a task ID to look up a `PAParam` value.",
              "createdAt": "2021-04-22T23:08:16Z",
              "updatedAt": "2021-04-23T21:13:15Z"
            },
            {
              "originalPosition": 262,
              "body": "One way or the other, I don't think `resend_shares` is an attribute of an individual `PAVerifyStartResp`. A helper server either has storage or not and so would presumably always send the same value of `resend_shares`. Should this be part of the `PATask` or `PAParam` that the leader and all helpers have to agree upon before the protocol starts?",
              "createdAt": "2021-04-22T23:11:07Z",
              "updatedAt": "2021-04-23T21:13:15Z"
            },
            {
              "originalPosition": 302,
              "body": "```suggestion\r\n`PAVerifyFinishReq.key_config_id`. If not found, then it aborts and alerts the\r\n```",
              "createdAt": "2021-04-22T23:13:57Z",
              "updatedAt": "2021-04-23T21:13:15Z"
            },
            {
              "originalPosition": 272,
              "body": "IIUC, the leader will run the FLPCP `decide` algorithm for the input using the `PAVerifyStartResp` messages it gathers from helpers, and the verify finish step means informing the helper(s) of the results of `decide`?",
              "createdAt": "2021-04-22T23:20:56Z",
              "updatedAt": "2021-04-23T21:13:15Z"
            },
            {
              "originalPosition": 278,
              "body": "If this is empty then I think you still need a list of share unique identifiers so that helper knows how to resolve the list of `{Prio|Hits}VerifyFinishReq` messages it gets against the shares it has stored.",
              "createdAt": "2021-04-22T23:21:59Z",
              "updatedAt": "2021-04-23T21:13:15Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjQyNzk3OTYz",
          "commit": {
            "abbreviatedOid": "0780ef2"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-04-23T00:20:01Z",
          "updatedAt": "2021-04-23T00:20:01Z",
          "comments": [
            {
              "originalPosition": 212,
              "body": "Yes that's the case. `PAVerifyStartREq.shares` should be `PAVerifyStartReq.payloads` here.",
              "createdAt": "2021-04-23T00:20:01Z",
              "updatedAt": "2021-04-23T21:13:15Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjQyNzk4OTkx",
          "commit": {
            "abbreviatedOid": "0780ef2"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-04-23T00:23:03Z",
          "updatedAt": "2021-04-23T00:23:03Z",
          "comments": [
            {
              "originalPosition": 217,
              "body": "That seemed tricky to do in TLS syntax, particularly because we need to select the type of `payload` on `task.proto`. I'm open to suggestions for how to spell this differently. In the meantime, I added a TODO below explaining that this would be better as a sequence of (share, payload) tuples.",
              "createdAt": "2021-04-23T00:23:03Z",
              "updatedAt": "2021-04-23T21:13:15Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjQyODAwODAw",
          "commit": {
            "abbreviatedOid": "0780ef2"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-04-23T00:28:18Z",
          "updatedAt": "2021-04-23T00:28:19Z",
          "comments": [
            {
              "originalPosition": 262,
              "body": "To clarify why this bit exists: the helper shares may be so big that the leader and helper agree to use state rather than have to retransmit them. If set, then the leader is supposed to retransmit *all* of the shares.\r\n\r\n> It also requires the leader to maintain a mapping between shares and messages it sent to the helper. That sort of state seems error prone to manage. Hmm... could this message indicate specifically which shares should be re-sent, if any?\r\n\r\nThe intention is that the leader needs to re-send *all* of the shares if the bit is true, or *none* if the bit is false. I don't think we should bother with supporting anything in the middle.\r\n\r\n\r\n> Also, I wonder if we should even make this an option. State management is hard enough as-is, so perhaps requiring just one entity to do it is better than possibly allowing others to do it?\r\n\r\nShares are likely to be fairly large, especially for heavy hitters. I think this is going to need to be an option.\r\n\r\n\r\n",
              "createdAt": "2021-04-23T00:28:18Z",
              "updatedAt": "2021-04-23T21:13:15Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjQyODAxMTUx",
          "commit": {
            "abbreviatedOid": "0780ef2"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-04-23T00:29:16Z",
          "updatedAt": "2021-04-23T00:29:17Z",
          "comments": [
            {
              "originalPosition": 262,
              "body": "> One way or the other, I don't think `resend_shares` is an attribute of an individual `PAVerifyStartResp`. A helper server either has storage or not and so would presumably always send the same value of `resend_shares`. Should this be part of the `PATask` or `PAParam` that the leader and all helpers have to agree upon before the protocol starts?\r\n\r\nThat is an option, though the bit is more deployment-specific rather than protocol-specific, which is why I put it in the high level message.",
              "createdAt": "2021-04-23T00:29:16Z",
              "updatedAt": "2021-04-23T21:13:15Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjQyODAxNDY5",
          "commit": {
            "abbreviatedOid": "0780ef2"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-04-23T00:30:05Z",
          "updatedAt": "2021-04-23T00:30:06Z",
          "comments": [
            {
              "originalPosition": 35,
              "body": "That's what the next line says. (See updated text.)",
              "createdAt": "2021-04-23T00:30:06Z",
              "updatedAt": "2021-04-23T21:13:15Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjQyODAyMzIx",
          "commit": {
            "abbreviatedOid": "0780ef2"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-04-23T00:32:40Z",
          "updatedAt": "2021-04-23T00:32:40Z",
          "comments": [
            {
              "originalPosition": 74,
              "body": "The task id is presumably encoded by the string `[leader]`.",
              "createdAt": "2021-04-23T00:32:40Z",
              "updatedAt": "2021-04-23T21:13:15Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjQyODA0Nzc4",
          "commit": {
            "abbreviatedOid": "0780ef2"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-04-23T00:34:23Z",
          "updatedAt": "2021-04-23T00:34:24Z",
          "comments": [
            {
              "originalPosition": 122,
              "body": "This refers to the TLS channel between client and helper.",
              "createdAt": "2021-04-23T00:34:24Z",
              "updatedAt": "2021-04-23T21:13:15Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjQyODEwNDQ1",
          "commit": {
            "abbreviatedOid": "0780ef2"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-04-23T00:37:59Z",
          "updatedAt": "2021-04-23T00:37:59Z",
          "comments": [
            {
              "originalPosition": 37,
              "body": "> What is the scope of an HPKE key pair? Does the helper use a single HPKE key for all deployments it participates in, or one per `PATask`?\r\n\r\nThat's up to the deployment I think.\r\n\r\n> If a helper has a single HPKE key pair across all `PATask`s (which makes sense to me if we think of the HPKE pub as analogous to a TLS server's certificate), then I think we should specify that `PAParam.task.id` gets used as a label in the HPKE KDF to ensure keys aren't re-used across `PATask`s.\r\n\r\nIt does! The context is computed as `SetupBaseR(share.enc, sk, PAParam.task)`\r\n\r\n",
              "createdAt": "2021-04-23T00:37:59Z",
              "updatedAt": "2021-04-23T21:13:15Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjQyODExNTk0",
          "commit": {
            "abbreviatedOid": "0780ef2"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-04-23T00:38:45Z",
          "updatedAt": "2021-04-23T00:38:46Z",
          "comments": [
            {
              "originalPosition": 40,
              "body": "That's premature. We may end up re-doing the encoding for #30.",
              "createdAt": "2021-04-23T00:38:45Z",
              "updatedAt": "2021-04-23T21:13:15Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjQyODEyNjgz",
          "commit": {
            "abbreviatedOid": "0780ef2"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-04-23T00:39:27Z",
          "updatedAt": "2021-04-23T00:39:28Z",
          "comments": [
            {
              "originalPosition": 44,
              "body": "~Not necessarily. In any case, `PATask` is supposed to encode what's common between `PAParam` and `PAClientParam`.~",
              "createdAt": "2021-04-23T00:39:27Z",
              "updatedAt": "2021-04-23T21:13:15Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjQyODE0NzE4",
          "commit": {
            "abbreviatedOid": "0780ef2"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-04-23T00:41:02Z",
          "updatedAt": "2021-04-23T00:41:03Z",
          "comments": [
            {
              "originalPosition": 49,
              "body": "In fact, the symmetric name would be `PAAggregatorParam`. I have a weak preference for `PAParam` because it's less wordy.",
              "createdAt": "2021-04-23T00:41:02Z",
              "updatedAt": "2021-04-23T21:13:15Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjQyODE5NTc5",
          "commit": {
            "abbreviatedOid": "0780ef2"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-04-23T00:44:23Z",
          "updatedAt": "2021-04-23T00:44:24Z",
          "comments": [
            {
              "originalPosition": 103,
              "body": "I removed the comment and added some clarification in the paragraph below.",
              "createdAt": "2021-04-23T00:44:23Z",
              "updatedAt": "2021-04-23T21:13:15Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjQyODIwNDQ3",
          "commit": {
            "abbreviatedOid": "0780ef2"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-04-23T00:44:58Z",
          "updatedAt": "2021-04-23T00:44:59Z",
          "comments": [
            {
              "originalPosition": 105,
              "body": "Yup.",
              "createdAt": "2021-04-23T00:44:58Z",
              "updatedAt": "2021-04-23T21:13:15Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjQyODI2MTA1",
          "commit": {
            "abbreviatedOid": "0780ef2"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-04-23T00:48:44Z",
          "updatedAt": "2021-04-23T00:48:44Z",
          "comments": [
            {
              "originalPosition": 167,
              "body": "For Prio, `PAHelperShare.payload` will be the empty string.",
              "createdAt": "2021-04-23T00:48:44Z",
              "updatedAt": "2021-04-23T21:13:15Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjQyODI3NjY1",
          "commit": {
            "abbreviatedOid": "0780ef2"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-04-23T00:49:46Z",
          "updatedAt": "2021-04-23T00:49:46Z",
          "comments": [
            {
              "originalPosition": 193,
              "body": "`task` also specifies the version (of this document) and the PA protocol (\"prio\" or \"hits\"). This info is needed in order to parse the rest of the message.",
              "createdAt": "2021-04-23T00:49:46Z",
              "updatedAt": "2021-04-23T21:13:15Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjQyODI5NTc4",
          "commit": {
            "abbreviatedOid": "0780ef2"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-04-23T00:51:05Z",
          "updatedAt": "2021-04-23T00:51:05Z",
          "comments": [
            {
              "originalPosition": 198,
              "body": "Shares might be big, but I don't think the corresponding protocol message will be big. Hence U24 for the former and U16 for the latter. For consistency, we could do U24 for both. I'm agnostic. (This may also change when we pin down a solution for #30.)",
              "createdAt": "2021-04-23T00:51:05Z",
              "updatedAt": "2021-04-23T21:13:15Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjQyODMyOTkx",
          "commit": {
            "abbreviatedOid": "0780ef2"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-04-23T00:53:29Z",
          "updatedAt": "2021-04-23T00:53:30Z",
          "comments": [
            {
              "originalPosition": 198,
              "body": "Right, `PrioVerifyStartReq` and `HItsVerifyStartReq` carries the protocol-specific stuff, e.g., the random value input to `query` in the context of Prio.",
              "createdAt": "2021-04-23T00:53:29Z",
              "updatedAt": "2021-04-23T21:13:15Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjQyODM2ODcz",
          "commit": {
            "abbreviatedOid": "0780ef2"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-04-23T00:56:07Z",
          "updatedAt": "2021-04-23T00:56:08Z",
          "comments": [
            {
              "originalPosition": 210,
              "body": "\"share\" is the thing that is encrypted and contains the input and proof share; \"payload\" is whatever else is needed by the helper in the next step. The reason these are separate is because the \"share\" is copied verbatim from the client's upload request, and the \"payload\" is generated by the leader.",
              "createdAt": "2021-04-23T00:56:07Z",
              "updatedAt": "2021-04-23T21:13:15Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjQyODM3MDg0",
          "commit": {
            "abbreviatedOid": "0780ef2"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-04-23T00:56:48Z",
          "updatedAt": "2021-04-23T00:56:49Z",
          "comments": [
            {
              "originalPosition": 224,
              "body": "Yup, that's the idea.",
              "createdAt": "2021-04-23T00:56:49Z",
              "updatedAt": "2021-04-23T21:13:15Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjQyODM3MjU4",
          "commit": {
            "abbreviatedOid": "0780ef2"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-04-23T00:57:22Z",
          "updatedAt": "2021-04-23T00:57:23Z",
          "comments": [
            {
              "originalPosition": 272,
              "body": "Yes.",
              "createdAt": "2021-04-23T00:57:23Z",
              "updatedAt": "2021-04-23T21:13:15Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjQyODM4MDQ4",
          "commit": {
            "abbreviatedOid": "0780ef2"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-04-23T00:59:54Z",
          "updatedAt": "2021-04-23T00:59:54Z",
          "comments": [
            {
              "originalPosition": 278,
              "body": "That seems like a lot of overhead that's not really necessary. It should be clear that the first element of `payloads` corresponds to the first share, the second element of `payloads` to the second share, and so on. This should be fairly straightforward if the helper is already maintaining state.",
              "createdAt": "2021-04-23T00:59:54Z",
              "updatedAt": "2021-04-23T21:13:15Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjQyODM5ODIx",
          "commit": {
            "abbreviatedOid": "f6b7589"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "Thanks, all, for your comments! I've tried to address them all... several remain unresolved.\r\n\r\nOne area of confusion and which we don't quite agree is the `resend_shares` flag in the verify start response. This allows the leader and helper to avoid retransmitting the shares, as long as the helper is able to maintain state between requests. This is helpful if the shares are really big. I don't think we have a use case with really big shares yet, so I'd be fine with just dropping this flag and having the leader always retransmit the shares. However, I think we want to keep this option in our back pocket.\r\n\r\nAlso, @ekr, at this stage I'm not trying to be overly formal with the spec. My goal is to describe the protocol in enough detail that we all basically know what's going on and we can start working on an implementation. There are also some open questions, which preclude a more formal description. That said, I did make an effort to be more clear about what's a POST and what's a GET, as well as the response status for each HTTP request.",
          "createdAt": "2021-04-23T01:05:10Z",
          "updatedAt": "2021-04-23T01:21:10Z",
          "comments": []
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjQyODQ0NzEx",
          "commit": {
            "abbreviatedOid": "f6b7589"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-04-23T01:19:56Z",
          "updatedAt": "2021-04-23T01:19:56Z",
          "comments": [
            {
              "originalPosition": 44,
              "body": "OH wait, I misunderstood. Yes, there's 1:1 map.",
              "createdAt": "2021-04-23T01:19:56Z",
              "updatedAt": "2021-04-23T21:13:15Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjQzNjMxOTUz",
          "commit": {
            "abbreviatedOid": "5d2a6ad"
          },
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "With the understanding that we still need to specify lots of details about message encoding and HTTP semantics, this looks good to me. Thanks Chris!",
          "createdAt": "2021-04-23T20:11:40Z",
          "updatedAt": "2021-04-23T20:21:44Z",
          "comments": [
            {
              "originalPosition": 4,
              "body": "```suggestion\r\n1. Helper: An aggregator that is not a leader.\r\n```",
              "createdAt": "2021-04-23T20:11:40Z",
              "updatedAt": "2021-04-23T21:13:15Z"
            },
            {
              "originalPosition": 198,
              "body": "Oh, I think I got confused by the notation. I thought `PAHelperShare shares<0..2^24-1>` meant \"between 0 and 2^24-1 `PAHelperShare` structures, but it means `0..2^24-1` bytes.",
              "createdAt": "2021-04-23T20:17:12Z",
              "updatedAt": "2021-04-23T21:13:15Z"
            },
            {
              "originalPosition": 224,
              "body": "I think it'd help to have language explaining that all participants are configured with a list of known `PAParam`s before the start of the discovery or ingestion protocols.",
              "createdAt": "2021-04-23T20:19:06Z",
              "updatedAt": "2021-04-23T21:13:15Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjQzNjY3MjE0",
          "commit": {
            "abbreviatedOid": "5d2a6ad"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-04-23T21:12:02Z",
          "updatedAt": "2021-04-23T21:12:57Z",
          "comments": [
            {
              "originalPosition": 224,
              "body": "Done. (See the changes to the beginning of {{proto-ingestion}}.",
              "createdAt": "2021-04-23T21:12:03Z",
              "updatedAt": "2021-04-23T21:13:15Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjQzNzA1ODcz",
          "commit": {
            "abbreviatedOid": "0e672cb"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-04-23T22:44:05Z",
          "updatedAt": "2021-04-23T22:44:06Z",
          "comments": [
            {
              "originalPosition": 262,
              "body": "Quick follow-up: I'm fine with removing the `resend_shares` bit for simplicity and just require the leader to always resend. We can always add it later if it's needed.",
              "createdAt": "2021-04-23T22:44:06Z",
              "updatedAt": "2021-04-23T22:44:06Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjQzNzA2MTY1",
          "commit": {
            "abbreviatedOid": "0e672cb"
          },
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-04-23T22:45:00Z",
          "updatedAt": "2021-04-23T22:45:00Z",
          "comments": [
            {
              "originalPosition": 262,
              "body": "I think we should err on the side of making the protocol simpler, and hence remove the option. My intuition is that shares should be small for Prio (since there aren't actually shares but rather just a PRNG seed from which shares are derived).",
              "createdAt": "2021-04-23T22:45:00Z",
              "updatedAt": "2021-04-23T22:45:01Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjQ2MDI0MTI5",
          "commit": {
            "abbreviatedOid": "0e672cb"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-04-27T15:38:00Z",
          "updatedAt": "2021-04-27T15:38:01Z",
          "comments": [
            {
              "originalPosition": 262,
              "body": "I plan to remove the bit.",
              "createdAt": "2021-04-27T15:38:00Z",
              "updatedAt": "2021-04-27T15:38:01Z"
            }
          ]
        }
      ]
    },
    {
      "number": 33,
      "id": "MDExOlB1bGxSZXF1ZXN0NjI0NzM4NTg3",
      "title": "Use mdbook to render doc",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/pull/33",
      "state": "MERGED",
      "author": "cjpatton",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "This allows us to use `mdbook` to render the design doc into HTML, as suggested by @acmiyaguchi. To run, do\r\n```\r\ncargo install mdbook\r\nmdbook server\r\n```\r\nThis starts an HTTP server that updates the page each time the source is edited. This makes editing the document much a more pleasant experience, I think.",
      "createdAt": "2021-04-27T23:50:15Z",
      "updatedAt": "2021-06-17T21:15:30Z",
      "baseRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "baseRefName": "main",
      "baseRefOid": "934b48a1119acfb264b213180437794b8241fdc4",
      "headRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "headRefName": "cjpatton/mkbook",
      "headRefOid": "3f1594a2f2d395c05fc9e6f89642751d1de589ea",
      "closedAt": "2021-04-29T17:29:43Z",
      "mergedAt": "2021-04-29T17:29:43Z",
      "mergedBy": "cjpatton",
      "mergeCommit": {
        "oid": "c195673a79cf4665e4df11bf3c5768f0b5644ad9"
      },
      "comments": [],
      "reviews": [
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjQ2NDg2Njk5",
          "commit": {
            "abbreviatedOid": "9674f31"
          },
          "author": "acmiyaguchi",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "I suggest adding a README with the instructions to build/serve the docs. Otherwise it's a good starting point \ud83d\udc4d.",
          "createdAt": "2021-04-27T23:57:29Z",
          "updatedAt": "2021-04-27T23:57:29Z",
          "comments": []
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjQ2NDk1OTQ0",
          "commit": {
            "abbreviatedOid": "8c9d67e"
          },
          "author": "acmiyaguchi",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "",
          "createdAt": "2021-04-28T00:22:26Z",
          "updatedAt": "2021-04-28T00:22:26Z",
          "comments": []
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjQ2NDk2MjM2",
          "commit": {
            "abbreviatedOid": "8c9d67e"
          },
          "author": "acmiyaguchi",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-04-28T00:23:10Z",
          "updatedAt": "2021-04-28T00:23:14Z",
          "comments": [
            {
              "originalPosition": 1,
              "body": "The document is title REAMDE instead of README",
              "createdAt": "2021-04-28T00:23:11Z",
              "updatedAt": "2021-04-29T17:27:54Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjQ2NTA0NDkw",
          "commit": {
            "abbreviatedOid": "8c9d67e"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-04-28T00:38:10Z",
          "updatedAt": "2021-04-28T00:38:10Z",
          "comments": [
            {
              "originalPosition": 1,
              "body": "Ugh, sorry.",
              "createdAt": "2021-04-28T00:38:10Z",
              "updatedAt": "2021-04-29T17:27:54Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjQ4NDY3OTEx",
          "commit": {
            "abbreviatedOid": "b55a223"
          },
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "state": "CHANGES_REQUESTED",
          "body": "",
          "createdAt": "2021-04-29T17:23:59Z",
          "updatedAt": "2021-04-29T17:24:12Z",
          "comments": [
            {
              "originalPosition": 2,
              "body": "Not that I don't appreciate your contributions but could we change this to \"The authors\" or \"The contributors\" or remove it altogether if it's optional?",
              "createdAt": "2021-04-29T17:23:59Z",
              "updatedAt": "2021-04-29T17:27:54Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjQ4NDY4ODcy",
          "commit": {
            "abbreviatedOid": "b55a223"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-04-29T17:25:05Z",
          "updatedAt": "2021-04-29T17:25:06Z",
          "comments": [
            {
              "originalPosition": 2,
              "body": "Oops, that was added auto-magically\r\n",
              "createdAt": "2021-04-29T17:25:06Z",
              "updatedAt": "2021-04-29T17:27:54Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjQ4NDcxMzI3",
          "commit": {
            "abbreviatedOid": "3f1594a"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-04-29T17:27:56Z",
          "updatedAt": "2021-04-29T17:27:57Z",
          "comments": [
            {
              "originalPosition": 2,
              "body": "Done.",
              "createdAt": "2021-04-29T17:27:56Z",
              "updatedAt": "2021-04-29T17:27:57Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjQ4NDcxODE2",
          "commit": {
            "abbreviatedOid": "3f1594a"
          },
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "",
          "createdAt": "2021-04-29T17:28:31Z",
          "updatedAt": "2021-04-29T17:28:31Z",
          "comments": []
        }
      ]
    },
    {
      "number": 34,
      "id": "MDExOlB1bGxSZXF1ZXN0NjI3OTY4NzQy",
      "title": "Doc rework and specification of upload and verify flows",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/pull/34",
      "state": "CLOSED",
      "author": "cjpatton",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "Specifies the upload and verify phases of a PA protocol. In the upload phase, the client uploads a report; in the verify phase, the aggregators verify that their shares correspond to a valid input. These flows apply to both Prio and heavy hitters (\"Hits\"), though the protocol-specific messages in these flows are left unspecified. (We will specify them in future PRs.)\r\n\r\nI've also broken the various sections of the document into separate files so that `mdbook` can create a table of contents.\r\n\r\n**Non-goal for this PR:** This PR is not meant to provide a definitive, formalized \"standard document\". It's meant only to get us one step closer to the final shape of the protocol.\r\n\r\nIssues addressed by this change:\r\n\r\n* Closes #4: In this design, the leader specifies any number of helpers. For each helper, the client initiates a run of the protocol with the leader and the helper. This allows the a helper to drop out without impacting data processing later on. However, the leader cannot drop out. (This seems OK, since this is the same up-time requirement as usual.)\r\n*Addresses #8. In this design, the joint randomness needed for a run of the protocol is picked by the leader and sent to the helpers in the PAVerifyStartReq message.\r\n* Closes #9. In this design, the leader tells the client the URL of each helper. The client gets each helper's public key by making an HTTP request.\r\n* Addresses #18. This PR specifies a high-level flow that should fit the input-validation protocol for heavy hitters.\r\n* Closes #21. Any protocol-specific parameters are carried by the PAClientParam message.\r\n* Addresses #22. In this design, multiple protocol runs are used to add resilience to aggregator drop-out. We still don't know whether we can use threshold secret sharing (i.e., Shamir) for the same purpose. (In any case, this design disallows it.) We should think about whether this works before closing that issue.\r\n",
      "createdAt": "2021-04-30T19:11:51Z",
      "updatedAt": "2021-04-30T21:16:39Z",
      "baseRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "baseRefName": "main",
      "baseRefOid": "c195673a79cf4665e4df11bf3c5768f0b5644ad9",
      "headRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "headRefName": "cjpatton/ingestion",
      "headRefOid": "478fdf435ec66df2f23189a301d6b775446e3189",
      "closedAt": "2021-04-30T20:02:49Z",
      "mergedAt": null,
      "mergedBy": null,
      "mergeCommit": null,
      "comments": [],
      "reviews": [
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjQ5NTcxNTE1",
          "commit": {
            "abbreviatedOid": "478fdf4"
          },
          "author": "acmiyaguchi",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-04-30T19:49:55Z",
          "updatedAt": "2021-04-30T20:56:52Z",
          "comments": [
            {
              "originalPosition": 10,
              "body": "Who assigns this identifier. Are 65k identifiers enough?",
              "createdAt": "2021-04-30T19:49:56Z",
              "updatedAt": "2021-04-30T20:56:52Z"
            },
            {
              "originalPosition": 43,
              "body": "UUIDs may be useful, albeit somewhat large? Also looks like `PAoTask.id` should be `PATask.id`.",
              "createdAt": "2021-04-30T19:52:21Z",
              "updatedAt": "2021-04-30T20:56:52Z"
            },
            {
              "originalPosition": 51,
              "body": "I think the `key_config` request should be broken out into it's own sub-section. ",
              "createdAt": "2021-04-30T20:44:26Z",
              "updatedAt": "2021-04-30T20:56:52Z"
            },
            {
              "originalPosition": 95,
              "body": "Should this be an array of helper shares, if there's more than a single helper?",
              "createdAt": "2021-04-30T20:45:09Z",
              "updatedAt": "2021-04-30T20:56:52Z"
            },
            {
              "originalPosition": 48,
              "body": "Suppose we're dealing with an anonymizing proxy: Is it possible for the parameters to be known ahead of time (e.g. hpke parameters shipped directly into client code) and to omit the first 2 stages of `[leader]/upload_start` and `[helper(s)]/key_config`?",
              "createdAt": "2021-04-30T20:49:52Z",
              "updatedAt": "2021-04-30T20:56:52Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjQ5NjE3NjE3",
          "commit": {
            "abbreviatedOid": "478fdf4"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-04-30T21:01:51Z",
          "updatedAt": "2021-04-30T21:01:51Z",
          "comments": [
            {
              "originalPosition": 10,
              "body": "- Unspecified at this time, though I imagine it'll be the collector that assigns this.\r\n- I'm not sure if 65k is enough (see OPEN ISSUE below).",
              "createdAt": "2021-04-30T21:01:51Z",
              "updatedAt": "2021-04-30T21:01:51Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjQ5NjE4NjUz",
          "commit": {
            "abbreviatedOid": "478fdf4"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-04-30T21:03:41Z",
          "updatedAt": "2021-04-30T21:03:42Z",
          "comments": [
            {
              "originalPosition": 43,
              "body": "+1 to UUID.",
              "createdAt": "2021-04-30T21:03:41Z",
              "updatedAt": "2021-04-30T21:03:42Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjQ5NjE5MDMw",
          "commit": {
            "abbreviatedOid": "478fdf4"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-04-30T21:04:16Z",
          "updatedAt": "2021-04-30T21:04:16Z",
          "comments": [
            {
              "originalPosition": 51,
              "body": "Ack, will do.",
              "createdAt": "2021-04-30T21:04:16Z",
              "updatedAt": "2021-04-30T21:04:17Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjQ5NjE5MzQ5",
          "commit": {
            "abbreviatedOid": "478fdf4"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-04-30T21:04:49Z",
          "updatedAt": "2021-04-30T21:04:50Z",
          "comments": [
            {
              "originalPosition": 95,
              "body": "Actually, there will only be one helper for this message.",
              "createdAt": "2021-04-30T21:04:49Z",
              "updatedAt": "2021-04-30T21:04:50Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjQ5NjIwMDg3",
          "commit": {
            "abbreviatedOid": "478fdf4"
          },
          "author": "acmiyaguchi",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-04-30T21:06:14Z",
          "updatedAt": "2021-04-30T21:06:15Z",
          "comments": [
            {
              "originalPosition": 95,
              "body": "Oh I see, the helper url is set in the message. :+1:",
              "createdAt": "2021-04-30T21:06:15Z",
              "updatedAt": "2021-04-30T21:06:15Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjQ5NjIxNzM0",
          "commit": {
            "abbreviatedOid": "478fdf4"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-04-30T21:09:13Z",
          "updatedAt": "2021-04-30T21:09:13Z",
          "comments": [
            {
              "originalPosition": 48,
              "body": "Yeah, that should be possible for most PA protocols. What's the added value of the anonymizing proxy? Unlinking any metadata, like UA, from the client IP?",
              "createdAt": "2021-04-30T21:09:13Z",
              "updatedAt": "2021-04-30T21:09:13Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjQ5NjI1NDM5",
          "commit": {
            "abbreviatedOid": "478fdf4"
          },
          "author": "acmiyaguchi",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-04-30T21:16:39Z",
          "updatedAt": "2021-04-30T21:16:39Z",
          "comments": [
            {
              "originalPosition": 48,
              "body": "Yeah, unlinking metadata like ip addresses, timestamps, and frequency of requests.\r\n\r\nI was thinking about ingestion services (e.g. the prio-server architecture) and whether it was possible to support that use-case with the http api proposed here. ",
              "createdAt": "2021-04-30T21:16:39Z",
              "updatedAt": "2021-04-30T21:16:39Z"
            }
          ]
        }
      ]
    },
    {
      "number": 35,
      "id": "MDExOlB1bGxSZXF1ZXN0NjI5MjkzMTYw",
      "title": "Port to IETF I-D format",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/pull/35",
      "state": "CLOSED",
      "author": "chris-wood",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "cc @ekr, @cjpatton ",
      "createdAt": "2021-05-03T18:49:45Z",
      "updatedAt": "2021-12-30T02:09:40Z",
      "baseRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "baseRefName": "main",
      "baseRefOid": "c195673a79cf4665e4df11bf3c5768f0b5644ad9",
      "headRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "headRefName": "caw/reformat",
      "headRefOid": "85d1284d7815b5d2ed30848984d64ebd1a479e98",
      "closedAt": "2021-05-03T18:54:19Z",
      "mergedAt": null,
      "mergedBy": null,
      "mergeCommit": null,
      "comments": [
        {
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "body": "(Wow, this was based on a way old version of main!)",
          "createdAt": "2021-05-03T18:54:30Z",
          "updatedAt": "2021-05-03T18:54:30Z"
        }
      ],
      "reviews": []
    },
    {
      "number": 36,
      "id": "MDExOlB1bGxSZXF1ZXN0NjI5MzAxMzI2",
      "title": "Port document and toolchain to IETF I-D format.",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/pull/36",
      "state": "MERGED",
      "author": "chris-wood",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "cc @ekr, @cjpatton ",
      "createdAt": "2021-05-03T19:04:40Z",
      "updatedAt": "2021-12-30T02:09:41Z",
      "baseRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "baseRefName": "main",
      "baseRefOid": "c195673a79cf4665e4df11bf3c5768f0b5644ad9",
      "headRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "headRefName": "caw/i-d-format",
      "headRefOid": "d62a94af619e7f3605b2928cee45a9b30a595e56",
      "closedAt": "2021-05-03T20:25:53Z",
      "mergedAt": "2021-05-03T20:25:53Z",
      "mergedBy": "chris-wood",
      "mergeCommit": {
        "oid": "d40d3893c1112d00cc640c131a075022f90357a3"
      },
      "comments": [
        {
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "body": "FYI, I'll fix the build after this is merged to main. (It might be due to me creating this on a branch that's not main, though I'm not entirely sure.)",
          "createdAt": "2021-05-03T19:07:47Z",
          "updatedAt": "2021-05-03T19:07:47Z"
        }
      ],
      "reviews": [
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjUwNjcxNTcw",
          "commit": {
            "abbreviatedOid": "d62a94a"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "This dumps some text related to choosing parameters for Prio. I need to rework this text anyway, so I'm happy to add it back later.",
          "createdAt": "2021-05-03T19:53:42Z",
          "updatedAt": "2021-05-03T19:53:42Z",
          "comments": []
        }
      ]
    },
    {
      "number": 37,
      "id": "MDExOlB1bGxSZXF1ZXN0NjI5MzU1NzYy",
      "title": "Create .nojekyll",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/pull/37",
      "state": "CLOSED",
      "author": "aaomidi",
      "authorAssociation": "NONE",
      "assignees": [],
      "labels": [],
      "body": "If we're not using jekyll, we should opt out of the github pages stuff for it.",
      "createdAt": "2021-05-03T20:47:08Z",
      "updatedAt": "2021-12-30T02:09:53Z",
      "baseRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "baseRefName": "gh-pages",
      "baseRefOid": "d38d2f153a85ff73a80441e1b9cbefaed97d0edb",
      "headRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "headRefName": "Add-no-jekyll-file-to-gh-pages",
      "headRefOid": "ae5636d4eb9cf52fbbed7ecebf6ca625de4a0399",
      "closedAt": "2021-05-03T20:47:35Z",
      "mergedAt": null,
      "mergedBy": null,
      "mergeCommit": null,
      "comments": [],
      "reviews": []
    },
    {
      "number": 38,
      "id": "MDExOlB1bGxSZXF1ZXN0NjI5MzYyMjE3",
      "title": "Rework overview and add skeleton for other stuff",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/pull/38",
      "state": "MERGED",
      "author": "cjpatton",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "",
      "createdAt": "2021-05-03T20:59:02Z",
      "updatedAt": "2021-06-17T21:15:23Z",
      "baseRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "baseRefName": "main",
      "baseRefOid": "c27740e1e9ba4acd85fae807444d1c3278c3baf2",
      "headRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "headRefName": "cjpatton/upload-verify",
      "headRefOid": "468fff76c34853e555bf94856663a4822f4c8976",
      "closedAt": "2021-05-08T22:38:15Z",
      "mergedAt": "2021-05-08T22:38:15Z",
      "mergedBy": "cjpatton",
      "mergeCommit": {
        "oid": "3b0e4468c79a00c5c20d1228248c8688bfac776a"
      },
      "comments": [
        {
          "author": "ekr",
          "authorAssociation": "COLLABORATOR",
          "body": "That seems fine.\n\n\n\nOn Mon, May 3, 2021 at 4:00 PM Christopher Patton ***@***.***>\nwrote:\n\n> ***@***.**** commented on this pull request.\n> ------------------------------\n>\n> In draft-pda-core.md\n> <https://github.com/abetterinternet/prio-documents/pull/38#discussion_r625418805>\n> :\n>\n> > -particular, a malicious client can corrupt the computation by submitting random\n> -integers instead of a proper secret sharing of a valid input.\n> -\n> -To solve this problem, Prio introduces a light-weight zero-knowledge proof\n> -system designed to operate on secret shared data. In addition to its input\n> -share, each client sends to each aggregator a share of a \"proof\" of the input's\n> -validity. The aggregators use these proof shares in a protocol designed to\n> -establish the input's validity, without leaking the input itself. We describe\n> -this input-validation protocol in detail in [[TODO:citeme]].\n> -\n> -## Assembling Reports\n> +**Hits.**\n> +A common PA task that can't be solved efficiently with Prio is the\n> +`t`-*heavy-hitters* problem {{BBCp21}}. In this setting, each user is in\n> +possession of a single `n`-bit string, and the goal is to compute the compute\n> +the set of strings that occur at least `t` times.\n>\n> How about: One reason Prio isn't applicable to the use case is that the\n> proof that is generated would be huge.\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/abetterinternet/prio-documents/pull/38#discussion_r625418805>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/AAIPLIJ5IQHZLSDXNCN5YB3TL4TKBANCNFSM44BP4QKA>\n> .\n>\n",
          "createdAt": "2021-05-03T23:07:00Z",
          "updatedAt": "2021-05-03T23:07:00Z"
        }
      ],
      "reviews": [
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjUwNzIwMjM0",
          "commit": {
            "abbreviatedOid": "e756234"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-05-03T21:01:07Z",
          "updatedAt": "2021-05-03T21:10:14Z",
          "comments": [
            {
              "originalPosition": 4,
              "body": "This is {{BBCp19}} in the document, referenced by DOI, so maybe we can drop this (or the other) so there aren't duplicates?",
              "createdAt": "2021-05-03T21:01:08Z",
              "updatedAt": "2021-05-08T22:37:50Z"
            },
            {
              "originalPosition": 107,
              "body": "Small = 2?",
              "createdAt": "2021-05-03T21:03:16Z",
              "updatedAt": "2021-05-08T22:37:50Z"
            },
            {
              "originalPosition": 117,
              "body": "```suggestion\r\nThe main cryptographic tool used for achieving this privacy goal is\r\n```",
              "createdAt": "2021-05-03T21:04:11Z",
              "updatedAt": "2021-05-08T22:37:50Z"
            },
            {
              "originalPosition": 207,
              "body": "```suggestion\r\npossession of a single `n`-bit string, and the goal is to compute the compute the set\r\n```",
              "createdAt": "2021-05-03T21:05:38Z",
              "updatedAt": "2021-05-08T22:37:50Z"
            },
            {
              "originalPosition": 229,
              "body": "Can we move these to security considerations? I don't think they're important here.",
              "createdAt": "2021-05-03T21:09:17Z",
              "updatedAt": "2021-05-08T22:37:50Z"
            },
            {
              "originalPosition": 225,
              "body": "```suggestion\r\nprotocol that allows the aggregators to verify that\r\n```\r\n\r\nIn general, I think we ought to try and keep these technical terms in the security considerations where possible.",
              "createdAt": "2021-05-03T21:09:55Z",
              "updatedAt": "2021-05-08T22:37:50Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjUwNzI5MjU4",
          "commit": {
            "abbreviatedOid": "e756234"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-05-03T21:13:59Z",
          "updatedAt": "2021-05-03T21:13:59Z",
          "comments": [
            {
              "originalPosition": 107,
              "body": "Small = O(1). Remember that the plan is to execute the protocol among multiple sets of two servers.",
              "createdAt": "2021-05-03T21:13:59Z",
              "updatedAt": "2021-05-08T22:37:50Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjUwNzMyNzgy",
          "commit": {
            "abbreviatedOid": "e756234"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-05-03T21:19:20Z",
          "updatedAt": "2021-05-03T21:19:21Z",
          "comments": [
            {
              "originalPosition": 229,
              "body": "I disagree.",
              "createdAt": "2021-05-03T21:19:20Z",
              "updatedAt": "2021-05-08T22:37:50Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjUwNzQwNzQ3",
          "commit": {
            "abbreviatedOid": "e756234"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-05-03T21:32:07Z",
          "updatedAt": "2021-05-03T21:32:07Z",
          "comments": [
            {
              "originalPosition": 225,
              "body": "Again, I disagree. \"ZKP\" is no less technical of a term than \"encryption\", which we use freely in this section. It's just that \"ZKP\" is less common.",
              "createdAt": "2021-05-03T21:32:07Z",
              "updatedAt": "2021-05-08T22:37:50Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjUwNzQ2MDI1",
          "commit": {
            "abbreviatedOid": "828c850"
          },
          "author": "ekr",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-05-03T21:41:00Z",
          "updatedAt": "2021-05-03T21:41:56Z",
          "comments": [
            {
              "originalPosition": 229,
              "body": "FWIW, I agree with Wood.  The point here is that there is a proof system that demonstrates validity. The details should go below.\r\n\r\n\r\n\r\n\r\n\r\n",
              "createdAt": "2021-05-03T21:41:00Z",
              "updatedAt": "2021-05-08T22:37:50Z"
            },
            {
              "originalPosition": 225,
              "body": "I would split the difference here and say \"includes a zero-knowledge proof\". That is somewhat less formal than \"zero-knowledge proof system\" and I think clearer in this context.",
              "createdAt": "2021-05-03T21:41:48Z",
              "updatedAt": "2021-05-08T22:37:50Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjUwNzUwMzU3",
          "commit": {
            "abbreviatedOid": "828c850"
          },
          "author": "ekr",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-05-03T21:48:26Z",
          "updatedAt": "2021-05-03T21:48:26Z",
          "comments": [
            {
              "originalPosition": 225,
              "body": "Or, for that matter, \"proof\"",
              "createdAt": "2021-05-03T21:48:26Z",
              "updatedAt": "2021-05-08T22:37:50Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjUwNzUxMjgw",
          "commit": {
            "abbreviatedOid": "828c850"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-05-03T21:50:10Z",
          "updatedAt": "2021-05-03T21:50:10Z",
          "comments": [
            {
              "originalPosition": 107,
              "body": "Yes, I'm aware. My point was that the core protocol runs with s=2 servers.",
              "createdAt": "2021-05-03T21:50:10Z",
              "updatedAt": "2021-05-08T22:37:50Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjUwNzUxNTI2",
          "commit": {
            "abbreviatedOid": "e756234"
          },
          "author": "ekr",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-05-03T21:50:36Z",
          "updatedAt": "2021-05-03T21:50:47Z",
          "comments": [
            {
              "originalPosition": 16,
              "body": "Lightweight,",
              "createdAt": "2021-05-03T21:50:36Z",
              "updatedAt": "2021-05-08T22:37:50Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjUwNzUyMjM0",
          "commit": {
            "abbreviatedOid": "828c850"
          },
          "author": "ekr",
          "authorAssociation": "COLLABORATOR",
          "state": "CHANGES_REQUESTED",
          "body": "",
          "createdAt": "2021-05-03T21:51:48Z",
          "updatedAt": "2021-05-03T21:57:35Z",
          "comments": [
            {
              "originalPosition": 39,
              "body": "```suggestion\r\nthemselves. This is made possible by distributing the computation among the servers in\r\n```",
              "createdAt": "2021-05-03T21:51:49Z",
              "updatedAt": "2021-05-08T22:37:50Z"
            },
            {
              "originalPosition": 54,
              "body": "I would rework this and the previous graf. It's not conventional in specifications to provide this kind of \"in this section, we do X, then in the next section we do Y\". Rather,  we just try to make the specification evolve clearly.",
              "createdAt": "2021-05-03T21:53:23Z",
              "updatedAt": "2021-05-08T22:37:50Z"
            },
            {
              "originalPosition": 106,
              "body": "```suggestion\r\nsecret sharing*. Rather than send its input in the clear, each client splits\r\n```",
              "createdAt": "2021-05-03T21:53:48Z",
              "updatedAt": "2021-05-08T22:37:50Z"
            },
            {
              "originalPosition": 109,
              "body": "```suggestion\r\n- It's impossible to deduce the measurement without knowing *all* of the\r\n```",
              "createdAt": "2021-05-03T21:54:02Z",
              "updatedAt": "2021-05-08T22:37:50Z"
            },
            {
              "originalPosition": 111,
              "body": "```suggestion\r\n- It allows the aggregators to compute the final output by first adding\r\n```\r\n\r\nBulleted lists do not need verbal indices.",
              "createdAt": "2021-05-03T21:54:32Z",
              "updatedAt": "2021-05-08T22:37:50Z"
            },
            {
              "originalPosition": 158,
              "body": "I think we could do without the \"prime field\" bit here. It's not necessary to explain what Prio is for.",
              "createdAt": "2021-05-03T21:55:43Z",
              "updatedAt": "2021-05-08T22:37:50Z"
            },
            {
              "originalPosition": 196,
              "body": "```With Prio, it would be necessary to encode 2^n values, where all but one is zero. This is clearly inefficient.```",
              "createdAt": "2021-05-03T21:56:35Z",
              "updatedAt": "2021-05-08T22:37:50Z"
            },
            {
              "originalPosition": 200,
              "body": "I would not actually talk about DPFs here. These sections should treat the protocols as black boxes.",
              "createdAt": "2021-05-03T21:57:01Z",
              "updatedAt": "2021-05-08T22:37:50Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjUwNzU5MDcx",
          "commit": {
            "abbreviatedOid": "828c850"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-05-03T22:03:57Z",
          "updatedAt": "2021-05-03T22:03:57Z",
          "comments": [
            {
              "originalPosition": 107,
              "body": "Ah, gotcha. I still think \"small set of servers\" is more accurate than \"two servers\" here, since this section is meant to describe the general of case of one leader and multiple helpers.",
              "createdAt": "2021-05-03T22:03:57Z",
              "updatedAt": "2021-05-08T22:37:50Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjUwNzY1NTg0",
          "commit": {
            "abbreviatedOid": "828c850"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-05-03T22:16:43Z",
          "updatedAt": "2021-05-03T22:16:44Z",
          "comments": [
            {
              "originalPosition": 16,
              "body": "Good catch! Thanks.",
              "createdAt": "2021-05-03T22:16:43Z",
              "updatedAt": "2021-05-08T22:37:50Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjUwNzY2OTMz",
          "commit": {
            "abbreviatedOid": "828c850"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-05-03T22:19:35Z",
          "updatedAt": "2021-05-03T22:19:35Z",
          "comments": [
            {
              "originalPosition": 196,
              "body": "Is that true? I believe there's more to it than this. To avoid misleading the reader I would just say less here and let them take it on faith that Prio isn't usable for heavy hitters.",
              "createdAt": "2021-05-03T22:19:35Z",
              "updatedAt": "2021-05-08T22:37:50Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjUwNzY3NTYx",
          "commit": {
            "abbreviatedOid": "828c850"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-05-03T22:20:44Z",
          "updatedAt": "2021-05-03T22:20:44Z",
          "comments": [
            {
              "originalPosition": 200,
              "body": "+1 to not mentioning DPFs.",
              "createdAt": "2021-05-03T22:20:44Z",
              "updatedAt": "2021-05-08T22:37:50Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjUwNzY3OTg0",
          "commit": {
            "abbreviatedOid": "828c850"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-05-03T22:21:37Z",
          "updatedAt": "2021-05-03T22:21:38Z",
          "comments": [
            {
              "originalPosition": 158,
              "body": "What would you put instead?",
              "createdAt": "2021-05-03T22:21:37Z",
              "updatedAt": "2021-05-08T22:37:50Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjUwNzY4Mjg3",
          "commit": {
            "abbreviatedOid": "828c850"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-05-03T22:22:13Z",
          "updatedAt": "2021-05-03T22:22:13Z",
          "comments": [
            {
              "originalPosition": 54,
              "body": "Ack, I'll remove the paragraphs for now.",
              "createdAt": "2021-05-03T22:22:13Z",
              "updatedAt": "2021-05-08T22:37:50Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjUwNzY5OTQ4",
          "commit": {
            "abbreviatedOid": "f7bdcb3"
          },
          "author": "ekr",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-05-03T22:25:29Z",
          "updatedAt": "2021-05-03T22:25:29Z",
          "comments": [
            {
              "originalPosition": 196,
              "body": "Why?",
              "createdAt": "2021-05-03T22:25:29Z",
              "updatedAt": "2021-05-08T22:37:50Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjUwNzcwMTA4",
          "commit": {
            "abbreviatedOid": "f7bdcb3"
          },
          "author": "ekr",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-05-03T22:25:48Z",
          "updatedAt": "2021-05-03T22:25:48Z",
          "comments": [
            {
              "originalPosition": 158,
              "body": "I would remove the entire sentence.",
              "createdAt": "2021-05-03T22:25:48Z",
              "updatedAt": "2021-05-08T22:37:50Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjUwNzcwNjU3",
          "commit": {
            "abbreviatedOid": "f7bdcb3"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-05-03T22:27:00Z",
          "updatedAt": "2021-05-03T22:27:00Z",
          "comments": [
            {
              "originalPosition": 229,
              "body": "I would push back as follows: several weeks ago I had to explain to @ekr that input validation fails to detect an invalid input with non-zero probability, but that this probability could be bounded. In general, this is a property of ZKP systems: the ZKP system is *sound* if verification correctly detects invalid inputs except with small probability. I don't think this is overly technical. Moreover, it's necessary to explain to the reader that input validation may fail. In my view, we might as well just say what the cryptographic technique is. \"Zero-knowlege proof\" is just another thing we use, like \"encryption\" or \"secret sharing\". Why not just say it?",
              "createdAt": "2021-05-03T22:27:00Z",
              "updatedAt": "2021-05-08T22:37:50Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjUwNzczNDcx",
          "commit": {
            "abbreviatedOid": "f7bdcb3"
          },
          "author": "ekr",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-05-03T22:32:53Z",
          "updatedAt": "2021-05-03T22:32:53Z",
          "comments": [
            {
              "originalPosition": 229,
              "body": "Nobody is saying that you don't say it. Rather, we're saying that you should say it *later*, because it's a detail and is not needed to understand the big picture.\r\n\r\nThe more detail you have in this section the harder it is for the reader to get the overall idea.\r\n\r\n\r\n\r\n\r\n",
              "createdAt": "2021-05-03T22:32:53Z",
              "updatedAt": "2021-05-08T22:37:50Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjUwNzczNzg1",
          "commit": {
            "abbreviatedOid": "df23def"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-05-03T22:33:36Z",
          "updatedAt": "2021-05-03T22:33:36Z",
          "comments": [
            {
              "originalPosition": 225,
              "body": "I reworked it to avoid using the word \"system\".",
              "createdAt": "2021-05-03T22:33:36Z",
              "updatedAt": "2021-05-08T22:37:50Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjUwNzczOTEy",
          "commit": {
            "abbreviatedOid": "df23def"
          },
          "author": "ekr",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-05-03T22:33:51Z",
          "updatedAt": "2021-05-03T22:33:51Z",
          "comments": [
            {
              "originalPosition": 196,
              "body": "As with the other text, I think the purpose of this section is to give people the right intuition.\r\n\r\nWhat's misleading about what I said?",
              "createdAt": "2021-05-03T22:33:51Z",
              "updatedAt": "2021-05-08T22:37:50Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjUwNzc5MjMw",
          "commit": {
            "abbreviatedOid": "df23def"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-05-03T22:46:03Z",
          "updatedAt": "2021-05-03T22:46:03Z",
          "comments": [
            {
              "originalPosition": 229,
              "body": "In general, I think there's a danger here of contorting the language so much in order to avoid using \"advanced\" crypto terminology that we confuse the reader.",
              "createdAt": "2021-05-03T22:46:03Z",
              "updatedAt": "2021-05-08T22:37:50Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjUwNzgxMjMy",
          "commit": {
            "abbreviatedOid": "df23def"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-05-03T22:50:43Z",
          "updatedAt": "2021-05-03T22:50:44Z",
          "comments": [
            {
              "originalPosition": 196,
              "body": "There's two things: \r\n1. Instead of \"encode 2^n values\" it would be more accurate to say \"generate a proof of length `O(some_function_of(n))`\". where `some_function_of(.)` depends on the proof strategy. I suppose we could just say \"generate a huge proof\".\r\n2. The \"collect\" step doesn't work the same way. It's not a simple matter of adding up shares; the collector has to interact with the aggregators over several rounds.",
              "createdAt": "2021-05-03T22:50:43Z",
              "updatedAt": "2021-05-08T22:37:50Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjUwNzgxNDYz",
          "commit": {
            "abbreviatedOid": "df23def"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-05-03T22:51:16Z",
          "updatedAt": "2021-05-03T22:51:16Z",
          "comments": [
            {
              "originalPosition": 229,
              "body": "That may be true, but I think Ekr's point is that we want to try and decrease cognitive load on the reader (implementer). They should exactly what they need to know to implement the protocol. Everything else can be described elsewhere!",
              "createdAt": "2021-05-03T22:51:16Z",
              "updatedAt": "2021-05-08T22:37:50Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjUwNzgyMTYz",
          "commit": {
            "abbreviatedOid": "df23def"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-05-03T22:52:48Z",
          "updatedAt": "2021-05-03T22:52:48Z",
          "comments": [
            {
              "originalPosition": 158,
              "body": "That works.",
              "createdAt": "2021-05-03T22:52:48Z",
              "updatedAt": "2021-05-08T22:37:50Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjUwNzgyNzIy",
          "commit": {
            "abbreviatedOid": "df23def"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-05-03T22:53:59Z",
          "updatedAt": "2021-05-03T22:54:00Z",
          "comments": [
            {
              "originalPosition": 196,
              "body": "I think the intuition (\"should I use Prio or HH?\") is good to add here. (@ekr's suggestion seems to clarify the \"this can't be solved efficiently claim\" with a simple example, so I'd support adding it)",
              "createdAt": "2021-05-03T22:53:59Z",
              "updatedAt": "2021-05-08T22:37:50Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjUwNzg0ODA4",
          "commit": {
            "abbreviatedOid": "df23def"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-05-03T22:58:40Z",
          "updatedAt": "2021-05-03T22:58:41Z",
          "comments": [
            {
              "originalPosition": 229,
              "body": "I think implementers are going to have to understand the term \"ZKP\" to the same depth they understand \"encrypt\" or \"secret share\". I'm defining \"ZKP\" here because w'er also defining \"secret sharing\" here. I don't think it makes sense to define one but not the other. They are both equally important at this stage.\r\n\r\nIn any case, this is a purely editorial point. I would suggest one of two paths forward: (1) we punt on this conversation and leave an \"OPEN ISSUE\" for cleaning up the presentation. (We'll have to do this at some point anyway.) (2) remove the text completely and leave a \"TODO\" for describing input validation.",
              "createdAt": "2021-05-03T22:58:40Z",
              "updatedAt": "2021-05-08T22:37:50Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjUwNzg1NjUw",
          "commit": {
            "abbreviatedOid": "df23def"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-05-03T23:00:33Z",
          "updatedAt": "2021-05-03T23:00:34Z",
          "comments": [
            {
              "originalPosition": 196,
              "body": "How about: `One reason Prio isn't applicable to the use case is that the proof that is generated would be huge.`",
              "createdAt": "2021-05-03T23:00:33Z",
              "updatedAt": "2021-05-08T22:37:50Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjUwNzkyMjgy",
          "commit": {
            "abbreviatedOid": "83e2a45"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-05-03T23:16:36Z",
          "updatedAt": "2021-05-03T23:16:36Z",
          "comments": [
            {
              "originalPosition": 196,
              "body": "Done.",
              "createdAt": "2021-05-03T23:16:36Z",
              "updatedAt": "2021-05-08T22:37:51Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjUwNzk0MDY1",
          "commit": {
            "abbreviatedOid": "83e2a45"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-05-03T23:21:27Z",
          "updatedAt": "2021-05-03T23:21:27Z",
          "comments": [
            {
              "originalPosition": 229,
              "body": "Or (3) does someone want to propose alternate text? The things I think are important to convey are (a) that the verification protocol does not leak the secret inputs to the aggregators and (b) the verification protocol may fail to detect invalid inputs with small probability.",
              "createdAt": "2021-05-03T23:21:27Z",
              "updatedAt": "2021-05-08T22:37:51Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjUwNzk3NjU5",
          "commit": {
            "abbreviatedOid": "83e2a45"
          },
          "author": "ekr",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-05-03T23:30:58Z",
          "updatedAt": "2021-05-03T23:30:59Z",
          "comments": [
            {
              "originalPosition": 229,
              "body": "@cjpatton I think we're talking past each other: I agree that this is useful text, I just don't think it belongs *here*.\r\n\r\nThe generic structure of this kind of specification is:\r\n\r\n- Problem statement\r\n- Overview of the solution that just is enough to give people the idea\r\n- Detailed protocol specification\r\n- Security considerations and the like\r\n\r\nThe key idea with point (2) is to be high level. That means avoiding detail which isn't absolutely necessary. In particular, why do we need to tell users at this point that it might fail to detect invalid inputs? They don't need to know that to understand the protocol specification. See https://tools.ietf.org/rfcmarkup?doc=4101 for more on this.",
              "createdAt": "2021-05-03T23:30:58Z",
              "updatedAt": "2021-05-08T22:37:51Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjUwODA3NzM0",
          "commit": {
            "abbreviatedOid": "83e2a45"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-05-03T23:59:17Z",
          "updatedAt": "2021-05-03T23:59:17Z",
          "comments": [
            {
              "originalPosition": 229,
              "body": "> The key idea with point (2) is to be high level. That means avoiding detail which isn't absolutely necessary. In particular, why do we need to tell users at this point that it might fail to detect invalid inputs?\r\n\r\nI guess I don't quite understand what \"absolutely necessary\" means. It's important to know that the input validation protocol can be attacked, since mitigating such attacks is one of the core design criteria for this class of protocols. IMO we have to mention it up front.\r\n\r\nTowards finding common ground, I'm wondering if it's strictly about using the term \"ZKP\"? Wood suggested that I might just be trying to use a fancy crypto term here. I assure you that I'm not. I'm just trying to provide the context one needs to understand the system. Using the term itself is useful because it connects what we're doing to a fairly well-known body of work. I don't want to give people the impression that the crypto herein is one-off.\r\n\r\n> They don't need to know that to understand the protocol specification. See https://tools.ietf.org/rfcmarkup?doc=4101 for more on this.\r\n\r\nSo, up until this point, I haven't been thinking of this document as a formal standard. Based on the feedback I'm getting from you and Wood, it seems like I might need to recalibrate. I thought the goal of this change was merely to get us all on the same page about overall shape of the protocol, not (yet!) to provide a reference for others to implement. It's probably worth working this out in the next design call.\r\n\r\nBy the way, I would love to participate in the task of shaping this into a formal standard. I just didn't think that's what we were doing yet.",
              "createdAt": "2021-05-03T23:59:17Z",
              "updatedAt": "2021-05-08T22:37:51Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjUwODEwNTIw",
          "commit": {
            "abbreviatedOid": "83e2a45"
          },
          "author": "ekr",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-05-04T00:07:25Z",
          "updatedAt": "2021-05-04T00:07:26Z",
          "comments": [
            {
              "originalPosition": 229,
              "body": "I don't care much one way or the other about the term \"zero-knowledge proof\". I think you could say \"proof\" just as well. What I am saying is that your list of properties is unnecessary here. You can just say:\r\n\r\n\"To solve this problem, in each PA protocol, the client generates a\r\n*zero-knowledge proof (ZKP)* of its input's validity, which the aggregators use\r\nto verify that their shares correspond to as valid input.\"\r\n\r\nAnd stop.  Or maybe say \"This proof can be verified without learning the input\".\r\n\r\nYou then move the properties to the Security Considerations. If you must, you can put a pointer to that here. Anyone who knows enough about ZKPs to care about the details can check there, and anyone who doesn't will read the text I have proposed and get substantively the right impression.\r\n\r\n\r\n> Using the term itself is useful because it connects what we're doing to a fairly well-known body of work. I don't want to give people the impression that the crypto herein is one-off.\r\n\r\nThat can be done later in the specification\r\n\r\n> So, up until this point, I haven't been thinking of this document as a formal standard. Based on the feedback I'm getting from you and Wood, it seems like I might need to recalibrate. I thought the goal of this change was merely to get us all on the same page about overall shape of the protocol, not (yet!) to provide a reference for others to implement. It's probably worth working this out in the next design call.\r\n\r\nWell, I don't understand the point of this text at all if it's not targeted at an eventual specification. But yes, I do think this should be an attempt to write down pieces of a specification to use as input into the standards process.\r\n\r\n\r\n\r\n\r\n",
              "createdAt": "2021-05-04T00:07:25Z",
              "updatedAt": "2021-05-08T22:37:51Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjUwODE1ODkz",
          "commit": {
            "abbreviatedOid": "248a0d6"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-05-04T00:24:21Z",
          "updatedAt": "2021-05-04T00:24:22Z",
          "comments": [
            {
              "originalPosition": 229,
              "body": "How's this:\r\n```\r\nTo solve this problem, in each PA protocol, the client generates a\r\nzero-knowledge proof of its input's validity that the aggregators use\r\nto verify that their shares correspond to as valid input. The verification\r\nprocedure is designed to ensure that the aggregators learn nothing about the\r\ninput beyond its validity.\r\n```\r\nTo me it's useful to use the term \"zero-knowledge\" because it signals what's under the hood. If you want I can remove it.\r\n\r\n> Well, I don't understand the point of this text at all if it's not targeted at an eventual specification. But yes, I do think this should be an attempt to write down pieces of a specification to use as input into the standards process.\r\n\r\nOf course that's what we're doing :) I meant more that I don't see why we need to settle on the presentation right now. I'd prefer to focus on the protocol itself and less on how it's presented. I figure that we will need to rework this doc quite a lot before we consider trying to get buy in from the wider community.",
              "createdAt": "2021-05-04T00:24:22Z",
              "updatedAt": "2021-05-08T22:37:51Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjUxNTk4ODE1",
          "commit": {
            "abbreviatedOid": "0c90bb5"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-05-04T19:39:20Z",
          "updatedAt": "2021-05-04T19:39:21Z",
          "comments": [
            {
              "originalPosition": 107,
              "body": "Sounds good!",
              "createdAt": "2021-05-04T19:39:21Z",
              "updatedAt": "2021-05-08T22:37:51Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjUzOTI4MTUw",
          "commit": {
            "abbreviatedOid": "2f8a6c9"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "",
          "createdAt": "2021-05-06T21:56:01Z",
          "updatedAt": "2021-05-06T21:56:01Z",
          "comments": []
        }
      ]
    },
    {
      "number": 40,
      "id": "MDExOlB1bGxSZXF1ZXN0NjI5NDU0OTAw",
      "title": "Fixup gh-pages",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/pull/40",
      "state": "MERGED",
      "author": "martinthomson",
      "authorAssociation": "CONTRIBUTOR",
      "assignees": [],
      "labels": [],
      "body": "No idea if this is going to fix your problems here, but it might.  Something went pretty badly wrong somewhere along the line and this might help fix it.\r\n\r\nThe fallback is to completely remove the branch and start over.  There's a script that you can use for that, but it's pretty scary.",
      "createdAt": "2021-05-04T01:04:04Z",
      "updatedAt": "2021-05-04T02:53:12Z",
      "baseRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "baseRefName": "gh-pages",
      "baseRefOid": "d38d2f153a85ff73a80441e1b9cbefaed97d0edb",
      "headRepository": "martinthomson/prio-documents",
      "headRefName": "gh-pages",
      "headRefOid": "7929b895297cb1632640368a34aebd3d74afd167",
      "closedAt": "2021-05-04T02:53:12Z",
      "mergedAt": "2021-05-04T02:53:12Z",
      "mergedBy": "chris-wood",
      "mergeCommit": {
        "oid": "f617ecc40d5af7e9ac1353a1f594737f748c652b"
      },
      "comments": [
        {
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "body": "Yeah, I tried blowing away gh-pages and trying from scratch. Maybe your fix will stick?",
          "createdAt": "2021-05-04T02:53:09Z",
          "updatedAt": "2021-05-04T02:53:09Z"
        }
      ],
      "reviews": []
    },
    {
      "number": 42,
      "id": "MDExOlB1bGxSZXF1ZXN0NjI5NDU1ODQx",
      "title": "Remove circle config",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/pull/42",
      "state": "MERGED",
      "author": "martinthomson",
      "authorAssociation": "CONTRIBUTOR",
      "assignees": [],
      "labels": [],
      "body": "You don't need it.",
      "createdAt": "2021-05-04T01:07:47Z",
      "updatedAt": "2021-05-04T02:52:20Z",
      "baseRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "baseRefName": "main",
      "baseRefOid": "dd0d113fd6daf2d0fa8d9c9c661bcad2c6dafee8",
      "headRepository": "martinthomson/prio-documents",
      "headRefName": "no-circle",
      "headRefOid": "2387049ae46af503b29ac4aafe0cfa01185ee15a",
      "closedAt": "2021-05-04T02:52:20Z",
      "mergedAt": "2021-05-04T02:52:20Z",
      "mergedBy": "chris-wood",
      "mergeCommit": {
        "oid": "c27740e1e9ba4acd85fae807444d1c3278c3baf2"
      },
      "comments": [],
      "reviews": []
    },
    {
      "number": 43,
      "id": "MDExOlB1bGxSZXF1ZXN0NjMwNjg1NDg1",
      "title": "Specify the upload and verify phases of the PA protocol",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/pull/43",
      "state": "MERGED",
      "author": "cjpatton",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "Based on #38.\r\n\r\n@chris-wood, @ekr ",
      "createdAt": "2021-05-05T15:19:56Z",
      "updatedAt": "2021-06-17T21:15:23Z",
      "baseRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "baseRefName": "main",
      "baseRefOid": "c9b7f30edf33f31979f514a756a8eeeb5fded787",
      "headRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "headRefName": "cjpatton/upload-verify-2",
      "headRefOid": "e962ba20ae6cd49cce87f491022fd33c861a8ef6",
      "closedAt": "2021-06-03T21:18:33Z",
      "mergedAt": "2021-06-03T21:18:33Z",
      "mergedBy": "chris-wood",
      "mergeCommit": {
        "oid": "f928255838517e6254d48d2d3e686da2d8346fa5"
      },
      "comments": [
        {
          "author": "csharrison",
          "authorAssociation": "CONTRIBUTOR",
          "body": "I have a high level concern with the architecture here, following up from our meeting on Wednesday related to heavy hitters.\r\n\r\n**TL;DR evaluating a hierarchy at only a subset of levels (which are specified at query time) is not optimal for performance if the verification step does not have access to those specified levels.**\r\n\r\nFor heavy hitters, we are considering a model where records form a binary tree, where aggregates can be reported at different levels of the tree. There are a few possible ways this could go:\r\n1. For every record, verify and evaluate the entire binary tree (i.e. bit-by-bit evaluation)\r\n2. For every record, verify and evaluate only a subset of the tree (at the limit, this can look more like Prio which only evaluates the last level of the tree)\r\n  2a. The subset of the tree to evaluate is configured within a particular record at record-creation time\r\n  2b. The subset of the tree to evaluate is configured dynamically at _collection / aggregation_ time\r\n\r\nFor our use-case (discussed in https://github.com/abetterinternet/prio-documents/issues/18#issuecomment-801248636), we are interested in (2b), for a few reasons:\r\n- (1) is potentially inefficient from both a performance and accuracy POV in that it requires more rounds, and additionally when used with differential privacy requires splitting a DP budget across all levels. Some prefixes might just not be interesting to the caller so we shouldn't waste privacy budget / compute on them.\r\n- (2a) is problematic in two dimensions.\r\n  - Embedding configuration in records may compromise user privacy if the configurations can be set by an adversary colluding with one of the aggregators (e.g. you can leak log2(n choose k) bits of information if you allow any subset of k prefixes for an n-bit domain).\r\n  - Levels must be pre-specified at record-creation time, which is non-ideal if new information comes up at collection time which informs how aggregation should work (e.g. realizing you have fewer records than expected so it is better to focus on querying only up to a given prefix).\r\n\r\nHowever, I think (2b) runs into a few issues with this architecture that separates verification from collection, in that without knowing the specific levels to evaluate, we run the risk of spending unnecessary compute verifying levels that will never end up being used. The protocol is more efficient (less computation, fewer rounds) if we can verify multiple levels at once (i.e. the levels the collector cares about).\r\n\r\nPossible solutions:\r\n1. Add a step where the collector and leader communicate prior to verification (but keep verification and collection separate)\r\n2. More tightly couple \"verify\" and \"collect\" stages, so that verification can be done based on communication with the collector.\r\n\r\nIn our setting, the \"leader\" and \"collector\" roles are somewhat merged which aligns with option (1), but it seems like a good idea to make the general architecture robust to this use-case.\r\n\r\ncc @schoppmp who is working on our C++ implementation of IDPFs.",
          "createdAt": "2021-05-06T18:33:58Z",
          "updatedAt": "2021-05-07T16:01:54Z"
        },
        {
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "body": "@csharrison can you please file an issue with your comment? It doesn't seem to apply to this PR, which punts on the aggregate protocol. ",
          "createdAt": "2021-05-06T23:49:06Z",
          "updatedAt": "2021-05-06T23:49:06Z"
        },
        {
          "author": "csharrison",
          "authorAssociation": "CONTRIBUTOR",
          "body": "Ah yes sorry, I included it here because I thought it may impact design for upload / verify. Let me delete and re-upload as an issue.",
          "createdAt": "2021-05-07T15:58:27Z",
          "updatedAt": "2021-05-07T15:58:27Z"
        },
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "TODO(@cjpatton) Allow an aribtrary number of verify requests",
          "createdAt": "2021-05-12T17:41:26Z",
          "updatedAt": "2021-05-12T17:41:26Z"
        }
      ],
      "reviews": [
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjUzOTYxMDc0",
          "commit": {
            "abbreviatedOid": "e2b3273"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-05-06T23:03:19Z",
          "updatedAt": "2021-05-06T23:46:51Z",
          "comments": [
            {
              "originalPosition": 68,
              "body": "This probably needs to be larger, say, `uint8 id[32]`?",
              "createdAt": "2021-05-06T23:03:19Z",
              "updatedAt": "2021-05-11T16:35:44Z"
            },
            {
              "originalPosition": 57,
              "body": "This seems out of place -- was it supposed to be move to some later point in the document?",
              "createdAt": "2021-05-06T23:03:40Z",
              "updatedAt": "2021-05-11T16:36:15Z"
            },
            {
              "originalPosition": 111,
              "body": "Can we lift the config from [OHTTP/ECH](https://unicorn-wg.github.io/oblivious-http/draft-thomson-http-oblivious.html#name-key-configuration-encoding)?",
              "createdAt": "2021-05-06T23:05:18Z",
              "updatedAt": "2021-05-11T16:36:15Z"
            },
            {
              "originalPosition": 135,
              "body": "Should we break out preconditions for each sub-protocol (upload, verify, aggregate), and then list them in their relevant section(s)?",
              "createdAt": "2021-05-06T23:06:28Z",
              "updatedAt": "2021-05-11T16:36:15Z"
            },
            {
              "originalPosition": 150,
              "body": "I envisioned this first request -- parameter fetching -- to be part of the configuration. Is there a scenario where clients would know the PATask but not the corresponding PAParam? ",
              "createdAt": "2021-05-06T23:09:46Z",
              "updatedAt": "2021-05-11T16:36:15Z"
            },
            {
              "originalPosition": 159,
              "body": "Yeah, it does. \ud83d\udc4d ",
              "createdAt": "2021-05-06T23:10:11Z",
              "updatedAt": "2021-05-11T16:35:44Z"
            },
            {
              "originalPosition": 157,
              "body": "\ud83d\udc4d agree with this, though it seems deployment specific? I might include this as an option for some deployments, maybe in an appendix.",
              "createdAt": "2021-05-06T23:10:23Z",
              "updatedAt": "2021-05-11T16:35:44Z"
            },
            {
              "originalPosition": 176,
              "body": "The `id` seems to tie the upload start and finish together. A couple questions:\r\n1. Can we drop it if we turn this into a single HTTP request?\r\n2. if we keep both requests, why do they need to be tied together?",
              "createdAt": "2021-05-06T23:11:17Z",
              "updatedAt": "2021-05-11T16:36:15Z"
            },
            {
              "originalPosition": 188,
              "body": "```suggestion\r\n  Url helper_urls<1..2^16-1>;\r\n```\r\n\r\nAlso, has `Url` been defined yet?",
              "createdAt": "2021-05-06T23:12:52Z",
              "updatedAt": "2021-05-11T16:36:15Z"
            },
            {
              "originalPosition": 215,
              "body": "Why is this alert important? What is the leader to do with this information?",
              "createdAt": "2021-05-06T23:15:49Z",
              "updatedAt": "2021-05-11T16:36:15Z"
            },
            {
              "originalPosition": 253,
              "body": "```suggestion\r\n  opaque enc<1..2^16-1>;     // Encapsulated HPKE context\r\n```",
              "createdAt": "2021-05-06T23:17:16Z",
              "updatedAt": "2021-05-11T16:36:15Z"
            },
            {
              "originalPosition": 254,
              "body": "Why is this allowed to be empty? ",
              "createdAt": "2021-05-06T23:17:25Z",
              "updatedAt": "2021-05-11T16:36:15Z"
            },
            {
              "originalPosition": 265,
              "body": "What does the client do if one helper returns a 200 and another returns an error?",
              "createdAt": "2021-05-06T23:28:58Z",
              "updatedAt": "2021-05-11T16:36:15Z"
            },
            {
              "originalPosition": 274,
              "body": "```suggestion\r\nthe *verify finish request*. The contents of each request depend on the\r\n```",
              "createdAt": "2021-05-06T23:30:04Z",
              "updatedAt": "2021-05-11T16:35:44Z"
            },
            {
              "originalPosition": 283,
              "body": "Is the set here the batch in total, or the set of individual reports?",
              "createdAt": "2021-05-06T23:31:33Z",
              "updatedAt": "2021-05-11T16:36:15Z"
            },
            {
              "originalPosition": 312,
              "body": "We've not defined joint randomness, so I might drop this example text entirely. The preceding text seems clear enough as-is.",
              "createdAt": "2021-05-06T23:35:50Z",
              "updatedAt": "2021-05-11T16:36:15Z"
            },
            {
              "originalPosition": 330,
              "body": "What does the leader do for a batch in this situation?",
              "createdAt": "2021-05-06T23:36:30Z",
              "updatedAt": "2021-05-11T16:36:15Z"
            },
            {
              "originalPosition": 389,
              "body": "Is there missing text here? What does the helper actually do with the FinishReq message?",
              "createdAt": "2021-05-06T23:37:55Z",
              "updatedAt": "2021-05-11T16:36:15Z"
            },
            {
              "originalPosition": 410,
              "body": "To clarify, this means the helper knows the valid bit after sending `PAVerifyFinishResp`, right?",
              "createdAt": "2021-05-06T23:39:23Z",
              "updatedAt": "2021-05-11T16:36:15Z"
            },
            {
              "originalPosition": 424,
              "body": "Is this what we want to do if the helper fails to process one share of a batch?",
              "createdAt": "2021-05-06T23:40:09Z",
              "updatedAt": "2021-05-11T16:36:15Z"
            },
            {
              "originalPosition": 438,
              "body": "```suggestion\r\nrequest, the response status is 400. When sent in a request to an\r\n```",
              "createdAt": "2021-05-06T23:42:33Z",
              "updatedAt": "2021-05-11T16:36:15Z"
            },
            {
              "originalPosition": 276,
              "body": "```suggestion\r\nreport submitted during the upload protocol, allowing the helper to run the verification protocol statelessly.\r\n```",
              "createdAt": "2021-05-06T23:46:27Z",
              "updatedAt": "2021-05-11T16:35:44Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjU1OTI0MTg0",
          "commit": {
            "abbreviatedOid": "e2b3273"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-05-10T18:03:32Z",
          "updatedAt": "2021-05-10T18:03:32Z",
          "comments": [
            {
              "originalPosition": 488,
              "body": "This should also have `PAParam`, right? How else does the client get that?",
              "createdAt": "2021-05-10T18:03:32Z",
              "updatedAt": "2021-05-11T16:36:15Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjU2ODYzNTE3",
          "commit": {
            "abbreviatedOid": "e2b3273"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-05-11T15:19:51Z",
          "updatedAt": "2021-05-11T15:19:52Z",
          "comments": [
            {
              "originalPosition": 57,
              "body": "No, it was meant to go here.",
              "createdAt": "2021-05-11T15:19:51Z",
              "updatedAt": "2021-05-11T16:36:15Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjU2ODY3Njg2",
          "commit": {
            "abbreviatedOid": "e2b3273"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-05-11T15:23:27Z",
          "updatedAt": "2021-05-11T15:23:27Z",
          "comments": [
            {
              "originalPosition": 111,
              "body": "The delta would be adding support for multiple HPKE ciphersuites. Although I see the value of aligning the structures across specs, I'd also like to push back on adding agility for now. I've added a TODO for resolving this later.",
              "createdAt": "2021-05-11T15:23:27Z",
              "updatedAt": "2021-05-11T16:36:15Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjU2ODc0NzE1",
          "commit": {
            "abbreviatedOid": "e2b3273"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-05-11T15:26:12Z",
          "updatedAt": "2021-05-11T15:26:13Z",
          "comments": [
            {
              "originalPosition": 135,
              "body": "I agree that would be clearer. However, addressing #44 will require us to change this three-phase structure in some way. I've added a TODO to address this later.",
              "createdAt": "2021-05-11T15:26:12Z",
              "updatedAt": "2021-05-11T16:36:15Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjU2ODgyMjA0",
          "commit": {
            "abbreviatedOid": "e2b3273"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-05-11T15:29:02Z",
          "updatedAt": "2021-05-11T15:29:03Z",
          "comments": [
            {
              "originalPosition": 150,
              "body": "Yes I think so. For aggregating mean/var of a sequence of integers, there are two parameters that might vary between uploads: the of the sequence and the length of each integer in bits.",
              "createdAt": "2021-05-11T15:29:03Z",
              "updatedAt": "2021-05-11T16:36:15Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjU2ODg0OTQ2",
          "commit": {
            "abbreviatedOid": "e2b3273"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-05-11T15:30:48Z",
          "updatedAt": "2021-05-11T15:30:48Z",
          "comments": [
            {
              "originalPosition": 159,
              "body": "Thanks for confirming. Moved this from an OPEN ISSUE to a NOTE. (We can massage it into text later.)",
              "createdAt": "2021-05-11T15:30:48Z",
              "updatedAt": "2021-05-11T16:36:15Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjU2ODk3NjAx",
          "commit": {
            "abbreviatedOid": "e2b3273"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-05-11T15:41:49Z",
          "updatedAt": "2021-05-11T15:41:49Z",
          "comments": [
            {
              "originalPosition": 176,
              "body": ">  The id seems to tie the upload start and finish together. A couple questions:\r\n>\r\n>     1. Can we drop it if we turn this into a single HTTP request?\r\n\r\nFor some Prio proof systems, it's useful for the leader to send the client a \"challenge\" that it'll use to generate the proof. One way to use the id is as a way of generating the challenge in a way that's unique for each upload.\r\n\r\n>     2. if we keep both requests, why do they need to be tied together?\r\n\r\nRetransmitting the id allows the two HTTP requests to be handled without carrying state between them.\r\n\r\n",
              "createdAt": "2021-05-11T15:41:49Z",
              "updatedAt": "2021-05-11T16:36:15Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjU2ODk5OTM5",
          "commit": {
            "abbreviatedOid": "e2b3273"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-05-11T15:43:53Z",
          "updatedAt": "2021-05-11T15:43:54Z",
          "comments": [
            {
              "originalPosition": 188,
              "body": "It hasn't! Added a definition.\r\n\r\nI'm not taking the suggestion because I don't want to get nit-picky about size ranges yet. This is something that's likely to change a lot.",
              "createdAt": "2021-05-11T15:43:54Z",
              "updatedAt": "2021-05-11T16:36:15Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjU2OTAwODU1",
          "commit": {
            "abbreviatedOid": "e2b3273"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-05-11T15:44:44Z",
          "updatedAt": "2021-05-11T15:44:44Z",
          "comments": [
            {
              "originalPosition": 215,
              "body": "If lots of clients abort this way, then it's a signal that something is amiss. For example, it may be that none of the helpers it is advertising are online.",
              "createdAt": "2021-05-11T15:44:44Z",
              "updatedAt": "2021-05-11T16:36:15Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjU2OTA0MDg3",
          "commit": {
            "abbreviatedOid": "e2b3273"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-05-11T15:47:40Z",
          "updatedAt": "2021-05-11T15:47:41Z",
          "comments": [
            {
              "originalPosition": 265,
              "body": "Hm, not sure what you mean. The upload finish request is made to the leader, not the helper.",
              "createdAt": "2021-05-11T15:47:41Z",
              "updatedAt": "2021-05-11T16:36:15Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjU2OTIwODE2",
          "commit": {
            "abbreviatedOid": "e2b3273"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-05-11T15:58:50Z",
          "updatedAt": "2021-05-11T15:58:50Z",
          "comments": [
            {
              "originalPosition": 330,
              "body": "Ah, good point. This might happen, say, if the helper advertises the wrong key config during the upload phase. The shares are useless if the helper can't decrypt them, so I don't think the leader has a choice other than to abort. This falls into the bucket of situations that re-running the protocol with multiple helpers is meant to address.",
              "createdAt": "2021-05-11T15:58:50Z",
              "updatedAt": "2021-05-11T16:36:15Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjU4MjI3NzUy",
          "commit": {
            "abbreviatedOid": "1cc6235"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-05-12T18:13:21Z",
          "updatedAt": "2021-05-12T18:13:21Z",
          "comments": [
            {
              "originalPosition": 57,
              "body": "Hmm, okay. It just feels out of place. We can always move later.",
              "createdAt": "2021-05-12T18:13:21Z",
              "updatedAt": "2021-05-12T18:13:21Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjU4MjI3ODUz",
          "commit": {
            "abbreviatedOid": "1cc6235"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-05-12T18:13:28Z",
          "updatedAt": "2021-05-12T18:13:29Z",
          "comments": [
            {
              "originalPosition": 135,
              "body": "\ud83d\udc4d ",
              "createdAt": "2021-05-12T18:13:28Z",
              "updatedAt": "2021-05-12T18:13:29Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjU4MjI3OTk0",
          "commit": {
            "abbreviatedOid": "1cc6235"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-05-12T18:13:39Z",
          "updatedAt": "2021-05-12T18:13:39Z",
          "comments": [
            {
              "originalPosition": 150,
              "body": "\ud83d\udc4d ",
              "createdAt": "2021-05-12T18:13:39Z",
              "updatedAt": "2021-05-12T18:13:39Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjU4MjI4MzA3",
          "commit": {
            "abbreviatedOid": "1cc6235"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-05-12T18:13:59Z",
          "updatedAt": "2021-05-12T18:13:59Z",
          "comments": [
            {
              "originalPosition": 188,
              "body": "Well, can the helper_urls be empty? If not, then we should take the suggestion. ",
              "createdAt": "2021-05-12T18:13:59Z",
              "updatedAt": "2021-05-12T18:13:59Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjU4MjMwMDkw",
          "commit": {
            "abbreviatedOid": "1cc6235"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-05-12T18:15:53Z",
          "updatedAt": "2021-05-12T18:15:53Z",
          "comments": [
            {
              "originalPosition": 215,
              "body": "Can't the leader determine if helpers are \"online\"? This seems to reveal information that's specific to clients. Imagine, for example, that clients are prohibited from talking to helpers but not the leader. Is it OK that leaders learn that about a client? I'm not sure, so I'd be inclined to remove this unless we have a concrete use case.",
              "createdAt": "2021-05-12T18:15:53Z",
              "updatedAt": "2021-05-12T18:15:53Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjU4MjMzNDU2",
          "commit": {
            "abbreviatedOid": "1cc6235"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-05-12T18:17:11Z",
          "updatedAt": "2021-05-12T18:17:11Z",
          "comments": [
            {
              "originalPosition": 265,
              "body": "The protocol (as specified here) allows n>1 helpers to be used, right? (We may just only ever use one in practice.) I'm asking what we do if there are n>1 helpers and they all don't return 200. Does that clarify?",
              "createdAt": "2021-05-12T18:17:11Z",
              "updatedAt": "2021-05-12T18:17:11Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjU4MjM0Nzg2",
          "commit": {
            "abbreviatedOid": "1cc6235"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-05-12T18:17:40Z",
          "updatedAt": "2021-05-12T18:17:41Z",
          "comments": [
            {
              "originalPosition": 330,
              "body": "Yeah, we might want to note this (or flag a TODO to spell it out later).",
              "createdAt": "2021-05-12T18:17:40Z",
              "updatedAt": "2021-05-12T18:17:41Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjYwMTM5Njk1",
          "commit": {
            "abbreviatedOid": "1cc6235"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-05-14T19:25:40Z",
          "updatedAt": "2021-05-14T19:25:40Z",
          "comments": [
            {
              "originalPosition": 188,
              "body": "Well, a Url is itself a u16-prefixed string, so I guess the minimum is actually 2. But that begs the question of whether the only Url can be empty or not. If not, then it needs be 3. But is a length-1 URL a valid URL?\r\n\r\nAgain, I don't think it's worth being picky about this right now.",
              "createdAt": "2021-05-14T19:25:40Z",
              "updatedAt": "2021-05-14T19:26:34Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjYwMTQzNjQ5",
          "commit": {
            "abbreviatedOid": "1cc6235"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "Post-prototype clean-up.",
          "createdAt": "2021-05-14T19:31:46Z",
          "updatedAt": "2021-05-14T22:22:32Z",
          "comments": [
            {
              "originalPosition": 215,
              "body": "I think it's OK, but I think we should cut off the discussion here and deal with it later. I'll leave your comment as an open issue.",
              "createdAt": "2021-05-14T19:31:46Z",
              "updatedAt": "2021-05-14T22:22:32Z"
            },
            {
              "originalPosition": 265,
              "body": "These requests are sent to the leader, not each helper. There's nothing for the client to do except abort. If, how, and when it retries is an open question. I suspect the answer will be deployment-specific.",
              "createdAt": "2021-05-14T19:34:56Z",
              "updatedAt": "2021-05-14T22:22:32Z"
            },
            {
              "originalPosition": 283,
              "body": "The verify phase runs several instances of the input-validation protocol in parallel. The \"set of valid client inputs\" corresponds to the set of inputs validated in the current flow.",
              "createdAt": "2021-05-14T19:37:25Z",
              "updatedAt": "2021-05-14T22:22:32Z"
            },
            {
              "originalPosition": 389,
              "body": "Described below.",
              "createdAt": "2021-05-14T19:41:24Z",
              "updatedAt": "2021-05-14T22:22:32Z"
            },
            {
              "originalPosition": 410,
              "body": "Right.",
              "createdAt": "2021-05-14T19:41:56Z",
              "updatedAt": "2021-05-14T22:22:32Z"
            },
            {
              "originalPosition": 424,
              "body": "It depends on how the helper fails, right? If it fails to send VerifyFinishResp, then the leader can't determine the inputs' valididty and must abort. If the helper sends VerifyFinishResp, but fails to store its input shares, the leader won't know that the batch has been corrupted. Either failure scenario can be addressed by running with multiple helpers.",
              "createdAt": "2021-05-14T19:45:10Z",
              "updatedAt": "2021-05-14T22:22:32Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjY2OTkyOTY3",
          "commit": {
            "abbreviatedOid": "5f9c72f"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-05-24T17:22:56Z",
          "updatedAt": "2021-05-24T18:15:39Z",
          "comments": [
            {
              "originalPosition": 53,
              "body": "```suggestion\r\nEach round of the protocol corresponds to an HTTP request and response. Use of\r\nHTTPS is REQUIRED for each transaction. The server MUST authenticate to the client\r\nfor each connection.\r\n```",
              "createdAt": "2021-05-24T17:22:56Z",
              "updatedAt": "2021-05-24T18:15:39Z"
            },
            {
              "originalPosition": 89,
              "body": "```suggestion\r\n```\r\nI think we can comfortably drop this.",
              "createdAt": "2021-05-24T17:24:36Z",
              "updatedAt": "2021-05-24T18:15:39Z"
            },
            {
              "originalPosition": 94,
              "body": "```suggestion\r\nid* in the remainder. This value is decided by the collector and configured for clients and \r\naggregators out-of-band. Clients and aggregators MUST ignore new `PATask` values if the\r\nid conflicts with an existing `PATask`.\r\n```",
              "createdAt": "2021-05-24T17:25:18Z",
              "updatedAt": "2021-05-24T18:15:39Z"
            },
            {
              "originalPosition": 96,
              "body": "Do we want to _negotiate_ it, or rather allow it to be configured some way? I think we ought to just drop this text.",
              "createdAt": "2021-05-24T17:25:58Z",
              "updatedAt": "2021-05-24T18:15:39Z"
            },
            {
              "originalPosition": 118,
              "body": "```suggestion\r\nThe `batch_size` field encodes the *batch size*, the minimum number of input shares\r\n```",
              "createdAt": "2021-05-24T17:27:51Z",
              "updatedAt": "2021-05-24T18:15:39Z"
            },
            {
              "originalPosition": 125,
              "body": "```suggestion\r\nThis protocol uses HPKE for public-key encryption {{!I-D.irtf-cfrg-hpke}}.  Each\r\n```",
              "createdAt": "2021-05-24T17:28:10Z",
              "updatedAt": "2021-05-24T18:15:39Z"
            },
            {
              "originalPosition": 146,
              "body": "```suggestion\r\nWe call this the helper's *key configuration*. The key configuration is used to\r\n```",
              "createdAt": "2021-05-24T17:28:38Z",
              "updatedAt": "2021-05-24T18:15:39Z"
            },
            {
              "originalPosition": 147,
              "body": "```suggestion\r\nset up a base-mode HPKE context (see {{I-D.irtf-cfrg-hpke}}, Section 5.1.1) to use to derive symmetric keys for protecting\r\n```",
              "createdAt": "2021-05-24T17:29:21Z",
              "updatedAt": "2021-05-24T18:15:39Z"
            },
            {
              "originalPosition": 154,
              "body": "What is \"the protocol\" here? Maybe we can say \"before clients can start uploading data\" instead?",
              "createdAt": "2021-05-24T17:31:08Z",
              "updatedAt": "2021-05-24T18:15:39Z"
            },
            {
              "originalPosition": 159,
              "body": "```suggestion\r\n1. The client and leader can establish a leader-authenticated HTTPS connection.\r\n```",
              "createdAt": "2021-05-24T17:31:31Z",
              "updatedAt": "2021-05-24T18:15:39Z"
            },
            {
              "originalPosition": 161,
              "body": "```suggestion\r\n1. The leader and each helper can establish a leader-authenticated HTTPS connection.\r\n```",
              "createdAt": "2021-05-24T17:31:44Z",
              "updatedAt": "2021-05-24T18:15:39Z"
            },
            {
              "originalPosition": 166,
              "body": "Yeah, some of these preconditions seem to apply to the upload protocol, whereas some apply only to the verify/collect protocols. It's probably worth splitting them out.",
              "createdAt": "2021-05-24T17:32:59Z",
              "updatedAt": "2021-05-24T18:15:39Z"
            },
            {
              "originalPosition": 238,
              "body": "```suggestion\r\n* the client failed to connect to the helper helper over HTTPS;\r\n```",
              "createdAt": "2021-05-24T17:38:35Z",
              "updatedAt": "2021-05-24T18:15:39Z"
            },
            {
              "originalPosition": 240,
              "body": "```suggestion\r\n* the GET request to the helper URL failed, i.e., returned a non-200 status code, or contained an invalid `HpkeConfig` message; or\r\n```",
              "createdAt": "2021-05-24T17:39:10Z",
              "updatedAt": "2021-05-24T18:15:39Z"
            },
            {
              "originalPosition": 305,
              "body": "```suggestion\r\n  opaque enc<1..2^16-1>;\r\n```\r\n`helper_enc` was undefined",
              "createdAt": "2021-05-24T17:43:03Z",
              "updatedAt": "2021-05-24T18:15:39Z"
            },
            {
              "originalPosition": 314,
              "body": "```suggestion\r\nField `enc` encodes the helper's encapsulated key computed as above. The remainder of the\r\n```",
              "createdAt": "2021-05-24T17:43:32Z",
              "updatedAt": "2021-05-24T18:15:39Z"
            },
            {
              "originalPosition": 265,
              "body": "This has been overcome by events now that the leader responds with 200 upon upload complete. ",
              "createdAt": "2021-05-24T17:45:37Z",
              "updatedAt": "2021-05-24T18:15:39Z"
            },
            {
              "originalPosition": 333,
              "body": "```suggestion\r\n{{pa-error-common-aborts}}. The leader does not attempt to validate any information for the \r\nhelper, e.g., whether or not PAHelperShare is valid. Such validation occurs during the subsequent \r\nverify protocol.\r\n```",
              "createdAt": "2021-05-24T17:48:01Z",
              "updatedAt": "2021-05-24T18:15:39Z"
            },
            {
              "originalPosition": 343,
              "body": "```suggestion\r\nparticular, the protocol is comprised of a sequence of HTTPS transactions between\r\nthe leader as client and helper as server. At the end of this phase, the leader and helper \r\nwill have\r\n```",
              "createdAt": "2021-05-24T17:48:45Z",
              "updatedAt": "2021-05-24T18:15:39Z"
            },
            {
              "originalPosition": 208,
              "body": "```suggestion\r\ngenerated. The second, `id` is the client's *upload id*, which MUST be chosen\r\nfrom a cryptographically secure pseudorandom number generator (CSPRNG);\r\nsee {{?RFC4086}} for guidance on generating such random values.\r\n```\r\n\r\nThough I do prefer the text in RFC8446 Appendix C.1, so maybe just pull some stuff from there? ",
              "createdAt": "2021-05-24T17:55:35Z",
              "updatedAt": "2021-05-24T18:15:39Z"
            },
            {
              "originalPosition": 201,
              "body": "Can we drop this field? It's not currently used during upload, and if it were, would require leaders to be stateful. (I see it's used during verify, but why can't the leader choose a per-report ID honestly, rather than each client in that case?) ",
              "createdAt": "2021-05-24T17:57:12Z",
              "updatedAt": "2021-05-25T16:07:13Z"
            },
            {
              "originalPosition": 382,
              "body": "```suggestion\r\nhelper's encapsulated HPKE context sent in the report. The remainder of the\r\n```",
              "createdAt": "2021-05-24T17:57:48Z",
              "updatedAt": "2021-05-24T18:15:39Z"
            },
            {
              "originalPosition": 396,
              "body": "```suggestion\r\nThe response is structured as a sequence of *sub-responses*, where the i-th\r\n```",
              "createdAt": "2021-05-24T17:58:50Z",
              "updatedAt": "2021-05-24T18:15:39Z"
            },
            {
              "originalPosition": 348,
              "body": "```suggestion\r\nThe leader begins with a sequence of reports that are all associated\r\n```\r\n\r\nSlightly reworded so as to not require servers to do some sort of batching if they don't have any reports to batch.\r\n",
              "createdAt": "2021-05-24T18:00:09Z",
              "updatedAt": "2021-05-24T18:15:39Z"
            },
            {
              "originalPosition": 414,
              "body": "```suggestion\r\nFor each sub-request `PAVerifyReq`, the helper computes the corresponding\r\n```",
              "createdAt": "2021-05-24T18:00:32Z",
              "updatedAt": "2021-05-24T18:15:39Z"
            },
            {
              "originalPosition": 424,
              "body": "Sorry, I was zeroing in on the \"tear down the HTTPS connection\" piece. I don't think that's really required. All that seems required is for the protocol (be it upload, verify, etc) to be aborted, which might manifest in tearing down HTTPS, or it might not. For upload, aborting is likely akin to tearing down the connection, but it might not be. (Clients could, e.g., keep open persistent connections to the leader if they're uploading many things.)",
              "createdAt": "2021-05-24T18:04:01Z",
              "updatedAt": "2021-05-24T18:15:39Z"
            },
            {
              "originalPosition": 60,
              "body": "Let's use [\"application/octet-stream\"](https://developer.mozilla.org/en-US/docs/Web/HTTP/Basics_of_HTTP/MIME_types/Common_types).",
              "createdAt": "2021-05-24T18:06:04Z",
              "updatedAt": "2021-05-24T18:15:39Z"
            },
            {
              "originalPosition": 334,
              "body": "```suggestion\r\n[[OPEN ISSUE: consider client->leader upload replays, and what leaders should do to mitigate against them. Prohibit early data? Strike register? Something else?]]\r\n```",
              "createdAt": "2021-05-24T18:08:55Z",
              "updatedAt": "2021-05-24T18:15:39Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjY3MDMzNjc5",
          "commit": {
            "abbreviatedOid": "5f9c72f"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-05-24T18:19:00Z",
          "updatedAt": "2021-05-24T18:19:00Z",
          "comments": [
            {
              "originalPosition": 176,
              "body": "I don't see why that's valuable or desired, since it just pushes state onto the server. (Left a separate comment for that, so will resolve this.)",
              "createdAt": "2021-05-24T18:19:00Z",
              "updatedAt": "2021-05-24T18:19:00Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjY3MDMzOTQ1",
          "commit": {
            "abbreviatedOid": "5f9c72f"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-05-24T18:19:24Z",
          "updatedAt": "2021-05-24T18:19:24Z",
          "comments": [
            {
              "originalPosition": 188,
              "body": "It's not really being picky. It's just saying that the URLs must be non-empty. ",
              "createdAt": "2021-05-24T18:19:24Z",
              "updatedAt": "2021-05-24T18:19:24Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjY3MDM0MzY5",
          "commit": {
            "abbreviatedOid": "5f9c72f"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-05-24T18:20:04Z",
          "updatedAt": "2021-05-24T18:20:05Z",
          "comments": [
            {
              "originalPosition": 368,
              "body": "```suggestion\r\n  opaque enc<1..2^16-1>;\r\n```",
              "createdAt": "2021-05-24T18:20:04Z",
              "updatedAt": "2021-05-24T18:20:05Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjY3OTg5MjIy",
          "commit": {
            "abbreviatedOid": "5f9c72f"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-05-25T15:36:22Z",
          "updatedAt": "2021-05-25T15:36:22Z",
          "comments": [
            {
              "originalPosition": 208,
              "body": "I'm fine with saying whatever here. (I don't actually think we need language about this yet.) I'll take the suggestion and we can overwrite it later if we choose.",
              "createdAt": "2021-05-25T15:36:22Z",
              "updatedAt": "2021-05-25T15:36:22Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjY4MDM2ODA2",
          "commit": {
            "abbreviatedOid": "5f9c72f"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-05-25T16:07:15Z",
          "updatedAt": "2021-05-25T16:49:00Z",
          "comments": [
            {
              "originalPosition": 166,
              "body": "Let's do so, but in a follow-up PR.",
              "createdAt": "2021-05-25T16:07:15Z",
              "updatedAt": "2021-05-25T16:49:00Z"
            },
            {
              "originalPosition": 201,
              "body": "(Getting rid of upload id, as it's motivation is tied to a particular instantiation of Prio.)",
              "createdAt": "2021-05-25T16:27:35Z",
              "updatedAt": "2021-05-25T16:49:00Z"
            },
            {
              "originalPosition": 424,
              "body": "Good point! \"Aborting\" just means forgetting any state associated with the protocol ... it needn't result in dropping the HTTPS state altogether.\r\n\r\nI guess we don't need to be explicit about what \"abort\" means right now. I just deleted this paragraph.",
              "createdAt": "2021-05-25T16:45:23Z",
              "updatedAt": "2021-05-25T16:49:00Z"
            },
            {
              "originalPosition": 154,
              "body": "That's right. Added.",
              "createdAt": "2021-05-25T16:46:41Z",
              "updatedAt": "2021-05-25T16:49:00Z"
            },
            {
              "originalPosition": 96,
              "body": "s/negotiated/configured",
              "createdAt": "2021-05-25T16:47:25Z",
              "updatedAt": "2021-05-25T16:49:00Z"
            },
            {
              "originalPosition": 60,
              "body": "Done.",
              "createdAt": "2021-05-25T16:48:06Z",
              "updatedAt": "2021-05-25T16:49:00Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Njc0NzI2NDQ1",
          "commit": {
            "abbreviatedOid": "2d93f6a"
          },
          "author": "ekr",
          "authorAssociation": "COLLABORATOR",
          "state": "CHANGES_REQUESTED",
          "body": "",
          "createdAt": "2021-06-02T22:16:26Z",
          "updatedAt": "2021-06-02T22:39:34Z",
          "comments": [
            {
              "originalPosition": 88,
              "body": "```suggestion\r\n```\r\n\r\nA reasonable point, but we are accumulating a lot of TODOs.",
              "createdAt": "2021-06-02T22:16:26Z",
              "updatedAt": "2021-06-02T22:39:34Z"
            },
            {
              "originalPosition": 90,
              "body": "Do you mean like draft-blah-blah-01?",
              "createdAt": "2021-06-02T22:16:50Z",
              "updatedAt": "2021-06-02T22:39:34Z"
            },
            {
              "originalPosition": 97,
              "body": "I'm not quite following what's going on here. Why not just give each task version its own UID? Or alternatively have version somewhere else.",
              "createdAt": "2021-06-02T22:18:35Z",
              "updatedAt": "2021-06-02T22:39:34Z"
            },
            {
              "originalPosition": 218,
              "body": "I don't quite understand the underlying assumptions here. If the client wants to upload some data, it's not going to be confused about whether the task involves heavy hitters or prio. What happens if it thinks it's doing prio and the leader responds with heavy hitterS?",
              "createdAt": "2021-06-02T22:35:57Z",
              "updatedAt": "2021-06-02T22:39:34Z"
            },
            {
              "originalPosition": 229,
              "body": "This seems like it has some obvious security problems. What stops the leader from just telling the client it runs all the helpers?",
              "createdAt": "2021-06-02T22:36:44Z",
              "updatedAt": "2021-06-02T22:39:34Z"
            },
            {
              "originalPosition": 291,
              "body": "Why are we replicating the leader_share for each helper?",
              "createdAt": "2021-06-02T22:38:43Z",
              "updatedAt": "2021-06-02T22:39:34Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Njc0NzM4NzM4",
          "commit": {
            "abbreviatedOid": "8dc85bc"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-06-02T22:42:04Z",
          "updatedAt": "2021-06-02T22:42:04Z",
          "comments": [
            {
              "originalPosition": 90,
              "body": "Yeah, I assume so, similar to what we did for ECH.",
              "createdAt": "2021-06-02T22:42:04Z",
              "updatedAt": "2021-06-02T22:42:04Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Njc0NzM5NzIy",
          "commit": {
            "abbreviatedOid": "8dc85bc"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-06-02T22:44:24Z",
          "updatedAt": "2021-06-02T22:44:24Z",
          "comments": [
            {
              "originalPosition": 97,
              "body": "The version here is \"version of the protocol.\" But maybe I'm misunderstanding you?",
              "createdAt": "2021-06-02T22:44:24Z",
              "updatedAt": "2021-06-02T22:44:24Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Njc0NzQwMjMw",
          "commit": {
            "abbreviatedOid": "8dc85bc"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-06-02T22:45:30Z",
          "updatedAt": "2021-06-02T22:45:30Z",
          "comments": [
            {
              "originalPosition": 218,
              "body": "This is to accommodate different parameters for the actual upload that are protocol specific. For example, if Hits or some future protocol requires per-upload data, that'd be in the HitsUploadStartResp.",
              "createdAt": "2021-06-02T22:45:30Z",
              "updatedAt": "2021-06-02T22:45:30Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Njc0NzQxMTk3",
          "commit": {
            "abbreviatedOid": "8dc85bc"
          },
          "author": "ekr",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-06-02T22:47:38Z",
          "updatedAt": "2021-06-02T22:47:38Z",
          "comments": [
            {
              "originalPosition": 218,
              "body": "Sure, but why is PAParam here? Almost nothing there can change.",
              "createdAt": "2021-06-02T22:47:38Z",
              "updatedAt": "2021-06-02T22:47:38Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Njc0NzQxNDky",
          "commit": {
            "abbreviatedOid": "8dc85bc"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-06-02T22:48:07Z",
          "updatedAt": "2021-06-02T22:48:08Z",
          "comments": [
            {
              "originalPosition": 229,
              "body": "Presumably clients will just check against their set of helpers or some local policy?",
              "createdAt": "2021-06-02T22:48:08Z",
              "updatedAt": "2021-06-02T22:48:08Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Njc0NzQxNjYw",
          "commit": {
            "abbreviatedOid": "8dc85bc"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-06-02T22:48:31Z",
          "updatedAt": "2021-06-02T22:48:32Z",
          "comments": [
            {
              "originalPosition": 291,
              "body": "There's only one helper here, so no duplication.",
              "createdAt": "2021-06-02T22:48:32Z",
              "updatedAt": "2021-06-02T22:48:32Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Njc0NzQyOTk4",
          "commit": {
            "abbreviatedOid": "8dc85bc"
          },
          "author": "ekr",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-06-02T22:51:33Z",
          "updatedAt": "2021-06-02T22:51:33Z",
          "comments": [
            {
              "originalPosition": 291,
              "body": "\"Otherwise, for each supported helper the client issues a POST request to `[leader]/upload_finish` with a payload\r\nconstructed as described below.",
              "createdAt": "2021-06-02T22:51:33Z",
              "updatedAt": "2021-06-02T22:51:33Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Njc0NzQzNzI3",
          "commit": {
            "abbreviatedOid": "8dc85bc"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-06-02T22:53:12Z",
          "updatedAt": "2021-06-02T22:53:13Z",
          "comments": [
            {
              "originalPosition": 218,
              "body": "I guess it depends on how things are configured? The assumption now is that clients start with a Task and then learn the Params for that task during Upload, but if we assume that Params are also distributed out-of-band, then we can drop it here.",
              "createdAt": "2021-06-02T22:53:12Z",
              "updatedAt": "2021-06-02T22:53:13Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Njc0NzQ0MTcx",
          "commit": {
            "abbreviatedOid": "8dc85bc"
          },
          "author": "ekr",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-06-02T22:54:06Z",
          "updatedAt": "2021-06-02T22:54:06Z",
          "comments": [
            {
              "originalPosition": 229,
              "body": "But then why do I need the server to tell me.\r\n\r\nI think there's a philosophical issue here: We should avoid having the leader tell the client anything that could be inconsistent with things it already needs to know. If we are trying to detect mismatch, we should instead have a config structure where the server sends the hash (or it's included in an AAD or something). That way we detect mismatch but don't rely on the client checking each parameter. Otherwise, we get into situations where the client might inappropriately trust the leader.\r\n\r\n\r\n",
              "createdAt": "2021-06-02T22:54:06Z",
              "updatedAt": "2021-06-02T22:54:06Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Njc0NzQ1ODk4",
          "commit": {
            "abbreviatedOid": "8dc85bc"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-06-02T22:58:08Z",
          "updatedAt": "2021-06-02T22:58:08Z",
          "comments": [
            {
              "originalPosition": 291,
              "body": "Oh I see. Will flag as an open issue.",
              "createdAt": "2021-06-02T22:58:08Z",
              "updatedAt": "2021-06-02T22:58:08Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Njc0NzQ5OTQx",
          "commit": {
            "abbreviatedOid": "8dc85bc"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-06-02T23:07:41Z",
          "updatedAt": "2021-06-02T23:07:41Z",
          "comments": [
            {
              "originalPosition": 229,
              "body": "That's a good point -- if the baseline assumption is that the leader is not trusted to not collude, and clients can't reasonably check for this, then this needs to change. (Let's do that in the next PR.)",
              "createdAt": "2021-06-02T23:07:41Z",
              "updatedAt": "2021-06-02T23:07:41Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Njc0NzA2NDUx",
          "commit": {
            "abbreviatedOid": "2d93f6a"
          },
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "state": "CHANGES_REQUESTED",
          "body": "",
          "createdAt": "2021-06-02T21:41:11Z",
          "updatedAt": "2021-06-02T23:17:21Z",
          "comments": [
            {
              "originalPosition": 155,
              "body": "```suggestion\r\ndata:\r\n\r\n```\r\nto make the list render properly in HTML",
              "createdAt": "2021-06-02T21:41:11Z",
              "updatedAt": "2021-06-02T23:17:21Z"
            },
            {
              "originalPosition": 191,
              "body": "The use of TLS is an optional implementation detail of the transport between two servers, so I think this document should avoid making assumptions about it (maybe I'm doing Prio over IPsec for some reason).",
              "createdAt": "2021-06-02T21:50:04Z",
              "updatedAt": "2021-06-02T23:17:21Z"
            },
            {
              "originalPosition": 202,
              "body": "IIUC the leader doesn't actually _do_ anything in response to the `upload_start` request except serve up some static configuration parameters. Thus I think that HTTP `GET` is a better fit here. Besides communicating API semantics to the client (`GET` is idempotent and should have no side effects on the server), you also get sensible caching behavior \"for free\" from the HTTP spec.\r\n\r\nThe complication is that [`GET` requests don't have bodies](https://developer.mozilla.org/en-US/docs/Web/HTTP/Methods/GET), but I think we can encode the `PATask` as either path fragments in the URI (i.e., `[leader]/upload_start/[task.version]/[task.id]`) or as query parameters (i.e., `[leader]/upload_start?version=[task.version];id=[task.id]`), which has the additional benefit of making it possible for leaders to implement the `upload_start` endpoint by putting a bunch of static files in a CDN.",
              "createdAt": "2021-06-02T22:03:44Z",
              "updatedAt": "2021-06-02T23:17:21Z"
            },
            {
              "originalPosition": 230,
              "body": "Given that an individual helper can be participating in multiple PDA deployments, I would have expected a `PATask` to be a parameter to this request. Does a helper server use the same HPKE config for all clients, or is the idea that `[helper]` somehow incorporates the `PATask`?",
              "createdAt": "2021-06-02T22:08:33Z",
              "updatedAt": "2021-06-02T23:17:21Z"
            },
            {
              "originalPosition": 232,
              "body": "```suggestion\r\nupload shares to. It ignores a helper if:\r\n\r\n```\r\nTo make the list render correctly in HTML",
              "createdAt": "2021-06-02T22:08:59Z",
              "updatedAt": "2021-06-02T23:17:21Z"
            },
            {
              "originalPosition": 231,
              "body": "How is key rotation handled? Since this is a `GET`, I think we could use a `Cache-Control` header in the HTTP response to indicate when the current key config expires, but maybe an explicit expiration date in the `HpkeConfig` message is more appropriate.",
              "createdAt": "2021-06-02T22:20:48Z",
              "updatedAt": "2021-06-02T23:17:21Z"
            },
            {
              "originalPosition": 262,
              "body": "A `PATask` unambiguously identifies a `PAParam` so it seems like the task version+ID should suffice.",
              "createdAt": "2021-06-02T22:24:05Z",
              "updatedAt": "2021-06-02T23:17:21Z"
            },
            {
              "originalPosition": 272,
              "body": "This wording is awkward: the HPKE context is used to encrypt the helper share, but it's not used for splitting the input and proof, right?",
              "createdAt": "2021-06-02T22:25:26Z",
              "updatedAt": "2021-06-02T23:17:21Z"
            },
            {
              "originalPosition": 230,
              "body": "This suggests that the client must consider *all* the helpers described in the leader's `PAUploadStartResp` and only ignore a helper if it doesn't meet one of the criteria listed below. Is that true or is the client permitted to select an arbitrary subset of available helpers?",
              "createdAt": "2021-06-02T22:30:49Z",
              "updatedAt": "2021-06-02T23:17:21Z"
            },
            {
              "originalPosition": 242,
              "body": "Given that the `PAUploadFinishReq` message includes both the helper and leader share, I find this kind of confusing. I think the idea here is that the client will select `k` out of the `n` helpers in the `PAUploadStartResp` obtained from the leader, and then construct a `PAUploadFinishReq`/report for each. That is, `k` independent instances of the PDA protocol will be run for aggregator pairs `(leader, helper[k])`, right?\r\n\r\n1. Does this mean we only support 2-way secret sharing? I think that's OK, but we should make that constraint of the system more obvious.\r\n1. Since all the reports are going to the same leader server, could they be combined into a single message, and hence a single request with a single state to be managed by the client and leader?\r\n1. Is the client expected to secret share the input differently for each `PAUploadFinishReq` it constructs? If not, then `PAUploadFinishReq.leader_share` will be identical in each message, and since the leader share will be much larger than the helper share (at least in Prio where the helper's share is a PRNG seed), we should work out a way to absolve the client (which might be on an expensive and slow cellular network) of having to upload the leader share `k` times.",
              "createdAt": "2021-06-02T22:47:54Z",
              "updatedAt": "2021-06-02T23:17:21Z"
            },
            {
              "originalPosition": 327,
              "body": "```suggestion\r\nstatus 200 and an empty body. Malformed requests are handled as described in\r\n```",
              "createdAt": "2021-06-02T22:49:34Z",
              "updatedAt": "2021-06-02T23:17:21Z"
            },
            {
              "originalPosition": 404,
              "body": "```suggestion\r\nPAParam.proto`. If not, it aborts and alerts the leader with \"incorrect protocol\r\n```\r\nHowever I think the `PAProto` field of `PAVerifyResp` and `PAVerifyReq` should be removed, precisely because you can get the protocol by getting the `PAParam` identified by the `PATask`. Having `PAProto` in the `PAVerify*` messages adds no information and only introduces an opportunity for implementations to get this wrong.",
              "createdAt": "2021-06-02T22:58:59Z",
              "updatedAt": "2021-06-02T23:17:21Z"
            },
            {
              "originalPosition": 193,
              "body": "The client obviously has to perform the `upload_finish` part of the protocol each time they want to submit a report, but it doesn't make sense to require them to run `upload_start` each time they submit metrics. We should specify client caching behavior for helper URL lists obtained from leaders and key configs obtained from helpers (see also my comment just below about using `HTTP GET` for cacheable, idempotent requests).",
              "createdAt": "2021-06-02T23:11:12Z",
              "updatedAt": "2021-06-02T23:17:21Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Njc0NzU0Njg4",
          "commit": {
            "abbreviatedOid": "2efcfd7"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-06-02T23:19:34Z",
          "updatedAt": "2021-06-02T23:19:34Z",
          "comments": [
            {
              "originalPosition": 191,
              "body": "Yeah, we're unlikely to make this change, so we can probably just delete the note.",
              "createdAt": "2021-06-02T23:19:34Z",
              "updatedAt": "2021-06-02T23:19:34Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Njc0NzU0ODc3",
          "commit": {
            "abbreviatedOid": "2efcfd7"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-06-02T23:20:01Z",
          "updatedAt": "2021-06-02T23:20:01Z",
          "comments": [
            {
              "originalPosition": 189,
              "body": "```suggestion\r\nelement.)]\r\n```",
              "createdAt": "2021-06-02T23:20:01Z",
              "updatedAt": "2021-06-02T23:20:01Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Njc0NzU1MzUy",
          "commit": {
            "abbreviatedOid": "2efcfd7"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-06-02T23:21:12Z",
          "updatedAt": "2021-06-02T23:21:12Z",
          "comments": [
            {
              "originalPosition": 202,
              "body": "> IIUC the leader doesn't actually do anything in response to the upload_start request except serve up some static configuration parameters.\r\n\r\nIn some cases, the server may supply per-upload data to be used in the finish message, so I think we ought to keep this to accommodate those protocols.",
              "createdAt": "2021-06-02T23:21:12Z",
              "updatedAt": "2021-06-02T23:21:12Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Njc0NzU1NjU1",
          "commit": {
            "abbreviatedOid": "2efcfd7"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-06-02T23:22:00Z",
          "updatedAt": "2021-06-02T23:22:00Z",
          "comments": [
            {
              "originalPosition": 230,
              "body": "@ekr pointed out that client's should probably dictate the helpers (on behalf of the data collector), so this is likely to change. ",
              "createdAt": "2021-06-02T23:22:00Z",
              "updatedAt": "2021-06-02T23:22:00Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Njc0NzU2MjQz",
          "commit": {
            "abbreviatedOid": "2efcfd7"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-06-02T23:23:34Z",
          "updatedAt": "2021-06-02T23:23:34Z",
          "comments": [
            {
              "originalPosition": 231,
              "body": "I think a Cache-Control header seems appropriate, but that does seem like an implementation detail. If the key has expired then the client's share will fail to be aggregated. (Though we would need to make sure this happens during Verify.)",
              "createdAt": "2021-06-02T23:23:34Z",
              "updatedAt": "2021-06-02T23:23:35Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Njc0NzU3MTQz",
          "commit": {
            "abbreviatedOid": "94b4669"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-06-02T23:25:54Z",
          "updatedAt": "2021-06-02T23:25:55Z",
          "comments": [
            {
              "originalPosition": 242,
              "body": "> Does this mean we only support 2-way secret sharing? I think that's OK, but we should make that constraint of the system more obvious.\r\n\r\nIndeed -- this is limited to the two-server case. \r\n\r\n> Since all the reports are going to the same leader server, could they be combined into a single message, and hence a single request with a single state to be managed by the client and leader?\r\n\r\nI don't see why not, though this seems like an optimization more than a functional change. \r\n\r\n> Is the client expected to secret share the input differently for each PAUploadFinishReq it constructs? If not, then PAUploadFinishReq.leader_share will be identical in each message, and since the leader share will be much larger than the helper share (at least in Prio where the helper's share is a PRNG seed), we should work out a way to absolve the client (which might be on an expensive and slow cellular network) of having to upload the leader share k times. \r\n\r\nYes, I think that's expected. (That is, I assume the proof is fresh for each upload.)",
              "createdAt": "2021-06-02T23:25:55Z",
              "updatedAt": "2021-06-02T23:25:55Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Njc0NzU3MzU3",
          "commit": {
            "abbreviatedOid": "94b4669"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-06-02T23:26:25Z",
          "updatedAt": "2021-06-02T23:26:25Z",
          "comments": [
            {
              "originalPosition": 262,
              "body": "Yeah, though we might want to fold in the entire PATask here anyway.",
              "createdAt": "2021-06-02T23:26:25Z",
              "updatedAt": "2021-06-02T23:26:25Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Njc0NzU3NDcx",
          "commit": {
            "abbreviatedOid": "94b4669"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-06-02T23:26:44Z",
          "updatedAt": "2021-06-02T23:26:44Z",
          "comments": [
            {
              "originalPosition": 272,
              "body": "That's right. Are you looking for a specific text change?",
              "createdAt": "2021-06-02T23:26:44Z",
              "updatedAt": "2021-06-02T23:26:44Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Njc1NTM2NDA1",
          "commit": {
            "abbreviatedOid": "e962ba2"
          },
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-06-03T17:15:14Z",
          "updatedAt": "2021-06-03T17:15:14Z",
          "comments": [
            {
              "originalPosition": 202,
              "body": "I suspect we can make this a GET without precluding those protocols, but we can pursue that question after merging this change: #48 ",
              "createdAt": "2021-06-03T17:15:14Z",
              "updatedAt": "2021-06-03T17:15:14Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Njc1NTQyODA2",
          "commit": {
            "abbreviatedOid": "e962ba2"
          },
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-06-03T17:18:54Z",
          "updatedAt": "2021-06-03T17:18:54Z",
          "comments": [
            {
              "originalPosition": 231,
              "body": "Filed #49 to consider key rotation and how it fits into the protocol.",
              "createdAt": "2021-06-03T17:18:54Z",
              "updatedAt": "2021-06-03T17:18:54Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Njc1NTQ0MzY2",
          "commit": {
            "abbreviatedOid": "e962ba2"
          },
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-06-03T17:20:52Z",
          "updatedAt": "2021-06-03T17:20:53Z",
          "comments": [
            {
              "originalPosition": 272,
              "body": "How about:\r\n```suggestion\r\nthen generates a validity proof for its input, splits the input and proof into\r\na *leader share* and a *helper share*, using `context` to protect the latter.\r\nNote that the details of each of these processing steps --- encode, prove,\r\nsplit, and encrypt --- are specific to the PA protocol.\r\n```",
              "createdAt": "2021-06-03T17:20:52Z",
              "updatedAt": "2021-06-03T17:20:53Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Njc1NTQ4MjEz",
          "commit": {
            "abbreviatedOid": "e962ba2"
          },
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-06-03T17:25:28Z",
          "updatedAt": "2021-06-03T17:25:28Z",
          "comments": [
            {
              "originalPosition": 242,
              "body": "I think this is fine, so long as each of the `k` protocol runs the client initiates for a given report are totally independent from one another.",
              "createdAt": "2021-06-03T17:25:28Z",
              "updatedAt": "2021-06-03T17:25:28Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Njc1NTU3MjAy",
          "commit": {
            "abbreviatedOid": "e962ba2"
          },
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "I wrote up my outstanding questions and comments in distinct issues in the name of unblocking progress here (#48, #49, #50). Otherwise this looks good to me.",
          "createdAt": "2021-06-03T17:36:31Z",
          "updatedAt": "2021-06-03T17:36:31Z",
          "comments": []
        }
      ]
    },
    {
      "number": 46,
      "id": "MDExOlB1bGxSZXF1ZXN0NjQ5NTc5Njc4",
      "title": "remove reference to core@ietf.org",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/pull/46",
      "state": "MERGED",
      "author": "tgeoghegan",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "Removes a paragraph which declares that Prio work is being discussed on\r\nany IETF mailing list, which is not (currently) the case.\r\n\r\nResolves #41",
      "createdAt": "2021-05-21T01:03:26Z",
      "updatedAt": "2021-12-30T00:53:20Z",
      "baseRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "baseRefName": "main",
      "baseRefOid": "3b0e4468c79a00c5c20d1228248c8688bfac776a",
      "headRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "headRefName": "timg/remove-ietf-core",
      "headRefOid": "a29bef442d369c79771d226e18c3d732c1bf72fc",
      "closedAt": "2021-05-21T16:16:48Z",
      "mergedAt": "2021-05-21T16:16:47Z",
      "mergedBy": "tgeoghegan",
      "mergeCommit": {
        "oid": "c9b7f30edf33f31979f514a756a8eeeb5fded787"
      },
      "comments": [],
      "reviews": [
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjY1NjI4MjY3",
          "commit": {
            "abbreviatedOid": "a29bef4"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "",
          "createdAt": "2021-05-21T16:02:24Z",
          "updatedAt": "2021-05-21T16:02:24Z",
          "comments": []
        }
      ]
    },
    {
      "number": 47,
      "id": "MDExOlB1bGxSZXF1ZXN0NjYwMzA2ODAz",
      "title": "remove reference to core@ietf.org from .note.xml",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/pull/47",
      "state": "CLOSED",
      "author": "tgeoghegan",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "",
      "createdAt": "2021-06-02T18:36:38Z",
      "updatedAt": "2021-12-30T00:53:22Z",
      "baseRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "baseRefName": "main",
      "baseRefOid": "c9b7f30edf33f31979f514a756a8eeeb5fded787",
      "headRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "headRefName": "timg/remove-ietf-core-again",
      "headRefOid": "b47eedacfe5d09c2ab57e9cc676db1799c88a310",
      "closedAt": "2021-06-12T00:34:30Z",
      "mergedAt": null,
      "mergedBy": null,
      "mergeCommit": null,
      "comments": [
        {
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "body": "Closing as overcome by events!",
          "createdAt": "2021-06-12T00:34:30Z",
          "updatedAt": "2021-06-12T00:34:30Z"
        }
      ],
      "reviews": []
    },
    {
      "number": 52,
      "id": "MDExOlB1bGxSZXF1ZXN0NjY2MTkxMzYx",
      "title": "Add a TODO for resolving aggregate consistency",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/pull/52",
      "state": "MERGED",
      "author": "cjpatton",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "Addresses #4 by adding a TODO. With #43 this issue has been solved in part: To ensure consistency in case of helper failure, the leader specifies a set of helpers, and the client runs the protocol with the leader and each helper. Each cohort produces an output, and the collector will need a way of deciding which output is \"correct\". Let's wait to answer this question until we close #51.",
      "createdAt": "2021-06-09T18:34:34Z",
      "updatedAt": "2021-06-17T21:15:22Z",
      "baseRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "baseRefName": "main",
      "baseRefOid": "d2bba0b8daf22de0cc7a226a8375d4714be6d166",
      "headRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "headRefName": "cjpatton/cross-aggregator-consistency",
      "headRefOid": "624fc01eee6c33cff2df42cb3161652fe8b7bb30",
      "closedAt": "2021-06-17T19:55:24Z",
      "mergedAt": "2021-06-17T19:55:24Z",
      "mergedBy": "cjpatton",
      "mergeCommit": {
        "oid": "ddc9e0904f1ada13935d88d69fe6575f06633b58"
      },
      "comments": [],
      "reviews": [
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Njg1NTIyODk1",
          "commit": {
            "abbreviatedOid": "624fc01"
          },
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "LGTM but I suggest modifying the PR description so that GitHub doesn't close #51 when this gets merged.",
          "createdAt": "2021-06-16T18:30:58Z",
          "updatedAt": "2021-06-16T18:30:58Z",
          "comments": []
        }
      ]
    },
    {
      "number": 54,
      "id": "MDExOlB1bGxSZXF1ZXN0NjY2MjM3MzU1",
      "title": "Define \"Report\"",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/pull/54",
      "state": "MERGED",
      "author": "cjpatton",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "Closes #53.",
      "createdAt": "2021-06-09T19:13:44Z",
      "updatedAt": "2021-06-17T21:15:21Z",
      "baseRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "baseRefName": "main",
      "baseRefOid": "d2bba0b8daf22de0cc7a226a8375d4714be6d166",
      "headRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "headRefName": "cjpatton/term-report",
      "headRefOid": "4f6bfd3d2481ec5d060e20648ad17d4eb01e9644",
      "closedAt": "2021-06-09T19:59:34Z",
      "mergedAt": "2021-06-09T19:59:34Z",
      "mergedBy": "tgeoghegan",
      "mergeCommit": {
        "oid": "9b4920ea8fef41e5b4706178fd1d0e0d00281bdf"
      },
      "comments": [],
      "reviews": [
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjgwMDkzOTY1",
          "commit": {
            "abbreviatedOid": "4f6bfd3"
          },
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "Thanks for putting the list back in alphabetical order, too!",
          "createdAt": "2021-06-09T19:59:23Z",
          "updatedAt": "2021-06-09T19:59:23Z",
          "comments": []
        }
      ]
    },
    {
      "number": 55,
      "id": "MDExOlB1bGxSZXF1ZXN0NjY3NTQxNjgw",
      "title": "Do rejection sampling when generating pseudorandom field elements",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/pull/55",
      "state": "MERGED",
      "author": "cjpatton",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "Closes #14.",
      "createdAt": "2021-06-11T00:11:34Z",
      "updatedAt": "2021-06-17T21:15:19Z",
      "baseRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "baseRefName": "main",
      "baseRefOid": "9b4920ea8fef41e5b4706178fd1d0e0d00281bdf",
      "headRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "headRefName": "cjpatton/prng-bias",
      "headRefOid": "ee0c253a8b071528acaef6cd8fc4a90ae995bb51",
      "closedAt": "2021-06-17T19:55:10Z",
      "mergedAt": "2021-06-17T19:55:10Z",
      "mergedBy": "cjpatton",
      "mergeCommit": {
        "oid": "fc27f20e076637b28310c5fc084927d7be31b7e5"
      },
      "comments": [],
      "reviews": [
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Njg1NTIwMDQx",
          "commit": {
            "abbreviatedOid": "ee0c253"
          },
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "",
          "createdAt": "2021-06-16T18:27:48Z",
          "updatedAt": "2021-06-16T18:27:48Z",
          "comments": []
        }
      ]
    },
    {
      "number": 56,
      "id": "MDExOlB1bGxSZXF1ZXN0NjY4NjQ0MjIw",
      "title": "Use le-automaton token for editor copy update",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/pull/56",
      "state": "MERGED",
      "author": "tgeoghegan",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "We set `GITHUB_TOKEN` to be read-only at the `abetterinternet` org\r\nlevel, but this breaks the \"Update GitHub Pages\" job in the \"Update\r\nEditor's Copy\" workflow. We now instead use a [personal account\r\ntoken](https://docs.github.com/en/github/authenticating-to-github/keeping-your-account-and-data-secure/creating-a-personal-access-token)\r\ngenerated from the `le-automaton` GitHub account which is scoped to\r\nallow actions on private repos.\r\n\r\nAdditionally, this deletes the `archive` workflow which I don't think we\r\nneed: GitHub itself is a perfectly good durable store of issues and PRs,\r\nand updating GH pages on push to main should suffice.",
      "createdAt": "2021-06-11T23:34:42Z",
      "updatedAt": "2021-12-30T00:53:22Z",
      "baseRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "baseRefName": "main",
      "baseRefOid": "9b4920ea8fef41e5b4706178fd1d0e0d00281bdf",
      "headRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "headRefName": "timg/fix-editor-copy",
      "headRefOid": "e6c23efbb66580c58bba55a0eef53e1c6f2cc8fe",
      "closedAt": "2021-06-12T00:30:31Z",
      "mergedAt": "2021-06-12T00:30:31Z",
      "mergedBy": "chris-wood",
      "mergeCommit": {
        "oid": "54dc32050ade4a56494887821a0077e655259caf"
      },
      "comments": [],
      "reviews": [
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjgyMjc4Nzc3",
          "commit": {
            "abbreviatedOid": "e6c23ef"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "",
          "createdAt": "2021-06-12T00:30:28Z",
          "updatedAt": "2021-06-12T00:30:28Z",
          "comments": []
        }
      ]
    },
    {
      "number": 59,
      "id": "MDExOlB1bGxSZXF1ZXN0Njc0NzAzNDU0",
      "title": "Specify data collection",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/pull/59",
      "state": "MERGED",
      "author": "cjpatton",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "Closes #44 by having the collector pass parameters to the aggregators for each round of verification and aggregation.\r\n\r\nReframes the execution of a PA protocol in terms of clients *pushing* input shares to the aggregators and the collector *pulling* output shares from the aggregators. This is meant to satisfy the requirements discussed in #51.",
      "createdAt": "2021-06-21T16:24:34Z",
      "updatedAt": "2021-12-30T02:09:57Z",
      "baseRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "baseRefName": "main",
      "baseRefOid": "aa4874af0ab968d514eed3859464d1a1984fd904",
      "headRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "headRefName": "caw/collect-overview",
      "headRefOid": "b0cc2706fbbf0f77068078408a47809b731a2286",
      "closedAt": "2021-07-07T21:27:20Z",
      "mergedAt": "2021-07-07T21:27:20Z",
      "mergedBy": "cjpatton",
      "mergeCommit": {
        "oid": "2ddbf5ed540db63bcc6edbb469777aa70ae4fb58"
      },
      "comments": [
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "> ### [leader]/collect calls block on multiple [helper]/aggregate calls\r\n> \r\n> The diagram in 3.4. illustrates that each collect request can cause the leader to make _L_ aggregate calls. The PACollectReq contains `Url helper`, so that can't be an aggregate call to each of the _L_ helpers enumerated in the `PAParams.helper_urls`.\r\n> \r\n>     * Why the _L_ calls then? Is the idea to e.g. allow a leader computing output over 10,000 inputs to feed the inputs to helpers 1,000 at a time to limit how big individual leader->helper HTTP requests can be?\r\n\r\nEach aggregate request corresponds to a round of the input validation protocol. For Prio, `L=1`; for Hits, `L = 2` I think. In general, I'd expect `L` to be small and constant.\r\n\r\n>     * What happens if an insufficient number of inputs (i.e., fewer than `PAParam.batch_size`) have been gathered when the leader receives the collect request? I assume the collector gets an error like \"not yet; try again later\".\r\n\r\nYes.\r\n\r\n> In this draft, the collector's `[leader]/collect` request will block until the _L_ `[helper]/aggregate` requests return. This seems like a problem to me: that would require the leader and collector to keep a connection open for what could be a long time while all the helpers finish aggregating. Additionally, it'd be hard for leaders to maintain any kind of response time SLOs if they are beholden to the response times of all the helpers (though of course the overall system's response times and throughput will be at the mercy of any defective server regardless). If we have to define a means for the leader to tell the collector to back off and try again later anyway, then I think we could use that to avoid blocking for a long time.\r\n\r\nThis is indeed a problem in general. For Hits the latency is unavoidable; for Prio we can avoid it because the aggregate requests can actually be made *as reports are uploade*. (Note that this is one of the requirements outline in #51. @acmiyaguchi and @ekr mention in the comments some ways we might deal with this. )\r\n\r\n\r\n> Collectors would be configured to hit `[leader]/collect` at some fixed interval (say every 12 hours) (I suspect this is already implicitly the case). If an insufficient number of inputs have been received since the last time a `PACollectResp` was delivered, the collector gets `EAGAIN` and tries again after the fixed interval elapses. If the leader decides it has enough inputs to generate output shares, it synchronously returns a collect request ID to the collector, and then asynchronously makes all the necessary `[helper]/aggregate` calls. Subsequently, the collector can poll on `[leader]/collect/<collect request id>` at a more aggressive interval. If it polls on the collect request ID before the output shares are ready, it gets `EAGAIN`. Eventually, leader completes its transactions with the helper(s) and the next time collector polls `[leader]/collect/<collect request id>`, it provides a `PACollectResp` populated with the output shares.\r\n\r\nThat sounds right to me.\r\n\r\n> ### What state does the leader or collector have to maintain, and how does `state.Finished()` work?\r\n> \r\n> Obviously it's protocol specific (prio vs. hits) but some concrete examples would help me understand.\r\n\r\nThe collector's state encodes whatever information it needs from previous request to figure out what the next request will be. I envision this being pretty application specific... I'm not sure it has intrinsic value to either Prio or Hits.\r\n\r\n> In the Prio case, it's finished when the collector gets a `PACollectResp` that contains the leader and helper output shares, and then it can reassemble them into the output.\r\n> \r\n>     * Is the leader then responsible for keeping track of which reports/inputs were included in the most recent `PACollectResp` delivered to the collector, to avoid double-counting reports in the next `PACollectResp`? If so, how does the leader track this state -- does a date suffice (i.e. inputs that arrived after the recorded date should be included in the next `PACollectResp`)?\r\n\r\nThis question reflects a requirement that we worked out on the design call: that right now the \"batch\" of reports that are used to respond to a collect request is not well-defined. As a first stab at this, we will timestamp reports and have the collect request specify a time range that defines the batch.\r\n\r\n> In the Hits case, then IIUC the successive collect requests sent by the collector represent traversing to the next level of a tree, so only the collector can know whether it feels it's gone deep enough.\r\n> \r\n>     * How does the leader know what set of inputs to include in the tree that the collector's query/collect request is applied to? Is it all the inputs gathered in the last _n_ hours, where _n_ is a Hits-specific portion of the PAParams? If so, is the leader responsible for keeping track of whether a given query has been applied to inputs from a given time window? Or is the query applied to all inputs gathered so far in the PATask? How does that affect data retention?\r\n\r\nSee above.\r\n\r\n\r\n\r\n",
          "createdAt": "2021-06-23T20:33:57Z",
          "updatedAt": "2021-06-23T20:33:57Z"
        },
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "Rebased.",
          "createdAt": "2021-06-23T20:47:42Z",
          "updatedAt": "2021-06-23T20:47:42Z"
        }
      ],
      "reviews": [
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Njg4OTQ0NjA1",
          "commit": {
            "abbreviatedOid": "68b178b"
          },
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "Thanks for all this great work! Besides the various inline comments, I have some higher-level comments/questions, which I think we should discuss in person during tomorrow (Weds 6/23)'s design call.\r\n\r\n### [leader]/collect calls block on multiple [helper]/aggregate calls\r\n\r\nThe diagram in 3.4. illustrates that each collect request can cause the leader to make _L_ aggregate calls. The PACollectReq contains `Url helper`, so that can't be an aggregate call to each of the _L_ helpers enumerated in the `PAParams.helper_urls`.\r\n\r\n* Why the _L_ calls then? Is the idea to e.g. allow a leader computing output over 10,000 inputs to feed the inputs to helpers 1,000 at a time to limit how big individual leader->helper HTTP requests can be?\r\n* What happens if an insufficient number of inputs (i.e., fewer than `PAParam.batch_size`) have been gathered when the leader receives the collect request? I assume the collector gets an error like \"not yet; try again later\".\r\n\r\nIn this draft, the collector's `[leader]/collect` request will block until the _L_ `[helper]/aggregate` requests return. This seems like a problem to me: that would require the leader and collector to keep a connection open for what could be a long time while all the helpers finish aggregating. Additionally, it'd be hard for leaders to maintain any kind of response time SLOs if they are beholden to the response times of all the helpers (though of course the overall system's response times and throughput will be at the mercy of any defective server regardless). If we have to define a means for the leader to tell the collector to back off and try again later anyway, then I think we could use that to avoid blocking for a long time.\r\n\r\nCollectors would be configured to hit `[leader]/collect` at some fixed interval (say every 12 hours) (I suspect this is already implicitly the case). If an insufficient number of inputs have been received since the last time a `PACollectResp` was delivered, the collector gets `EAGAIN` and tries again after the fixed interval elapses. If the leader decides it has enough inputs to generate output shares, it synchronously returns a collect request ID to the collector, and then asynchronously makes all the necessary `[helper]/aggregate` calls. Subsequently, the collector can poll on `[leader]/collect/<collect request id>` at a more aggressive interval. If it polls on the collect request ID before the output shares are ready, it gets `EAGAIN`. Eventually, leader completes its transactions with the helper(s) and the next time collector polls `[leader]/collect/<collect request id>`, it provides a `PACollectResp` populated with the output shares.\r\n\r\n### What state does the leader or collector have to maintain, and how does `state.Finished()` work?\r\n\r\nObviously it's protocol specific (prio vs. hits) but some concrete examples would help me understand.\r\n\r\nIn the Prio case, it's finished when the collector gets a `PACollectResp` that contains the leader and helper output shares, and then it can reassemble them into the output.\r\n\r\n* Is the leader then responsible for keeping track of which reports/inputs were included in the most recent `PACollectResp` delivered to the collector, to avoid double-counting reports in the next `PACollectResp`? If so, how does the leader track this state -- does a date suffice (i.e. inputs that arrived after the recorded date should be included in the next `PACollectResp`)?\r\n\r\nIn the Hits case, then IIUC the successive collect requests sent by the collector represent traversing to the next level of a tree, so only the collector can know whether it feels it's gone deep enough.\r\n\r\n* How does the leader know what set of inputs to include in the tree that the collector's query/collect request is applied to? Is it all the inputs gathered in the last _n_ hours, where _n_ is a Hits-specific portion of the PAParams? If so, is the leader responsible for keeping track of whether a given query has been applied to inputs from a given time window? Or is the query applied to all inputs gathered so far in the PATask? How does that affect data retention?",
          "createdAt": "2021-06-21T23:37:52Z",
          "updatedAt": "2021-06-23T00:31:24Z",
          "comments": [
            {
              "originalPosition": 62,
              "body": "```suggestion\r\n    |                    |\r\n    |                    |\r\n    | 1.              1. | 2.\r\n```\r\nto indicate that leader->helper communication happens during both upload and collect",
              "createdAt": "2021-06-21T23:37:53Z",
              "updatedAt": "2021-06-23T00:31:24Z"
            },
            {
              "originalPosition": 88,
              "body": "```suggestion\r\n[TODO: Say that the helper is stateless. To make this possible, it encrypts\r\n```",
              "createdAt": "2021-06-21T23:39:00Z",
              "updatedAt": "2021-06-23T00:31:24Z"
            },
            {
              "originalPosition": 175,
              "body": "```suggestion\r\nURLs. The `collector_config` is the HPKE configuration of the collector\r\n```",
              "createdAt": "2021-06-21T23:54:17Z",
              "updatedAt": "2021-06-23T00:31:24Z"
            },
            {
              "originalPosition": 239,
              "body": "Surely an individual client could be participating in multiple tasks? As written this implies that clients have a 1:1 relationship with PATasks.",
              "createdAt": "2021-06-21T23:59:14Z",
              "updatedAt": "2021-06-23T00:31:24Z"
            },
            {
              "originalPosition": 268,
              "body": "I think this diagram should include the `key_config` request made by the client against each helper, which IIUC must occur before upload finish.",
              "createdAt": "2021-06-22T02:35:24Z",
              "updatedAt": "2021-06-23T00:31:24Z"
            },
            {
              "originalPosition": 326,
              "body": "```suggestion\r\n[OPEN ISSUE: Should the request URL encode the PA task? This would be necessary if we make `upload_start` an idempotent GET per issue#48.]\r\n```",
              "createdAt": "2021-06-22T02:37:41Z",
              "updatedAt": "2021-06-23T00:31:24Z"
            },
            {
              "originalPosition": 399,
              "body": "We could clarify here that the leader share is sent in plaintext but over a channel that is assumed to be confidential w.r.t. observers on the network (i.e., TLS). Do we enumerate the requirements for the transport anywhere?",
              "createdAt": "2021-06-22T02:41:11Z",
              "updatedAt": "2021-06-23T00:31:24Z"
            },
            {
              "originalPosition": 514,
              "body": "```suggestion\r\nzero knowledge that the proof is valid. The exact procedure for doing so\r\n```\r\nSince \"validity\" is what we discuss elsewhere in the document. Mind you this was wrong before your PR.",
              "createdAt": "2021-06-22T02:49:13Z",
              "updatedAt": "2021-06-23T00:31:24Z"
            },
            {
              "originalPosition": 477,
              "body": "Given a `PATask`, the collector should be able to look up the corresponding `PAParam` and figure out the `PAProto`, no? I bring this up because I think collector implementations will need to check `PACollectResp.proto` against `PAParam.proto` no matter what, so including this member in `PACollectResp` only introduces the possibility of malformed messages and doesn't carry any additional information.",
              "createdAt": "2021-06-22T22:09:40Z",
              "updatedAt": "2021-06-23T00:31:24Z"
            },
            {
              "originalPosition": 463,
              "body": "I think the `PAProto` will be implied by the `PAParam` uniquely identified by the `PATask`.",
              "createdAt": "2021-06-22T22:11:22Z",
              "updatedAt": "2021-06-23T00:31:24Z"
            },
            {
              "originalPosition": 462,
              "body": "A `PAParam` can contain _n_ `helper_urls`, but a client may only select _k_ < _n_ of them to send reports to. So how does the collector know which `helper_urls` to use? I'm guessing that collectors are meant to send a `PACollectReq` for all _n_ helpers, but if _k_ << _n_ this seems wasteful. Are we assuming that _k_ is exactly or close to _n_?\r\n\r\nSupposing that some helper did not participate, what does the `PACollectResp` look like? Does it return an error (which should be described in 3.x. Common abort conditions) or does it provide a `PACollectResp` with empty `leader_share` and `encrypted_helper_share`?\r\n\r\nWhat about the case where `PACollectReq.helper` does not occur in `PAParam.helper_urls`? Does that get rejected by leader as an invalid message, or treated the same as a valid helper that did not participate?",
              "createdAt": "2021-06-22T22:14:33Z",
              "updatedAt": "2021-06-23T00:31:24Z"
            },
            {
              "originalPosition": 586,
              "body": "```suggestion\r\nassociated with `PAAggregateReq.helper_hpke_config_id`. If not found, then it aborts and\r\n```",
              "createdAt": "2021-06-22T22:45:54Z",
              "updatedAt": "2021-06-23T00:31:24Z"
            },
            {
              "originalPosition": 541,
              "body": "`uint8` seems kinda small for this, if a helper is meant to participate in multiple PA instantiations. Or is the idea that key configs are identified by `task+hpke_config_id`?",
              "createdAt": "2021-06-22T22:47:23Z",
              "updatedAt": "2021-06-23T00:31:24Z"
            },
            {
              "originalPosition": 670,
              "body": "```suggestion\r\n    case prio: PrioOutputShare;\r\n```",
              "createdAt": "2021-06-22T23:02:14Z",
              "updatedAt": "2021-06-23T00:31:24Z"
            },
            {
              "originalPosition": 479,
              "body": "If we made it the leader's responsibility to reassemble output shares into the final aggregate, then we wouldn't need to go to the trouble of establishing an authenticated+confidential helper<->collector channel. Am I right in guessing that protocols like hits make it impossible for the leader to reassemble outputs on the collector's behalf?",
              "createdAt": "2021-06-22T23:15:57Z",
              "updatedAt": "2021-06-23T00:31:24Z"
            },
            {
              "originalPosition": 495,
              "body": "We should make sure to version all these API endpoints, but that's probably premature at this stage: #61",
              "createdAt": "2021-06-22T23:27:53Z",
              "updatedAt": "2021-06-23T00:31:24Z"
            },
            {
              "originalPosition": 647,
              "body": "```suggestion\r\nOnce the aggregators have verified at least as many reports as\r\nrequired for the PA task, the leader issues an *output share request* to the\r\n```\r\nI think this is how this sentence should read?",
              "createdAt": "2021-06-22T23:32:43Z",
              "updatedAt": "2021-06-23T00:31:24Z"
            },
            {
              "originalPosition": 684,
              "body": "```suggestion\r\nconfiguration and `output_share` is its serialized output share.\r\n```",
              "createdAt": "2021-06-22T23:39:32Z",
              "updatedAt": "2021-06-23T00:31:24Z"
            },
            {
              "originalPosition": 158,
              "body": "If the collector HPKE config is here, then it can't be rotated without distributing a new `PAParam` to all participating servers. Could we have `[collector]/key_config` for discovering collector public keys dynamically?",
              "createdAt": "2021-06-22T23:41:57Z",
              "updatedAt": "2021-06-23T00:31:24Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjkwODc5NTky",
          "commit": {
            "abbreviatedOid": "68b178b"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-06-23T16:15:12Z",
          "updatedAt": "2021-06-23T16:49:45Z",
          "comments": [
            {
              "originalPosition": 62,
              "body": "The leader doesn't interact with the helper during upload, only during collect.",
              "createdAt": "2021-06-23T16:15:12Z",
              "updatedAt": "2021-06-23T16:49:45Z"
            },
            {
              "originalPosition": 158,
              "body": "Yeah, some spelling of this is a good idea I think. I've left this as an OPEN ISSUE for now, since it's somewhat orthogonal. See below.",
              "createdAt": "2021-06-23T16:17:02Z",
              "updatedAt": "2021-06-23T16:49:45Z"
            },
            {
              "originalPosition": 239,
              "body": "Yes indeed. I don't this criterion is very clear. What we mean is \"each client has selected a PA task for which it will upload a report\". Fixed.",
              "createdAt": "2021-06-23T16:23:33Z",
              "updatedAt": "2021-06-23T16:49:45Z"
            },
            {
              "originalPosition": 268,
              "body": "Good call. Done.",
              "createdAt": "2021-06-23T16:25:07Z",
              "updatedAt": "2021-06-23T16:49:45Z"
            },
            {
              "originalPosition": 399,
              "body": "Noted.\r\n\r\nAll we say about transport is that it should be a \"server-authenticated secure channel\". (I don't think we should be more specific than this.)",
              "createdAt": "2021-06-23T16:28:06Z",
              "updatedAt": "2021-06-23T16:49:45Z"
            },
            {
              "originalPosition": 462,
              "body": "> A `PAParam` can contain _n_ `helper_urls`, but a client may only select _k_ < _n_ of them to send reports to. So how does the collector know which `helper_urls` to use? I'm guessing that collectors are meant to send a `PACollectReq` for all _n_ helpers, but if _k_ << _n_ this seems wasteful. Are we assuming that _k_ is exactly or close to _n_?\r\n\r\nThe collector knows `helper_urls` because it's now specified by `PAParam`. (Note that this is change is new to this PR.) Nominally, _k_ would be close to _n_ (and _n_ would be be around 2 or 3).\r\n\r\n> Supposing that some helper did not participate, what does the `PACollectResp` look like? Does it return an error (which should be described in 3.x. Common abort conditions) or does it provide a `PACollectResp` with empty `leader_share` and `encrypted_helper_share`?\r\n\r\nGood question. (This is subsumed by the OPEN ISSUE below; I added your particular question as an example.) I think the right answer is that the leader would \"abort\" the request as described in {{pa-error}}. An important thing to note about this case is that it's (partially) recoverable, since the collector can try again with another helper.\r\n\r\n> What about the case where `PACollectReq.helper` does not occur in `PAParam.helper_urls`? Does that get rejected by leader as an invalid message, or treated the same as a valid helper that did not participate?\r\n\r\nThis would be another \"abort\" I think.\r\n",
              "createdAt": "2021-06-23T16:36:12Z",
              "updatedAt": "2021-06-23T16:49:45Z"
            },
            {
              "originalPosition": 463,
              "body": "But there is no `PAParam` in this struct. I guess you could argue that the leader knows the `PAParam` since it has the task id. However, I tend to think that protocol messages should always be deserializaeable without extra context.",
              "createdAt": "2021-06-23T16:38:23Z",
              "updatedAt": "2021-06-23T16:49:45Z"
            },
            {
              "originalPosition": 477,
              "body": "I see what you mean. As I mentioned above, I think protocol messages should always be deserializeable without needing context. Another way of phrasing this is that protocol messages should be \"self describing\". Maybe this property isn't needed here.",
              "createdAt": "2021-06-23T16:41:37Z",
              "updatedAt": "2021-06-23T16:49:45Z"
            },
            {
              "originalPosition": 479,
              "body": "The purpose of encryption here is to ensure that the aggregators don't learn the final output. (This is one of the requirements enumerated in #51.) This is a useful property to have if the collector \"outsources\" aggregation to a third-party leader. (See @ekr's comment on #51.)",
              "createdAt": "2021-06-23T16:44:54Z",
              "updatedAt": "2021-06-23T16:49:45Z"
            },
            {
              "originalPosition": 541,
              "body": "The config_id is meant to uniquely identify the HPKE config. We're using the same type for the config_id in ODoH and ECH, and it hasn't been a problem there. Usually the server will only have a small number of keys at any one time, e.g., 3 or 4.",
              "createdAt": "2021-06-23T16:46:24Z",
              "updatedAt": "2021-06-23T16:49:45Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjkxMTQ5ODUw",
          "commit": {
            "abbreviatedOid": "d820f60"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-06-23T21:18:14Z",
          "updatedAt": "2021-06-23T21:18:14Z",
          "comments": [
            {
              "originalPosition": 479,
              "body": "It also occurs to me that encrypting the output share is important to prevent the leader from doing Sybil attacks. ",
              "createdAt": "2021-06-23T21:18:14Z",
              "updatedAt": "2021-06-23T21:18:14Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjkxMjEwODE5",
          "commit": {
            "abbreviatedOid": "60de8d3"
          },
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "",
          "createdAt": "2021-06-23T23:01:42Z",
          "updatedAt": "2021-06-23T23:49:22Z",
          "comments": [
            {
              "originalPosition": 16,
              "body": "Since we're getting into the -arity of things: does a report contain shares of a _single_ input or could several inputs be encoded into a single report?",
              "createdAt": "2021-06-23T23:01:42Z",
              "updatedAt": "2021-06-23T23:49:22Z"
            },
            {
              "originalPosition": 45,
              "body": "This would allow the leader to impersonate the collector when it relays the HPKE config to the helper -- but as you say, it's an open issue so we don't have to solve it right now.",
              "createdAt": "2021-06-23T23:11:02Z",
              "updatedAt": "2021-06-23T23:49:22Z"
            },
            {
              "originalPosition": 135,
              "body": "I like making the collector specify the batch window, as I think it absolves us of specifying some tricky edge cases w.r.t. insufficient # of reports in the window (we can just say that it's up to the collector to try again with wider batch windows until they find one that works).",
              "createdAt": "2021-06-23T23:24:33Z",
              "updatedAt": "2021-06-23T23:49:22Z"
            },
            {
              "originalPosition": 541,
              "body": "I had assumed that a helper wouldn't re-use HPKE configs across PATasks, but thinking about it further there's no reason to assume that.",
              "createdAt": "2021-06-23T23:47:55Z",
              "updatedAt": "2021-06-23T23:49:22Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjkxMjMwNTM1",
          "commit": {
            "abbreviatedOid": "60de8d3"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-06-23T23:52:58Z",
          "updatedAt": "2021-06-23T23:55:41Z",
          "comments": [
            {
              "originalPosition": 16,
              "body": "I think one input per report. As has been said, it might be that the \"input\" is actually comprised of multiple measurements. The \"input\" is meant to capture the thing that's validated in a single run of the input validation protocol.",
              "createdAt": "2021-06-23T23:52:58Z",
              "updatedAt": "2021-06-23T23:55:41Z"
            },
            {
              "originalPosition": 45,
              "body": "Actually, at the moment the helper is \"pre-configured\" with the PAParam (and thus the collectors HPKE config). But yeah, this something we have to work out.",
              "createdAt": "2021-06-23T23:54:30Z",
              "updatedAt": "2021-06-23T23:55:41Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Njk2NzE5Njg2",
          "commit": {
            "abbreviatedOid": "3e73742"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "First pass complete -- looking great! ",
          "createdAt": "2021-07-01T00:38:24Z",
          "updatedAt": "2021-07-01T00:56:56Z",
          "comments": [
            {
              "originalPosition": 100,
              "body": "```suggestion\r\n2. **Collect:** The collector makes one or more requests to the leader in order to obtain the\r\n```",
              "createdAt": "2021-07-01T00:38:24Z",
              "updatedAt": "2021-07-01T00:56:56Z"
            },
            {
              "originalPosition": 112,
              "body": "Can we move this to an issue and discuss separately? What does \"we run the protocol in parallel with multiple helpers\" actually mean? (Who is \"we\"?)",
              "createdAt": "2021-07-01T00:39:43Z",
              "updatedAt": "2021-07-01T00:56:56Z"
            },
            {
              "originalPosition": 485,
              "body": "```suggestion\r\n[TODO: Decide if and how the collector's request is authenticated.]\r\n```",
              "createdAt": "2021-07-01T00:45:01Z",
              "updatedAt": "2021-07-01T00:56:56Z"
            },
            {
              "originalPosition": 135,
              "body": "Or maybe the collector can try again with a smaller window if it wants a different slice?",
              "createdAt": "2021-07-01T00:46:55Z",
              "updatedAt": "2021-07-01T00:56:56Z"
            },
            {
              "originalPosition": 462,
              "body": "It seems a lot of complexity right now is coming from the fact that the collector allows for multiple helpers to be used by the client, and the client to make a selection. Can we just remove that option, and have the collector force which helpers to use? ",
              "createdAt": "2021-07-01T00:48:38Z",
              "updatedAt": "2021-07-01T00:56:56Z"
            },
            {
              "originalPosition": 201,
              "body": "Are we concerned about skew between collectors and aggregators?",
              "createdAt": "2021-07-01T00:49:36Z",
              "updatedAt": "2021-07-01T00:56:56Z"
            },
            {
              "originalPosition": 612,
              "body": "This is generated by the leader, presumably? Is it set when the report is received from the client, or when aggregation is actually done during collection? Could the client set the timestamp in its encrypted share for the helper?",
              "createdAt": "2021-07-01T00:51:40Z",
              "updatedAt": "2021-07-01T00:56:56Z"
            },
            {
              "originalPosition": 713,
              "body": "```suggestion\r\ncarries is up to the helper implementation.\r\n```",
              "createdAt": "2021-07-01T00:53:36Z",
              "updatedAt": "2021-07-01T00:56:56Z"
            },
            {
              "originalPosition": 733,
              "body": "Should we require that the helper check that the OutputShareReq is not sent before the batch limit is hit? (That is, should the helper track how many shares aggregated so far and error if the number is less than the size?)",
              "createdAt": "2021-07-01T00:55:07Z",
              "updatedAt": "2021-07-01T00:56:56Z"
            },
            {
              "originalPosition": 729,
              "body": "Hmm, where does the batch window come into play here? Shouldn't it be the case that aggregate outputs are only produced for a given batch window once the size is hit? Do the collector's request parameters need to fold into this OutputShareReq?",
              "createdAt": "2021-07-01T00:55:51Z",
              "updatedAt": "2021-07-01T00:56:56Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Njk3MzQyMDk3",
          "commit": {
            "abbreviatedOid": "3e73742"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-07-01T14:50:47Z",
          "updatedAt": "2021-07-01T16:48:56Z",
          "comments": [
            {
              "originalPosition": 201,
              "body": "Clock skew? Yes, their clocks will need to be roughly synchronized, at least within `batch_window` seconds of each other.",
              "createdAt": "2021-07-01T14:50:47Z",
              "updatedAt": "2021-07-01T16:48:56Z"
            },
            {
              "originalPosition": 485,
              "body": "It will need to be authenticated, so it's not a question of \"if\".",
              "createdAt": "2021-07-01T14:51:25Z",
              "updatedAt": "2021-07-01T16:48:56Z"
            },
            {
              "originalPosition": 135,
              "body": "I think it should be able to do so, as long a (1) `batch_start` and `batch_end` are multiples of `batch_window` and (2) `batch_end - batch_start >= batch_window`. (The aggregators enforce this.) Furthermore, it shouldn't be able to change `batch_size` or `batch_window` adaptively, as this could lead to privacy violations.",
              "createdAt": "2021-07-01T14:55:54Z",
              "updatedAt": "2021-07-01T16:48:56Z"
            },
            {
              "originalPosition": 612,
              "body": "Actually, the time stamp is generated by the client when it uploads the report. See \"PAUploadFinishReq\".",
              "createdAt": "2021-07-01T15:11:50Z",
              "updatedAt": "2021-07-01T16:48:56Z"
            },
            {
              "originalPosition": 729,
              "body": "Ah, good catch. I added the `batch_start` and `batch_end` parameters so that the helper can enforce the `batch_window` and `batch_size` parameters.",
              "createdAt": "2021-07-01T16:35:40Z",
              "updatedAt": "2021-07-01T16:48:56Z"
            },
            {
              "originalPosition": 733,
              "body": "Yes indeed. I updated the text to make this check explicit.",
              "createdAt": "2021-07-01T16:42:13Z",
              "updatedAt": "2021-07-01T16:48:56Z"
            },
            {
              "originalPosition": 112,
              "body": "We decided previously that multiple helpers would be used for resiliency. This has already been baked into the spec. This TODO is merely about motivating and describing this design choice. There are two issues that are impacted by this: #4 and #22.",
              "createdAt": "2021-07-01T16:47:09Z",
              "updatedAt": "2021-07-01T16:48:56Z"
            },
            {
              "originalPosition": 462,
              "body": "This discussion seems regressive given that we've already decided that multiple helpers would be used to add resiliency. If we want to discuss changing course, then let's do so in an separate issue.",
              "createdAt": "2021-07-01T16:48:42Z",
              "updatedAt": "2021-07-01T16:48:56Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Njk3NTM5NjQx",
          "commit": {
            "abbreviatedOid": "6089524"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-07-01T18:22:08Z",
          "updatedAt": "2021-07-01T18:22:08Z",
          "comments": [
            {
              "originalPosition": 485,
              "body": "Why does a collector's request to get the aggregate output need to be authenticated? That seems like a deployment specific property. ",
              "createdAt": "2021-07-01T18:22:08Z",
              "updatedAt": "2021-07-01T18:22:08Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Njk3NTM5ODUx",
          "commit": {
            "abbreviatedOid": "6089524"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-07-01T18:22:27Z",
          "updatedAt": "2021-07-01T18:22:27Z",
          "comments": [
            {
              "originalPosition": 112,
              "body": "I'll raise as a separate issue as I no longer thing this is necessary to bake into the protocol this way.",
              "createdAt": "2021-07-01T18:22:27Z",
              "updatedAt": "2021-07-01T18:22:27Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Njk3NTQwMTk1",
          "commit": {
            "abbreviatedOid": "6089524"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-07-01T18:22:55Z",
          "updatedAt": "2021-07-01T18:22:55Z",
          "comments": [
            {
              "originalPosition": 201,
              "body": "We should then (a) note that as a requirement and (b) note what happens if that does not happen.",
              "createdAt": "2021-07-01T18:22:55Z",
              "updatedAt": "2021-07-01T18:22:56Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Njk3NTQwNzM1",
          "commit": {
            "abbreviatedOid": "6089524"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-07-01T18:23:42Z",
          "updatedAt": "2021-07-01T18:23:43Z",
          "comments": [
            {
              "originalPosition": 612,
              "body": "What stops the leader from altering the timestamp, then? Should it be folded into the helper AAD, perhaps?",
              "createdAt": "2021-07-01T18:23:42Z",
              "updatedAt": "2021-07-01T18:23:43Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Njk3NzE4MDQw",
          "commit": {
            "abbreviatedOid": "6089524"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-07-01T23:18:48Z",
          "updatedAt": "2021-07-01T23:46:53Z",
          "comments": [
            {
              "originalPosition": 201,
              "body": "More precisely, I think all that's required for privacy is that each aggregator needs to have a clock that's roughly in sync with true time (within batch_window seconds). Added this to \"Pre-conditions\".",
              "createdAt": "2021-07-01T23:18:48Z",
              "updatedAt": "2021-07-01T23:46:53Z"
            },
            {
              "originalPosition": 485,
              "body": "I don't think this is going to end up being deployment specific, but I'll concede the point for now.",
              "createdAt": "2021-07-01T23:21:02Z",
              "updatedAt": "2021-07-01T23:46:53Z"
            },
            {
              "originalPosition": 112,
              "body": "Done -> https://github.com/abetterinternet/prio-documents/issues/68",
              "createdAt": "2021-07-01T23:40:03Z",
              "updatedAt": "2021-07-01T23:46:53Z"
            },
            {
              "originalPosition": 462,
              "body": "Filed: https://github.com/abetterinternet/prio-documents/issues/68",
              "createdAt": "2021-07-01T23:43:32Z",
              "updatedAt": "2021-07-01T23:46:53Z"
            },
            {
              "originalPosition": 612,
              "body": "Yup, that's the idea. There's a TODO for this in \"Upload Finish Request\".",
              "createdAt": "2021-07-01T23:44:54Z",
              "updatedAt": "2021-07-01T23:46:53Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Njk3NzI4ODMy",
          "commit": {
            "abbreviatedOid": "8605ff6"
          },
          "author": "ekr",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-07-01T23:50:34Z",
          "updatedAt": "2021-07-02T00:26:15Z",
          "comments": [
            {
              "originalPosition": 148,
              "body": "The convention here is ```opaque```",
              "createdAt": "2021-07-01T23:50:34Z",
              "updatedAt": "2021-07-02T00:26:15Z"
            },
            {
              "originalPosition": 522,
              "body": "Do we understand what the contents of this might be? Are they really going to be per-request? In particular, why do we need ```proto```. Each task should just have one proto\r\n",
              "createdAt": "2021-07-02T00:02:11Z",
              "updatedAt": "2021-07-02T00:26:15Z"
            },
            {
              "originalPosition": 504,
              "body": "I'd prefer we don't describe this in this object oriented fashion. It's incredibly hard to read. Just talk about the protocol messages, not member functions.",
              "createdAt": "2021-07-02T00:02:50Z",
              "updatedAt": "2021-07-02T00:26:15Z"
            },
            {
              "originalPosition": 564,
              "body": "As noted in in issue #68 this just seems like extra complexity. The helpers for any given task should be fixed.",
              "createdAt": "2021-07-02T00:05:35Z",
              "updatedAt": "2021-07-02T00:26:15Z"
            },
            {
              "originalPosition": 608,
              "body": "What is the hpke_config_id used for? And why is it only one octet long?",
              "createdAt": "2021-07-02T00:13:05Z",
              "updatedAt": "2021-07-02T00:26:15Z"
            },
            {
              "originalPosition": 617,
              "body": "Again, why is ```proto``` being carried here? You can't change it on the fly.",
              "createdAt": "2021-07-02T00:22:42Z",
              "updatedAt": "2021-07-02T00:26:15Z"
            },
            {
              "originalPosition": 657,
              "body": "Why are you assuming that each report uses the same key_id. Suppose you had a situation in which you had a batch of a day's reports and the helper changed keys halfway through? ",
              "createdAt": "2021-07-02T00:23:49Z",
              "updatedAt": "2021-07-02T00:26:15Z"
            },
            {
              "originalPosition": 694,
              "body": "This could be avoided by just not having these fields.",
              "createdAt": "2021-07-02T00:24:15Z",
              "updatedAt": "2021-07-02T00:26:15Z"
            },
            {
              "originalPosition": 771,
              "body": "I don't see how this works and why is it just one byte?",
              "createdAt": "2021-07-02T00:26:09Z",
              "updatedAt": "2021-07-02T00:26:15Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzAwMjI0NjE0",
          "commit": {
            "abbreviatedOid": "8605ff6"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-07-06T17:44:11Z",
          "updatedAt": "2021-07-06T17:44:11Z",
          "comments": [
            {
              "originalPosition": 522,
              "body": "- PrioCollectReq would minimally have some identifier for the validity circuit and, potentially, the field.\r\n- HitsCollectReq might might specify one or two fields.",
              "createdAt": "2021-07-06T17:44:11Z",
              "updatedAt": "2021-07-06T17:44:11Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzAwMjI2NzAy",
          "commit": {
            "abbreviatedOid": "8605ff6"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-07-06T17:46:38Z",
          "updatedAt": "2021-07-06T17:56:01Z",
          "comments": [
            {
              "originalPosition": 504,
              "body": "This was @chris-wood's idea. I think it's nice, but not strictly necessary. I added a TODO to decide whether to change this.",
              "createdAt": "2021-07-06T17:46:39Z",
              "updatedAt": "2021-07-06T17:56:01Z"
            },
            {
              "originalPosition": 617,
              "body": "The structure of the rest of this message depends on the PA protocol. Maybe there's a better way to express this?",
              "createdAt": "2021-07-06T17:47:47Z",
              "updatedAt": "2021-07-06T17:56:01Z"
            },
            {
              "originalPosition": 657,
              "body": "In that case, the leader would need to split the reports into two requests.\r\n\r\n> Why are you assuming that each report uses the same key_id.\r\n\r\nIt seemed to me like it would be simpler if there's just one HPKE key used per request. \r\n\r\n> Suppose you had a situation in which you had a batch of a day's reports and the helper changed keys halfway through?\r\n\r\nThe leader would split the reports into two separate requests, one for the old key and another for the new.\r\n\r\n",
              "createdAt": "2021-07-06T17:53:45Z",
              "updatedAt": "2021-07-06T17:56:01Z"
            },
            {
              "originalPosition": 771,
              "body": "This is basically the same thing we do in ECH: there is a 1-byte config identifier that's used to inform the decrypting party which HPKE key it needs to decrypt. It's a byte only because other HPKE applications have only a byte for the config id.",
              "createdAt": "2021-07-06T17:55:54Z",
              "updatedAt": "2021-07-06T17:56:01Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzAwMjU4MzU4",
          "commit": {
            "abbreviatedOid": "3e50ed7"
          },
          "author": "ekr",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-07-06T18:26:07Z",
          "updatedAt": "2021-07-06T18:28:36Z",
          "comments": [
            {
              "originalPosition": 504,
              "body": "OK, I think it's a regression.",
              "createdAt": "2021-07-06T18:26:07Z",
              "updatedAt": "2021-07-06T18:28:36Z"
            },
            {
              "originalPosition": 522,
              "body": "I don't see why any of this needs to be per-request. They should just be fixed per-task.",
              "createdAt": "2021-07-06T18:26:38Z",
              "updatedAt": "2021-07-06T18:28:36Z"
            },
            {
              "originalPosition": 617,
              "body": "You don't need to carry that in the message. You just do like ```select (proto_in_use)``` or something and then note in the text that it's pointing to something external.",
              "createdAt": "2021-07-06T18:27:33Z",
              "updatedAt": "2021-07-06T18:28:36Z"
            },
            {
              "originalPosition": 657,
              "body": "But that might end up with a tail that could never be aggregated because it was smaller than the minimal batch size.",
              "createdAt": "2021-07-06T18:28:15Z",
              "updatedAt": "2021-07-06T18:28:36Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzAxNDQ4OTc2",
          "commit": {
            "abbreviatedOid": "3e50ed7"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-07-07T21:08:21Z",
          "updatedAt": "2021-07-07T21:16:35Z",
          "comments": [
            {
              "originalPosition": 522,
              "body": "For Hits this is also going to convey the set of candidate prefixes. It's therefore not fixed per request.",
              "createdAt": "2021-07-07T21:08:21Z",
              "updatedAt": "2021-07-07T21:16:35Z"
            },
            {
              "originalPosition": 564,
              "body": "Ack, I'm sending a PR today to rip this out.",
              "createdAt": "2021-07-07T21:08:43Z",
              "updatedAt": "2021-07-07T21:16:35Z"
            },
            {
              "originalPosition": 617,
              "body": "Added a TODO to address this later.",
              "createdAt": "2021-07-07T21:11:07Z",
              "updatedAt": "2021-07-07T21:16:35Z"
            },
            {
              "originalPosition": 657,
              "body": "Not true, since the number of \"sub-requests\" isn't necessarily the same as the batch size. The leader makes several aggregate requests and not just one.\r\n\r\nIn any case, I'm good with relaxing this constraint. Added a TODO.",
              "createdAt": "2021-07-07T21:13:00Z",
              "updatedAt": "2021-07-07T21:16:35Z"
            },
            {
              "originalPosition": 694,
              "body": "Ack, added a TODO.",
              "createdAt": "2021-07-07T21:14:32Z",
              "updatedAt": "2021-07-07T21:16:35Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzAxNDU2MjM3",
          "commit": {
            "abbreviatedOid": "b0cc270"
          },
          "author": "ekr",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-07-07T21:19:04Z",
          "updatedAt": "2021-07-07T21:19:05Z",
          "comments": [
            {
              "originalPosition": 522,
              "body": "Well, we should definitely factor out the things that are per-task and things that are per-collector-request.",
              "createdAt": "2021-07-07T21:19:05Z",
              "updatedAt": "2021-07-07T21:19:05Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzAxNDYwOTU0",
          "commit": {
            "abbreviatedOid": "b0cc270"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-07-07T21:26:05Z",
          "updatedAt": "2021-07-07T21:26:05Z",
          "comments": [
            {
              "originalPosition": 608,
              "body": "[Oops, I thought I commented on this, but somehow the comment didn't make into the queue.] We're following the precedent set by ECH here: the config id is just a byte. It's used by the decrypting party to figure out which key to use.",
              "createdAt": "2021-07-07T21:26:05Z",
              "updatedAt": "2021-07-07T21:26:05Z"
            }
          ]
        }
      ]
    },
    {
      "number": 60,
      "id": "MDExOlB1bGxSZXF1ZXN0Njc0NzExNDg4",
      "title": "Clean up Prio section and update field selection criteria",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/pull/60",
      "state": "MERGED",
      "author": "cjpatton",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "- Removes the old Prio text, which by now is out-of-date.\r\n- Addresses #32 by changing the criteria.\r\n",
      "createdAt": "2021-06-21T16:37:07Z",
      "updatedAt": "2021-06-23T20:46:19Z",
      "baseRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "baseRefName": "main",
      "baseRefOid": "ddc9e0904f1ada13935d88d69fe6575f06633b58",
      "headRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "headRefName": "cjpatton/prio-cleanup",
      "headRefOid": "afb156e233228da420168e6203c4ac3a0d4fbd3e",
      "closedAt": "2021-06-23T20:46:02Z",
      "mergedAt": "2021-06-23T20:46:01Z",
      "mergedBy": "cjpatton",
      "mergeCommit": {
        "oid": "aa4874af0ab968d514eed3859464d1a1984fd904"
      },
      "comments": [],
      "reviews": [
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Njg4ODgwMzQ3",
          "commit": {
            "abbreviatedOid": "1ee985e"
          },
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "state": "CHANGES_REQUESTED",
          "body": "",
          "createdAt": "2021-06-21T21:35:10Z",
          "updatedAt": "2021-06-21T21:38:16Z",
          "comments": [
            {
              "originalPosition": 145,
              "body": "```suggestion\r\n   roots of unity for any 1 <= a <= b. Note that b imposes an upper bound on the\r\n```",
              "createdAt": "2021-06-21T21:35:10Z",
              "updatedAt": "2021-06-21T21:38:16Z"
            },
            {
              "originalPosition": 170,
              "body": "The idea here is that we use HPKE and thus don't need to specify key encapsulation beyond a reference to https://datatracker.ietf.org/doc/draft-irtf-cfrg-hpke/?",
              "createdAt": "2021-06-21T21:38:00Z",
              "updatedAt": "2021-06-21T21:38:16Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Njg4ODg5NDgw",
          "commit": {
            "abbreviatedOid": "afb156e"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-06-21T21:50:32Z",
          "updatedAt": "2021-06-21T21:50:32Z",
          "comments": [
            {
              "originalPosition": 170,
              "body": "No, we'll need to specify this.",
              "createdAt": "2021-06-21T21:50:32Z",
              "updatedAt": "2021-06-21T21:50:32Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Njg5ODY1MDMz",
          "commit": {
            "abbreviatedOid": "afb156e"
          },
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "",
          "createdAt": "2021-06-22T18:25:19Z",
          "updatedAt": "2021-06-22T18:25:19Z",
          "comments": []
        }
      ]
    },
    {
      "number": 63,
      "id": "MDExOlB1bGxSZXF1ZXN0Njc2NjQ3MTYy",
      "title": "Make upload start request a GET",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/pull/63",
      "state": "MERGED",
      "author": "cjpatton",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "In #48 we did away with the requirement for interaction between the client and leader. This PR resolves the issue by making the upload start request an idempotent GET.",
      "createdAt": "2021-06-23T21:54:33Z",
      "updatedAt": "2021-07-07T21:37:16Z",
      "baseRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "baseRefName": "main",
      "baseRefOid": "2ddbf5ed540db63bcc6edbb469777aa70ae4fb58",
      "headRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "headRefName": "cjpatton/upload-start-get",
      "headRefOid": "cb1e5618125b891d808d7e45e13096ce0a7c2edc",
      "closedAt": "2021-07-07T21:31:23Z",
      "mergedAt": "2021-07-07T21:31:23Z",
      "mergedBy": "cjpatton",
      "mergeCommit": {
        "oid": "29f83237ad416a493a6f51a9f9bca5c40dc98c38"
      },
      "comments": [
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "Based on this week's design call (2021/7/7), \"upload start\" is likely going away altogether.",
          "createdAt": "2021-07-07T21:31:18Z",
          "updatedAt": "2021-07-07T21:31:18Z"
        }
      ],
      "reviews": [
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Njk2Njg1MDE0",
          "commit": {
            "abbreviatedOid": "8b9eebe"
          },
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "",
          "createdAt": "2021-06-30T23:04:27Z",
          "updatedAt": "2021-06-30T23:05:21Z",
          "comments": [
            {
              "originalPosition": 21,
              "body": "Our experience with caching OCSP for Let's Encrypt has been that caching POST responses is tricky because CDNs don't always support this as well as caching GETs. However we can resolve that question in #61.",
              "createdAt": "2021-06-30T23:04:27Z",
              "updatedAt": "2021-06-30T23:05:21Z"
            }
          ]
        }
      ]
    },
    {
      "number": 70,
      "id": "MDExOlB1bGxSZXF1ZXN0Njg1NTM4ODYz",
      "title": "Don't have the PA params specify multiple helpers",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/pull/70",
      "state": "MERGED",
      "author": "cjpatton",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "Partially addresses #68. (We also need to decide if/how to allow a particular PA protocol to use multiple helpers for privacy.)\r\n\r\nRight now, multiple helpers are used for redundancy in case one of the\r\nhelpers dropped out. This removes this mechanism from the core protocol.",
      "createdAt": "2021-07-07T21:59:26Z",
      "updatedAt": "2021-07-12T15:05:22Z",
      "baseRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "baseRefName": "main",
      "baseRefOid": "e2a6657e0e3328e14eb38a2789f9b91045f5cb4b",
      "headRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "headRefName": "cjpatton/undo-multiple-helpers",
      "headRefOid": "4b14883bd990377ed9c6ca5e73837db7fdf85d5a",
      "closedAt": "2021-07-12T14:47:09Z",
      "mergedAt": "2021-07-12T14:47:09Z",
      "mergedBy": "cjpatton",
      "mergeCommit": {
        "oid": "e25240af57a9056b358f4a4f35dfc3c082ed4741"
      },
      "comments": [
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "Squashed and rebased.",
          "createdAt": "2021-07-08T22:13:12Z",
          "updatedAt": "2021-07-08T22:13:12Z"
        },
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "> LGTM. Multiple helpers \"for privacy\" seems like it's inherently a per-protocol thing (Prio supports it, Hits does not). If and when we decide to address that, should we move this to the protocol-specific slot in PAParam?\r\n\r\nThat's a good idea,",
          "createdAt": "2021-07-09T16:04:41Z",
          "updatedAt": "2021-07-09T16:04:41Z"
        },
        {
          "author": "ekr",
          "authorAssociation": "COLLABORATOR",
          "body": "> LGTM. Multiple helpers \"for privacy\" seems like it's inherently a per-protocol thing (Prio supports it, Hits does not). If and when we decide to address that, should we move this to the protocol-specific slot in PAParam?\r\n\r\nHmm... Do we need to decide. Per our discussion on Wednesday, if the clients learn this out of band then we won't need this field at all because clients will get it separately and helpers don't need to know what the other helpers are, right?\r\n\r\n\r\n\r\n",
          "createdAt": "2021-07-09T17:08:00Z",
          "updatedAt": "2021-07-09T17:08:00Z"
        },
        {
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "body": "> Hmm... Do we need to decide. Per our discussion on Wednesday, if the clients learn this out of band then we won't need this field at all because clients will get it separately and helpers don't need to know what the other helpers are, right?\r\n\r\nMy takeaway is that the parameters must contain all input needed to run the protocol, including the helpers. And all of this is configured out of band. You could punt everything except for the cryptographic goop out of the parameters structure, forcing clients to know the leader and helper and get their public keys out of band as well, which would be fine. It's just different. I think both work just fine, but I lean towards having params specify everything. It just seems simpler to me.\r\n\r\nThat said... making public key discovery part of the client upload protocol here _is_ more complex, I think. So, \ud83e\udd37. ",
          "createdAt": "2021-07-09T17:24:11Z",
          "updatedAt": "2021-07-09T17:26:34Z"
        },
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "Squashed.",
          "createdAt": "2021-07-12T14:43:32Z",
          "updatedAt": "2021-07-12T14:43:32Z"
        }
      ],
      "reviews": [
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzAzMTA5NzYx",
          "commit": {
            "abbreviatedOid": "0d656ee"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "LGTM. Multiple helpers \"for privacy\" seems like it's inherently a per-protocol thing (Prio supports it, Hits does not). If and when we decide to address that, should we move this to the protocol-specific slot in PAParam?",
          "createdAt": "2021-07-09T14:29:22Z",
          "updatedAt": "2021-07-09T14:30:59Z",
          "comments": [
            {
              "originalPosition": 50,
              "body": "```suggestion\r\nmessage. The client aborts if any of the following happen:\r\n```",
              "createdAt": "2021-07-09T14:29:22Z",
              "updatedAt": "2021-07-09T14:30:59Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzAzMjAzMTEw",
          "commit": {
            "abbreviatedOid": "27ff023"
          },
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "",
          "createdAt": "2021-07-09T16:12:00Z",
          "updatedAt": "2021-07-09T16:12:00Z",
          "comments": []
        }
      ]
    },
    {
      "number": 71,
      "id": "MDExOlB1bGxSZXF1ZXN0Njg1NTQwNDAz",
      "title": "Editorial",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/pull/71",
      "state": "MERGED",
      "author": "cjpatton",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "Updating authors' comments",
      "createdAt": "2021-07-07T22:02:42Z",
      "updatedAt": "2021-07-12T15:05:15Z",
      "baseRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "baseRefName": "main",
      "baseRefOid": "fa4707ebad34820f3cd2aeebfbbd9b6edf1ef02f",
      "headRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "headRefName": "editorial",
      "headRefOid": "43121c2c0ce8c4dbb334322b0f247f7cece34f1a",
      "closedAt": "2021-07-08T22:06:53Z",
      "mergedAt": "2021-07-08T22:06:53Z",
      "mergedBy": "cjpatton",
      "mergeCommit": {
        "oid": "e2a6657e0e3328e14eb38a2789f9b91045f5cb4b"
      },
      "comments": [
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "Rebased and squashed.",
          "createdAt": "2021-07-08T22:06:42Z",
          "updatedAt": "2021-07-08T22:06:42Z"
        }
      ],
      "reviews": [
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzAxNDg3MDUw",
          "commit": {
            "abbreviatedOid": "90ac29d"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "",
          "createdAt": "2021-07-07T22:09:08Z",
          "updatedAt": "2021-07-07T22:10:04Z",
          "comments": [
            {
              "originalPosition": 43,
              "body": "```suggestion\r\nserver-authenticated secure channel over which the request is made.)\r\n```",
              "createdAt": "2021-07-07T22:09:09Z",
              "updatedAt": "2021-07-07T22:10:04Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzAyNTIyNjU4",
          "commit": {
            "abbreviatedOid": "30ca601"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "",
          "createdAt": "2021-07-08T21:40:18Z",
          "updatedAt": "2021-07-08T21:40:18Z",
          "comments": []
        }
      ]
    },
    {
      "number": 73,
      "id": "MDExOlB1bGxSZXF1ZXN0Njg1NTc1OTI3",
      "title": "Encrypt the leader's share as well",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/pull/73",
      "state": "MERGED",
      "author": "cjpatton",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "Based on #70 (review that first).\r\nCloses #69.",
      "createdAt": "2021-07-07T23:31:02Z",
      "updatedAt": "2021-07-12T15:05:20Z",
      "baseRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "baseRefName": "main",
      "baseRefOid": "e25240af57a9056b358f4a4f35dfc3c082ed4741",
      "headRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "headRefName": "cjpatton/encrypt-leader-share",
      "headRefOid": "8661a987fa275363e047772817b848832098c952",
      "closedAt": "2021-07-12T15:04:33Z",
      "mergedAt": "2021-07-12T15:04:33Z",
      "mergedBy": "cjpatton",
      "mergeCommit": {
        "oid": "e0d1e7c1985adf398b9c58dd977c9ffa1b3aa1da"
      },
      "comments": [
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "Squashed and rebased.",
          "createdAt": "2021-07-09T00:37:59Z",
          "updatedAt": "2021-07-09T00:37:59Z"
        },
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "Rebased.",
          "createdAt": "2021-07-12T15:01:06Z",
          "updatedAt": "2021-07-12T15:01:06Z"
        },
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "Squashed.",
          "createdAt": "2021-07-12T15:03:34Z",
          "updatedAt": "2021-07-12T15:03:34Z"
        }
      ],
      "reviews": [
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzAxNTQ5ODg4",
          "commit": {
            "abbreviatedOid": "d021dfe"
          },
          "author": "ekr",
          "authorAssociation": "COLLABORATOR",
          "state": "CHANGES_REQUESTED",
          "body": "",
          "createdAt": "2021-07-08T00:40:35Z",
          "updatedAt": "2021-07-08T00:44:56Z",
          "comments": [
            {
              "originalPosition": 59,
              "body": "Hmm.... So how does this work if the client can't connect to the leader.",
              "createdAt": "2021-07-08T00:40:35Z",
              "updatedAt": "2021-07-08T00:44:56Z"
            },
            {
              "originalPosition": 87,
              "body": "This seems like a good opportunity to just be:\r\n\r\n```\r\nPAEncryptedInputShare shares<...>;\r\n```\r\n\r\nThat is like the least we can do to lay the groundwork for >1 helper.",
              "createdAt": "2021-07-08T00:41:32Z",
              "updatedAt": "2021-07-08T00:44:56Z"
            },
            {
              "originalPosition": 175,
              "body": "This is another opportunity to avoid duplication, but just talking about aggregators.",
              "createdAt": "2021-07-08T00:43:24Z",
              "updatedAt": "2021-07-08T00:44:56Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzAyMzQ2NDU1",
          "commit": {
            "abbreviatedOid": "d021dfe"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-07-08T17:50:08Z",
          "updatedAt": "2021-07-08T20:49:25Z",
          "comments": [
            {
              "originalPosition": 59,
              "body": "It doesn't :) The leader needs to be online for the client to be able to upload a report. (This was already the case before this PR.)",
              "createdAt": "2021-07-08T17:50:08Z",
              "updatedAt": "2021-07-08T20:49:25Z"
            },
            {
              "originalPosition": 87,
              "body": "Done.",
              "createdAt": "2021-07-08T20:48:02Z",
              "updatedAt": "2021-07-08T20:49:25Z"
            },
            {
              "originalPosition": 175,
              "body": "Done.",
              "createdAt": "2021-07-08T20:49:05Z",
              "updatedAt": "2021-07-08T20:49:25Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzAyNDkxMTM0",
          "commit": {
            "abbreviatedOid": "b1b4f7f"
          },
          "author": "ekr",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "",
          "createdAt": "2021-07-08T20:53:28Z",
          "updatedAt": "2021-07-08T20:53:50Z",
          "comments": [
            {
              "originalPosition": 47,
              "body": "Yeah, you can't do this in the TLS syntax. I would just say this stuff verbally\r\n\"Of the appropriate share type for the protocol and role\" down on line 593 below.",
              "createdAt": "2021-07-08T20:53:28Z",
              "updatedAt": "2021-07-08T20:53:51Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzAyNTAzNzY2",
          "commit": {
            "abbreviatedOid": "b1b4f7f"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-07-08T21:10:53Z",
          "updatedAt": "2021-07-08T21:11:33Z",
          "comments": [
            {
              "originalPosition": 47,
              "body": "Removed the PAInputShare structure altogether and clarified above that the the format of the input share depends on the protocol and aggreagtor role.",
              "createdAt": "2021-07-08T21:10:53Z",
              "updatedAt": "2021-07-08T21:11:33Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzAyNTA1MTM5",
          "commit": {
            "abbreviatedOid": "e729056"
          },
          "author": "ekr",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "",
          "createdAt": "2021-07-08T21:12:58Z",
          "updatedAt": "2021-07-08T22:02:12Z",
          "comments": [
            {
              "originalPosition": 59,
              "body": "Right. I think I'm wondering if this feedback channel is actually helpful.",
              "createdAt": "2021-07-08T21:12:59Z",
              "updatedAt": "2021-07-08T22:02:12Z"
            },
            {
              "originalPosition": 117,
              "body": "nit: isn't this 7..2^16-1:\r\n\r\n1 for config id\r\n2 each for the lengths of enc and payload\r\n1 each for the minimum size of length and payload.",
              "createdAt": "2021-07-08T22:00:57Z",
              "updatedAt": "2021-07-08T22:02:12Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzAyNTM5OTk1",
          "commit": {
            "abbreviatedOid": "252caf1"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-07-08T22:10:33Z",
          "updatedAt": "2021-07-08T22:10:34Z",
          "comments": [
            {
              "originalPosition": 117,
              "body": "Yeah, well, we'll need to fix up the bounds elsewhere as well. I'll add a TODO to handle this later, once the protocol gets closer to settled.",
              "createdAt": "2021-07-08T22:10:33Z",
              "updatedAt": "2021-07-08T22:10:34Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzAyNTQwMTgx",
          "commit": {
            "abbreviatedOid": "252caf1"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-07-08T22:10:54Z",
          "updatedAt": "2021-07-08T22:10:54Z",
          "comments": [
            {
              "originalPosition": 59,
              "body": "What do you mean by \"feedback channel\"?",
              "createdAt": "2021-07-08T22:10:54Z",
              "updatedAt": "2021-07-08T22:10:54Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzAyNTQ5MDUx",
          "commit": {
            "abbreviatedOid": "252caf1"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-07-08T22:28:58Z",
          "updatedAt": "2021-07-08T22:28:59Z",
          "comments": [
            {
              "originalPosition": 59,
              "body": "I assume he means the alert from client to leader. What is the leader actually supposed to do with that information?",
              "createdAt": "2021-07-08T22:28:58Z",
              "updatedAt": "2021-07-08T22:28:59Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzAyNTkyNzY4",
          "commit": {
            "abbreviatedOid": "805aa1b"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-07-09T00:23:34Z",
          "updatedAt": "2021-07-09T00:23:34Z",
          "comments": [
            {
              "originalPosition": 59,
              "body": "Ah yes, good call. I removed the alert.",
              "createdAt": "2021-07-09T00:23:34Z",
              "updatedAt": "2021-07-09T00:23:34Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzAzMjA2NDEw",
          "commit": {
            "abbreviatedOid": "b603894"
          },
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "",
          "createdAt": "2021-07-09T16:16:12Z",
          "updatedAt": "2021-07-09T16:16:12Z",
          "comments": []
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzAzMzkzOTA1",
          "commit": {
            "abbreviatedOid": "b603894"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "LGTM with #75 spun out!",
          "createdAt": "2021-07-09T21:08:41Z",
          "updatedAt": "2021-07-09T21:14:55Z",
          "comments": [
            {
              "originalPosition": 120,
              "body": "```suggestion\r\n  PATask task;\r\n```\r\n(There is no more UploadStartReq, right?)",
              "createdAt": "2021-07-09T21:08:41Z",
              "updatedAt": "2021-07-09T21:14:55Z"
            },
            {
              "originalPosition": 191,
              "body": "I filed #75 to follow up on this, but: what good is authenticating the timestamp if the client can just lie about it?",
              "createdAt": "2021-07-09T21:13:45Z",
              "updatedAt": "2021-07-09T21:14:55Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzA0MTgwNTg3",
          "commit": {
            "abbreviatedOid": "b603894"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-07-12T14:27:42Z",
          "updatedAt": "2021-07-12T14:27:42Z",
          "comments": [
            {
              "originalPosition": 191,
              "body": "Authenticating the timestamp is for the client's sake. It's meant to ensure its report is only used for a single batch.",
              "createdAt": "2021-07-12T14:27:42Z",
              "updatedAt": "2021-07-12T14:27:43Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzA0MTgxMDE1",
          "commit": {
            "abbreviatedOid": "b603894"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-07-12T14:28:03Z",
          "updatedAt": "2021-07-12T14:28:03Z",
          "comments": [
            {
              "originalPosition": 120,
              "body": "There is, as of this PR.",
              "createdAt": "2021-07-12T14:28:03Z",
              "updatedAt": "2021-07-12T14:28:04Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzA0MTg0NDY3",
          "commit": {
            "abbreviatedOid": "b603894"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-07-12T14:30:51Z",
          "updatedAt": "2021-07-12T14:30:52Z",
          "comments": [
            {
              "originalPosition": 191,
              "body": "Hmm, I don't really see how it helps the client at all. Can you elaborate?",
              "createdAt": "2021-07-12T14:30:51Z",
              "updatedAt": "2021-07-12T14:30:52Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzA0MTk1NDY5",
          "commit": {
            "abbreviatedOid": "b603894"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-07-12T14:40:17Z",
          "updatedAt": "2021-07-12T14:40:17Z",
          "comments": [
            {
              "originalPosition": 191,
              "body": "The idea was discussed a few weeks ago, but hasn't been fully fleshed out. Basically the PA parameters specify a batch window [batch_start, batch_end). To check that a report should be added to a batch, an aggregator decrypts its input share. Decryption will fail if the reported timestamp doesn't match the timestamp generated by the client. This ensures that an honest aggregator only includes an input share in a batch if the timestamp is in the batch window.",
              "createdAt": "2021-07-12T14:40:17Z",
              "updatedAt": "2021-07-12T14:40:32Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzA0MjAwNTA1",
          "commit": {
            "abbreviatedOid": "b603894"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-07-12T14:44:30Z",
          "updatedAt": "2021-07-12T14:44:30Z",
          "comments": [
            {
              "originalPosition": 191,
              "body": "I get that, but how does this benefit the _client_? (We should just take this to #75.)",
              "createdAt": "2021-07-12T14:44:30Z",
              "updatedAt": "2021-07-12T14:44:30Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzA0MjAxMzAw",
          "commit": {
            "abbreviatedOid": "b603894"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-07-12T14:45:11Z",
          "updatedAt": "2021-07-12T14:45:11Z",
          "comments": [
            {
              "originalPosition": 120,
              "body": "I may be missing something then. I don't see PAUploadStartReq defined in this PR's diff?",
              "createdAt": "2021-07-12T14:45:11Z",
              "updatedAt": "2021-07-12T14:45:11Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzA0MjE3NzEz",
          "commit": {
            "abbreviatedOid": "b603894"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-07-12T14:58:55Z",
          "updatedAt": "2021-07-12T14:58:55Z",
          "comments": [
            {
              "originalPosition": 191,
              "body": "Done.",
              "createdAt": "2021-07-12T14:58:55Z",
              "updatedAt": "2021-07-12T14:58:55Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzA0MjIyNTU1",
          "commit": {
            "abbreviatedOid": "109e97a"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-07-12T15:02:55Z",
          "updatedAt": "2021-07-12T15:02:55Z",
          "comments": [
            {
              "originalPosition": 120,
              "body": "Ohhh right! The message got removed, but the \"upload start\" flow still exists. Good call :)",
              "createdAt": "2021-07-12T15:02:55Z",
              "updatedAt": "2021-07-12T15:02:55Z"
            }
          ]
        }
      ]
    },
    {
      "number": 74,
      "id": "MDExOlB1bGxSZXF1ZXN0Njg1NTgxODI2",
      "title": "Add a length field to PAParam",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/pull/74",
      "state": "MERGED",
      "author": "cjpatton",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "Closes #66.\r\n\r\nThis ensures that this structure can be parsed once we add more PAProto variants.",
      "createdAt": "2021-07-07T23:49:39Z",
      "updatedAt": "2021-07-12T15:05:12Z",
      "baseRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "baseRefName": "main",
      "baseRefOid": "29f83237ad416a493a6f51a9f9bca5c40dc98c38",
      "headRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "headRefName": "cjpatton/pa-param-length",
      "headRefOid": "98c4338798bf6414b07ea59114b8aa161cc2983f",
      "closedAt": "2021-07-08T12:15:42Z",
      "mergedAt": "2021-07-08T12:15:42Z",
      "mergedBy": "chris-wood",
      "mergeCommit": {
        "oid": "fa4707ebad34820f3cd2aeebfbbd9b6edf1ef02f"
      },
      "comments": [],
      "reviews": [
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzAxNTUxNDg3",
          "commit": {
            "abbreviatedOid": "98c4338"
          },
          "author": "ekr",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "LGTM",
          "createdAt": "2021-07-08T00:45:28Z",
          "updatedAt": "2021-07-08T00:45:28Z",
          "comments": []
        }
      ]
    },
    {
      "number": 76,
      "id": "MDExOlB1bGxSZXF1ZXN0Njg3OTUwMTA2",
      "title": "Derive task id and remove doc version",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/pull/76",
      "state": "MERGED",
      "author": "cjpatton",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "Closes #67 by removing the `version` field from each of the protocol messages.\r\nPartially addresses #72 by establishing that the task id is derived from the PA parameters for a task. We still need to specify this procedure.",
      "createdAt": "2021-07-12T15:33:38Z",
      "updatedAt": "2021-07-13T18:54:04Z",
      "baseRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "baseRefName": "main",
      "baseRefOid": "e0d1e7c1985adf398b9c58dd977c9ffa1b3aa1da",
      "headRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "headRefName": "cjpatton/derive-task-id",
      "headRefOid": "0460f73dc27872038aa952821d272b83f26b69af",
      "closedAt": "2021-07-13T18:54:04Z",
      "mergedAt": "2021-07-13T18:54:04Z",
      "mergedBy": "chris-wood",
      "mergeCommit": {
        "oid": "adf34141a918e5019d327f67f3ba50bc52ed2457"
      },
      "comments": [],
      "reviews": [
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzA0MjYwMTA0",
          "commit": {
            "abbreviatedOid": "0460f73"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "",
          "createdAt": "2021-07-12T15:35:42Z",
          "updatedAt": "2021-07-12T15:36:47Z",
          "comments": [
            {
              "originalPosition": 44,
              "body": "Can we follow up on this in a new issue? What's the motivation to remove this?",
              "createdAt": "2021-07-12T15:35:42Z",
              "updatedAt": "2021-07-12T15:36:47Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzA0MjY3MjUx",
          "commit": {
            "abbreviatedOid": "0460f73"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-07-12T15:42:29Z",
          "updatedAt": "2021-07-12T15:42:29Z",
          "comments": [
            {
              "originalPosition": 44,
              "body": "It was brought up here: https://github.com/abetterinternet/prio-documents/issues/65",
              "createdAt": "2021-07-12T15:42:29Z",
              "updatedAt": "2021-07-12T15:42:29Z"
            }
          ]
        }
      ]
    },
    {
      "number": 77,
      "id": "MDExOlB1bGxSZXF1ZXN0Njg3OTc0Nzk1",
      "title": "Refactor upload request",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/pull/77",
      "state": "MERGED",
      "author": "cjpatton",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "Based on #76 (review that first).\r\nPartially addresses #65.\r\n\r\n* Assume the client knows PAParam ahead of time, per issue#65.\r\n* Add leader URL to PAParam so that client can request its key config.\r\n* Get rid of upload start request.",
      "createdAt": "2021-07-12T16:06:56Z",
      "updatedAt": "2021-08-04T17:43:54Z",
      "baseRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "baseRefName": "cjpatton/derive-task-id",
      "baseRefOid": "0460f73dc27872038aa952821d272b83f26b69af",
      "headRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "headRefName": "cjpatton/upload-refactor",
      "headRefOid": "d80c7156c65fdcfc34bab0a21dfe63511295500a",
      "closedAt": "2021-07-13T18:54:37Z",
      "mergedAt": "2021-07-13T18:54:36Z",
      "mergedBy": "chris-wood",
      "mergeCommit": {
        "oid": "3585f951e7d7d3847f092b9a8842f5cb764de0dd"
      },
      "comments": [],
      "reviews": [
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzA0MzA0OTAw",
          "commit": {
            "abbreviatedOid": "d80c715"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "",
          "createdAt": "2021-07-12T16:18:42Z",
          "updatedAt": "2021-07-12T16:18:42Z",
          "comments": []
        }
      ]
    },
    {
      "number": 78,
      "id": "MDExOlB1bGxSZXF1ZXN0Njg4MDE3Nzgy",
      "title": "Allow multiple reports in the same upload request",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/pull/78",
      "state": "CLOSED",
      "author": "cjpatton",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "Based on #77 (review that first).\r\nCloses #64.\r\n\r\ncc/ @csharrison",
      "createdAt": "2021-07-12T17:09:37Z",
      "updatedAt": "2021-12-30T02:10:01Z",
      "baseRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "baseRefName": "cjpatton/upload-refactor",
      "baseRefOid": "d80c7156c65fdcfc34bab0a21dfe63511295500a",
      "headRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "headRefName": "cjpatton/batched-upload",
      "headRefOid": "78b0e191584195e96bd23d1e4a1697b6f2ceb686",
      "closedAt": "2021-07-14T17:59:58Z",
      "mergedAt": null,
      "mergedBy": null,
      "mergeCommit": null,
      "comments": [
        {
          "author": "ekr",
          "authorAssociation": "COLLABORATOR",
          "body": "I actually don't understand what the benefit of this is. I see why you would want to do multiple submissions in a batch, but modern networking protocols such as H2 and H3 can do multiple concurrent HTTP requests in parallel, so why not just do one report at a time?",
          "createdAt": "2021-07-12T17:22:42Z",
          "updatedAt": "2021-07-12T17:22:42Z"
        },
        {
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "body": "> I actually don't understand what the benefit of this is.\r\n\r\nI see it as purely an optimization to avoid sending the task ID over and over for large batches. ",
          "createdAt": "2021-07-12T17:25:13Z",
          "updatedAt": "2021-07-12T17:25:13Z"
        },
        {
          "author": "ekr",
          "authorAssociation": "COLLABORATOR",
          "body": "> I see it as purely an optimization to avoid sending the task ID over and over for large batches.\r\n\r\nHmm... The task ID is in general going to be quite small compared to almost any report, right? I mean, just the crypto overhead is going to be order 48 bytes.",
          "createdAt": "2021-07-12T17:31:27Z",
          "updatedAt": "2021-07-12T17:31:27Z"
        },
        {
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "body": "> Hmm... The task ID is in general going to be quite small compared to almost any report, right? I mean, just the crypto overhead is going to be order 48 bytes.\r\n\r\nIt is -- I didn't say it was the most _useful_ optimization ;)",
          "createdAt": "2021-07-12T17:32:14Z",
          "updatedAt": "2021-07-12T17:32:14Z"
        },
        {
          "author": "csharrison",
          "authorAssociation": "CONTRIBUTOR",
          "body": "cc @hostirosti FYI. I like that this matches the mechanism we use to implement batch uploads from leader -> helper. Whatever future optimizations we implement for that could be useful here too (e.g. if we move away from HTTP POST and pass some file handle thing).",
          "createdAt": "2021-07-12T17:52:55Z",
          "updatedAt": "2021-07-12T17:52:55Z"
        },
        {
          "author": "ekr",
          "authorAssociation": "COLLABORATOR",
          "body": "I don't understand why moving away from POST will make things better. The vast amount of HTTP overhead is just moving the actual data around.\r\n\r\nIn any case, this seems like a case of adding protocol complexity for very little additional value, so I think we should not merge it.",
          "createdAt": "2021-07-12T21:58:59Z",
          "updatedAt": "2021-07-12T21:58:59Z"
        },
        {
          "author": "hostirosti",
          "authorAssociation": "NONE",
          "body": "We should also look at this from the server side, yes with HTTP/2 you can have non-blocking parallel connections yet the server side needs to be able to handle the amount of connections as well, every connection carries overhead for establishing the connection (TCP, TLS handshake, ...). So reducing the number of connections from the client side will have a benefit for cost and operation on the server side, after all we talk 10^5s to millions of clients here. I'd definitely recommend reusing the connection and if that means batching, use batching. Since H2 supports streaming and if streaming individual reports is easier this should not add much additional overhead (other than redundant info we'd need for each report instead of once per batch) on the connection side I assume.",
          "createdAt": "2021-07-13T19:53:50Z",
          "updatedAt": "2021-07-13T19:56:52Z"
        },
        {
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "body": "@hostirosti I think @ekr's point is that you can do batching _within_ the protocol, as is proposed in this PR, or outside the protocol using independent HTTP streams. In both cases, the number of client<>server connections remains the same, right?",
          "createdAt": "2021-07-13T21:36:50Z",
          "updatedAt": "2021-07-13T21:36:50Z"
        },
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "In the 2021/7/14 call we decided to \"park\" this change for now. We all agree that the issue needs to be addressed, i.e., that an entity (client or collector) should be able to upload multiple reports. We haven't decided on whether these should be in the same HTTP request.",
          "createdAt": "2021-07-14T17:59:45Z",
          "updatedAt": "2021-07-14T17:59:45Z"
        }
      ],
      "reviews": [
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzA0MzU3ODU0",
          "commit": {
            "abbreviatedOid": "78b0e19"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "",
          "createdAt": "2021-07-12T17:16:02Z",
          "updatedAt": "2021-07-12T17:16:02Z",
          "comments": []
        }
      ]
    },
    {
      "number": 79,
      "id": "MDExOlB1bGxSZXF1ZXN0Njg4MDQxNjM0",
      "title": "Clean up aggregate sub-request handling",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/pull/79",
      "state": "MERGED",
      "author": "cjpatton",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "* Update the aggregate request text to reflect recent protocol changes.\r\n* Relax the requirement that all sub-requests use the same key config.\r\n* Do https://github.com/abetterinternet/prio-documents/pull/77, which was previously merged into the wrong branch.",
      "createdAt": "2021-07-12T17:40:10Z",
      "updatedAt": "2021-08-04T17:43:52Z",
      "baseRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "baseRefName": "main",
      "baseRefOid": "a9fb326f52273e6aafd1cb148d3dfbaeb607b7c6",
      "headRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "headRefName": "cjpatton/aggregate-request-relaxation",
      "headRefOid": "ad015cc6e9d60363c8ef69d23f645ef9482a3b7d",
      "closedAt": "2021-07-14T18:24:59Z",
      "mergedAt": "2021-07-14T18:24:59Z",
      "mergedBy": "chris-wood",
      "mergeCommit": {
        "oid": "3f47963fcc220ac3c844fbad89638e22c57dd3fd"
      },
      "comments": [
        {
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "body": "@tgeoghegan, @ekr: please have a look when you can.",
          "createdAt": "2021-07-13T19:00:03Z",
          "updatedAt": "2021-07-13T19:00:03Z"
        }
      ],
      "reviews": [
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzA0NDE0NTM4",
          "commit": {
            "abbreviatedOid": "a2c64ff"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "",
          "createdAt": "2021-07-12T18:22:17Z",
          "updatedAt": "2021-07-12T18:25:05Z",
          "comments": [
            {
              "originalPosition": 4,
              "body": "\u2764\ufe0f ",
              "createdAt": "2021-07-12T18:22:17Z",
              "updatedAt": "2021-07-12T18:25:05Z"
            }
          ]
        }
      ]
    },
    {
      "number": 80,
      "id": "MDExOlB1bGxSZXF1ZXN0Njg5MzIzNzUx",
      "title": "Add timestamp rationale.",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/pull/80",
      "state": "MERGED",
      "author": "chris-wood",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "Partially addresses #75 via clarification. Intra-batch replay attacks need more text.",
      "createdAt": "2021-07-13T18:56:51Z",
      "updatedAt": "2021-12-30T02:10:05Z",
      "baseRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "baseRefName": "main",
      "baseRefOid": "adf34141a918e5019d327f67f3ba50bc52ed2457",
      "headRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "headRefName": "caw/timestamp-rationale",
      "headRefOid": "8e4c429a5c7c8eaf5708d254f9cc7054f14fc1fb",
      "closedAt": "2021-07-14T17:52:01Z",
      "mergedAt": "2021-07-14T17:52:01Z",
      "mergedBy": "chris-wood",
      "mergeCommit": {
        "oid": "a9fb326f52273e6aafd1cb148d3dfbaeb607b7c6"
      },
      "comments": [
        {
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "body": "@cjpatton I was going to file a separate issue to discuss it. Stay tuned!",
          "createdAt": "2021-07-13T19:13:45Z",
          "updatedAt": "2021-07-13T19:13:45Z"
        }
      ],
      "reviews": [
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzA1NTU0MTg0",
          "commit": {
            "abbreviatedOid": "8e4c429"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "Might be worth adding an OPEN ISSUE to note the inter-batch replay attack we talked about yesterday.",
          "createdAt": "2021-07-13T19:11:58Z",
          "updatedAt": "2021-07-13T19:11:58Z",
          "comments": []
        }
      ]
    },
    {
      "number": 83,
      "id": "MDExOlB1bGxSZXF1ZXN0NjkwMjAwMzA4",
      "title": "s/PA/PDA/g",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/pull/83",
      "state": "MERGED",
      "author": "cjpatton",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "",
      "createdAt": "2021-07-14T20:22:34Z",
      "updatedAt": "2021-08-04T17:43:50Z",
      "baseRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "baseRefName": "main",
      "baseRefOid": "3f47963fcc220ac3c844fbad89638e22c57dd3fd",
      "headRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "headRefName": "cjpatton/editorial",
      "headRefOid": "641088ede02e3b80a3f5f2afa3114f0c4f244bd4",
      "closedAt": "2021-07-14T20:49:14Z",
      "mergedAt": "2021-07-14T20:49:14Z",
      "mergedBy": "cjpatton",
      "mergeCommit": {
        "oid": "f00398767e2ce563b88cf3a6e603bb2f8a17732f"
      },
      "comments": [
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "Squashed.",
          "createdAt": "2021-07-14T20:48:37Z",
          "updatedAt": "2021-07-14T20:48:37Z"
        }
      ],
      "reviews": [
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzA2Njk0MTk1",
          "commit": {
            "abbreviatedOid": "494b2e5"
          },
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "LGTM modulo one nit",
          "createdAt": "2021-07-14T20:32:30Z",
          "updatedAt": "2021-07-14T20:36:47Z",
          "comments": [
            {
              "originalPosition": 5,
              "body": "```suggestion\r\n*private data aggregation (PDA) protocol* is to compute `y = F(x_1, ..., x_n)` for\r\n```",
              "createdAt": "2021-07-14T20:32:31Z",
              "updatedAt": "2021-07-14T20:36:47Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzA2NzA1Mzkw",
          "commit": {
            "abbreviatedOid": "494b2e5"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-07-14T20:46:47Z",
          "updatedAt": "2021-07-14T20:46:47Z",
          "comments": [
            {
              "originalPosition": 5,
              "body": "Good catch",
              "createdAt": "2021-07-14T20:46:47Z",
              "updatedAt": "2021-07-14T20:46:47Z"
            }
          ]
        }
      ]
    },
    {
      "number": 84,
      "id": "MDExOlB1bGxSZXF1ZXN0NjkwMjQ1NTI0",
      "title": "Tidy and expand security considerations",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/pull/84",
      "state": "MERGED",
      "author": "tgeoghegan",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "Cleans up the \"Security Considerations\" section which had some excessive nesting and adds content to address #15 and #58",
      "createdAt": "2021-07-14T21:45:45Z",
      "updatedAt": "2021-12-30T00:53:25Z",
      "baseRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "baseRefName": "main",
      "baseRefOid": "989cea565fbeaf0dcc7f5f9ac7f7cf0f3446a246",
      "headRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "headRefName": "timg/security-considerations",
      "headRefOid": "6a05ef00e84c1537fa8e1cbdbd966313c6d4bd6a",
      "closedAt": "2021-07-28T21:24:37Z",
      "mergedAt": "2021-07-28T21:24:37Z",
      "mergedBy": "tgeoghegan",
      "mergeCommit": {
        "oid": "dd4aeffbfbb9245fff64f1eccff16d35e7cdf07e"
      },
      "comments": [],
      "reviews": [
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzA3NzY3NTE1",
          "commit": {
            "abbreviatedOid": "6cd5910"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "CHANGES_REQUESTED",
          "body": "",
          "createdAt": "2021-07-15T19:58:29Z",
          "updatedAt": "2021-07-15T20:00:17Z",
          "comments": [
            {
              "originalPosition": 194,
              "body": "Depending on how authentication is implemented, it might end up deanonmyzing clients that go through an an anomyzing proxy service like OHTTP.  For instance, suppose clients just sign their reports, and the leader is supposed to look up their public key to check the signature. Of course, anonymous credentials are possible, e.g., one of the myriad DAA schemes implemented by TPMs these days.\r\n\r\nIn any case, I think we want to decouple these things. OHTTP may be useful *independently* of client authentication. ",
              "createdAt": "2021-07-15T19:58:30Z",
              "updatedAt": "2021-07-15T20:00:17Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzE3NDcyNDA3",
          "commit": {
            "abbreviatedOid": "9c04a9e"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "I suggest we remove the client auth stuff atogether and punt to the PR we discussed today, then merge this bad boy.",
          "createdAt": "2021-07-28T21:15:03Z",
          "updatedAt": "2021-07-28T21:16:05Z",
          "comments": [
            {
              "originalPosition": 26,
              "body": "On today's call (2021/07/28) we decided to address issue#89 by sticking in an opaque blob that deployment can use for attestation purposes. I think we should just remove this section and replace it with:\r\n```\r\n## Client Attestation\r\n[TODO: Solve issue#89]\r\n```\r\nThen we can fully address it in a follow-on PR.",
              "createdAt": "2021-07-28T21:15:04Z",
              "updatedAt": "2021-07-28T21:15:48Z"
            }
          ]
        }
      ]
    },
    {
      "number": 87,
      "id": "MDExOlB1bGxSZXF1ZXN0NjkwOTE2NTUz",
      "title": "clarify PATaskID derivation",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/pull/87",
      "state": "MERGED",
      "author": "tgeoghegan",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "Resolves #72",
      "createdAt": "2021-07-15T17:38:09Z",
      "updatedAt": "2021-12-30T00:53:23Z",
      "baseRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "baseRefName": "main",
      "baseRefOid": "f00398767e2ce563b88cf3a6e603bb2f8a17732f",
      "headRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "headRefName": "timg/pda-params-uniqueness",
      "headRefOid": "98c2954cbc5befcc17eae3d1cb750cda86612228",
      "closedAt": "2021-07-20T17:54:50Z",
      "mergedAt": "2021-07-20T17:54:50Z",
      "mergedBy": "tgeoghegan",
      "mergeCommit": {
        "oid": "a55f71ac65e531a7a4e7c10ab83307be08032586"
      },
      "comments": [
        {
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "body": "> Approved, with the following suggestion: Let's leave a [TODO: ...] comment under the definition of `nonce` for clarifying how it should be chosen.\r\n\r\nI added a clarification that the nonce is random. IMO the question of *who* randomly generates the nonce goes with the question of how participants agree upon PDAParams, which is to say it's outside the protocol.",
          "createdAt": "2021-07-15T21:22:48Z",
          "updatedAt": "2021-07-15T21:22:48Z"
        }
      ],
      "reviews": [
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzA3NzcxMDgx",
          "commit": {
            "abbreviatedOid": "2e7348c"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "Approved, with the following suggestion: Let's leave a [TODO: ...] comment under the definition of `nonce` for clarifying how it should be chosen.",
          "createdAt": "2021-07-15T20:02:51Z",
          "updatedAt": "2021-07-15T20:02:51Z",
          "comments": []
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzEwMDY3NjA0",
          "commit": {
            "abbreviatedOid": "549388e"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "",
          "createdAt": "2021-07-19T23:41:55Z",
          "updatedAt": "2021-07-19T23:46:11Z",
          "comments": [
            {
              "originalPosition": 34,
              "body": "```suggestion\r\nThe task ID is of a `PDAParam` instance `param` is derived using the following procedure:\r\n\r\n~~~\r\ntask_id = SHA-256(param)\r\n~~~\r\n```\r\n\r\nWhere SHA-256 is as specified in {{FIPS180-4}}.",
              "createdAt": "2021-07-19T23:41:55Z",
              "updatedAt": "2021-07-19T23:46:11Z"
            },
            {
              "originalPosition": 12,
              "body": "```suggestion\r\n* `nonce`: A unique sequence of bytes used to ensure that two otherwise\r\n```",
              "createdAt": "2021-07-19T23:43:28Z",
              "updatedAt": "2021-07-19T23:46:11Z"
            },
            {
              "originalPosition": 13,
              "body": "```suggestion\r\n  identical `PDAParam` instances will have distinct `PDATaskID`s. It is RECOMMENDED\r\n  that this be set to a random 16-byte string derived from a cryptographically secure \r\n  pseudorandom number generator.\r\n```",
              "createdAt": "2021-07-19T23:45:57Z",
              "updatedAt": "2021-07-19T23:46:11Z"
            }
          ]
        }
      ]
    },
    {
      "number": 88,
      "id": "MDExOlB1bGxSZXF1ZXN0NjkwOTI1Nzcw",
      "title": "introduce definitions for time units",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/pull/88",
      "state": "MERGED",
      "author": "tgeoghegan",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "Introduces `Time` and `Duration` definitions, principally to make it\r\nmore obvious that `batch_window` is a number of seconds.",
      "createdAt": "2021-07-15T17:52:55Z",
      "updatedAt": "2021-12-30T00:53:24Z",
      "baseRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "baseRefName": "main",
      "baseRefOid": "a55f71ac65e531a7a4e7c10ab83307be08032586",
      "headRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "headRefName": "timg/time-units",
      "headRefOid": "a6ed069a6e4b283bc94a5fff4e1eb38e467b2d41",
      "closedAt": "2021-07-20T18:07:42Z",
      "mergedAt": "2021-07-20T18:07:42Z",
      "mergedBy": "tgeoghegan",
      "mergeCommit": {
        "oid": "989cea565fbeaf0dcc7f5f9ac7f7cf0f3446a246"
      },
      "comments": [],
      "reviews": [
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzA3NzcxODIw",
          "commit": {
            "abbreviatedOid": "e3c0bdf"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "Good idea!",
          "createdAt": "2021-07-15T20:03:44Z",
          "updatedAt": "2021-07-15T20:03:44Z",
          "comments": []
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzEwMDY5Njc1",
          "commit": {
            "abbreviatedOid": "e3c0bdf"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "Yeah, this is a nice improvement. I'd keep Time and Duration colocated so we can more clearly define in terms of the other.",
          "createdAt": "2021-07-19T23:47:11Z",
          "updatedAt": "2021-07-19T23:47:34Z",
          "comments": [
            {
              "originalPosition": 14,
              "body": "```suggestion\r\nTime uint64; /* seconds elapsed since start of UNIX epoch */\r\nDuration uint64; /* Number of seconds elapsed between two Time instants */\r\n```",
              "createdAt": "2021-07-19T23:47:11Z",
              "updatedAt": "2021-07-19T23:47:34Z"
            }
          ]
        }
      ]
    },
    {
      "number": 90,
      "id": "MDExOlB1bGxSZXF1ZXN0Njk3MzY0ODI4",
      "title": "Add additional anti-replay protection",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/pull/90",
      "state": "MERGED",
      "author": "cjpatton",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "Closes #81.",
      "createdAt": "2021-07-26T21:26:19Z",
      "updatedAt": "2021-08-04T17:43:49Z",
      "baseRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "baseRefName": "main",
      "baseRefOid": "dd4aeffbfbb9245fff64f1eccff16d35e7cdf07e",
      "headRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "headRefName": "cjpatton/intra-batch",
      "headRefOid": "56a949c5a3a8d697ce1b2bd219bc8a061b404196",
      "closedAt": "2021-07-29T20:55:06Z",
      "mergedAt": "2021-07-29T20:55:06Z",
      "mergedBy": "cjpatton",
      "mergeCommit": {
        "oid": "51efe71f37bb2d09acef59dde80326acb2e22b8f"
      },
      "comments": [],
      "reviews": [
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzE3MDg1ODc5",
          "commit": {
            "abbreviatedOid": "65495b1"
          },
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "I have a few questions but nothing blocking.",
          "createdAt": "2021-07-28T14:34:15Z",
          "updatedAt": "2021-07-28T14:50:57Z",
          "comments": [
            {
              "originalPosition": 173,
              "body": "```suggestion\r\nreport than intended by the PDA protocol. For example, this may violate\r\ndifferential privacy. To mitigate this issue, the core specification imposes an\r\n```",
              "createdAt": "2021-07-28T14:34:15Z",
              "updatedAt": "2021-07-28T14:50:57Z"
            },
            {
              "originalPosition": 188,
              "body": "With 32 bit jitter, by the birthday paradox, we'd expect jitter collisions if a single task generates more than 2.1 billion reports in a second across all clients. That's definitely a lot, but why not make the jitter 64 bits so that it's astronomically unlikely?",
              "createdAt": "2021-07-28T14:44:09Z",
              "updatedAt": "2021-07-28T14:50:57Z"
            },
            {
              "originalPosition": 45,
              "body": "Do we have to define \"||\" as concatenation somewhere?",
              "createdAt": "2021-07-28T14:45:42Z",
              "updatedAt": "2021-07-28T14:50:57Z"
            },
            {
              "originalPosition": 101,
              "body": "If the leader is responsible for reordering reports, then it should allow a grace period after an aggregation window starts for late reports to arrive from clients. Unlike Prio v2, the two aggregators don't need to agree on the grace period, since the leader drives aggregations (at the request of a collector, but since those are going to have to be asynchronous anyway I think it's OK for a leader to acknowledge a collect request but not service it until the leader is satisfied the aggregation window's grace period has elapsed). So I think we don't need to put grace period into PDAParams or specify much about what leaders should do, but perhaps we should have a SHOULD statement urging leader implementations to implement a grace period proportional to the aggregation window or other deployment specific details (e.g. special knowledge of the schedule on which clients upload reports)?",
              "createdAt": "2021-07-28T14:49:57Z",
              "updatedAt": "2021-07-28T14:50:57Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzE4MzY0MzE3",
          "commit": {
            "abbreviatedOid": "65495b1"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-07-29T17:36:57Z",
          "updatedAt": "2021-07-29T17:58:06Z",
          "comments": [
            {
              "originalPosition": 45,
              "body": "I don't think so.",
              "createdAt": "2021-07-29T17:36:57Z",
              "updatedAt": "2021-07-29T17:58:07Z"
            },
            {
              "originalPosition": 188,
              "body": "Actually, by the birthday paradox, the probability of a collision among just 2^16 reports is about 1.  For 64 bits, this same is true for 2^32 reports. If we want this probability to be negligible (i.e., about as unlikely as cracking AES-GCM, say) we would need 128 bits.\r\n\r\nPersonally, I'd be happy with 64 bits.",
              "createdAt": "2021-07-29T17:41:14Z",
              "updatedAt": "2021-07-29T17:58:07Z"
            },
            {
              "originalPosition": 101,
              "body": "Good idea, done.",
              "createdAt": "2021-07-29T17:57:55Z",
              "updatedAt": "2021-07-29T17:58:07Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzE4MzgzMjYw",
          "commit": {
            "abbreviatedOid": "161225f"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-07-29T17:58:24Z",
          "updatedAt": "2021-07-29T17:58:24Z",
          "comments": [
            {
              "originalPosition": 188,
              "body": "Done.",
              "createdAt": "2021-07-29T17:58:24Z",
              "updatedAt": "2021-07-29T17:58:24Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzE4NDQ4Nzcz",
          "commit": {
            "abbreviatedOid": "161225f"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "",
          "createdAt": "2021-07-29T19:16:14Z",
          "updatedAt": "2021-07-29T19:16:36Z",
          "comments": [
            {
              "originalPosition": 69,
              "body": "Should we say that leaders should drop reports whose timestamps fall outside of the batch window? (Happy for that to be an open issue, if desired.)",
              "createdAt": "2021-07-29T19:16:15Z",
              "updatedAt": "2021-07-29T19:16:36Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzE4NTI0Nzc3",
          "commit": {
            "abbreviatedOid": "161225f"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-07-29T20:53:56Z",
          "updatedAt": "2021-07-29T20:53:56Z",
          "comments": [
            {
              "originalPosition": 69,
              "body": "I think this would be a bit confusing here. Ideally this is clear from {{pa-aggregate}}.",
              "createdAt": "2021-07-29T20:53:56Z",
              "updatedAt": "2021-07-29T20:53:56Z"
            }
          ]
        }
      ]
    },
    {
      "number": 91,
      "id": "MDExOlB1bGxSZXF1ZXN0Njk5MDYyODk3",
      "title": "Add differential privacy as a threat mitigation",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/pull/91",
      "state": "MERGED",
      "author": "csharrison",
      "authorAssociation": "CONTRIBUTOR",
      "assignees": [],
      "labels": [],
      "body": "Differential privacy can protect against attacks where a portion of the input data is known a priori, or when the size of a batch is small. This PR adds DP as an optional mitigation for PDA deployments and lists where it helps mitigate various threats.\r\n\r\nAdditionally:\r\n- Removes a false statement that revealing user input does not compromise other users' privacy. This is not necessarily the case (e.g. imagine if the batch size is 2 or if many users reveal their input).\r\n- Removes a statement that clients revealing their inputs is outside the threat model (is this still relevant?)",
      "createdAt": "2021-07-28T22:49:41Z",
      "updatedAt": "2021-08-02T16:47:42Z",
      "baseRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "baseRefName": "main",
      "baseRefOid": "dd4aeffbfbb9245fff64f1eccff16d35e7cdf07e",
      "headRepository": "csharrison/prio-documents",
      "headRefName": "diff-priv",
      "headRefOid": "fc636b12595727337cb83c28065306ae78b899d6",
      "closedAt": "2021-08-02T16:47:42Z",
      "mergedAt": "2021-08-02T16:47:42Z",
      "mergedBy": "cjpatton",
      "mergeCommit": {
        "oid": "2590598856adae8dd386d8e6762c42de89f83161"
      },
      "comments": [],
      "reviews": [
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzE4MzU1Mzg4",
          "commit": {
            "abbreviatedOid": "5ffc351"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "CHANGES_REQUESTED",
          "body": "Excellent! Requested changes are editorial.",
          "createdAt": "2021-07-29T17:26:53Z",
          "updatedAt": "2021-07-29T17:34:33Z",
          "comments": [
            {
              "originalPosition": 47,
              "body": "I would work in the term \"Sybil attack\" here. While we're at it, let's add a reference for Sybil attacks (i.e., `{{sybil}}`). I think the canonical reference is https://link.springer.com/chapter/10.1007/3-540-45748-8_24.",
              "createdAt": "2021-07-29T17:26:53Z",
              "updatedAt": "2021-07-29T17:34:33Z"
            },
            {
              "originalPosition": 28,
              "body": "Would you mind adding a reference for `{{dp}}` and verify the document builds by running `make`? See the top of the document for guidance. If you don't have time, then please at least provide a link to an article you think would be a suitable reference. The most useful reference would be something that describes the distinction between client-side and server-side noise addition.",
              "createdAt": "2021-07-29T17:31:10Z",
              "updatedAt": "2021-07-29T17:34:33Z"
            },
            {
              "originalPosition": 65,
              "body": "EDITED: Given that the likely trajectory of this document is an IETF WG draft, it would be better to replace this markdown with a reference to a paper about DP. The most useful reference would be something that describes the distinction between client-side and server-side noise addition.",
              "createdAt": "2021-07-29T17:32:27Z",
              "updatedAt": "2021-07-29T18:00:03Z"
            },
            {
              "originalPosition": 66,
              "body": "```suggestion\r\nA simple approach would require the aggregators to add two-sided\r\n```\r\nDepending on what we do for #68 there may be more than one helper.",
              "createdAt": "2021-07-29T17:33:29Z",
              "updatedAt": "2021-07-29T17:34:33Z"
            },
            {
              "originalPosition": 69,
              "body": "```suggestion\r\neven if all but one of the aggregators is malicious. Differential privacy is a strong\r\n```",
              "createdAt": "2021-07-29T17:33:53Z",
              "updatedAt": "2021-07-29T17:34:33Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzE4MzY2OTg2",
          "commit": {
            "abbreviatedOid": "5ffc351"
          },
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "I have one question about whether we need more explicit protocol support for DP but if so, that can land in a subsequent PR.",
          "createdAt": "2021-07-29T17:40:01Z",
          "updatedAt": "2021-07-29T17:40:42Z",
          "comments": [
            {
              "originalPosition": 62,
              "body": "Besides this informal recommendation, do we need explicit protocol support for differential privacy so that collectors can de-noise outputs? We can leave it up to aggregators to decide how they're going to implement DP but I wonder if `PDAOutputShare` should have a field for the epsilon value that was used by the aggregator. Forgive me if I'm talking nonsense about DP, I am speaking in the terms that we used in Prio v2.",
              "createdAt": "2021-07-29T17:40:01Z",
              "updatedAt": "2021-07-29T17:40:42Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzE4Mzg0MDU5",
          "commit": {
            "abbreviatedOid": "5ffc351"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-07-29T17:59:15Z",
          "updatedAt": "2021-07-29T17:59:15Z",
          "comments": [
            {
              "originalPosition": 28,
              "body": "Oops, I missed that {{dp}} refers to a section and not a paper. Disregard.",
              "createdAt": "2021-07-29T17:59:15Z",
              "updatedAt": "2021-07-29T17:59:15Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzE4Mzg0ODMy",
          "commit": {
            "abbreviatedOid": "5ffc351"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-07-29T18:00:06Z",
          "updatedAt": "2021-07-29T18:00:21Z",
          "comments": [
            {
              "originalPosition": 65,
              "body": "Edited this comment.",
              "createdAt": "2021-07-29T18:00:21Z",
              "updatedAt": "2021-07-29T18:00:21Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzE4NjA4NDcy",
          "commit": {
            "abbreviatedOid": "20fd3cb"
          },
          "author": "csharrison",
          "authorAssociation": "CONTRIBUTOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-07-29T23:26:35Z",
          "updatedAt": "2021-07-29T23:53:47Z",
          "comments": [
            {
              "originalPosition": 47,
              "body": "Done",
              "createdAt": "2021-07-29T23:26:35Z",
              "updatedAt": "2021-07-29T23:53:47Z"
            },
            {
              "originalPosition": 62,
              "body": "Hm. I am nervous about being to prescriptive here. In the simplest protocol design nothing is needed since the epsilon is hardcoded into the specific protocol instantiation and won't change.\r\n\r\nIn practice, some specific instantiations may want to reveal even more information about how noise was applied, e.g.\r\n- The distribution noise is sampled from (Laplace, Gaussian, etc)\r\n- Parameters of the noise distribution\r\n- Any kind of threshold used (for example, if you are using approximate DP)\r\n\r\nI think we should make this as opaque to the protocol as possible vs. prescribing some single \"epsilon\" field which might be too constraining. What do you think?",
              "createdAt": "2021-07-29T23:41:07Z",
              "updatedAt": "2021-07-29T23:53:47Z"
            },
            {
              "originalPosition": 65,
              "body": "Done, I added a general DP reference in place of the wikipedia link. It discusses central, local, and multi-party DP.",
              "createdAt": "2021-07-29T23:42:20Z",
              "updatedAt": "2021-07-29T23:53:47Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzE5MzQ5NzE5",
          "commit": {
            "abbreviatedOid": "1cb3234"
          },
          "author": "csharrison",
          "authorAssociation": "CONTRIBUTOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-07-30T18:09:05Z",
          "updatedAt": "2021-07-30T18:09:05Z",
          "comments": [
            {
              "originalPosition": 62,
              "body": "However, I still think this current PR is land-able given that a basic instantiation can hardcode everything without requiring any communication.",
              "createdAt": "2021-07-30T18:09:05Z",
              "updatedAt": "2021-07-30T18:09:05Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzE5MzczNzQz",
          "commit": {
            "abbreviatedOid": "1cb3234"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "",
          "createdAt": "2021-07-30T18:44:43Z",
          "updatedAt": "2021-07-30T18:44:52Z",
          "comments": [
            {
              "originalPosition": 62,
              "body": "The way to go here, I think, is to document the open question by adding an `[OPEN ISSUE: blah blah blah]`.",
              "createdAt": "2021-07-30T18:44:43Z",
              "updatedAt": "2021-07-30T18:44:52Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzE5MzkyODQ1",
          "commit": {
            "abbreviatedOid": "fc636b1"
          },
          "author": "csharrison",
          "authorAssociation": "CONTRIBUTOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-07-30T19:13:14Z",
          "updatedAt": "2021-07-30T19:13:14Z",
          "comments": [
            {
              "originalPosition": 62,
              "body": "Done",
              "createdAt": "2021-07-30T19:13:14Z",
              "updatedAt": "2021-07-30T19:13:14Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzE5Mzk3NzE3",
          "commit": {
            "abbreviatedOid": "fc636b1"
          },
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-07-30T19:20:22Z",
          "updatedAt": "2021-07-30T19:20:22Z",
          "comments": [
            {
              "originalPosition": 62,
              "body": "I put a note about this in #19, which I think is an appropriate issue to track this discussion.",
              "createdAt": "2021-07-30T19:20:22Z",
              "updatedAt": "2021-07-30T19:20:22Z"
            }
          ]
        }
      ]
    },
    {
      "number": 93,
      "id": "MDExOlB1bGxSZXF1ZXN0Njk5NzcyNjgz",
      "title": "Document minimal operational capabilities.",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/pull/93",
      "state": "MERGED",
      "author": "chris-wood",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "I also deleted a bunch of the (outdated) system design text. I'm sure this can be simplified, but I think this captures the basic assumptions (at least in my mental model).",
      "createdAt": "2021-07-29T19:04:06Z",
      "updatedAt": "2021-12-30T02:10:12Z",
      "baseRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "baseRefName": "main",
      "baseRefOid": "da975086d315cfd9e41d8ee7243a19df1fd6c736",
      "headRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "headRefName": "caw/operational-assumptions",
      "headRefOid": "ff840dc95a07a75a4677728e8c8feb6baa0407fc",
      "closedAt": "2021-08-11T02:25:25Z",
      "mergedAt": "2021-08-11T02:25:25Z",
      "mergedBy": "chris-wood",
      "mergeCommit": {
        "oid": "67ac55bf0cd06ad755dc0096f01bfebbbf27717d"
      },
      "comments": [
        {
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "body": "> At this point, isn't it our intent to spell out the anti-replay mechanism? These changes suggest some mechanism is required, but isn't more prescriptive than that.\r\n\r\nIndeed, the text doesn't require any specific mitigation, and I don't see why it should. Aggregators could do the thing described in the appendix, or they could keep a huge list of all reports seen thus far. There could even be some simpler variant in the future \ud83e\udd37 I don't think we lose anything by eliding the implementation details here.",
          "createdAt": "2021-08-10T15:08:34Z",
          "updatedAt": "2021-08-10T15:08:34Z"
        }
      ],
      "reviews": [
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzE4NTA0NjMw",
          "commit": {
            "abbreviatedOid": "c802c12"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "CHANGES_REQUESTED",
          "body": "",
          "createdAt": "2021-07-29T20:27:01Z",
          "updatedAt": "2021-07-29T20:44:31Z",
          "comments": [
            {
              "originalPosition": 47,
              "body": "```suggestion\r\nPDA protocols have inherent constraints derived from the tradeoff between privacy\r\n```",
              "createdAt": "2021-07-29T20:27:01Z",
              "updatedAt": "2021-07-29T20:44:31Z"
            },
            {
              "originalPosition": 67,
              "body": "```suggestion\r\nare (1) the PDAParam structure configured out of band and (2) a measurement. Clients\r\nare not expected to store any state across any upload\r\n```",
              "createdAt": "2021-07-29T20:28:22Z",
              "updatedAt": "2021-07-29T20:44:31Z"
            },
            {
              "originalPosition": 70,
              "body": "Also worth mentioning here: The aggregators validate inputs before consuming them.",
              "createdAt": "2021-07-29T20:29:36Z",
              "updatedAt": "2021-07-29T20:44:31Z"
            },
            {
              "originalPosition": 78,
              "body": "```suggestion\r\nor computation limitations or constraints, but only a modestly provisioned helper, i.e., one that\r\n```",
              "createdAt": "2021-07-29T20:30:26Z",
              "updatedAt": "2021-07-29T20:44:31Z"
            },
            {
              "originalPosition": 93,
              "body": "Clarify here that some of the offloaded state can be used for anti-replay, but not all.",
              "createdAt": "2021-07-29T20:31:38Z",
              "updatedAt": "2021-07-29T20:44:31Z"
            },
            {
              "originalPosition": 98,
              "body": "This will be resolved (at least partially) by #90.",
              "createdAt": "2021-07-29T20:32:13Z",
              "updatedAt": "2021-07-29T20:44:31Z"
            },
            {
              "originalPosition": 111,
              "body": "This is also a requirement for the helper.",
              "createdAt": "2021-07-29T20:33:50Z",
              "updatedAt": "2021-07-29T20:44:31Z"
            },
            {
              "originalPosition": 120,
              "body": "They also need to keep around an HPKE secret key for the lifetime of the PDAParam.",
              "createdAt": "2021-07-29T20:34:25Z",
              "updatedAt": "2021-07-29T20:44:31Z"
            },
            {
              "originalPosition": 168,
              "body": "```suggestion\r\nPDA deployments should ensure that aggregators do not have common dependencies\r\n```",
              "createdAt": "2021-07-29T20:34:48Z",
              "updatedAt": "2021-07-29T20:44:31Z"
            },
            {
              "originalPosition": 186,
              "body": "```suggestion\r\ntolerable; the input-verification procedure of the PDA protocol\r\n```\r\nThe term \"AFE\" is specific to Prio.",
              "createdAt": "2021-07-29T20:36:28Z",
              "updatedAt": "2021-07-29T20:44:31Z"
            },
            {
              "originalPosition": 194,
              "body": "I realize this is copy-pasted, but I'm questioning the value of this paragraph at this point. Is it saying anything that's new and not obvious?",
              "createdAt": "2021-07-29T20:40:23Z",
              "updatedAt": "2021-07-29T20:44:31Z"
            },
            {
              "originalPosition": 182,
              "body": "> Data integrity constraints may be at odds with the threat model if meeting the constraints requires replaying data.\r\n\r\nI realize this statement was copy-pated, but I think we should remove it. The origin of this sentence is the observation that Hits requires multiple collect rounds over the same data. This fact isn't at odds with the need for anti-replay, since mutliple collect requests aren't \"replaying\" reports in an illegal way.",
              "createdAt": "2021-07-29T20:44:16Z",
              "updatedAt": "2021-07-29T20:44:31Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzE4NTIwMDM3",
          "commit": {
            "abbreviatedOid": "9c60e50"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-07-29T20:47:39Z",
          "updatedAt": "2021-07-29T20:47:39Z",
          "comments": [
            {
              "originalPosition": 70,
              "body": "That's just par for the course -- I don't think it changes any of the capacity or operational requirements?",
              "createdAt": "2021-07-29T20:47:39Z",
              "updatedAt": "2021-07-29T20:47:39Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzE4NTIwMjkz",
          "commit": {
            "abbreviatedOid": "563cb41"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-07-29T20:48:02Z",
          "updatedAt": "2021-07-29T20:48:03Z",
          "comments": [
            {
              "originalPosition": 98,
              "body": "Yep, noted it as such.",
              "createdAt": "2021-07-29T20:48:03Z",
              "updatedAt": "2021-07-29T20:48:03Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzE4NTIwODMz",
          "commit": {
            "abbreviatedOid": "2d3b361"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-07-29T20:48:44Z",
          "updatedAt": "2021-07-29T20:48:45Z",
          "comments": [
            {
              "originalPosition": 186,
              "body": "This is moved text, so let's change that separately.",
              "createdAt": "2021-07-29T20:48:45Z",
              "updatedAt": "2021-07-29T20:48:45Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzE4NTEyMDY2",
          "commit": {
            "abbreviatedOid": "c802c12"
          },
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-07-29T20:36:51Z",
          "updatedAt": "2021-07-29T20:48:49Z",
          "comments": [
            {
              "originalPosition": 66,
              "body": "Corresponding to what?",
              "createdAt": "2021-07-29T20:36:51Z",
              "updatedAt": "2021-07-29T20:48:49Z"
            },
            {
              "originalPosition": 68,
              "body": "```suggestion\r\nflows, nor are they required to implement any sort of report upload retry mechanism.\r\n```\r\nIt was unclear what \"it\" referred to, and I think retry implies a failure.",
              "createdAt": "2021-07-29T20:37:29Z",
              "updatedAt": "2021-07-29T20:48:49Z"
            },
            {
              "originalPosition": 100,
              "body": "```suggestion\r\nBeyond the minimal capabilities required of helpers, leaders are generally required to:\r\n```",
              "createdAt": "2021-07-29T20:39:29Z",
              "updatedAt": "2021-07-29T20:48:49Z"
            },
            {
              "originalPosition": 180,
              "body": "Distributed systems people will hiss at you for saying \"exactly once\". Should this be \"at most once\"?",
              "createdAt": "2021-07-29T20:41:27Z",
              "updatedAt": "2021-07-29T20:48:49Z"
            },
            {
              "originalPosition": 186,
              "body": "\"AFE\" turns up in a handful of places in the doc now. Perhaps it merits an entry in the `Terminology` section at the top, especially since it's not obvious that \"AFE\" expands to \"affine-aggregatable encodings\".",
              "createdAt": "2021-07-29T20:43:00Z",
              "updatedAt": "2021-07-29T20:48:49Z"
            },
            {
              "originalPosition": 110,
              "body": "I find this a bit confusing. Is the intent here that for a report, the corresponding aggregator *output* shares must either both be included or both be omitted?",
              "createdAt": "2021-07-29T20:44:12Z",
              "updatedAt": "2021-07-29T20:48:49Z"
            },
            {
              "originalPosition": 36,
              "body": "It seems like this would require clients to maintain a list of uploaded reports to avoid double-uploads, which contradicts the later statement:\r\n>Clients are not expected to store any state across any upload flows\r\n\r\nBesides which, I think leaders will need to implement detection of duplicate report uploads no matter what, in which case they can return an error to clients in the case of a double upload, which downgrades this to a SHOULD NOT.",
              "createdAt": "2021-07-29T20:47:28Z",
              "updatedAt": "2021-07-29T20:48:49Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzE4NTIwOTQ5",
          "commit": {
            "abbreviatedOid": "2d3b361"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-07-29T20:48:54Z",
          "updatedAt": "2021-07-29T20:48:55Z",
          "comments": [
            {
              "originalPosition": 194,
              "body": "Nope, we can delete.",
              "createdAt": "2021-07-29T20:48:54Z",
              "updatedAt": "2021-07-29T20:48:55Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzE4NTIxMTE2",
          "commit": {
            "abbreviatedOid": "2d3b361"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-07-29T20:49:07Z",
          "updatedAt": "2021-07-29T20:49:08Z",
          "comments": [
            {
              "originalPosition": 182,
              "body": "Less text is better :-) I'll remove it.",
              "createdAt": "2021-07-29T20:49:07Z",
              "updatedAt": "2021-07-29T20:49:08Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzE4NTIxNzUz",
          "commit": {
            "abbreviatedOid": "13e1c02"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-07-29T20:50:02Z",
          "updatedAt": "2021-07-29T20:50:02Z",
          "comments": [
            {
              "originalPosition": 180,
              "body": "Hah, yeah, fair :-) That's a good suggestion!",
              "createdAt": "2021-07-29T20:50:02Z",
              "updatedAt": "2021-07-29T20:50:02Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzE4NTI3OTEz",
          "commit": {
            "abbreviatedOid": "13e1c02"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-07-29T20:57:57Z",
          "updatedAt": "2021-07-29T20:57:58Z",
          "comments": [
            {
              "originalPosition": 186,
              "body": "In fact, I'm not so sure we want to bolt ourselves to this term too much. First, it's not meaningful for every PDA protocol (for Hits in particular). Second, the term was coined in the original Prio paper, which we don't actually implement.",
              "createdAt": "2021-07-29T20:57:57Z",
              "updatedAt": "2021-07-29T20:57:58Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzI2NTI2MDI3",
          "commit": {
            "abbreviatedOid": "13e1c02"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-08-10T14:39:02Z",
          "updatedAt": "2021-08-10T14:39:03Z",
          "comments": [
            {
              "originalPosition": 93,
              "body": "I don't think that's necessary to do here.",
              "createdAt": "2021-08-10T14:39:02Z",
              "updatedAt": "2021-08-10T14:39:03Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzI2NTM1NjIz",
          "commit": {
            "abbreviatedOid": "13e1c02"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-08-10T14:46:51Z",
          "updatedAt": "2021-08-10T14:46:51Z",
          "comments": [
            {
              "originalPosition": 186,
              "body": "(Overcome by events)",
              "createdAt": "2021-08-10T14:46:51Z",
              "updatedAt": "2021-08-10T14:46:51Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzI2NTM3NjQ3",
          "commit": {
            "abbreviatedOid": "13e1c02"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-08-10T14:48:24Z",
          "updatedAt": "2021-08-10T14:48:24Z",
          "comments": [
            {
              "originalPosition": 36,
              "body": "Yeah, this seems reasonable.",
              "createdAt": "2021-08-10T14:48:24Z",
              "updatedAt": "2021-08-10T14:48:25Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzI2NTUxMTU0",
          "commit": {
            "abbreviatedOid": "873a725"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "Some nits, and a question: At this point, isn't it our intent to spell out the anti-replay mechanism? These changes suggest *some* mechanism is required, but isn't more prescriptive than that.",
          "createdAt": "2021-08-10T14:59:07Z",
          "updatedAt": "2021-08-10T15:05:36Z",
          "comments": [
            {
              "originalPosition": 70,
              "body": "Agreed.",
              "createdAt": "2021-08-10T14:59:07Z",
              "updatedAt": "2021-08-10T15:05:36Z"
            },
            {
              "originalPosition": 93,
              "body": "```suggestion\r\n- Publish and manage an HPKE configuration that can be used for the upload protocol.\r\n```",
              "createdAt": "2021-08-10T15:00:02Z",
              "updatedAt": "2021-08-10T15:05:36Z"
            },
            {
              "originalPosition": 102,
              "body": "```suggestion\r\n  replay attack mitigation. One replay mitigation strategy is described in {{anti-replay}}.\r\n```\r\nAlso, isn't the strategy in {{anti-replay}} *the* strategy? Do we intend to allow deployments to skip this, or do something else?",
              "createdAt": "2021-08-10T15:01:17Z",
              "updatedAt": "2021-08-10T15:05:36Z"
            },
            {
              "originalPosition": 110,
              "body": "+1",
              "createdAt": "2021-08-10T15:02:21Z",
              "updatedAt": "2021-08-10T15:05:36Z"
            },
            {
              "originalPosition": 119,
              "body": "Again, at this point it seems like there is one and only one replay mitigation, and it's spelled out in the doc.",
              "createdAt": "2021-08-10T15:03:05Z",
              "updatedAt": "2021-08-10T15:05:36Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzI2NTYyODcz",
          "commit": {
            "abbreviatedOid": "ad987ff"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-08-10T15:08:42Z",
          "updatedAt": "2021-08-10T15:08:43Z",
          "comments": [
            {
              "originalPosition": 119,
              "body": "(Commented below.)",
              "createdAt": "2021-08-10T15:08:43Z",
              "updatedAt": "2021-08-10T15:08:43Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzI2NTc3NTE0",
          "commit": {
            "abbreviatedOid": "1acb0ff"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "",
          "createdAt": "2021-08-10T15:21:31Z",
          "updatedAt": "2021-08-10T16:36:21Z",
          "comments": [
            {
              "originalPosition": 119,
              "body": "```suggestion\r\n- Implement and store state for the form of inter- and intra-batch replay mitigation in {{anti-replay}}; and\r\n```",
              "createdAt": "2021-08-10T15:21:32Z",
              "updatedAt": "2021-08-10T16:36:21Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzI2ODk4NDU4",
          "commit": {
            "abbreviatedOid": "0fe6750"
          },
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "state": "CHANGES_REQUESTED",
          "body": "I flagged one typo and would like to see the text referred to in [this comment](https://github.com/abetterinternet/prio-documents/pull/93/files#r679473812) clarified.",
          "createdAt": "2021-08-10T22:32:50Z",
          "updatedAt": "2021-08-10T22:34:40Z",
          "comments": [
            {
              "originalPosition": 125,
              "body": "```suggestion\r\ninput to the protocol is the PDAParam structure, configured out of band, which contains\r\n```",
              "createdAt": "2021-08-10T22:32:50Z",
              "updatedAt": "2021-08-10T22:34:40Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzI2OTA0NDE5",
          "commit": {
            "abbreviatedOid": "22e040b"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-08-10T22:45:08Z",
          "updatedAt": "2021-08-10T22:45:08Z",
          "comments": [
            {
              "originalPosition": 110,
              "body": "This is indeed somewhat confusing, and probably not needed, so dropped.",
              "createdAt": "2021-08-10T22:45:08Z",
              "updatedAt": "2021-08-10T22:45:08Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzI2OTM3MTAz",
          "commit": {
            "abbreviatedOid": "ff840dc"
          },
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "",
          "createdAt": "2021-08-11T00:01:50Z",
          "updatedAt": "2021-08-11T00:01:50Z",
          "comments": []
        }
      ]
    },
    {
      "number": 94,
      "id": "MDExOlB1bGxSZXF1ZXN0Njk5Nzk0NDg5",
      "title": "Add an extension slot to the upload request.",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/pull/94",
      "state": "MERGED",
      "author": "chris-wood",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "One possible extension would be an opaque blob to carry client attestation information (for #89), if desired. The current set is empty, but I suspect we'll need freedom to extend here as this gets used without totally changing the protocol version.\r\n\r\nIf folks are generally supportive of this, it should probably land after #90, which touches and renames PDAUploadReq to PDAReport. ",
      "createdAt": "2021-07-29T19:41:21Z",
      "updatedAt": "2021-12-30T02:10:09Z",
      "baseRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "baseRefName": "main",
      "baseRefOid": "51efe71f37bb2d09acef59dde80326acb2e22b8f",
      "headRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "headRefName": "caw/upload-extensions",
      "headRefOid": "61be64d144f5afbf49b61d4b30b20600b7abb616",
      "closedAt": "2021-07-30T19:15:37Z",
      "mergedAt": "2021-07-30T19:15:37Z",
      "mergedBy": "chris-wood",
      "mergeCommit": {
        "oid": "37925a8b7ee811f5e5abacdb57dcb299ff96660b"
      },
      "comments": [
        {
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "body": "> I'm supportive of solving #89 in a generic way, but it's not clear that this change has enough plumbing. In particular, there doesn't appear to be a way for the helper to verify either property of the report (1 - the report was generated by a trusted client; 2 - the report was generated in a trusted environment)\r\n\r\nBoth (1) and (2) are _external to the protocol_. The purpose of extensions is to allow whatever mechanism exists for addressing them to be bound to the report, as is done here. \r\n\r\n> Copy the extension into the aggregate sub-request \r\n\r\nThis is done in the change. \r\n\r\n> and add an OPEN ISSUE for deciding whether this is sufficient plumbing for client attestation\r\n\r\nThis is _not meant_ to close the attestation issue. It's meant to give us the mechanics to address it later. ",
          "createdAt": "2021-07-29T20:29:45Z",
          "updatedAt": "2021-07-29T20:32:40Z"
        }
      ],
      "reviews": [
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzE4NDkyNjI5",
          "commit": {
            "abbreviatedOid": "cbe12d4"
          },
          "author": "ekr",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "",
          "createdAt": "2021-07-29T20:11:25Z",
          "updatedAt": "2021-07-29T20:11:40Z",
          "comments": [
            {
              "originalPosition": 4,
              "body": "Isn't this actually 4..2^16-1",
              "createdAt": "2021-07-29T20:11:26Z",
              "updatedAt": "2021-07-29T20:11:40Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzE4NDkzNTY5",
          "commit": {
            "abbreviatedOid": "cbe12d4"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-07-29T20:12:35Z",
          "updatedAt": "2021-07-29T20:12:36Z",
          "comments": [
            {
              "originalPosition": 4,
              "body": "```suggestion\r\n  Extension extensions<4..2^16-1>;\r\n```",
              "createdAt": "2021-07-29T20:12:35Z",
              "updatedAt": "2021-07-29T20:12:36Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzE4NDk1NzE5",
          "commit": {
            "abbreviatedOid": "f3001a7"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "CHANGES_REQUESTED",
          "body": "I'm supportive of solving #89 in a generic way, but it's not clear that this change has enough plumbing. In particular, there doesn't appear to be a way for the helper to verify either property of the report (1 - the report was generated by a trusted client; 2 - the report was generated in a trusted environment) Minimally, I think we would need to echo the extension in the aggregate sub-request.\r\n\r\nI'd be happy with one of of the following outcomes:\r\n- Copy the extension into the aggregate sub-request and add an OPEN ISSUE for deciding whether this is sufficient plumbing for client attestation\r\n- Close this PR and park the issue",
          "createdAt": "2021-07-29T20:15:18Z",
          "updatedAt": "2021-07-29T20:25:13Z",
          "comments": [
            {
              "originalPosition": 11,
              "body": "In fact, when the extension is used for the purpose of attestation, it probably *needs* to be echoed in each aggregate sub-request. ",
              "createdAt": "2021-07-29T20:15:18Z",
              "updatedAt": "2021-07-29T20:25:13Z"
            },
            {
              "originalPosition": 29,
              "body": "```suggestion\r\nadditional, authenticated[TODO: Specify how] information in the report. Each extension is a tag-length\r\n```",
              "createdAt": "2021-07-29T20:16:02Z",
              "updatedAt": "2021-07-29T20:25:13Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzE4NTA1Nzk4",
          "commit": {
            "abbreviatedOid": "f3001a7"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-07-29T20:28:33Z",
          "updatedAt": "2021-07-29T20:28:33Z",
          "comments": [
            {
              "originalPosition": 29,
              "body": "The contents of the extensions are presumably fed into the AAD, so closing.",
              "createdAt": "2021-07-29T20:28:33Z",
              "updatedAt": "2021-07-29T20:28:33Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzE4NTA2MTU1",
          "commit": {
            "abbreviatedOid": "f3001a7"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-07-29T20:29:00Z",
          "updatedAt": "2021-07-29T20:29:00Z",
          "comments": [
            {
              "originalPosition": 11,
              "body": "That is where I lean, too, but it does mean extension bloat in each request. That's probably fine, though.",
              "createdAt": "2021-07-29T20:29:00Z",
              "updatedAt": "2021-07-29T20:29:00Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzE4NTIyMDQ2",
          "commit": {
            "abbreviatedOid": "f3001a7"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "Right you are. What threw me off was the following statement:\r\n> [OPEN ISSUE: if we include extensions in the AAD then these extensions are required to be\r\n> echoed in each aggregate subrequest. We could either not include this in the AAD, or replace\r\n> the list with a hash of the list (that's sent separately), or something else.]\r\n\r\nThe \"then these extensions are required to be echoed...\" makes it sound as if they're *not* echoed, which they are. I'm happy with this PR modulo fixing this statement.",
          "createdAt": "2021-07-29T20:50:21Z",
          "updatedAt": "2021-07-29T20:50:21Z",
          "comments": []
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzE4NTI4MTM2",
          "commit": {
            "abbreviatedOid": "f3001a7"
          },
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-07-29T20:58:14Z",
          "updatedAt": "2021-07-29T20:59:44Z",
          "comments": [
            {
              "originalPosition": 54,
              "body": "Any reason this is `<8..2^16-1>` here but `<4..2^16-1>` in `PDAUploadReq`?",
              "createdAt": "2021-07-29T20:58:14Z",
              "updatedAt": "2021-07-29T20:59:44Z"
            },
            {
              "originalPosition": 77,
              "body": "Do we need to provide this much structure for the extensions? IIUC at the PDA protocol layer, we will never examine or modify these extensions so why can't they be completely opaque blobs?",
              "createdAt": "2021-07-29T20:59:22Z",
              "updatedAt": "2021-07-29T20:59:44Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzE4NTM5MzQ0",
          "commit": {
            "abbreviatedOid": "f3001a7"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-07-29T21:12:51Z",
          "updatedAt": "2021-07-29T21:12:51Z",
          "comments": [
            {
              "originalPosition": 54,
              "body": "Me not making the change in two places :)",
              "createdAt": "2021-07-29T21:12:51Z",
              "updatedAt": "2021-07-29T21:12:51Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzE4NTM5NTI1",
          "commit": {
            "abbreviatedOid": "f3001a7"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-07-29T21:13:06Z",
          "updatedAt": "2021-07-29T21:13:06Z",
          "comments": [
            {
              "originalPosition": 54,
              "body": "```suggestion\r\n  Extension extensions<4..2^16-1>;\r\n```",
              "createdAt": "2021-07-29T21:13:06Z",
              "updatedAt": "2021-07-29T21:13:06Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzE4NTQwMDU0",
          "commit": {
            "abbreviatedOid": "f3001a7"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-07-29T21:13:49Z",
          "updatedAt": "2021-07-29T21:13:49Z",
          "comments": [
            {
              "originalPosition": 77,
              "body": "This just creates the registry where extensions will go. We don't need to do anything more here, unless we decide we want to introduce some mandatory extensions.",
              "createdAt": "2021-07-29T21:13:49Z",
              "updatedAt": "2021-07-29T21:13:49Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzE5MzkyNjk5",
          "commit": {
            "abbreviatedOid": "61be64d"
          },
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-07-30T19:13:03Z",
          "updatedAt": "2021-07-30T19:13:03Z",
          "comments": [
            {
              "originalPosition": 77,
              "body": "Well, my point applies more to the `struct Extension` definition. The extension just be an opaque blob of bytes, and the responsibility of protocol implementations would be to relay the blob unmodified from `PDAReport` to `PDAAggregateSubReq`. Then the format of that blob is something to be agreed upon by the client that generated it and the aggregator that is examining it, out of band from the PDA protocol.",
              "createdAt": "2021-07-30T19:13:03Z",
              "updatedAt": "2021-07-30T19:13:03Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzE5Mzk0NTIz",
          "commit": {
            "abbreviatedOid": "61be64d"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-07-30T19:15:31Z",
          "updatedAt": "2021-07-30T19:15:31Z",
          "comments": [
            {
              "originalPosition": 77,
              "body": "The contents of the extension, and how they're used, are up to the thing that defines the extension. So, yeah, I think what we have here aligns with what you envision.",
              "createdAt": "2021-07-30T19:15:31Z",
              "updatedAt": "2021-07-30T19:15:31Z"
            }
          ]
        }
      ]
    },
    {
      "number": 96,
      "id": "MDExOlB1bGxSZXF1ZXN0NzAzODE0NTI4",
      "title": "Draft charter",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/pull/96",
      "state": "MERGED",
      "author": "ekr",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "",
      "createdAt": "2021-08-04T18:17:14Z",
      "updatedAt": "2021-08-27T21:07:11Z",
      "baseRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "baseRefName": "main",
      "baseRefOid": "2590598856adae8dd386d8e6762c42de89f83161",
      "headRepository": "ekr/ppm-specification",
      "headRefName": "charter",
      "headRefOid": "8ed99d50d7e9a31e52b6b69223c1722de8d8cb91",
      "closedAt": "2021-08-27T21:07:10Z",
      "mergedAt": "2021-08-27T21:07:10Z",
      "mergedBy": "ekr",
      "mergeCommit": {
        "oid": "560afbee40ac7d13154d2ea536273e28ea319e7e"
      },
      "comments": [],
      "reviews": [
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzIyNTk5OTg3",
          "commit": {
            "abbreviatedOid": "96e0894"
          },
          "author": "stpeter",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-08-04T18:22:18Z",
          "updatedAt": "2021-08-04T18:22:19Z",
          "comments": [
            {
              "originalPosition": 7,
              "body": "```suggestion\r\nconventional methods require collecting individual responses and then\r\n```",
              "createdAt": "2021-08-04T18:22:18Z",
              "updatedAt": "2021-08-04T18:22:19Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzIyNjAwMjI0",
          "commit": {
            "abbreviatedOid": "96e0894"
          },
          "author": "stpeter",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-08-04T18:22:37Z",
          "updatedAt": "2021-08-04T18:22:37Z",
          "comments": [
            {
              "originalPosition": 8,
              "body": "```suggestion\r\naggregating them, thus representing a threat to user privacy and\r\n```",
              "createdAt": "2021-08-04T18:22:37Z",
              "updatedAt": "2021-08-04T18:22:37Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzIyNjE2NzUy",
          "commit": {
            "abbreviatedOid": "96e0894"
          },
          "author": "stpeter",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-08-04T18:41:49Z",
          "updatedAt": "2021-08-04T18:45:19Z",
          "comments": [
            {
              "originalPosition": 18,
              "body": "```suggestion\r\n- Client submission of individual reports, including proofs of validity, to a primary server.\r\n```",
              "createdAt": "2021-08-04T18:41:49Z",
              "updatedAt": "2021-08-04T18:45:19Z"
            },
            {
              "originalPosition": 19,
              "body": "```suggestion\r\n- Verification of validity proofs by two or more servers\r\n```",
              "createdAt": "2021-08-04T18:43:15Z",
              "updatedAt": "2021-08-04T18:45:19Z"
            },
            {
              "originalPosition": 20,
              "body": "```suggestion\r\n- Computation of aggregate values by two or more servers\r\n```",
              "createdAt": "2021-08-04T18:44:30Z",
              "updatedAt": "2021-08-04T18:45:19Z"
            },
            {
              "originalPosition": 21,
              "body": "```suggestion\r\n- Reporting of aggregate results to the entity taking the measurement\r\n```",
              "createdAt": "2021-08-04T18:45:06Z",
              "updatedAt": "2021-08-04T18:45:19Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzIyNjUxNzE4",
          "commit": {
            "abbreviatedOid": "2017b1e"
          },
          "author": "ekr",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-08-04T19:18:37Z",
          "updatedAt": "2021-08-04T19:18:37Z",
          "comments": [
            {
              "originalPosition": 18,
              "body": "I actually don't think we should commit to this in the charter (even though I think it's a good idea).",
              "createdAt": "2021-08-04T19:18:37Z",
              "updatedAt": "2021-08-04T19:18:37Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzIyNjUxOTc3",
          "commit": {
            "abbreviatedOid": "2017b1e"
          },
          "author": "ekr",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-08-04T19:18:56Z",
          "updatedAt": "2021-08-04T19:18:57Z",
          "comments": [
            {
              "originalPosition": 19,
              "body": "Hmm.... I think if we're going to say >1 server somewhere it should be above this.",
              "createdAt": "2021-08-04T19:18:56Z",
              "updatedAt": "2021-08-04T19:18:57Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzIyNjUyMDYz",
          "commit": {
            "abbreviatedOid": "2017b1e"
          },
          "author": "ekr",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-08-04T19:19:02Z",
          "updatedAt": "2021-08-04T19:19:02Z",
          "comments": [
            {
              "originalPosition": 20,
              "body": "Same here.",
              "createdAt": "2021-08-04T19:19:02Z",
              "updatedAt": "2021-08-04T19:19:02Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzIyNjUyMzIz",
          "commit": {
            "abbreviatedOid": "93d9ca0"
          },
          "author": "ekr",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-08-04T19:19:21Z",
          "updatedAt": "2021-08-04T19:19:21Z",
          "comments": [
            {
              "originalPosition": 19,
              "body": "Maybe \"by the servers\" here and below.",
              "createdAt": "2021-08-04T19:19:21Z",
              "updatedAt": "2021-08-04T19:19:21Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzIyNzAxMzk0",
          "commit": {
            "abbreviatedOid": "93d9ca0"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-08-04T20:19:29Z",
          "updatedAt": "2021-08-04T20:21:27Z",
          "comments": [
            {
              "originalPosition": 11,
              "body": "\"Heavy Hitters\" isn't the name of the protocol in ePrint 2021/017. \"Prio\" is the name of a protocol, but we don't implement it. (We actually implement ePrint 2019/088.) Rather than name the protocols, I suggest we just cite the papers.",
              "createdAt": "2021-08-04T20:19:29Z",
              "updatedAt": "2021-08-04T20:21:27Z"
            },
            {
              "originalPosition": 28,
              "body": "```suggestion\r\nThe WG will deliver a protocol which can accommodate multiple PDA\r\ntasks, with the initial deliverable supporting both simple\r\n```",
              "createdAt": "2021-08-04T20:21:16Z",
              "updatedAt": "2021-08-04T20:21:27Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzIyNzA5ODE5",
          "commit": {
            "abbreviatedOid": "93d9ca0"
          },
          "author": "ekr",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-08-04T20:29:46Z",
          "updatedAt": "2021-08-04T20:29:46Z",
          "comments": [
            {
              "originalPosition": 11,
              "body": "I think perhaps we just say \"Prio\". We're not saying we're going to standardize that, we're giving an example.",
              "createdAt": "2021-08-04T20:29:46Z",
              "updatedAt": "2021-08-04T20:29:46Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzIyNzEwMTE1",
          "commit": {
            "abbreviatedOid": "93d9ca0"
          },
          "author": "ekr",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-08-04T20:30:06Z",
          "updatedAt": "2021-08-04T20:30:06Z",
          "comments": [
            {
              "originalPosition": 11,
              "body": "Also, I'm trying to get HCG to just rename all this stuff Prio",
              "createdAt": "2021-08-04T20:30:06Z",
              "updatedAt": "2021-08-04T20:30:06Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzI1ODg5NzEx",
          "commit": {
            "abbreviatedOid": "93d9ca0"
          },
          "author": "martinthomson",
          "authorAssociation": "CONTRIBUTOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-08-09T23:30:41Z",
          "updatedAt": "2021-08-09T23:30:41Z",
          "comments": [
            {
              "originalPosition": 27,
              "body": "a protocol?  seems like something that a working group might decide, but HH and Prio are very different things functionally.  my take: make two, share as many design elements as possible",
              "createdAt": "2021-08-09T23:30:41Z",
              "updatedAt": "2021-08-09T23:30:41Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzI4MDE3Nzkz",
          "commit": {
            "abbreviatedOid": "93d9ca0"
          },
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-08-11T22:46:04Z",
          "updatedAt": "2021-08-11T22:46:04Z",
          "comments": [
            {
              "originalPosition": 11,
              "body": "> Also, I'm trying to get HCG to just rename all this stuff Prio\r\n\r\nThis would be great for ISRG since [we have already invested in \"Prio Services\" as a brand](https://www.abetterinternet.org/prio/)!",
              "createdAt": "2021-08-11T22:46:04Z",
              "updatedAt": "2021-08-11T22:46:04Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzQwODY3MDc2",
          "commit": {
            "abbreviatedOid": "5f1d278"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "",
          "createdAt": "2021-08-27T20:21:47Z",
          "updatedAt": "2021-08-27T20:31:34Z",
          "comments": [
            {
              "originalPosition": 3,
              "body": "```suggestion\r\none might want to measure the most common sites that people visit\r\n```",
              "createdAt": "2021-08-27T20:21:47Z",
              "updatedAt": "2021-08-27T20:31:34Z"
            },
            {
              "originalPosition": 7,
              "body": "```suggestion\r\nrather in aggregated data (e.g., how many users visit URL X).\r\nConventional methods require collecting individual measurements and then\r\n```",
              "createdAt": "2021-08-27T20:22:31Z",
              "updatedAt": "2021-08-27T20:31:34Z"
            },
            {
              "originalPosition": 11,
              "body": "```suggestion\r\nNew cryptographic techniques such as Prio address this gap by splitting\r\n```",
              "createdAt": "2021-08-27T20:22:59Z",
              "updatedAt": "2021-08-27T20:31:34Z"
            },
            {
              "originalPosition": 14,
              "body": "```suggestion\r\nmeasurements. The Privacy Preserving Measurement (PPM) work will standardize\r\n```",
              "createdAt": "2021-08-27T20:23:22Z",
              "updatedAt": "2021-08-27T20:31:34Z"
            },
            {
              "originalPosition": 12,
              "body": "```suggestion\r\nmeasurements between multiple, non-colluding servers which can jointly compute the\r\n```",
              "createdAt": "2021-08-27T20:25:04Z",
              "updatedAt": "2021-08-27T20:31:34Z"
            },
            {
              "originalPosition": 18,
              "body": "```suggestion\r\n- Client submission of individual measurements, including proofs of validity.\r\n```",
              "createdAt": "2021-08-27T20:25:34Z",
              "updatedAt": "2021-08-27T20:31:35Z"
            },
            {
              "originalPosition": 25,
              "body": "```suggestion\r\nPPM service. \r\n```",
              "createdAt": "2021-08-27T20:25:47Z",
              "updatedAt": "2021-08-27T20:31:34Z"
            },
            {
              "originalPosition": 28,
              "body": "```suggestion\r\nPPM algorithms. The initial deliverable will support measurements of simple\r\n```",
              "createdAt": "2021-08-27T20:25:57Z",
              "updatedAt": "2021-08-27T20:31:35Z"
            },
            {
              "originalPosition": 32,
              "body": "```suggestion\r\nset of arbitrary strings submitted by users.  The PPM protocols will use\r\ncryptographic algorithms defined by the CFRG.\r\n```",
              "createdAt": "2021-08-27T20:27:18Z",
              "updatedAt": "2021-08-27T20:31:35Z"
            },
            {
              "originalPosition": 29,
              "body": "```suggestion\r\npredefined statistical aggregates such as averages, as well as measurement of \"heavy hitters\" out of the\r\n```",
              "createdAt": "2021-08-27T20:31:31Z",
              "updatedAt": "2021-08-27T20:31:35Z"
            }
          ]
        }
      ]
    },
    {
      "number": 97,
      "id": "MDExOlB1bGxSZXF1ZXN0NzAzODk2NTEx",
      "title": "Define \"valid\" collect requests",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/pull/97",
      "state": "MERGED",
      "author": "cjpatton",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "This partially addresses the problem of preventing inter-batch replay attacks described by @chris-wood in #82. Along the way, clean up the description of collect requests so that it talks about protocol messages rather than API calls (as @ekr suggested).",
      "createdAt": "2021-08-04T19:23:04Z",
      "updatedAt": "2021-12-30T02:10:11Z",
      "baseRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "baseRefName": "main",
      "baseRefOid": "2590598856adae8dd386d8e6762c42de89f83161",
      "headRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "headRefName": "cjpatton/inter-batch",
      "headRefOid": "8b39cf50f094ee19d203316dfe33b76c7816a553",
      "closedAt": "2021-08-10T14:37:35Z",
      "mergedAt": "2021-08-10T14:37:35Z",
      "mergedBy": "chris-wood",
      "mergeCommit": {
        "oid": "da975086d315cfd9e41d8ee7243a19df1fd6c736"
      },
      "comments": [],
      "reviews": [
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzI2NTI0MTIx",
          "commit": {
            "abbreviatedOid": "8b39cf5"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "",
          "createdAt": "2021-08-10T14:37:30Z",
          "updatedAt": "2021-08-10T14:37:30Z",
          "comments": []
        }
      ]
    },
    {
      "number": 99,
      "id": "MDExOlB1bGxSZXF1ZXN0NzA3OTU0MDYw",
      "title": "typos, formatting errors, obsolete todos",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/pull/99",
      "state": "MERGED",
      "author": "tgeoghegan",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "Fixes a miscellany of typos, formatting errors and obsolete todos I encountered while reviewing the document.",
      "createdAt": "2021-08-11T01:19:35Z",
      "updatedAt": "2021-12-30T00:53:26Z",
      "baseRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "baseRefName": "main",
      "baseRefOid": "67ac55bf0cd06ad755dc0096f01bfebbbf27717d",
      "headRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "headRefName": "timg/misc",
      "headRefOid": "4f70e808b980e47afae48878a30fd0273ad4c0f1",
      "closedAt": "2021-08-11T22:24:34Z",
      "mergedAt": "2021-08-11T22:24:34Z",
      "mergedBy": "tgeoghegan",
      "mergeCommit": {
        "oid": "0baeb82d199db7c929dde0c6c3e769bb917cd005"
      },
      "comments": [],
      "reviews": [
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzI2OTY2MTc3",
          "commit": {
            "abbreviatedOid": "034144c"
          },
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-08-11T01:20:45Z",
          "updatedAt": "2021-08-11T01:20:45Z",
          "comments": [
            {
              "originalPosition": 121,
              "body": "We have a section in security considerations about OHTTP and anonymizing proxies so I think this is settled.",
              "createdAt": "2021-08-11T01:20:45Z",
              "updatedAt": "2021-08-11T01:20:45Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzI2OTY2OTUz",
          "commit": {
            "abbreviatedOid": "034144c"
          },
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-08-11T01:22:47Z",
          "updatedAt": "2021-08-11T01:22:48Z",
          "comments": [
            {
              "originalPosition": 144,
              "body": "IIUC the concern here is that leaders or helpers can learn which clients are uploading data, and I believe deployments can address that by using OHTTP.",
              "createdAt": "2021-08-11T01:22:47Z",
              "updatedAt": "2021-08-11T01:22:48Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzI2OTcwMTY4",
          "commit": {
            "abbreviatedOid": "c0b46ef"
          },
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-08-11T01:31:30Z",
          "updatedAt": "2021-08-11T01:31:31Z",
          "comments": [
            {
              "originalPosition": 174,
              "body": "I don't think this requirement is correct. If the minimum batch window is 8 hours, why does it matter if the collector wants to aggregate over 0400-1200 instead of 0000-0800? Maybe the intent here was that `batch_end - batch_start` be a multiple of `PDAParam.batch_window`, but I don't think that's necessary, either. I think it's OK if a collector wants to aggregate over a window larger than the minimum value in the PDAParams, so long as the next aggregate doesn't overlap. The aggregators implement anti-replay by keeping track of the newest report timestamp aggregated for a PDATask, so they don't need all the batch windows to be the same or to be multiples of the minimum, do they?",
              "createdAt": "2021-08-11T01:31:31Z",
              "updatedAt": "2021-08-11T01:31:31Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzI2OTkwNDM1",
          "commit": {
            "abbreviatedOid": "c0b46ef"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "",
          "createdAt": "2021-08-11T02:27:00Z",
          "updatedAt": "2021-08-11T02:29:01Z",
          "comments": [
            {
              "originalPosition": 107,
              "body": "```suggestion\r\n1. The clients, aggregators, and collector agree on a set of PDA tasks, as well\r\n```",
              "createdAt": "2021-08-11T02:27:00Z",
              "updatedAt": "2021-08-11T02:29:01Z"
            },
            {
              "originalPosition": 174,
              "body": "Assuming the batch size criteria is met, this seems right.",
              "createdAt": "2021-08-11T02:28:03Z",
              "updatedAt": "2021-08-11T02:29:01Z"
            },
            {
              "originalPosition": 272,
              "body": "We might consider just punting this to the underlying CFRG document. Maybe we can move this section to the parking lot?",
              "createdAt": "2021-08-11T02:28:52Z",
              "updatedAt": "2021-08-11T02:29:01Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzI3NDk1NTE1",
          "commit": {
            "abbreviatedOid": "c0b46ef"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "CHANGES_REQUESTED",
          "body": "My only blocking comment is that I think we want (something like) the requirement you're removing. It's useful for the aggregators to be able to know the possible batch intervals before a collect request is made.",
          "createdAt": "2021-08-11T13:37:18Z",
          "updatedAt": "2021-08-11T13:55:24Z",
          "comments": [
            {
              "originalPosition": 88,
              "body": "```suggestion\r\n* `batch_window`: The window of time covered by a batch, i.e., the maximum interval\r\n   between the oldest and newest report in a batch.\r\n```",
              "createdAt": "2021-08-11T13:37:18Z",
              "updatedAt": "2021-08-11T13:55:24Z"
            },
            {
              "originalPosition": 174,
              "body": "Yeah, this maybe wasn't very clear. The intent of this requirement is to divide time into intervals that the aggregators and collector agree on in advance of the collect request. This has the advantage of allowing aggregators to aggregate input shares in each window as they arrive, thereby reducing the aggregators' storage requirements. Note that this isn't possible for Hits, but it is for Prio.",
              "createdAt": "2021-08-11T13:51:08Z",
              "updatedAt": "2021-08-11T13:55:24Z"
            },
            {
              "originalPosition": 253,
              "body": "What changed here? Looks like we're just inserting a line break?",
              "createdAt": "2021-08-11T13:52:32Z",
              "updatedAt": "2021-08-11T13:55:24Z"
            },
            {
              "originalPosition": 272,
              "body": "Yeah, I think we're going to end up removing the Prio stuff altogether. (See #98.) But we can do so in a future PR.",
              "createdAt": "2021-08-11T13:53:31Z",
              "updatedAt": "2021-08-11T13:55:24Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzI3NjY2MjY0",
          "commit": {
            "abbreviatedOid": "c0b46ef"
          },
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-08-11T15:56:32Z",
          "updatedAt": "2021-08-11T15:56:32Z",
          "comments": [
            {
              "originalPosition": 253,
              "body": "I'm putting `` around the math terms to make them fixed-width. I find it more readable if those stand out from the regular text, but I'm happy to revert.",
              "createdAt": "2021-08-11T15:56:32Z",
              "updatedAt": "2021-08-11T15:56:32Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzI3NjY4OTU4",
          "commit": {
            "abbreviatedOid": "c0b46ef"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-08-11T15:58:58Z",
          "updatedAt": "2021-08-11T15:58:58Z",
          "comments": [
            {
              "originalPosition": 253,
              "body": "Ack, no need!",
              "createdAt": "2021-08-11T15:58:58Z",
              "updatedAt": "2021-08-11T15:58:58Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzI3Njc1ODE5",
          "commit": {
            "abbreviatedOid": "c0b46ef"
          },
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-08-11T16:05:24Z",
          "updatedAt": "2021-08-11T16:05:24Z",
          "comments": [
            {
              "originalPosition": 174,
              "body": "Aggregators need to jointly evaluate the validity proof on a Prio input before it can be included in an aggregate, and proofs are not verified until the collect phase, which doesn't start until a collect request is emitted by the collector. I'm not sure how aggregators could speculatively aggregate input shares unless they are capable of removing an input share from their output if the proof is later found to be invalid, which would have its own storage requirements.",
              "createdAt": "2021-08-11T16:05:24Z",
              "updatedAt": "2021-08-11T16:05:24Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzI3Njg2Njg5",
          "commit": {
            "abbreviatedOid": "c0b46ef"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-08-11T16:15:45Z",
          "updatedAt": "2021-08-11T16:15:45Z",
          "comments": [
            {
              "originalPosition": 174,
              "body": "> Aggregators need to jointly evaluate the validity proof on a Prio input before it can be included in an aggregate, and proofs are not verified until the collect phase, which doesn't start until a collect request is emitted by the collector.\r\n\r\nI don't this is quite right. My understanding is that the aggregators can verify an input's validity as long as they have the PDAParam. Waiting on the collect request is only necessary for Hits, where you need to know the set of candidate prefixes before you know how to proceed.\r\n",
              "createdAt": "2021-08-11T16:15:45Z",
              "updatedAt": "2021-08-11T16:15:45Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzI3Njg5MDI5",
          "commit": {
            "abbreviatedOid": "c0b46ef"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-08-11T16:18:01Z",
          "updatedAt": "2021-08-11T16:18:01Z",
          "comments": [
            {
              "originalPosition": 174,
              "body": "In general you're right: the first aggregate request needs to block on a collect request. But with Prio it's perfectly fine to do aggregation (including input validation) in advance of the collect request.",
              "createdAt": "2021-08-11T16:18:01Z",
              "updatedAt": "2021-08-11T16:18:01Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzI4MDA0MzI2",
          "commit": {
            "abbreviatedOid": "4f70e80"
          },
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-08-11T22:19:03Z",
          "updatedAt": "2021-08-11T22:19:04Z",
          "comments": [
            {
              "originalPosition": 174,
              "body": "Following from our discussion in the design call earlier today, I've reverted this specific change so that @cjpatton can revisit this language later. I believe that we concluded that we want the batch windows in the collect requests to have the same size as the batch window in the PDAParams.",
              "createdAt": "2021-08-11T22:19:04Z",
              "updatedAt": "2021-08-11T22:19:04Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzI4MDA2NTkw",
          "commit": {
            "abbreviatedOid": "4f70e80"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "",
          "createdAt": "2021-08-11T22:23:24Z",
          "updatedAt": "2021-08-11T22:23:24Z",
          "comments": []
        }
      ]
    },
    {
      "number": 100,
      "id": "MDExOlB1bGxSZXF1ZXN0NzA5NzQ3OTEx",
      "title": "Rename",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/pull/100",
      "state": "CLOSED",
      "author": "ekr",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "",
      "createdAt": "2021-08-11T22:34:51Z",
      "updatedAt": "2021-08-11T22:35:11Z",
      "baseRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "baseRefName": "main",
      "baseRefOid": "0baeb82d199db7c929dde0c6c3e769bb917cd005",
      "headRepository": "ekr/ppm-specification",
      "headRefName": "rename",
      "headRefOid": "53aa7057e7e8d3d02e5320b0dbd630e203c0c57a",
      "closedAt": "2021-08-11T22:35:11Z",
      "mergedAt": null,
      "mergedBy": null,
      "mergeCommit": null,
      "comments": [],
      "reviews": []
    },
    {
      "number": 101,
      "id": "MDExOlB1bGxSZXF1ZXN0NzA5NzUwMjkz",
      "title": "Rename",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/pull/101",
      "state": "MERGED",
      "author": "ekr",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "",
      "createdAt": "2021-08-11T22:36:48Z",
      "updatedAt": "2021-08-11T22:44:33Z",
      "baseRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "baseRefName": "main",
      "baseRefOid": "0baeb82d199db7c929dde0c6c3e769bb917cd005",
      "headRepository": "ekr/ppm-specification",
      "headRefName": "rename",
      "headRefOid": "610d9d2f000281c528f7415239e902a54cc4e51b",
      "closedAt": "2021-08-11T22:44:33Z",
      "mergedAt": "2021-08-11T22:44:33Z",
      "mergedBy": "chris-wood",
      "mergeCommit": {
        "oid": "120515ccebfc5454d564d220370ebd4d124d580a"
      },
      "comments": [],
      "reviews": [
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzI4MDE3MDY3",
          "commit": {
            "abbreviatedOid": "610d9d2"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "",
          "createdAt": "2021-08-11T22:44:29Z",
          "updatedAt": "2021-08-11T22:44:29Z",
          "comments": []
        }
      ]
    },
    {
      "number": 103,
      "id": "MDExOlB1bGxSZXF1ZXN0NzA5NzgyMjMw",
      "title": "clarify `PPMParam.collector_config` field",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/pull/103",
      "state": "MERGED",
      "author": "tgeoghegan",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "Removes some TODOs, clarifies why we have `HpkeConfig\r\ncollector_config` in `struct PPMParam` instead of `Url collector_url`,\r\nand amends collect protocol so that leader output shares are\r\nencrypted to collector's HPKE config. Several response structures\r\nno longer have `PPMProto` or `PPMTaskID` fields if the appropriate\r\ntask (and hence `PPMParam` and hence `PPMProto`) can be inferred\r\nfrom the request.",
      "createdAt": "2021-08-11T23:03:22Z",
      "updatedAt": "2021-12-30T00:53:27Z",
      "baseRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "baseRefName": "main",
      "baseRefOid": "a801f7f6018ec929fa6199baa4e3caea7642609c",
      "headRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "headRefName": "timg/collector-hpke",
      "headRefOid": "757f4b197dff2d05035d21989bfc7cdcf4f5e4f6",
      "closedAt": "2021-08-19T14:19:00Z",
      "mergedAt": "2021-08-19T14:19:00Z",
      "mergedBy": "chris-wood",
      "mergeCommit": {
        "oid": "84ddcbc789b0e4475358dc27f2379998b2484cb4"
      },
      "comments": [
        {
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "body": "I want to address #95 in this PR as well, so downgrading to draft for now.",
          "createdAt": "2021-08-11T23:07:22Z",
          "updatedAt": "2021-08-11T23:07:22Z"
        },
        {
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "body": "@chris-wood @cjpatton This is ready; please review at your convenience.",
          "createdAt": "2021-08-13T17:54:36Z",
          "updatedAt": "2021-08-13T17:54:36Z"
        },
        {
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "body": "Thank you for the review, @cjpatton. This picked up some merge conflicts so I will wait for all of @ekr's changes to land and then rebase.",
          "createdAt": "2021-08-17T23:34:43Z",
          "updatedAt": "2021-08-17T23:34:43Z"
        },
        {
          "author": "ekr",
          "authorAssociation": "COLLABORATOR",
          "body": "You should be able to rebase now. I am mostly done.\n\nOn Tue, Aug 17, 2021 at 4:34 PM Tim Geoghegan ***@***.***>\nwrote:\n\n> Thank you for the review, @cjpatton <https://github.com/cjpatton>. This\n> picked up some merge conflicts so I will wait for all of @ekr\n> <https://github.com/ekr>'s changes to land and then rebase.\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/abetterinternet/prio-documents/pull/103#issuecomment-900699786>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/AAIPLIKRFMTJT63D74Y6FXDT5LWZ3ANCNFSM5B7VXOCA>\n> .\n> Triage notifications on the go with GitHub Mobile for iOS\n> <https://apps.apple.com/app/apple-store/id1477376905?ct=notification-email&mt=8&pt=524675>\n> or Android\n> <https://play.google.com/store/apps/details?id=com.github.android&utm_campaign=notification-email>\n> .\n>\n",
          "createdAt": "2021-08-17T23:39:05Z",
          "updatedAt": "2021-08-17T23:39:05Z"
        },
        {
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "body": "Rebased, reordered, ready for re-review",
          "createdAt": "2021-08-18T01:12:53Z",
          "updatedAt": "2021-08-18T01:12:53Z"
        }
      ],
      "reviews": [
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzI4MDU5Mzg1",
          "commit": {
            "abbreviatedOid": "22d0a06"
          },
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-08-12T00:28:53Z",
          "updatedAt": "2021-08-12T00:28:53Z",
          "comments": [
            {
              "originalPosition": 94,
              "body": "Besides moving this definition to here from the \"Aggregate Request\" section, I also appended `server_role` to the `info` string passed to `SetupBaseS`.",
              "createdAt": "2021-08-12T00:28:53Z",
              "updatedAt": "2021-08-12T00:28:53Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzI4MDU5NTEw",
          "commit": {
            "abbreviatedOid": "22d0a06"
          },
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-08-12T00:29:19Z",
          "updatedAt": "2021-08-12T00:29:19Z",
          "comments": [
            {
              "originalPosition": 113,
              "body": "Changed the verb to avoid confusion since this section discusses the \"collect\" protocol.",
              "createdAt": "2021-08-12T00:29:19Z",
              "updatedAt": "2021-08-12T00:29:19Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzMwODIwNDAw",
          "commit": {
            "abbreviatedOid": "22d0a06"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "",
          "createdAt": "2021-08-16T15:00:42Z",
          "updatedAt": "2021-08-16T15:03:32Z",
          "comments": [
            {
              "originalPosition": 65,
              "body": "In `PPMReport` the encrypted input shares have type `PDAEncryptedInputShare encrypted_input_shares<1..2^16-1>`, which would allow PPM tasks to specify more than one helper. The current \r\nprotocol doesn't support this right now, of course, but it might be a good idea to mirror what we have there.\r\n\r\n```suggestion\r\n  PPMEncryptedOutputShare encrypted_output_shares<0..2^16-1>;\r\n```\r\n\r\nIf you take this suggestion, remember to update the text below.",
              "createdAt": "2021-08-16T15:00:42Z",
              "updatedAt": "2021-08-16T15:03:32Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzMyMzQ4Mzg2",
          "commit": {
            "abbreviatedOid": "470f14a"
          },
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-08-18T01:06:00Z",
          "updatedAt": "2021-08-18T01:06:01Z",
          "comments": [
            {
              "originalPosition": 97,
              "body": "Besides fixing the order of the arguments to `context.Seal`, I also appended `server_role` to the `info` string passed to `SetupBaseS`, since both helper and leader now encrypt output shares.",
              "createdAt": "2021-08-18T01:06:01Z",
              "updatedAt": "2021-08-18T01:06:01Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzMyMzQ4NzUw",
          "commit": {
            "abbreviatedOid": "470f14a"
          },
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-08-18T01:07:05Z",
          "updatedAt": "2021-08-18T01:07:05Z",
          "comments": [
            {
              "originalPosition": 65,
              "body": "I'd prefer to punt this to #117, so that the document is updated in one step to handle multiple helpers.",
              "createdAt": "2021-08-18T01:07:05Z",
              "updatedAt": "2021-08-18T01:07:05Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzM0MDUwMDQw",
          "commit": {
            "abbreviatedOid": "757f4b1"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "",
          "createdAt": "2021-08-19T14:18:54Z",
          "updatedAt": "2021-08-19T14:18:54Z",
          "comments": []
        }
      ]
    },
    {
      "number": 115,
      "id": "MDExOlB1bGxSZXF1ZXN0NzEyNjU1NDQ1",
      "title": "Restructure the document",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/pull/115",
      "state": "MERGED",
      "author": "ekr",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "This PR restructures the document to have a more traditional IETF flow, including an overview of operation and then serially going through each operation. It also moves the crypto detail to an appendix in preparation for moving it to a separate CFRG document.",
      "createdAt": "2021-08-13T22:23:02Z",
      "updatedAt": "2021-08-17T19:37:05Z",
      "baseRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "baseRefName": "main",
      "baseRefOid": "120515ccebfc5454d564d220370ebd4d124d580a",
      "headRepository": "ekr/ppm-specification",
      "headRefName": "ekr_restructure",
      "headRefOid": "f4a201b792457a39b0f6530dc59407828ddd2e95",
      "closedAt": "2021-08-17T19:37:05Z",
      "mergedAt": "2021-08-17T19:37:05Z",
      "mergedBy": "ekr",
      "mergeCommit": {
        "oid": "0102342a28ab5006bc76172d99b06914d1a7cdd2"
      },
      "comments": [
        {
          "author": "ekr",
          "authorAssociation": "COLLABORATOR",
          "body": "> I'm very happy with this restructure. However, I think there are a couple of things that get lost, which should be addressed:\r\n\r\n>    One thing that's no longer clear is that, in general (and for Hits in particular), an aggregate or output-share request cannot be made until the collector has issued a collect request. This is discussed a bit in {{pa-collect}}, but I think it needs to be made clear much earlier. In particular, in the Aggregate Request section, we should be clear that the parameters of the collect request must be known before the aggregate request can be made.\r\n\r\nAs noted above, I think this is an unnecessary limitation in the current text. There is no a priori reason why it needs to be so for *either* protocol. Even for Hits, one might imagine having the leader preconfigured with a specific heavy hitters measurement strategy.\r\n\r\n\r\n>   Something that gets a bit lost is the idea that there are two processes being executed simultaneously: report uploading and collection. This idea is important to understand where the potential bottle necks are.\r\n\r\nI actually think there are *three* things going on:\r\n\r\n1. Clients sending in reports.\r\n1. The leader issuing aggregation requests\r\n1. The collector asking for results.\r\n\r\nThat's how this text is structure.\r\n\r\n>  For example, as collect request can't be completed until a sufficient number of shares have been uploaded, validated, and aggregated.\r\n\r\nSure, but this is just one instance of where the collector may have to wait. For instance, the computation may just take some time.\r\n\r\n\r\n",
          "createdAt": "2021-08-16T18:10:34Z",
          "updatedAt": "2021-08-16T18:10:34Z"
        },
        {
          "author": "ekr",
          "authorAssociation": "COLLABORATOR",
          "body": "@cjpatton I added some clarifying text. Maybe we're now at the point where this is probably close enough and we should merge and then fix other things later. WDYT?",
          "createdAt": "2021-08-17T17:43:07Z",
          "updatedAt": "2021-08-17T17:43:07Z"
        }
      ],
      "reviews": [
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzMwODI5NjIz",
          "commit": {
            "abbreviatedOid": "5dcb6ab"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "I'm very happy with this restructure. However, I think there are a couple of things that get lost, which should be addressed:\r\n\r\n* One thing that's no longer clear is that, in general (and for Hits in particular), an aggregate or output-share request _cannot_ be made until the collector has issued a collect request. This is discussed a bit in `{{pa-collect}}`, but I think it needs to be made clear much earlier. In particular, in the Aggregate Request section, we should be clear that the parameters of the collect request must be known before the aggregate request can be made.\r\n\r\n* Something that gets a bit lost is the idea that there are two processes being executed simultaneously: report uploading and collection. This idea is important to understand where the potential bottle necks are. For example, as collect request can't be completed until a sufficient number of shares have been uploaded, validated, and aggregated.",
          "createdAt": "2021-08-16T15:08:58Z",
          "updatedAt": "2021-08-16T16:18:08Z",
          "comments": [
            {
              "originalPosition": 258,
              "body": "The architecture diagram shows two helpers. We intend allow each PPM protocol to specify any number of helpers, so maybe it makes sense to codify that here in the intro/overview. The wrapper protocol doesn't quite permit this yet, but it should suffice to add TODOs as needed, or file an issue.",
              "createdAt": "2021-08-16T15:08:58Z",
              "updatedAt": "2021-08-16T16:18:08Z"
            },
            {
              "originalPosition": 271,
              "body": "nit: Remove duplicate blank line",
              "createdAt": "2021-08-16T15:09:40Z",
              "updatedAt": "2021-08-16T16:18:08Z"
            },
            {
              "originalPosition": 275,
              "body": "The meaning of measurement is somewhat ambiguous at this point. On the one hand it sounds like a measurement is a single event from which a report is constructed. On the other hand, it sounds as if a measurement is an on-going progress that results in multiple reports generated by a single client for the same task.\r\n\r\nI think the right definition is the former, i.e., a \"mesurement\" is the value used by the client to generate a report for a task. Therefore, a \"task\" encompasses the process of taking multiple measurements over time. If we want to change the meaning of these terms, we need to be consistent throughout.",
              "createdAt": "2021-08-16T15:12:20Z",
              "updatedAt": "2021-08-16T16:18:08Z"
            },
            {
              "originalPosition": 283,
              "body": "```suggestion\r\n* The minimum \"batch size\" of reports which can be aggregated.\r\n```",
              "createdAt": "2021-08-16T15:20:23Z",
              "updatedAt": "2021-08-16T16:18:08Z"
            },
            {
              "originalPosition": 283,
              "body": "I'd also add:\r\n* The rate at which measurements can be taken, i.e., the \"minimum batch window\".",
              "createdAt": "2021-08-16T15:21:20Z",
              "updatedAt": "2021-08-16T16:18:08Z"
            },
            {
              "originalPosition": 286,
              "body": "Is the task ID important at this stage?",
              "createdAt": "2021-08-16T15:21:45Z",
              "updatedAt": "2021-08-16T16:18:08Z"
            },
            {
              "originalPosition": 291,
              "body": "```suggestion\r\nthough they pass through the leader, the leader is unable to see or modify\r\n```",
              "createdAt": "2021-08-16T15:22:53Z",
              "updatedAt": "2021-08-16T16:18:08Z"
            },
            {
              "originalPosition": 300,
              "body": "```suggestion\r\nuntil the entire batch of reports is received. \r\n```",
              "createdAt": "2021-08-16T15:24:43Z",
              "updatedAt": "2021-08-16T16:18:08Z"
            },
            {
              "originalPosition": 305,
              "body": "I think it's confusing to say the protocol is \"compatible\" with both a push and pull deployment mode. It's more accurate to say that the protocol is comprised of two processes: one in which clients push reports to the aggregators; and another in which the collector pulls results from the aggregators.",
              "createdAt": "2021-08-16T15:26:35Z",
              "updatedAt": "2021-08-16T16:18:08Z"
            },
            {
              "originalPosition": 407,
              "body": "I think this description of how a PPM task works  would be useful, even in a condensed form. The important takeways are:\r\n1. The upload process is carried out by the clients and aggregators.\r\n2. The collect process is carried out by the collector and aggregators.\r\n3. These processes are carried out _simultaneously_.",
              "createdAt": "2021-08-16T15:31:50Z",
              "updatedAt": "2021-08-16T16:18:08Z"
            },
            {
              "originalPosition": 462,
              "body": "```suggestion\r\nwhere `task_id` is the associated PPM task (this value is always known) and\r\n```",
              "createdAt": "2021-08-16T15:33:44Z",
              "updatedAt": "2021-08-16T16:18:08Z"
            },
            {
              "originalPosition": 447,
              "body": "We need to define task ID before we get to this section. Perhaps we should wait to discuss error handling until task ID is introduced below?",
              "createdAt": "2021-08-16T15:35:05Z",
              "updatedAt": "2021-08-16T16:18:08Z"
            },
            {
              "originalPosition": 597,
              "body": "TODO: Check that this is reflected elsewhere.",
              "createdAt": "2021-08-16T15:41:37Z",
              "updatedAt": "2021-08-16T16:18:08Z"
            },
            {
              "originalPosition": 730,
              "body": "```suggestion\r\nThis process is illustrated below in {{pa-aggregate-flow}}. In this example,\r\n```",
              "createdAt": "2021-08-16T15:44:19Z",
              "updatedAt": "2021-08-16T16:18:08Z"
            },
            {
              "originalPosition": 722,
              "body": "s/AggregateReq/PPMAggregateReq/, here and below.",
              "createdAt": "2021-08-16T15:48:45Z",
              "updatedAt": "2021-08-16T16:18:08Z"
            },
            {
              "originalPosition": 741,
              "body": "```suggestion\r\nIn order to allow the helpers to minimize the state they need to run the protocol, the helper can attach a\r\n```",
              "createdAt": "2021-08-16T15:49:31Z",
              "updatedAt": "2021-08-16T16:18:08Z"
            },
            {
              "originalPosition": 743,
              "body": "```suggestion\r\nvalue in the next request, thus offloading the state to the\r\n```",
              "createdAt": "2021-08-16T15:49:55Z",
              "updatedAt": "2021-08-16T16:18:08Z"
            },
            {
              "originalPosition": 745,
              "body": "`{{helper-state}}` isn't a section. Also, how the state is used is currently up the helper. Without specifying a  protection mechanism I don't see what we're trying to enforce with this MUST.",
              "createdAt": "2021-08-16T15:52:48Z",
              "updatedAt": "2021-08-16T16:18:08Z"
            },
            {
              "originalPosition": 781,
              "body": "s/AggregateResp/PPMAggregateResp/ (here and below)",
              "createdAt": "2021-08-16T15:53:34Z",
              "updatedAt": "2021-08-16T16:18:08Z"
            },
            {
              "originalPosition": 827,
              "body": "I don't think there's a need to restrict it this way.",
              "createdAt": "2021-08-16T15:55:06Z",
              "updatedAt": "2021-08-16T16:18:08Z"
            },
            {
              "originalPosition": 646,
              "body": "```suggestion\r\n### Upload Request\r\n```",
              "createdAt": "2021-08-16T15:58:52Z",
              "updatedAt": "2021-08-16T16:18:08Z"
            },
            {
              "originalPosition": 900,
              "body": "s/CollectReq/PPMCollectReq/ (here and, in all likelihood, below)",
              "createdAt": "2021-08-16T16:03:04Z",
              "updatedAt": "2021-08-16T16:18:08Z"
            },
            {
              "originalPosition": 997,
              "body": "It's not merely a matter of how the leader is configured. In fact, it mostly depends on which PPM protocol is in use. For instance, Prio lets you start validating and aggregating inputs right away, whereas Hits requires you to wait until you have full batch.",
              "createdAt": "2021-08-16T16:10:56Z",
              "updatedAt": "2021-08-16T16:18:08Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzMwOTU4NTQw",
          "commit": {
            "abbreviatedOid": "5dcb6ab"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-08-16T17:22:11Z",
          "updatedAt": "2021-08-16T17:22:12Z",
          "comments": [
            {
              "originalPosition": 271,
              "body": "```suggestion\r\n```",
              "createdAt": "2021-08-16T17:22:11Z",
              "updatedAt": "2021-08-16T17:22:12Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzMwOTY1MTUx",
          "commit": {
            "abbreviatedOid": "2776fe7"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-08-16T17:29:56Z",
          "updatedAt": "2021-08-16T17:29:57Z",
          "comments": [
            {
              "originalPosition": 997,
              "body": "```suggestion\r\nDepending on the PPM scheme and how the leader is configured, the CollectReq may cause\r\n```",
              "createdAt": "2021-08-16T17:29:56Z",
              "updatedAt": "2021-08-16T17:30:10Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzMwOTY2Njgz",
          "commit": {
            "abbreviatedOid": "6dacfe5"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-08-16T17:31:43Z",
          "updatedAt": "2021-08-16T17:31:44Z",
          "comments": [
            {
              "originalPosition": 900,
              "body": "Let's punt to #116?",
              "createdAt": "2021-08-16T17:31:44Z",
              "updatedAt": "2021-08-16T17:31:44Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzMwOTY3ODAy",
          "commit": {
            "abbreviatedOid": "de3df67"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-08-16T17:33:05Z",
          "updatedAt": "2021-08-16T17:33:05Z",
          "comments": [
            {
              "originalPosition": 511,
              "body": "```suggestion\r\n## Task Configuration {#task-configuration}\r\n```",
              "createdAt": "2021-08-16T17:33:05Z",
              "updatedAt": "2021-08-16T17:33:05Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzMwOTY4NTEx",
          "commit": {
            "abbreviatedOid": "de3df67"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-08-16T17:33:57Z",
          "updatedAt": "2021-08-16T17:33:58Z",
          "comments": [
            {
              "originalPosition": 452,
              "body": "```suggestion\r\nwhere `task_id` is the associated PPM task (this value is always known, see {{task-configuration}}) and\r\n```",
              "createdAt": "2021-08-16T17:33:57Z",
              "updatedAt": "2021-08-16T17:33:58Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzMwOTY5MTA4",
          "commit": {
            "abbreviatedOid": "5dcb6ab"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-08-16T17:34:40Z",
          "updatedAt": "2021-08-16T17:34:40Z",
          "comments": [
            {
              "originalPosition": 447,
              "body": "(forward pointer inserted)",
              "createdAt": "2021-08-16T17:34:40Z",
              "updatedAt": "2021-08-16T17:34:40Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzMwOTY5NTQ5",
          "commit": {
            "abbreviatedOid": "effc468"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-08-16T17:35:12Z",
          "updatedAt": "2021-08-16T17:35:13Z",
          "comments": [
            {
              "originalPosition": 722,
              "body": "Punt to #116?",
              "createdAt": "2021-08-16T17:35:12Z",
              "updatedAt": "2021-08-16T17:35:13Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzMwOTcxMDEx",
          "commit": {
            "abbreviatedOid": "123df9c"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-08-16T17:37:01Z",
          "updatedAt": "2021-08-16T17:37:02Z",
          "comments": [
            {
              "originalPosition": 745,
              "body": "We're requiring that the state be encrypted, which is the purpose of this MUST, no?",
              "createdAt": "2021-08-16T17:37:01Z",
              "updatedAt": "2021-08-16T17:37:02Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzMwOTcxMTM1",
          "commit": {
            "abbreviatedOid": "123df9c"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-08-16T17:37:11Z",
          "updatedAt": "2021-08-16T17:37:11Z",
          "comments": [
            {
              "originalPosition": 781,
              "body": "Punt to #116?",
              "createdAt": "2021-08-16T17:37:11Z",
              "updatedAt": "2021-08-16T17:37:11Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzMwOTQ0NDU2",
          "commit": {
            "abbreviatedOid": "5dcb6ab"
          },
          "author": "ekr",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-08-16T17:05:30Z",
          "updatedAt": "2021-08-16T18:06:31Z",
          "comments": [
            {
              "originalPosition": 286,
              "body": "It's a forward reference so I won't have the dependency issue you mention later.",
              "createdAt": "2021-08-16T17:05:30Z",
              "updatedAt": "2021-08-16T18:06:31Z"
            },
            {
              "originalPosition": 305,
              "body": "Well, I think I'm saying something different here, which is that there ought to be a mode in which the leader just computes the results and automatically hands them off to the collector; the only thing preventing that is some sort of HTTP notification mechanics which we're actually going to need anyway to make long collection activities work.\r\n\r\nIf you want, I can make this an open issue.\r\n\r\n",
              "createdAt": "2021-08-16T17:07:27Z",
              "updatedAt": "2021-08-16T18:06:31Z"
            },
            {
              "originalPosition": 447,
              "body": "This is why I mentioned above that the task ID was a 32-byte value. I think that's sufficient to understand this section.\r\n\r\n",
              "createdAt": "2021-08-16T17:08:10Z",
              "updatedAt": "2021-08-16T18:06:31Z"
            },
            {
              "originalPosition": 462,
              "body": "Note that this is a defect in the previous text, which just moved.",
              "createdAt": "2021-08-16T17:08:51Z",
              "updatedAt": "2021-08-16T18:06:31Z"
            },
            {
              "originalPosition": 597,
              "body": "I deliberately removed this text. I don't think it's useful to have this kind of laundry list. Better to let the requirements become clear.",
              "createdAt": "2021-08-16T17:09:42Z",
              "updatedAt": "2021-08-16T18:06:31Z"
            },
            {
              "originalPosition": 646,
              "body": "I think we should name these sections by the function they perform. It's just HTTP mechanics that this is a \"Request\"",
              "createdAt": "2021-08-16T17:10:32Z",
              "updatedAt": "2021-08-16T18:06:31Z"
            },
            {
              "originalPosition": 722,
              "body": "I'm actually ambivalent on this",
              "createdAt": "2021-08-16T17:10:46Z",
              "updatedAt": "2021-08-16T18:06:31Z"
            },
            {
              "originalPosition": 730,
              "body": "What's wrong with \"shown\"?",
              "createdAt": "2021-08-16T17:11:00Z",
              "updatedAt": "2021-08-16T18:06:31Z"
            },
            {
              "originalPosition": 745,
              "body": "IETF markdown automatically turns heds into section markers by doing tr/A-Z /a-z\\-/.\r\n\r\nI agree that the section there is imprecise, but I think that that section should describe the security requirements.",
              "createdAt": "2021-08-16T17:12:48Z",
              "updatedAt": "2021-08-16T18:06:31Z"
            },
            {
              "originalPosition": 827,
              "body": "I think it's going to be incredibly confusing if not. You could easily end up in a situation where batch A is ready to read but batch B is not. It's much clearer to have multiple concurrent state machines.\r\n\r\n",
              "createdAt": "2021-08-16T17:13:35Z",
              "updatedAt": "2021-08-16T18:06:31Z"
            },
            {
              "originalPosition": 275,
              "body": "I actually think some imprecision is helpful here. There are actually three things:\r\n\r\n- A given client report\r\n- A given set of client reports fed to the collector.\r\n- The configuration [task]\r\n\r\nI don't think it's that problematic to use \"measurement\" informally for 1 and 2. If we just think about this in a standard telemetry setting, one could say that the operator takes a measurement by collecting all the client measurements. I agree that PDUs need to be clearly defined, but this is expository text.\r\n\r\n",
              "createdAt": "2021-08-16T18:06:21Z",
              "updatedAt": "2021-08-16T18:06:31Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzMxMTE2NzY4",
          "commit": {
            "abbreviatedOid": "8be8a64"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-08-16T20:42:37Z",
          "updatedAt": "2021-08-16T20:56:01Z",
          "comments": [
            {
              "originalPosition": 305,
              "body": "Oh, I see. By \"push\" you mean there might be some alternative to an HTTP request for gathering a CollectResp? Remember that, in general, thee collector needs to convey CollectReq to the aggregators somehow. (For instance, in Hits, the output can't be produced until the collector hands the aggregators the set of candidate prefixes.)\r\n\r\nIf that's what you mean, an open issue sounds fine.",
              "createdAt": "2021-08-16T20:42:37Z",
              "updatedAt": "2021-08-16T20:56:01Z"
            },
            {
              "originalPosition": 646,
              "body": "That's cool with me, but it's a bit odd that this section's super section is also called \"Uploading Reports\".",
              "createdAt": "2021-08-16T20:43:28Z",
              "updatedAt": "2021-08-16T20:56:01Z"
            },
            {
              "originalPosition": 722,
              "body": "SGTM",
              "createdAt": "2021-08-16T20:43:42Z",
              "updatedAt": "2021-08-16T20:56:01Z"
            },
            {
              "originalPosition": 745,
              "body": "IMO the behavior that a MUST enforces should be fully specified. My suggestion is to drop this MUST and replace it with an open issue:\r\n> [OPEN ISSUE: Security requires the helper state to be encrypted, but we haven't said how.]",
              "createdAt": "2021-08-16T20:45:52Z",
              "updatedAt": "2021-08-16T20:56:01Z"
            },
            {
              "originalPosition": 827,
              "body": "Yeah, that'd be pretty terrible. It seems like this would be addressed by https://github.com/abetterinternet/prio-documents/issues/109, right? Mind referring to that issue here?",
              "createdAt": "2021-08-16T20:48:32Z",
              "updatedAt": "2021-08-16T20:56:01Z"
            },
            {
              "originalPosition": 286,
              "body": "It seems out of place here. Could we at least provide a bit more information about the ID's purpose?",
              "createdAt": "2021-08-16T20:54:12Z",
              "updatedAt": "2021-08-16T20:56:01Z"
            },
            {
              "originalPosition": 597,
              "body": "Could you at least move it down to the dead text section below? It's useful to have this documented somewhere, at least temporarily. ",
              "createdAt": "2021-08-16T20:55:40Z",
              "updatedAt": "2021-08-16T20:56:01Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzMxMTMwNzU0",
          "commit": {
            "abbreviatedOid": "8be8a64"
          },
          "author": "ekr",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-08-16T21:01:29Z",
          "updatedAt": "2021-08-16T21:01:30Z",
          "comments": [
            {
              "originalPosition": 827,
              "body": "Sure.",
              "createdAt": "2021-08-16T21:01:29Z",
              "updatedAt": "2021-08-16T21:01:30Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzMxMTMwODU3",
          "commit": {
            "abbreviatedOid": "8be8a64"
          },
          "author": "ekr",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-08-16T21:01:36Z",
          "updatedAt": "2021-08-16T21:01:37Z",
          "comments": [
            {
              "originalPosition": 646,
              "body": "Oh, this could be an error on my part. Will check.",
              "createdAt": "2021-08-16T21:01:37Z",
              "updatedAt": "2021-08-16T21:02:02Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzMxMTMwOTU4",
          "commit": {
            "abbreviatedOid": "8be8a64"
          },
          "author": "ekr",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-08-16T21:01:45Z",
          "updatedAt": "2021-08-16T21:01:45Z",
          "comments": [
            {
              "originalPosition": 597,
              "body": "Sure.",
              "createdAt": "2021-08-16T21:01:45Z",
              "updatedAt": "2021-08-16T21:01:45Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzMxMTMxMjcx",
          "commit": {
            "abbreviatedOid": "8be8a64"
          },
          "author": "ekr",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-08-16T21:02:12Z",
          "updatedAt": "2021-08-16T21:02:12Z",
          "comments": [
            {
              "originalPosition": 283,
              "body": "SG",
              "createdAt": "2021-08-16T21:02:12Z",
              "updatedAt": "2021-08-16T21:02:12Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzMxMTMyMjA3",
          "commit": {
            "abbreviatedOid": "8be8a64"
          },
          "author": "ekr",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-08-16T21:03:23Z",
          "updatedAt": "2021-08-16T21:25:33Z",
          "comments": [
            {
              "originalPosition": 745,
              "body": "As a general matter, we often require MUSTs that aren't fully specified (e.g., MUST be cryptographically random) but I agree that given the state of things, an OPEN ISSUE makes sense.",
              "createdAt": "2021-08-16T21:03:24Z",
              "updatedAt": "2021-08-16T21:25:33Z"
            },
            {
              "originalPosition": 305,
              "body": "Wood and I spent a while discussing this on IM and it seems\r\nto me that there are a few pieces here:\r\n\r\n- Incremental computation\r\n- Proactively producing results\r\n\r\nTo take Prio as our example, it's quite possible for the leader to\r\njust send every report to the helpers as it comes in, then issue\r\nOutputShareReq when the batch window + jitter window expires and then\r\njust store the data for CollectReq.  It seems like that has some\r\nobvious advantages, though note that it's soft state and is invisible\r\nto the collector except for timing.\r\n\r\nMoving to Hits, the situation seems a bit more complicated.  As I\r\nunderstand it, it's not possible to collect all hits above a given\r\nthreshold and have the output concealed from the leader [0]. It\r\nmight, however, be possible to verify the proofs first, or at\r\nleast be theoretically possible even if Hits doesn't allow it\r\nnow. Again, this would be soft state.\r\n\r\n\r\nConversely, I think it's clear we're going to need some way for the\r\ncollector to set off a long running computation and get the results\r\nwhen its done. This could either be via a long poll/ websockets or\r\nsome sort of notification hook. It's possible that the leader could\r\nuse this mechanism whatever it is to proactively inform the collector\r\nof results (i.e., publish/subscribe), though maybe that's premature\r\nhere.\r\n\r\nIOW I think it's important that we don't say that this protocol\r\nrequires that all AggregateReq/OutputShare operations are triggered\r\nby a CollectReq. I think it's less important that there be some way\r\nfor it to automatically do that and deliver the results. I can remove\r\nthat and/or add an OPEN ISSUE.\r\n\r\n\r\n[0] Though presumably the pattern of queries allows the\r\nleader to infer which strings are of interest, right?\r\n\r\n          \r\n\r\n\r\n\r\n\r\n\r\n",
              "createdAt": "2021-08-16T21:25:26Z",
              "updatedAt": "2021-08-16T21:25:33Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzMxMjE4MzA1",
          "commit": {
            "abbreviatedOid": "8be8a64"
          },
          "author": "ekr",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-08-16T23:48:51Z",
          "updatedAt": "2021-08-16T23:48:51Z",
          "comments": [
            {
              "originalPosition": 258,
              "body": "https://github.com/abetterinternet/prio-documents/issues/117",
              "createdAt": "2021-08-16T23:48:51Z",
              "updatedAt": "2021-08-16T23:48:51Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzMxMjE4NjYz",
          "commit": {
            "abbreviatedOid": "8be8a64"
          },
          "author": "ekr",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-08-16T23:49:44Z",
          "updatedAt": "2021-08-16T23:49:44Z",
          "comments": [
            {
              "originalPosition": 646,
              "body": "Fixed.",
              "createdAt": "2021-08-16T23:49:44Z",
              "updatedAt": "2021-08-16T23:49:44Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzMxMjQ3OTUx",
          "commit": {
            "abbreviatedOid": "b715ef6"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-08-17T01:04:46Z",
          "updatedAt": "2021-08-17T01:04:47Z",
          "comments": [
            {
              "originalPosition": 305,
              "body": "> To take Prio as our example, it's quite possible for the leader to\r\n> just send every report to the helpers as it comes in, then issue\r\n> OutputShareReq when the batch window + jitter window expires and then\r\n> just store the data for CollectReq. It seems like that has some\r\n> obvious advantages, though note that it's soft state and is invisible\r\n> to the collector except for timing.\r\n\r\nYup!\r\n\r\n> Moving to Hits, the situation seems a bit more complicated. As I\r\n> understand it, it's not possible to collect all hits above a given\r\n> threshold and have the output concealed from the leader [0]. It\r\n> might, however, be possible to verify the proofs first, or at\r\n> least be theoretically possible even if Hits doesn't allow it\r\n> now. Again, this would be soft state.\r\n\r\nThis isn't possible for the current Hits protocol, sadly. The input validation protocol involves first evaluating the IDPF on the set of candidate prefixes, then running the \"secure sketching\" protocol of Section 4 to make sure that at most of one of these prefixes evaluates to 1 (and the others evaluate to 0). That means that input validation has to wait until the candidate prefixes are disseminated (from the collector to the aggregators). Maybe there's an alternative protocol for which input validation doesn't depend on the prefixes, but we don't have it yet.\r\n\r\n> Conversely, I think it's clear we're going to need some way for the\r\n> collector to set off a long running computation and get the results\r\n> when its done. This could either be via a long poll/ websockets or\r\n> some sort of notification hook. It's possible that the leader could\r\n> use this mechanism whatever it is to proactively inform the collector\r\n> of results (i.e., publish/subscribe), though maybe that's premature\r\n> here.\r\n\r\nAgreed. it's definitely going to be the case that the time between a collect request is issued and the response is generated could be a matter of hours. Though I wonder if it's as simple as responding to as collect request by saying \"call back in two hours, I should have your answer ready by then\"? Do we really need something fancier than this?\r\n\r\n> IOW I think it's important that we don't say that this protocol\r\n> requires that all AggregateReq/OutputShare operations are triggered\r\n> by a CollectReq.\r\n\r\nIf we want to implement Hits, then we have to accept that, in general, input validation and aggregation depends on parameters disseminated by the collector. Saying otherwise means trying to fit Hits into a box it doesn't fit in.\r\n\r\nOf course, we could consider changing the shape of the box. In particular, we might remove the encryption from the output share request and have the leader combine the output shares to get the candidate prefixes and initiate the next round itself, without involving the collector. This way the collector would only be involved at the very end, once all `n` collect rounds (i.e., rounds of input validation and aggregation) are completed. (Is this what you're suggesting?)\r\n\r\nIt's not clear to me that this results in any significant speed-up. It seems like the main advantage of this approach is that it eliminates the interaction with the collector at each round. The downside is that it rules out uses cases brought up @csharrison in which the collector wants the opportunity to \"prune\" the search space at each round based on knowledge it has of the input space. Wherever this optimization is possible, it is sure to bring a significant performance boost.\r\n\r\n> I think it's less important that there be some way\r\n> for it to automatically do that and deliver the results. I can remove\r\n> that and/or add an OPEN ISSUE.\r\n\r\nBy \"less\" do you mean \"more\" here?\r\n\r\n> [0] Though presumably the pattern of queries allows the\r\n> leader to infer which strings are of interest, right?\r\n\r\nRight, there's no way to avoid this with the current Hits protocol.\r\n\r\nBy the way, this conversation raises an interesting question. Right now we have just two PPM protocols, one in which input validation and aggregation are triggered by parameters that need to be disseminated to the aggregators (Hits), and another in which these steps can proceed immediately (Prio). The question is: _For other PPM protocols, which of these scenario is more likely?_ I don't think we have an answer right now.",
              "createdAt": "2021-08-17T01:04:47Z",
              "updatedAt": "2021-08-17T01:12:43Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzMxMjQ5MTkz",
          "commit": {
            "abbreviatedOid": "b715ef6"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-08-17T01:08:04Z",
          "updatedAt": "2021-08-17T01:08:05Z",
          "comments": [
            {
              "originalPosition": 275,
              "body": "Ok. I'm not sure I agree but I'm happy to differ to your experience and expertise here :)",
              "createdAt": "2021-08-17T01:08:05Z",
              "updatedAt": "2021-08-17T01:08:05Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzMxMjUwMTc2",
          "commit": {
            "abbreviatedOid": "b715ef6"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-08-17T01:10:59Z",
          "updatedAt": "2021-08-17T01:10:59Z",
          "comments": [
            {
              "originalPosition": 745,
              "body": "Ah, good point. Though I think \"MUST use a cryptographically secure random number generator\" and \"MUST use some encryption mechanism\" are qualitatively a bit different. Namely, the former statement can be made fairly precise, whereas the latter statement leaves a lot of room for misinterpretation. (Do you use an AEAD scheme? How do you pick the nonce? etc.)",
              "createdAt": "2021-08-17T01:10:59Z",
              "updatedAt": "2021-08-17T01:17:58Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzMyMTUwMjg4",
          "commit": {
            "abbreviatedOid": "f4a201b"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "",
          "createdAt": "2021-08-17T19:34:39Z",
          "updatedAt": "2021-08-17T19:34:39Z",
          "comments": []
        }
      ]
    },
    {
      "number": 119,
      "id": "MDExOlB1bGxSZXF1ZXN0NzE0NTE3MzM3",
      "title": "PPMFoo->Foo. Fixed #116",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/pull/119",
      "state": "MERGED",
      "author": "ekr",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "",
      "createdAt": "2021-08-17T19:41:54Z",
      "updatedAt": "2021-08-17T19:49:32Z",
      "baseRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "baseRefName": "main",
      "baseRefOid": "0102342a28ab5006bc76172d99b06914d1a7cdd2",
      "headRepository": "ekr/ppm-specification",
      "headRefName": "issue116_ppm",
      "headRefOid": "704888136f7bfe1cb7c30f502cf5bfe60f47bbe1",
      "closedAt": "2021-08-17T19:49:32Z",
      "mergedAt": "2021-08-17T19:49:32Z",
      "mergedBy": "chris-wood",
      "mergeCommit": {
        "oid": "37248d64b5e2b2124e1c2815fb77371fdb5d7df8"
      },
      "comments": [
        {
          "author": "ekr",
          "authorAssociation": "COLLABORATOR",
          "body": "@cjpatton I'm struggling with Github here and can't figure out what change you want.",
          "createdAt": "2021-08-17T19:43:50Z",
          "updatedAt": "2021-08-17T19:43:50Z"
        },
        {
          "author": "ekr",
          "authorAssociation": "COLLABORATOR",
          "body": "Thanks. ",
          "createdAt": "2021-08-17T19:46:45Z",
          "updatedAt": "2021-08-17T19:46:45Z"
        }
      ],
      "reviews": [
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzMyMTU3MTM0",
          "commit": {
            "abbreviatedOid": "a796b9a"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "CHANGES_REQUESTED",
          "body": "Yesterday I spotted an old \"PA\" prefix that was missed when we did s/PA/PDA/ would you mind finding it and fixing it?",
          "createdAt": "2021-08-17T19:43:06Z",
          "updatedAt": "2021-08-17T19:43:06Z",
          "comments": []
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzMyMTU3MjQx",
          "commit": {
            "abbreviatedOid": "a796b9a"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "",
          "createdAt": "2021-08-17T19:43:14Z",
          "updatedAt": "2021-08-17T19:43:14Z",
          "comments": []
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzMyMTU5NTM0",
          "commit": {
            "abbreviatedOid": "7048881"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "Disregard, I found it and pushed myself.",
          "createdAt": "2021-08-17T19:45:55Z",
          "updatedAt": "2021-08-17T19:45:55Z",
          "comments": []
        }
      ]
    },
    {
      "number": 120,
      "id": "MDExOlB1bGxSZXF1ZXN0NzE0NTQ2MTYz",
      "title": "Problem documents",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/pull/120",
      "state": "MERGED",
      "author": "ekr",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "",
      "createdAt": "2021-08-17T20:30:44Z",
      "updatedAt": "2021-08-17T23:25:44Z",
      "baseRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "baseRefName": "main",
      "baseRefOid": "37248d64b5e2b2124e1c2815fb77371fdb5d7df8",
      "headRepository": "ekr/ppm-specification",
      "headRefName": "problem_documents",
      "headRefOid": "13f1c0e2902556ca99f2ce4d83036998e8706aed",
      "closedAt": "2021-08-17T23:25:44Z",
      "mergedAt": "2021-08-17T23:25:44Z",
      "mergedBy": "ekr",
      "mergeCommit": {
        "oid": "c477edb1dc5c6cb82dd0545d9f41118517839de9"
      },
      "comments": [],
      "reviews": [
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzMyMjAxMzMy",
          "commit": {
            "abbreviatedOid": "f50ed20"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "",
          "createdAt": "2021-08-17T20:36:40Z",
          "updatedAt": "2021-08-17T20:38:37Z",
          "comments": [
            {
              "originalPosition": 55,
              "body": "```suggestion\r\n| unrecognizedMessage     | The message type for a response was incorrect or the payload was malformed. |\r\n```",
              "createdAt": "2021-08-17T20:36:40Z",
              "updatedAt": "2021-08-17T20:38:37Z"
            },
            {
              "originalPosition": 41,
              "body": "```suggestion\r\nchallenge objects as defined in {{iana-considerations}}.  PPM servers can return\r\n```",
              "createdAt": "2021-08-17T20:37:13Z",
              "updatedAt": "2021-08-17T20:38:37Z"
            },
            {
              "originalPosition": 81,
              "body": "```suggestion\r\nfollowing the template in {{!RFC3553}}:\r\n```",
              "createdAt": "2021-08-17T20:37:42Z",
              "updatedAt": "2021-08-17T20:38:37Z"
            },
            {
              "originalPosition": 58,
              "body": "```suggestion\r\nThis list is not exhaustive.  The server MAY return errors\r\n```",
              "createdAt": "2021-08-17T20:38:05Z",
              "updatedAt": "2021-08-17T20:38:37Z"
            }
          ]
        }
      ]
    },
    {
      "number": 121,
      "id": "MDExOlB1bGxSZXF1ZXN0NzE0NTU2MjE3",
      "title": "Add bof request",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/pull/121",
      "state": "MERGED",
      "author": "ekr",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "",
      "createdAt": "2021-08-17T20:48:46Z",
      "updatedAt": "2021-08-22T23:33:27Z",
      "baseRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "baseRefName": "main",
      "baseRefOid": "37248d64b5e2b2124e1c2815fb77371fdb5d7df8",
      "headRepository": "ekr/ppm-specification",
      "headRefName": "bof_request",
      "headRefOid": "b2a4a44b95ba447e9823390c541c0dd5f24154ff",
      "closedAt": "2021-08-22T23:33:27Z",
      "mergedAt": "2021-08-22T23:33:27Z",
      "mergedBy": "ekr",
      "mergeCommit": {
        "oid": "6a13c7909cdaa65b51fc32351fb11d5829e0cb3b"
      },
      "comments": [],
      "reviews": [
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzMyMzA3MTQ3",
          "commit": {
            "abbreviatedOid": "e6b4f54"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-08-17T23:30:07Z",
          "updatedAt": "2021-08-17T23:31:44Z",
          "comments": [
            {
              "originalPosition": 15,
              "body": "```suggestion\r\nNew cryptographic techniques such as Prio and, more recently, a protocol for privacy preserving heavy hitters, address\r\n```",
              "createdAt": "2021-08-17T23:30:07Z",
              "updatedAt": "2021-08-17T23:31:44Z"
            },
            {
              "originalPosition": 43,
              "body": "```suggestion\r\n   - Key Participant Conflict: Chris Wood, Eric Rescorla, Christopher Patton, Martin Thomson,\r\n```",
              "createdAt": "2021-08-17T23:31:27Z",
              "updatedAt": "2021-08-17T23:31:44Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzMyMzEyMjI0",
          "commit": {
            "abbreviatedOid": "1269961"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "You might want to wrap the long line but otherwise :+1: ",
          "createdAt": "2021-08-17T23:42:29Z",
          "updatedAt": "2021-08-17T23:42:29Z",
          "comments": []
        }
      ]
    },
    {
      "number": 122,
      "id": "MDExOlB1bGxSZXF1ZXN0NzE0NTY2Mzc0",
      "title": "Add abstract",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/pull/122",
      "state": "MERGED",
      "author": "ekr",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "",
      "createdAt": "2021-08-17T21:06:25Z",
      "updatedAt": "2021-08-17T21:21:16Z",
      "baseRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "baseRefName": "main",
      "baseRefOid": "37248d64b5e2b2124e1c2815fb77371fdb5d7df8",
      "headRepository": "ekr/ppm-specification",
      "headRefName": "abstract",
      "headRefOid": "ad849cc9a5de80d6b9ef471e79f4c292043a8a36",
      "closedAt": "2021-08-17T21:21:16Z",
      "mergedAt": "2021-08-17T21:21:16Z",
      "mergedBy": "chris-wood",
      "mergeCommit": {
        "oid": "917910995e6915ca2ccf188b5460a98cb61826ab"
      },
      "comments": [],
      "reviews": [
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzMyMjMzMzUz",
          "commit": {
            "abbreviatedOid": "fb8c1b0"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "",
          "createdAt": "2021-08-17T21:16:01Z",
          "updatedAt": "2021-08-17T21:19:14Z",
          "comments": [
            {
              "originalPosition": 14,
              "body": "```suggestion\r\nrevealing any individual user's data.\r\n```\r\n(just to avoid repeated \"collect\" in the same sentence)",
              "createdAt": "2021-08-17T21:16:01Z",
              "updatedAt": "2021-08-17T21:19:14Z"
            },
            {
              "originalPosition": 11,
              "body": "```suggestion\r\npeople's individual responses but rather in aggregated data. \r\nConventional methods require collecting individual responses and then\r\naggregating them, thus representing a threat to user privacy and\r\nrendering many such measurements difficult and impractical.\r\n```",
              "createdAt": "2021-08-17T21:16:41Z",
              "updatedAt": "2021-08-17T21:19:14Z"
            },
            {
              "originalPosition": 12,
              "body": "```suggestion\r\nThis document describes a multi-party privacy preserving measurement (PPM)\r\n```\r\nTake it or leave it, but IMO clarifying that this involves multiple entities seems like a useful thing to be up front about.",
              "createdAt": "2021-08-17T21:19:11Z",
              "updatedAt": "2021-08-17T21:19:14Z"
            }
          ]
        }
      ]
    },
    {
      "number": 123,
      "id": "MDExOlB1bGxSZXF1ZXN0NzE0NjEzMjY5",
      "title": "Remove/restructure attic stuff",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/pull/123",
      "state": "MERGED",
      "author": "ekr",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "",
      "createdAt": "2021-08-17T22:48:07Z",
      "updatedAt": "2021-08-18T00:14:21Z",
      "baseRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "baseRefName": "main",
      "baseRefOid": "cb9ec06593f99dbb89fa9e518366349e2c990d1b",
      "headRepository": "ekr/ppm-specification",
      "headRefName": "cleanup",
      "headRefOid": "9d4107dc80e5992fbe95cfcca767b72a6eddd514",
      "closedAt": "2021-08-18T00:14:21Z",
      "mergedAt": "2021-08-18T00:14:21Z",
      "mergedBy": "chris-wood",
      "mergeCommit": {
        "oid": "a801f7f6018ec929fa6199baa4e3caea7642609c"
      },
      "comments": [],
      "reviews": [
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzMyMzA4MDU2",
          "commit": {
            "abbreviatedOid": "5628724"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "",
          "createdAt": "2021-08-17T23:32:26Z",
          "updatedAt": "2021-08-17T23:32:26Z",
          "comments": []
        }
      ]
    },
    {
      "number": 124,
      "id": "MDExOlB1bGxSZXF1ZXN0NzE0NjE4OTA1",
      "title": "Convert to definition lists",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/pull/124",
      "state": "MERGED",
      "author": "ekr",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "This is just converting to defn. list format. I'm going to submit a separate PR to clean up the contents.",
      "createdAt": "2021-08-17T23:03:35Z",
      "updatedAt": "2021-08-17T23:04:51Z",
      "baseRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "baseRefName": "main",
      "baseRefOid": "917910995e6915ca2ccf188b5460a98cb61826ab",
      "headRepository": "ekr/ppm-specification",
      "headRefName": "glossary",
      "headRefOid": "1958c0eadb8072689f2b742dd166a3f9f3d483ee",
      "closedAt": "2021-08-17T23:04:51Z",
      "mergedAt": "2021-08-17T23:04:51Z",
      "mergedBy": "chris-wood",
      "mergeCommit": {
        "oid": "60d64dde0e5cf7f7330cb645ea8348771cf47fff"
      },
      "comments": [],
      "reviews": [
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzMyMjk2MDYy",
          "commit": {
            "abbreviatedOid": "1958c0e"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "",
          "createdAt": "2021-08-17T23:04:47Z",
          "updatedAt": "2021-08-17T23:04:47Z",
          "comments": []
        }
      ]
    },
    {
      "number": 125,
      "id": "MDExOlB1bGxSZXF1ZXN0NzE0NjIyMzkx",
      "title": "Triage the glossary:",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/pull/125",
      "state": "MERGED",
      "author": "ekr",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "- Remove terms which are infrequently used (and in a few cases,\r\n  remove the unnecessary references)\r\n\r\n- Clean up a few terms which appear to be defined incorrectly.",
      "createdAt": "2021-08-17T23:12:13Z",
      "updatedAt": "2021-08-17T23:24:20Z",
      "baseRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "baseRefName": "main",
      "baseRefOid": "60d64dde0e5cf7f7330cb645ea8348771cf47fff",
      "headRepository": "ekr/ppm-specification",
      "headRefName": "glossary_triage",
      "headRefOid": "91cd66393215d113eed14daaa2854d4773389b41",
      "closedAt": "2021-08-17T23:24:20Z",
      "mergedAt": "2021-08-17T23:24:20Z",
      "mergedBy": "chris-wood",
      "mergeCommit": {
        "oid": "7d002ffddde5e7c36e6a39410560eccb7099e7e9"
      },
      "comments": [],
      "reviews": [
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzMyMzA0NzAy",
          "commit": {
            "abbreviatedOid": "91cd663"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "",
          "createdAt": "2021-08-17T23:24:15Z",
          "updatedAt": "2021-08-17T23:24:15Z",
          "comments": []
        }
      ]
    },
    {
      "number": 126,
      "id": "MDExOlB1bGxSZXF1ZXN0NzE0NjIzMTcw",
      "title": "Add open issue",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/pull/126",
      "state": "MERGED",
      "author": "ekr",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "",
      "createdAt": "2021-08-17T23:14:06Z",
      "updatedAt": "2021-08-17T23:25:05Z",
      "baseRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "baseRefName": "main",
      "baseRefOid": "60d64dde0e5cf7f7330cb645ea8348771cf47fff",
      "headRepository": "ekr/ppm-specification",
      "headRefName": "batch_window_issue",
      "headRefOid": "c9dfb53b6038b1e84004e5fcb789a59070b26af4",
      "closedAt": "2021-08-17T23:25:05Z",
      "mergedAt": "2021-08-17T23:25:05Z",
      "mergedBy": "chris-wood",
      "mergeCommit": {
        "oid": "54246a63987049b909ce20c0dce63ac3fc21a728"
      },
      "comments": [],
      "reviews": [
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzMyMzA0OTcz",
          "commit": {
            "abbreviatedOid": "c9dfb53"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "",
          "createdAt": "2021-08-17T23:24:54Z",
          "updatedAt": "2021-08-17T23:24:54Z",
          "comments": []
        }
      ]
    },
    {
      "number": 127,
      "id": "MDExOlB1bGxSZXF1ZXN0NzE0NjM0NDM4",
      "title": "s/jitter/nonce, and file an open issue to track removing nonce altogether",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/pull/127",
      "state": "MERGED",
      "author": "chris-wood",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "Apply `make fix-lint` to clean up some other whitespace stuff, too.\r\n\r\nCloses #113.",
      "createdAt": "2021-08-17T23:48:59Z",
      "updatedAt": "2021-12-30T02:10:14Z",
      "baseRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "baseRefName": "main",
      "baseRefOid": "c477edb1dc5c6cb82dd0545d9f41118517839de9",
      "headRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "headRefName": "caw/rename-jitter",
      "headRefOid": "ab0aa5e72987c185058f787d7970e81cf1c6cdf7",
      "closedAt": "2021-08-18T00:10:23Z",
      "mergedAt": "2021-08-18T00:10:23Z",
      "mergedBy": "chris-wood",
      "mergeCommit": {
        "oid": "cb9ec06593f99dbb89fa9e518366349e2c990d1b"
      },
      "comments": [],
      "reviews": [
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzMyMzE1NTAy",
          "commit": {
            "abbreviatedOid": "48afcf2"
          },
          "author": "ekr",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "",
          "createdAt": "2021-08-17T23:51:03Z",
          "updatedAt": "2021-08-17T23:51:03Z",
          "comments": []
        }
      ]
    },
    {
      "number": 128,
      "id": "MDExOlB1bGxSZXF1ZXN0NzE0NjQyMzcw",
      "title": "Add boilerplate media type definitions for each protocol message.",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/pull/128",
      "state": "MERGED",
      "author": "chris-wood",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "Closes #105",
      "createdAt": "2021-08-18T00:10:02Z",
      "updatedAt": "2021-12-30T02:10:17Z",
      "baseRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "baseRefName": "main",
      "baseRefOid": "a801f7f6018ec929fa6199baa4e3caea7642609c",
      "headRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "headRefName": "caw/media-types",
      "headRefOid": "d21113d3da57302cb21246f41f396665b51d8e34",
      "closedAt": "2021-08-19T16:21:11Z",
      "mergedAt": "2021-08-19T16:21:11Z",
      "mergedBy": "chris-wood",
      "mergeCommit": {
        "oid": "0aa718758829395915806b531060b3680593a10c"
      },
      "comments": [
        {
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "body": "@mnot -- is it better practice to define media types per protocol message, or to define a single media type for all protocol messages?",
          "createdAt": "2021-08-18T00:17:15Z",
          "updatedAt": "2021-08-18T00:17:15Z"
        },
        {
          "author": "mnot",
          "authorAssociation": "NONE",
          "body": "Generally, if they're different formats -- e.g., they have different schema, or just different syntax -- they need different media types (or an explicitly generic one like `application/octet-stream`). If it's one format that has different uses, you can give it a single media type and then switch contexts based upon internal flags.\r\n\r\nThe real question, though, is whether you have any potential for use cases where it's important for generic software that's handling these messages to do different things based upon the media type. ",
          "createdAt": "2021-08-18T00:37:44Z",
          "updatedAt": "2021-08-18T00:37:44Z"
        },
        {
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "body": "> Generally, if they're different formats -- e.g., they have different schema, or just different syntax -- they need different media types (or an explicitly generic one like application/octet-stream). If it's one format that has different uses, you can give it a single media type and then switch contexts based upon internal flags.\r\n>\r\n> The real question, though, is whether you have any potential for use cases where it's important for generic software that's handling these messages to do different things based upon the media type.\r\n\r\nI don't think there'd ever be generic software using these types (beyond the HpkeConfig?). Most messages are meant to be consumed by PPM and PPM alone. I moved protocol messages to the \"message\" registry space and kept the HpkeConfig in the application type space, and also left all intended usage fields as COMMON. I also added an open issue to have someone more familiar with these registries give these allocation requests a review.\r\n\r\n@ekr, this should be good to go based on the above.\r\n",
          "createdAt": "2021-08-18T12:28:53Z",
          "updatedAt": "2021-08-18T12:28:53Z"
        }
      ],
      "reviews": [
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzM0MjEwNjUy",
          "commit": {
            "abbreviatedOid": "ad650c7"
          },
          "author": "ekr",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "LGTM except for the hed.",
          "createdAt": "2021-08-19T16:14:42Z",
          "updatedAt": "2021-08-19T16:15:19Z",
          "comments": [
            {
              "originalPosition": 5,
              "body": "This hed seems a bit short. What's your thinking here.",
              "createdAt": "2021-08-19T16:14:42Z",
              "updatedAt": "2021-08-19T16:15:19Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzM0MjE1NTAy",
          "commit": {
            "abbreviatedOid": "ad650c7"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-08-19T16:19:34Z",
          "updatedAt": "2021-08-19T16:19:34Z",
          "comments": [
            {
              "originalPosition": 5,
              "body": "Only that it was more clear, but it's a separate change, so I'll just revert.",
              "createdAt": "2021-08-19T16:19:34Z",
              "updatedAt": "2021-08-19T16:19:34Z"
            }
          ]
        }
      ]
    },
    {
      "number": 129,
      "id": "MDExOlB1bGxSZXF1ZXN0NzE0NjU0NDA0",
      "title": "Cache using HTTP headers, invalidate and retry upon upload.",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/pull/129",
      "state": "MERGED",
      "author": "chris-wood",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "Closes #106.",
      "createdAt": "2021-08-18T00:34:28Z",
      "updatedAt": "2021-12-30T02:10:15Z",
      "baseRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "baseRefName": "main",
      "baseRefOid": "a801f7f6018ec929fa6199baa4e3caea7642609c",
      "headRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "headRefName": "caw/config-cache-and-invalidate",
      "headRefOid": "47ee415bcae18486c33a77194386e5cbdb1631e0",
      "closedAt": "2021-08-18T20:33:17Z",
      "mergedAt": "2021-08-18T20:33:17Z",
      "mergedBy": "chris-wood",
      "mergeCommit": {
        "oid": "44b507c61a5b15f36e354b0c937e0f05601361ea"
      },
      "comments": [],
      "reviews": [
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzMyMzUxMjY1",
          "commit": {
            "abbreviatedOid": "a71f7c0"
          },
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "state": "CHANGES_REQUESTED",
          "body": "",
          "createdAt": "2021-08-18T01:14:18Z",
          "updatedAt": "2021-08-18T01:20:50Z",
          "comments": [
            {
              "originalPosition": 31,
              "body": "```suggestion\r\nAggregators SHOULD use HTTP caching to permit client-side caching of this\r\n```",
              "createdAt": "2021-08-18T01:14:18Z",
              "updatedAt": "2021-08-18T01:20:50Z"
            },
            {
              "originalPosition": 59,
              "body": "`HpkeConfig.id` is a uint8, meaning that any server can have 256 different keys, ever. If the lifetime of any HPKE key is on the order of days (which is what I infer from the suggested `Cache-Control` value above), and we don't allow recycling of `HpkeConfig.id`, then won't servers run out of key configs in just a few years? Which is a roundabout way of asking: should `HpkeConfig.id` be bigger than 8 bits?",
              "createdAt": "2021-08-18T01:19:55Z",
              "updatedAt": "2021-08-18T01:20:50Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzMyMzYzNjQ2",
          "commit": {
            "abbreviatedOid": "a71f7c0"
          },
          "author": "ekr",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-08-18T01:47:54Z",
          "updatedAt": "2021-08-18T01:47:54Z",
          "comments": [
            {
              "originalPosition": 59,
              "body": "That seems like probably the right approach, though I suppose we could recycle.",
              "createdAt": "2021-08-18T01:47:54Z",
              "updatedAt": "2021-08-18T01:47:55Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzMyNzc5MzQ5",
          "commit": {
            "abbreviatedOid": "bd955b9"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-08-18T12:08:30Z",
          "updatedAt": "2021-08-18T12:08:30Z",
          "comments": [
            {
              "originalPosition": 59,
              "body": "Indeed -- the current design requires aggregators to recycle. Since this is orthogonal to caching the config, let's file an open issue to address separately?",
              "createdAt": "2021-08-18T12:08:30Z",
              "updatedAt": "2021-08-18T12:08:30Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzMyNzgxMjUx",
          "commit": {
            "abbreviatedOid": "bd955b9"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-08-18T12:10:28Z",
          "updatedAt": "2021-08-18T12:10:28Z",
          "comments": [
            {
              "originalPosition": 59,
              "body": "(We had an issue tracking HpkeConfig updates, so I just updated that issue accordingly.)",
              "createdAt": "2021-08-18T12:10:28Z",
              "updatedAt": "2021-08-18T12:10:29Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzMzMDI2OTEy",
          "commit": {
            "abbreviatedOid": "47ee415"
          },
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "",
          "createdAt": "2021-08-18T15:17:30Z",
          "updatedAt": "2021-08-18T15:17:30Z",
          "comments": []
        }
      ]
    },
    {
      "number": 132,
      "id": "MDExOlB1bGxSZXF1ZXN0NzE1MzI3ODMw",
      "title": "Added an author list.",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/pull/132",
      "state": "MERGED",
      "author": "ekr",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "This adds a list of authors based on the main contributors in alphabetical order.\r\n\r\n@cjpatton, @tgeoghegan I would recommend changing your email addresses to something that's not your employer so that you get emails even if you change jobs.",
      "createdAt": "2021-08-18T18:38:54Z",
      "updatedAt": "2021-08-18T22:22:01Z",
      "baseRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "baseRefName": "main",
      "baseRefOid": "a801f7f6018ec929fa6199baa4e3caea7642609c",
      "headRepository": "ekr/ppm-specification",
      "headRefName": "authors",
      "headRefOid": "792904f4a1435210abf956ce0bcc33637ea46b15",
      "closedAt": "2021-08-18T22:22:01Z",
      "mergedAt": "2021-08-18T22:22:01Z",
      "mergedBy": "ekr",
      "mergeCommit": {
        "oid": "d271f629357d3d7c0bcb7a90ee25cf6fd1cdf295"
      },
      "comments": [],
      "reviews": [
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzMzMjk3NDgy",
          "commit": {
            "abbreviatedOid": "7aed549"
          },
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-08-18T19:58:17Z",
          "updatedAt": "2021-08-18T19:58:18Z",
          "comments": [
            {
              "originalPosition": 13,
              "body": "```suggestion\r\n       email: timgeog+ietf@gmail.com\r\n```",
              "createdAt": "2021-08-18T19:58:17Z",
              "updatedAt": "2021-08-18T19:58:18Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzMzMjk3NzM3",
          "commit": {
            "abbreviatedOid": "7aed549"
          },
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "",
          "createdAt": "2021-08-18T19:58:36Z",
          "updatedAt": "2021-08-18T19:58:36Z",
          "comments": []
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzMzMzkwNzg5",
          "commit": {
            "abbreviatedOid": "b16e12e"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-08-18T22:03:36Z",
          "updatedAt": "2021-08-18T22:03:37Z",
          "comments": [
            {
              "originalPosition": 19,
              "body": "```suggestion\r\n       email: chrispatton+ietf@gmail.com\r\n```",
              "createdAt": "2021-08-18T22:03:36Z",
              "updatedAt": "2021-08-18T22:03:37Z"
            }
          ]
        }
      ]
    },
    {
      "number": 134,
      "id": "MDExOlB1bGxSZXF1ZXN0NzE1Mzk3NDQ0",
      "title": "use `urn:ietf:params:ppm` sub-namespace",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/pull/134",
      "state": "MERGED",
      "author": "tgeoghegan",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "I think this is correct given the namespace reserved in `#ppm-urn-space`.",
      "createdAt": "2021-08-18T20:32:16Z",
      "updatedAt": "2021-12-30T00:53:28Z",
      "baseRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "baseRefName": "main",
      "baseRefOid": "a801f7f6018ec929fa6199baa4e3caea7642609c",
      "headRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "headRefName": "timg/urn-ietf-ppm-params",
      "headRefOid": "ad5865654c5cd7e2d6d48b6e37e110f4bb987bc4",
      "closedAt": "2021-08-18T20:33:06Z",
      "mergedAt": "2021-08-18T20:33:06Z",
      "mergedBy": "chris-wood",
      "mergeCommit": {
        "oid": "7abf55dc9bc07ec3e86c3df00bd792cdbf5cc7d4"
      },
      "comments": [
        {
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "body": "Good catch!",
          "createdAt": "2021-08-18T20:33:02Z",
          "updatedAt": "2021-08-18T20:33:02Z"
        }
      ],
      "reviews": [
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzMzMzI1MzAw",
          "commit": {
            "abbreviatedOid": "ad58656"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "",
          "createdAt": "2021-08-18T20:32:56Z",
          "updatedAt": "2021-08-18T20:32:56Z",
          "comments": []
        }
      ]
    },
    {
      "number": 135,
      "id": "MDExOlB1bGxSZXF1ZXN0NzE1NDk2NTkx",
      "title": "Amend PDUs to support multiple helpers",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/pull/135",
      "state": "MERGED",
      "author": "tgeoghegan",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "Modify `struct Param`, `struct Report` and `struct CollectResp` to\r\naccommodate more than one helper. Note that the PPM protocol doesn't\r\nactually support multiple helpers to enhance privacy (#68) but we\r\nnonetheless want to define the PDUs so it is possible to introduce that\r\nfeature in the future. We do this by introducing an `AggregatorId` type\r\ninto various struct definitions, allowing participants to tell which\r\naggregator an input share or output share corresponds to. We also\r\nintroduce a special, reserved value of `AggregatorId` that allows\r\nclients to tell which aggregator is the leader to which reports should\r\nbe uploaded. Finally, we use the aggregator ID in HPKE context\r\nconstruction instead of the existing constants 0x00 and 0x01 for leader\r\nand helper, respectively.\r\n\r\nAlong the way, we introduce the `HpkeConfigId` type alias used in few\r\ndifferent places.\r\n\r\nResolves #117, #133",
      "createdAt": "2021-08-19T00:13:44Z",
      "updatedAt": "2021-12-30T00:53:32Z",
      "baseRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "baseRefName": "main",
      "baseRefOid": "6a13c7909cdaa65b51fc32351fb11d5829e0cb3b",
      "headRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "headRefName": "timg/many-helpers",
      "headRefOid": "b891bdd145fe2c46da04ae356efea79ddbb502cf",
      "closedAt": "2021-08-26T22:31:56Z",
      "mergedAt": "2021-08-26T22:31:56Z",
      "mergedBy": "tgeoghegan",
      "mergeCommit": {
        "oid": "0ba2398d5cd14c916261ae8f3ae2f8c3e1ed302b"
      },
      "comments": [
        {
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "body": "Note that this change is stacked on #103 (sorry).\r\n\r\n- [x] make sure this PR targets `main` before merging",
          "createdAt": "2021-08-19T00:14:19Z",
          "updatedAt": "2021-08-19T15:33:26Z"
        },
        {
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "body": "@tgeoghegan I merged #103, so we can retarget this one now.",
          "createdAt": "2021-08-19T14:20:25Z",
          "updatedAt": "2021-08-19T14:20:25Z"
        },
        {
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "body": "> @tgeoghegan I merged #103, so we can retarget this one now.\r\n\r\nThanks! This is retargeted onto `main` and ready for review.",
          "createdAt": "2021-08-19T15:34:06Z",
          "updatedAt": "2021-08-19T15:34:06Z"
        },
        {
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "body": "> With that in mind, my high level ask is to be stricter about how ids are assigned. In particular, the ids should be contiguous (i.e., 0, 1, ..., len(Param.aggregators)-1) and Param.aggregators should be sorted by id.\r\n\r\nWhat value does sorting these add?",
          "createdAt": "2021-08-19T21:17:24Z",
          "updatedAt": "2021-08-19T21:17:24Z"
        },
        {
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "body": "After discussion with cjpatton, I tacked on a commit that attempts to\r\n    specify this stuff without defining `AggregatorId` and inserting it into\r\n    various messages. Instead, we now require a consistent ordering between\r\n    `Param.aggregator_endpoints` and `Report.encrypted_input_shares` (the\r\n    order of `CollectResp.encrypted_output_shares` doesn't matter; the\r\n    collector doesn't need to do anything special with the leader's share).\r\n    \r\nI'm not sure if this is better than the `AggregatorId` approach but now we can compare them.\r\n",
          "createdAt": "2021-08-20T00:58:53Z",
          "updatedAt": "2021-08-20T00:59:06Z"
        },
        {
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "body": "Taking a step back, is it true that we're simply trying to address aggregator routing at the leader here? In particular, upon receipt of a Report, the leader needs to know what aggregators should get the shares contained therein. The latest commit does this by saying \"send the i-th share to the i-th helper that was agreed upon in the Param structure.\" Is this a correct interpretation of the problem?",
          "createdAt": "2021-08-20T16:53:39Z",
          "updatedAt": "2021-08-20T16:53:39Z"
        },
        {
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "body": "> Taking a step back, is it true that we're simply trying to address aggregator routing at the leader here? In particular, upon receipt of a Report, the leader needs to know what aggregators should get the shares contained therein.\r\n\r\nThis PR is about addressing #117: putting enough structure into the PDUs so that we could extend the protocol in the future to support multiple helpers without changing the wire format of messages, even if actually supporting >1 helper might require more rounds of communication and new, yet undefined messages. IMO, that also requires solving #133, the problem of matching an encrypted input share to an aggregator. I also think that now that we have introduced a means of distinguishing arbitrary numbers of aggregators from each other, we should use it to diversify key material (but see my question below).\r\n\r\nThe actual protocol extensions are #68, which this PR does not address, nor do I think we intend to do anything about that issue anytime soon.\r\n\r\n> The latest commit does this by saying \"send the i-th share to the i-th helper that was agreed upon in the Param structure.\" Is this a correct interpretation of the problem?\r\n\r\nYes.\r\n\r\nI apologize for the back and forth on this. I think we have two important questions to resolve in this PR:\r\n\r\n## Question 1\r\nWe currently diversify keys by \"server role\", which is either \"leader\" or \"helper\". Now that we admit that there can be more than two server roles, do we want to further diversify key material by that role? \r\n\r\n### Question 1.(a)\r\nIf yes to 1., do we want to do that in this PR or should we punt to a subsequent change and leave `server_role = 0x00` for leader, `0x01` for helper?\r\n\r\n## Question 2\r\nWe want some protocol messages to be able to contain a vector of sub-messages, one for each participating aggregator. Do we want to achieve that with a vector of labeled tuples `(aggregator_id, value)` (as in commit d510e04ee4843b37e774cf3826af70f051272f7a), or with a simple vector of values, where the index into the vector is effectively the aggregator ID (as in commit 351d2a941369c048bc515cd8df32f91a7c48a3a8)?\r\n\r\nI think both are workable, with different tradeoffs. I prefer the labeled tuples approach because I think it is more explicit and  imposing fewer requirements on the order of lists in different messages means less validation code and removes opportunities for implementation bugs. @cjpatton argues for the simple vector approach.\r\n\r\nI'm not sure how to resolve that disagreement, except that consensus matters more to me than which one we choose. Should we, uh, vote on it or something?",
          "createdAt": "2021-08-20T20:00:22Z",
          "updatedAt": "2021-08-20T20:00:22Z"
        },
        {
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "body": "> I apologize for the back and forth on this. \r\n\r\nNo worries -- we're in alignment on the problem here. \r\n\r\nAs for the questions:\r\n\r\n1) Further diversification seems not useful, and appears like it only complicates matters. In particular, a helper doesn't necessarily need to know that it's helper i or j -- it just needs to know that it's not the leader. Sticking with what we currently have makes sense.\r\n2) I claim this is about routing messages to aggregators. As a silly example, imagine we split up Report into multiple HTTP requests, where each request carried one share for each aggregator. The request could identify the aggregator. This would also solve the problem here, but perhaps in a (much) worse way. \r\n\r\nBoth proposals -- tagging each share by an ID, or sorting the report based on the parameters -- seem fine, but I lean towards something like the former. Sorting the report means that everyone needs to agree on the order of helpers everywhere, which seems like an unnecessary constraint. I would prefer a design wherein each share unambiguously, and without additional coordination, identifies the intended aggregator.",
          "createdAt": "2021-08-20T20:20:01Z",
          "updatedAt": "2021-08-20T20:20:34Z"
        },
        {
          "author": "ekr",
          "authorAssociation": "COLLABORATOR",
          "body": "SGTM\n\nOn Mon, Aug 23, 2021 at 11:27 AM Tim Geoghegan ***@***.***>\nwrote:\n\n> ***@***.**** commented on this pull request.\n> ------------------------------\n>\n> In draft-pda-protocol.md\n> <https://github.com/abetterinternet/prio-documents/pull/135#discussion_r694209946>\n> :\n>\n> > @@ -419,12 +418,15 @@ Duration uint64; /* Number of seconds elapsed between two instants */\n>  Time uint64; /* seconds elapsed since start of UNIX epoch */\n>  ~~~\n>\n> -* `uuid`: A unique sequence of bytes used  to ensure that two otherwise\n> +* `uuid`: A unique sequence of bytes used to ensure that two otherwise\n>\n> I agree, but I think struct Param will go away altogether when someone\n> (perhaps me, later this week) addresses #104\n> <https://github.com/abetterinternet/prio-documents/issues/104>, and we\n> will be left with nothing but task_id. So I prefer to leave this text\n> alone until it gets deleted in that PR (except, I guess, to delete this\n> extra space).\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/abetterinternet/prio-documents/pull/135#discussion_r694209946>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/AAIPLILWUDR7YM562RUZ73LT6KHK7ANCNFSM5CNCZXCA>\n> .\n> Triage notifications on the go with GitHub Mobile for iOS\n> <https://apps.apple.com/app/apple-store/id1477376905?ct=notification-email&mt=8&pt=524675>\n> or Android\n> <https://play.google.com/store/apps/details?id=com.github.android&utm_campaign=notification-email>\n> .\n>\n",
          "createdAt": "2021-08-23T18:37:11Z",
          "updatedAt": "2021-08-23T18:37:11Z"
        },
        {
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "body": "In the interest of continuing to move forward, I am going to keep the version where we keep the ordering consistent across different messages. Per @chris-wood's observation, I've punted the question of aggregator IDs or server roles beyond the existing 0x01/0x00 constants to #138. ",
          "createdAt": "2021-08-23T19:00:38Z",
          "updatedAt": "2021-08-23T19:00:38Z"
        }
      ],
      "reviews": [
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzM0MjIyODE3",
          "commit": {
            "abbreviatedOid": "24be953"
          },
          "author": "ekr",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-08-19T16:27:03Z",
          "updatedAt": "2021-08-19T16:31:15Z",
          "comments": [
            {
              "originalPosition": 45,
              "body": "I would consider making this larger. I could imagine there being > 256 aggregators.",
              "createdAt": "2021-08-19T16:27:03Z",
              "updatedAt": "2021-08-19T16:31:15Z"
            },
            {
              "originalPosition": 55,
              "body": "```suggestion\r\n  when constructing other messages containing vectors with one value for each\r\n```",
              "createdAt": "2021-08-19T16:27:20Z",
              "updatedAt": "2021-08-19T16:31:15Z"
            },
            {
              "originalPosition": 57,
              "body": "Why do aggregators need to know their ID?",
              "createdAt": "2021-08-19T16:27:35Z",
              "updatedAt": "2021-08-19T16:31:16Z"
            },
            {
              "originalPosition": 57,
              "body": "```suggestion\r\n  Each aggregator knows its own `id`. `id` values must be unique in a `Param` but may have different meanings in different Params.\r\n```",
              "createdAt": "2021-08-19T16:28:28Z",
              "updatedAt": "2021-08-19T16:31:16Z"
            },
            {
              "originalPosition": 45,
              "body": "Would it actually make sense to not have an integer in this field and only in the submissions, and just have those values refer to indexes here.",
              "createdAt": "2021-08-19T16:30:21Z",
              "updatedAt": "2021-08-19T16:31:16Z"
            },
            {
              "originalPosition": 160,
              "body": "Actually, why do we need this field at all?",
              "createdAt": "2021-08-19T16:31:04Z",
              "updatedAt": "2021-08-19T16:31:16Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzM0MjE5MzUx",
          "commit": {
            "abbreviatedOid": "24be953"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "Nice! This really cleans stuff up.",
          "createdAt": "2021-08-19T16:23:33Z",
          "updatedAt": "2021-08-19T16:31:41Z",
          "comments": [
            {
              "originalPosition": 57,
              "body": "```suggestion\r\n  Each aggregator knows its own `id`. `id` values MUST be unique in a `Param`.\r\n  A `Param` structure with duplicate `id` values is considered malformed and MUST\r\n  be ignored by clients.\r\n```",
              "createdAt": "2021-08-19T16:23:34Z",
              "updatedAt": "2021-08-19T16:31:41Z"
            },
            {
              "originalPosition": 62,
              "body": "```suggestion\r\n  `Param`. A `Param` structure without the `leader_aggregator_id` is considered malformed\r\n   and MUST be ignored by clients.\r\n```",
              "createdAt": "2021-08-19T16:24:29Z",
              "updatedAt": "2021-08-19T16:31:41Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzM0MjI5NzEy",
          "commit": {
            "abbreviatedOid": "24be953"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-08-19T16:34:12Z",
          "updatedAt": "2021-08-19T16:34:13Z",
          "comments": [
            {
              "originalPosition": 57,
              "body": "> Why do aggregators need to know their ID?\r\n\r\nThis is a fair question -- it seems like the aggregator ID is only used to coordinate messages, and might not need to be included in the AAD.",
              "createdAt": "2021-08-19T16:34:12Z",
              "updatedAt": "2021-08-19T16:34:13Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzM0MzQ1ODMy",
          "commit": {
            "abbreviatedOid": "24be953"
          },
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-08-19T18:43:22Z",
          "updatedAt": "2021-08-19T18:43:22Z",
          "comments": [
            {
              "originalPosition": 57,
              "body": "Yes, an aggregator only needs to know its own ID to put in the AAD when establishing HPKE context. That is also why I made that field `uint8`, to match the previous leader/helper `server_role` values. However we could also make the aggregator ID into a longer string of bytes, allowing the values to be human readable strings, which I think will be nice for logging purposes. But it sounds like you are doubting the value of including server role in the AAD at all? I would think that since a given aggregator could be acting as either a leader or a helper in different protocol instantiations, and maybe using the same HPKE config for both, including server role diversifies keys across protocol instantiations. Then again, if that's the goal, then we should probably also mix in the `task_id` since `aggregator_id` values could be re-used across different protocol instantiations.\r\n\r\nSo my take here is we should:\r\n\r\n* define `opaque AggregatorId<1..256>;`\r\n* use `enc, context = SetupBase(S|R)(pk, \"pda input share\" || task_id || aggregator_id)` and `enc, context = SetupBaseS(pk, \"pda output share\" || task_id || aggregator_id)`\r\n\r\nBut I will defer to the superior crypto brains of @chris-wood and @ekr ... should we just drop `server_role`/`aggregator_id` from the HPKE application info?",
              "createdAt": "2021-08-19T18:43:22Z",
              "updatedAt": "2021-08-19T19:50:04Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzM0MzYwMzQ5",
          "commit": {
            "abbreviatedOid": "24be953"
          },
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-08-19T19:00:12Z",
          "updatedAt": "2021-08-19T19:00:12Z",
          "comments": [
            {
              "originalPosition": 57,
              "body": "Or we could go back to leader = `0x00` / helper = `0x01` in the info, which has the virtue of not entangling our mechanism for coordinating messages with our mechanism for key diversity, but then we will have to revisit the question of what application info should be provided by helpers beyond the first one, if and when we introduce multiple helpers. My goal in introducing the aggregator_id into the AAD was to avoid such a disruptive change.",
              "createdAt": "2021-08-19T19:00:12Z",
              "updatedAt": "2021-08-19T19:00:12Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzM0MzYzMzA5",
          "commit": {
            "abbreviatedOid": "24be953"
          },
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-08-19T19:03:34Z",
          "updatedAt": "2021-08-19T19:03:34Z",
          "comments": [
            {
              "originalPosition": 45,
              "body": "I agree, there's no reason not to make this a 64 bit integer (or even a much longer byte string as I suggest in another thread on this PR). However I'm not sure if we want the IDs in other messages to refer to indexes here, because that imposes the new constraint on aggregator IDs that they be sequential, which is not required with the current `Aggregator` definition.\r\n",
              "createdAt": "2021-08-19T19:03:34Z",
              "updatedAt": "2021-08-19T19:03:34Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzM0NDQ1NDg3",
          "commit": {
            "abbreviatedOid": "49ce09c"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "CHANGES_REQUESTED",
          "body": "This change is basically right. The main thing I would change is to make more clear the intended meaning of aggregator ID. While it was intended to solve the indexing-into-input-shares-array problem, this PR also addresses the more fundamental problem of assigning roles to each of the aggregators in the protocol. I think this is a great idea, and that's what this should be about.\r\n\r\nWith that in mind, my high level ask is to be stricter about how ids are assigned. In particular, the ids should be contiguous (i.e., `0, 1, ..., len(Param.aggregators)-1`) and `Param.aggregators` should be sorted by id.",
          "createdAt": "2021-08-19T20:36:49Z",
          "updatedAt": "2021-08-19T21:02:55Z",
          "comments": [
            {
              "originalPosition": 45,
              "body": "256 or more aggregators sounds crazy to me, but maybe we have a different mental model for AggregatorId. I would think that AggregatorId identifies the *role* of an endpoint of the protocol. Having more than, say, 10 different roles (1 leader and 9 helpers, all doing the same thing, but maybe in a particular order) seems inconceivable to me.",
              "createdAt": "2021-08-19T20:36:49Z",
              "updatedAt": "2021-08-19T21:02:55Z"
            },
            {
              "originalPosition": 87,
              "body": "```suggestion\r\nBefore the client can upload its report to the leader, it must know the public key of\r\n```",
              "createdAt": "2021-08-19T20:42:03Z",
              "updatedAt": "2021-08-19T21:02:55Z"
            },
            {
              "originalPosition": 89,
              "body": "This is hard to read because it uses some non-standard notation. Is there anything technically wrong with what we had before? It seems to me that nothing has changed semantically.",
              "createdAt": "2021-08-19T20:45:13Z",
              "updatedAt": "2021-08-19T21:02:55Z"
            },
            {
              "originalPosition": 47,
              "body": "Instead of reserving a special value, could we just insist that each `Aggregator` in `Param.aggregators` is sorted by `Aggregator.id`? While at it, I think we should insist that the sequence of ids is always `0, 1, ..., len(Param.aggregators)-1`. (Maybe we already have this?)",
              "createdAt": "2021-08-19T20:48:21Z",
              "updatedAt": "2021-08-19T21:02:55Z"
            },
            {
              "originalPosition": 137,
              "body": "If we insist that the aggregator ids are unique, contiguous, and start at 0, then here we could just say `aggregator_id in [0, num_aggregators)`.",
              "createdAt": "2021-08-19T20:49:37Z",
              "updatedAt": "2021-08-19T21:02:55Z"
            },
            {
              "originalPosition": 221,
              "body": "It would be cleaner if we could just insist that `agregator.id > 0`.",
              "createdAt": "2021-08-19T20:51:46Z",
              "updatedAt": "2021-08-19T21:02:55Z"
            },
            {
              "originalPosition": 222,
              "body": "Here again is some non-standard notation. Can we express this differently?",
              "createdAt": "2021-08-19T20:52:05Z",
              "updatedAt": "2021-08-19T21:02:55Z"
            },
            {
              "originalPosition": 317,
              "body": "```suggestion\r\nID of the aggregator. `output_share` is the serialized `OutputShare`.\r\n```",
              "createdAt": "2021-08-19T20:54:48Z",
              "updatedAt": "2021-08-19T21:02:55Z"
            },
            {
              "originalPosition": 336,
              "body": "```suggestion\r\n* `aggregator_id` is the ID of the aggregator constructing the\r\n```",
              "createdAt": "2021-08-19T20:55:32Z",
              "updatedAt": "2021-08-19T21:02:55Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzM0NDc2Njk2",
          "commit": {
            "abbreviatedOid": "4cd6bd2"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-08-19T21:18:19Z",
          "updatedAt": "2021-08-19T21:18:19Z",
          "comments": [
            {
              "originalPosition": 47,
              "body": "How would this value (of zero) different from having the leader appear first (also a value of zero)?",
              "createdAt": "2021-08-19T21:18:19Z",
              "updatedAt": "2021-08-19T21:18:19Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzM0NDc3NTEz",
          "commit": {
            "abbreviatedOid": "4cd6bd2"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-08-19T21:19:29Z",
          "updatedAt": "2021-08-19T21:19:29Z",
          "comments": [
            {
              "originalPosition": 57,
              "body": "FWIW, I'd drop it from the AAD, and then mark an open issue asking whether or not we believe it's important to authenticate. (My impression is that this is not important to authenticate.)",
              "createdAt": "2021-08-19T21:19:29Z",
              "updatedAt": "2021-08-19T21:19:29Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzM0NTUzOTcx",
          "commit": {
            "abbreviatedOid": "4cd6bd2"
          },
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-08-19T23:38:01Z",
          "updatedAt": "2021-08-19T23:38:02Z",
          "comments": [
            {
              "originalPosition": 89,
              "body": "I guess I'm not sure how clearly an RFC needs to spell out things like this for implementors. I agree it was pretty clear before so I think I'll put it back.",
              "createdAt": "2021-08-19T23:38:02Z",
              "updatedAt": "2021-08-19T23:38:02Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzM1NjIyMTAx",
          "commit": {
            "abbreviatedOid": "351d2a9"
          },
          "author": "ekr",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "I'm also a bit concerned about universal sorting, but I think we can resolve this separately, b/c it's really just about what goes into the HPKE functions. I suggest we land this once the more minor comments have been resolved.",
          "createdAt": "2021-08-22T23:38:56Z",
          "updatedAt": "2021-08-22T23:56:27Z",
          "comments": [
            {
              "originalPosition": 15,
              "body": "I wouldn't call this \"uuid\" because then some IETF nitpicker will complain that it's not actually a UUID.\r\n\r\nMaybe ```task_nonce```",
              "createdAt": "2021-08-22T23:38:56Z",
              "updatedAt": "2021-08-22T23:56:27Z"
            },
            {
              "originalPosition": 25,
              "body": "I would rewrite this because it's the reports which have to be consistent with this:\r\n```suggestion\r\n  endpoints can be found. The leader's endpoint MUST be the first in the vector.\r\n  The order in encrypted input shares in a `Report` (see\r\n  {{uploading-reports}}) MUST be the same as the\r\n  order in which aggregators appear in this vector.\r\n```",
              "createdAt": "2021-08-22T23:40:19Z",
              "updatedAt": "2021-08-22T23:56:27Z"
            },
            {
              "originalPosition": 34,
              "body": "FYI, you don't need this. kramdown automatically creates anchors by doing tr/A-Z /a-z\\-/.",
              "createdAt": "2021-08-22T23:41:24Z",
              "updatedAt": "2021-08-22T23:56:27Z"
            },
            {
              "originalPosition": 49,
              "body": "```suggestion\r\naggregator's endpoint URL, provided in the `Param` for the task. The aggregator responds to\r\n```",
              "createdAt": "2021-08-22T23:42:24Z",
              "updatedAt": "2021-08-22T23:56:27Z"
            },
            {
              "originalPosition": 73,
              "body": "```suggestion\r\nThe client MUST abort if any of the following happen for any `key_config` request:\r\n```",
              "createdAt": "2021-08-22T23:42:46Z",
              "updatedAt": "2021-08-22T23:56:27Z"
            },
            {
              "originalPosition": 84,
              "body": "FWIW, I prefer the phrasing before. \"Let\" is a bit stilted.",
              "createdAt": "2021-08-22T23:43:14Z",
              "updatedAt": "2021-08-22T23:56:27Z"
            },
            {
              "originalPosition": 96,
              "body": "```suggestion\r\n  should be for the first helper, and so on).\r\n```",
              "createdAt": "2021-08-22T23:44:59Z",
              "updatedAt": "2021-08-22T23:56:27Z"
            },
            {
              "originalPosition": 208,
              "body": "This bit of mathiness seems a bit confusing. Instead of expanding the formula, I would consider \"where each subresponse corresponds to the sub-request in the same position in AggregateReq\"\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n",
              "createdAt": "2021-08-22T23:51:30Z",
              "updatedAt": "2021-08-22T23:56:27Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzM2NDM3NjY2",
          "commit": {
            "abbreviatedOid": "351d2a9"
          },
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-08-23T18:27:48Z",
          "updatedAt": "2021-08-23T18:27:48Z",
          "comments": [
            {
              "originalPosition": 15,
              "body": "I agree, but I think `struct Param` will go away altogether when someone (perhaps me, later this week) addresses #104, and we will be left with nothing but `task_id`. So I prefer to leave this text alone until it gets deleted in that PR (except, I guess, to delete this extra space).",
              "createdAt": "2021-08-23T18:27:48Z",
              "updatedAt": "2021-08-23T18:27:48Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzM3ODA0OTUw",
          "commit": {
            "abbreviatedOid": "ce83f1b"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "Yup! This is looking good to me. A couple more questions in-line.",
          "createdAt": "2021-08-25T00:53:43Z",
          "updatedAt": "2021-08-25T00:57:18Z",
          "comments": [
            {
              "originalPosition": 108,
              "body": "Does it make sense to replace `server_role` with the index of the input share in the report struct? This may be useful for protocols with more than two aggregators.",
              "createdAt": "2021-08-25T00:53:44Z",
              "updatedAt": "2021-08-25T00:57:18Z"
            },
            {
              "originalPosition": 185,
              "body": "Do you intend to start a new paragraph here? It's usually OK to inline OPEN ISSUEs with surrounding text.",
              "createdAt": "2021-08-25T00:55:08Z",
              "updatedAt": "2021-08-25T00:57:18Z"
            },
            {
              "originalPosition": 213,
              "body": "See comment above.",
              "createdAt": "2021-08-25T00:55:48Z",
              "updatedAt": "2021-08-25T00:57:18Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzM3ODIwOTIw",
          "commit": {
            "abbreviatedOid": "ce83f1b"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-08-25T01:38:17Z",
          "updatedAt": "2021-08-25T01:38:17Z",
          "comments": [
            {
              "originalPosition": 108,
              "body": "We punted this to a separate issue. ",
              "createdAt": "2021-08-25T01:38:17Z",
              "updatedAt": "2021-08-25T01:38:17Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzM4ODA2NTQ4",
          "commit": {
            "abbreviatedOid": "ce83f1b"
          },
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-08-25T20:37:40Z",
          "updatedAt": "2021-08-25T20:37:40Z",
          "comments": [
            {
              "originalPosition": 108,
              "body": "Namely #138. I do agree that server role will end up being the index of the aggregator in the vector.",
              "createdAt": "2021-08-25T20:37:40Z",
              "updatedAt": "2021-08-25T20:38:56Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzM4ODA4ODg0",
          "commit": {
            "abbreviatedOid": "e42452b"
          },
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-08-25T20:40:33Z",
          "updatedAt": "2021-08-25T20:40:33Z",
          "comments": [
            {
              "originalPosition": 185,
              "body": "I think I did that because I rewrote this paragraph so many times that I got tired of re-word-wrapping the [OPEN ISSUE]. I put it back inline.",
              "createdAt": "2021-08-25T20:40:33Z",
              "updatedAt": "2021-08-25T20:40:33Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzM4ODA5MDYz",
          "commit": {
            "abbreviatedOid": "e42452b"
          },
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-08-25T20:40:45Z",
          "updatedAt": "2021-08-25T20:40:45Z",
          "comments": [
            {
              "originalPosition": 213,
              "body": "Also #138. ",
              "createdAt": "2021-08-25T20:40:45Z",
              "updatedAt": "2021-08-25T20:40:45Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzM4OTM2ODE2",
          "commit": {
            "abbreviatedOid": "e42452b"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "CHANGES_REQUESTED",
          "body": "Just a few more comments, one of which is blocking.",
          "createdAt": "2021-08-26T00:36:39Z",
          "updatedAt": "2021-08-26T00:50:01Z",
          "comments": [
            {
              "originalPosition": 129,
              "body": "nit\r\n```suggestion\r\n`extensions` are the corresponding fields of `Report`.\r\n```",
              "createdAt": "2021-08-26T00:36:40Z",
              "updatedAt": "2021-08-26T00:50:01Z"
            },
            {
              "originalPosition": 150,
              "body": "```suggestion\r\ncan send them to the helpers to be validated and aggregated. In order\r\n```",
              "createdAt": "2021-08-26T00:37:35Z",
              "updatedAt": "2021-08-26T00:50:01Z"
            },
            {
              "originalPosition": 166,
              "body": "Hmm, this is a bit hairy. We haven't yet fleshed out the communication pattern for protocols with multiple helpers. This seems to imply that the leader always starts by making an aggregate request to each helper. But in what order? Do you wait for the response form the first helper before making a request to the next?\r\n\r\nI think we need to punt on this problem for now by writing this section as if there's just one helper. Here for example you would say something like\r\n> The leader sends a POST request to `[helper]/aggregate`, where `[helper]` is the helper URL specified by the PPM parameters for task ID `AggregateReq.task_id`.",
              "createdAt": "2021-08-26T00:44:26Z",
              "updatedAt": "2021-08-26T00:50:01Z"
            },
            {
              "originalPosition": 236,
              "body": "Here again it might be best to speak in terms of 1 leader and 1 helper. I can't imagine that the order in which output-share requests are made would matter, but maybe we should err on the side of simplicity.",
              "createdAt": "2021-08-26T00:49:23Z",
              "updatedAt": "2021-08-26T00:50:01Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzM4OTY4MDUw",
          "commit": {
            "abbreviatedOid": "e42452b"
          },
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-08-26T02:02:26Z",
          "updatedAt": "2021-08-26T02:02:26Z",
          "comments": [
            {
              "originalPosition": 166,
              "body": "Sure, seems reasonable. The goal of this change was just to make it possible to admit more helpers, so we can certainly make this language simpler without losing anything.",
              "createdAt": "2021-08-26T02:02:26Z",
              "updatedAt": "2021-08-26T02:02:26Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzM5OTU0MTAy",
          "commit": {
            "abbreviatedOid": "4b6797f"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "",
          "createdAt": "2021-08-26T21:30:34Z",
          "updatedAt": "2021-08-26T21:30:34Z",
          "comments": []
        }
      ]
    },
    {
      "number": 136,
      "id": "MDExOlB1bGxSZXF1ZXN0NzE2Mjk4Njkz",
      "title": "s/pda/ppm",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/pull/136",
      "state": "MERGED",
      "author": "cjpatton",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "The draft name still has the acronym \"pda\" in it. Let's kill this for good.",
      "createdAt": "2021-08-19T22:16:25Z",
      "updatedAt": "2021-12-30T02:10:18Z",
      "baseRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "baseRefName": "main",
      "baseRefOid": "0aa718758829395915806b531060b3680593a10c",
      "headRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "headRefName": "cjpatton/pda2ppm",
      "headRefOid": "a2541ee2928fcb70fc134564085be9092c878522",
      "closedAt": "2021-08-20T15:02:24Z",
      "mergedAt": "2021-08-20T15:02:24Z",
      "mergedBy": "chris-wood",
      "mergeCommit": {
        "oid": "7c14a1f6c535662376033749d8636440ac74ff82"
      },
      "comments": [
        {
          "author": "ekr",
          "authorAssociation": "COLLABORATOR",
          "body": "You also need to fix .targets.mk I believe",
          "createdAt": "2021-08-19T22:19:14Z",
          "updatedAt": "2021-08-19T22:19:14Z"
        },
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "nice catch, @ekr",
          "createdAt": "2021-08-19T22:39:14Z",
          "updatedAt": "2021-08-19T22:39:14Z"
        }
      ],
      "reviews": [
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzM0NTQzNTE3",
          "commit": {
            "abbreviatedOid": "a2541ee"
          },
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "",
          "createdAt": "2021-08-19T23:12:11Z",
          "updatedAt": "2021-08-19T23:12:11Z",
          "comments": []
        }
      ]
    },
    {
      "number": 137,
      "id": "MDExOlB1bGxSZXF1ZXN0NzE2MzczMDgx",
      "title": "Resolve open batch boundary issues",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/pull/137",
      "state": "MERGED",
      "author": "cjpatton",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "We have the following security/operational considerations, not all of\r\nwhich can be addressed at the same time:\r\n\r\n  - Enforcing privacy budgets for DP requires us to limit the number of\r\n  batches the same report is used.\r\n  - Hits requires the same report to be used in some number of batches.\r\n\r\nTo resolve these issues, this change adds a `max_report_lifetime`\r\nparameter, which specifies the maximum number of times a report may be\r\naggregated into an output. This enables Hits while allowing PPM\r\nprotocols to enforce a privacy budget.\r\n\r\nThis change also seeks to clarify some ambiguities in how the batch\r\nboundaries are defined, and why they're defined that way. Along the way,\r\nit cleans up some protocol bits that got lost in the last refactor.\r\n\r\nCloses #118 by doing nothing. Hopefully the new text makes the issue more\r\nclear.",
      "createdAt": "2021-08-20T01:46:13Z",
      "updatedAt": "2021-12-30T02:10:20Z",
      "baseRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "baseRefName": "main",
      "baseRefOid": "14625bf507ab723949271d78f4667d74aedfaaa7",
      "headRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "headRefName": "cjpatton/batch-boundaries",
      "headRefOid": "f4168a161758c111d6d5487819b7f4c43c8bbaa2",
      "closedAt": "2021-09-09T14:12:05Z",
      "mergedAt": "2021-09-09T14:12:05Z",
      "mergedBy": "cjpatton",
      "mergeCommit": {
        "oid": "fc7dfe824f1586d76bde80aea403c98615a5ce92"
      },
      "comments": [
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "Rebased.",
          "createdAt": "2021-09-07T23:32:35Z",
          "updatedAt": "2021-09-07T23:32:35Z"
        },
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "Squashed.",
          "createdAt": "2021-09-09T14:12:00Z",
          "updatedAt": "2021-09-09T14:12:00Z"
        }
      ],
      "reviews": [
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzM1MzgwNTU2",
          "commit": {
            "abbreviatedOid": "a467f99"
          },
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "state": "CHANGES_REQUESTED",
          "body": "",
          "createdAt": "2021-08-20T20:55:14Z",
          "updatedAt": "2021-08-20T22:02:29Z",
          "comments": [
            {
              "originalPosition": 66,
              "body": "I think the idea is that if you have an extension whose purpose is client->server authentication, then the authenticity and/or integrity and/or confidentiality of the contents of the extension are internal to the structure of the extension and opaque to PPM. But I don't think we want to get into that conversation in this PR, and your `OPEN ISSUE` as written is valid.",
              "createdAt": "2021-08-20T20:55:14Z",
              "updatedAt": "2021-08-20T22:02:29Z"
            },
            {
              "originalPosition": 7,
              "body": "Eight usages of the term \"batch interval\" are introduced by this change. Should it be defined here?",
              "createdAt": "2021-08-20T21:03:27Z",
              "updatedAt": "2021-08-20T22:02:29Z"
            },
            {
              "originalPosition": 167,
              "body": " \"each input share\" -> this means that helper has to track privacy budget per-input, which I think is a significant increase in the storage requirements on the helper (and/or the size of the opaque state stored for helper by leader). Isn't the idea that the helper can just maintain a few tuples of `(timestamp, consumed_privacy)`, meaning that `consumed_privacy` worth of privacy budget has been used up for all the reports up to `timestamp`? e.g.:\r\n\r\n```\r\ntimestamp | consumed_privacy\r\n1000      | 20\r\n2000      | 10\r\n```\r\nmeans reports with timestamp in range `[0, 1000)` have consumed 20 points of privacy, `[1001, 2000)` have consumed 10 points of privacy, `[2000, end)` have consumed 0 points of privacy.",
              "createdAt": "2021-08-20T21:24:22Z",
              "updatedAt": "2021-08-20T22:02:29Z"
            },
            {
              "originalPosition": 168,
              "body": "Is an integer count of inclusions in an output sufficient? I think that assumes that every query against a set of input shares consumes the same \"amount\" of privacy budget. Is that true in all schemes? In heavy hitters, the idea is that the collector will iteratively make queries with longer and longer string prefixes. Does varying prefix length change \"how much\" privacy is consumed by a query?",
              "createdAt": "2021-08-20T21:25:42Z",
              "updatedAt": "2021-08-20T22:02:29Z"
            },
            {
              "originalPosition": 169,
              "body": "`lifetime` does not seem like the right word, particularly because it implies an interval or duration of time. Why not `Param.privacy_budget`?",
              "createdAt": "2021-08-20T21:31:28Z",
              "updatedAt": "2021-08-20T22:02:29Z"
            },
            {
              "originalPosition": 174,
              "body": "I'm not sure this is correct. I think \"except as required\" is referring to a case like heavy hitters where the collector may do multiple queries against a single batch with longer and longer string prefixes, right? But even then, then I think aggregators still need to enforce that an input only ever appears in a single batch, and appears at most once in that batch.\r\n\r\nPut differently, our notions of anti-replay are about how inputs are assigned to batches, and apply uniformly regardless of PPM scheme. The question of how many queries are allowed against a batch by some scheme is orthogonal.",
              "createdAt": "2021-08-20T21:46:09Z",
              "updatedAt": "2021-08-20T22:02:29Z"
            },
            {
              "originalPosition": 274,
              "body": "See my comment in #{{anti-replay}} -- I don't think this is correct.",
              "createdAt": "2021-08-20T21:50:09Z",
              "updatedAt": "2021-08-20T22:02:29Z"
            },
            {
              "originalPosition": 157,
              "body": "To double confirm: this means that given a `Param.min_batch_duration` of eight hours, then batch intervals of 8, 16, 24 hours are valid, but 12 or 17 are not, right? And the aim here is to allow aggregators to pre-compute output shares before a collect request, since servicing a collect request over `0800-2400` just requires summing the already computed output shares for `0800-1600` and `1600-2400`?",
              "createdAt": "2021-08-20T21:54:24Z",
              "updatedAt": "2021-08-20T22:02:29Z"
            },
            {
              "originalPosition": 292,
              "body": "```suggestion\r\nclients, but are not robust against malicious servers. Any aggregator can\r\n```",
              "createdAt": "2021-08-20T21:55:32Z",
              "updatedAt": "2021-08-20T22:02:29Z"
            },
            {
              "originalPosition": 243,
              "body": "This would also be a good place to discuss efficient means of tracking privacy budgets.",
              "createdAt": "2021-08-20T22:02:04Z",
              "updatedAt": "2021-08-20T22:02:29Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzM3NzkxNDQ2",
          "commit": {
            "abbreviatedOid": "a467f99"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-08-25T00:15:29Z",
          "updatedAt": "2021-08-25T00:50:06Z",
          "comments": [
            {
              "originalPosition": 157,
              "body": "Yes.",
              "createdAt": "2021-08-25T00:15:29Z",
              "updatedAt": "2021-08-25T00:50:06Z"
            },
            {
              "originalPosition": 167,
              "body": "There is indeed an increase of storage requirements compared to the status quo. However, the status quo doesn't account for privacy budgets at all. Hence, I claim this is a cost we have to eat no matter what.\r\n\r\nBut how big is the cost? The key thing to notice is that the increase in storage requirements is linear in the number of batch intervals _that can still be queried_. This number depends on the minimum batch duration and the rate at which the collector makes requests. Crucially, the storage increase _does not depend on the number of reports_.",
              "createdAt": "2021-08-25T00:21:20Z",
              "updatedAt": "2021-08-25T00:50:06Z"
            },
            {
              "originalPosition": 168,
              "body": "Interesting question. To put it another way: Is the max report lifetime too coarse-grained?\r\n\r\nThe interesting thing about Hits is that, without DP, _some amount of leakage_ is inevitable, but as you point out, how much is leaked depends on the distribution of inputs. (As an extreme example, suppose a large number of non-heavy-hitters share a common prefix.)\r\n\r\nVanilla Hits doesn't try to mitigate this at all, so we would set the max report lifetime to be the length of the input. (This is the maximum number of collect requests that would be needed to compute the heavy hitters.) The current proposal for mitigating this leakage is via DP. Interestingly, if the aggregators are adding the noise, then the distribution of the noise -- and therefore the privacy budget -- can only depend on the candidate prefixes of the previous rounds. I don't imagine it would, it seems reasonable to just pick a max report lifetime. But we don't want to preclude the possibility of someone doing something fancier.\r\n\r\nOf course, nothing about the protocol precludes the aggregators from bailing out _before_ the max report lifetime is reached... what's important is that they agree on when to bail out.\r\n\r\nWhich leads me to this conclusion: the max report lifetime parameter seems to wear to hats:\r\n1. It provides a coarse-grained way of enforcing a privacy budget. In particular, it should suffice for \"simple\" schemes in which the privacy budget is independent of the input distribution.\r\n2. It provides a way for aggregators to know how long they have to keep around reports (or the output shares derived from them). Namely, if a report has reached its max lifetime, it's OK to throw it away.\r\n\r\nThis PR talks about (1.), but perhaps it also makes sense to talk about (2.).",
              "createdAt": "2021-08-25T00:43:20Z",
              "updatedAt": "2021-08-25T00:50:06Z"
            },
            {
              "originalPosition": 174,
              "body": "You're right, this needs to be rephrased. What do you think about\r\n\r\n> Using a report multiple times withing a single batch, or using the same report in multiple batches, is considered a privacy violation. To prevent such attacks...",
              "createdAt": "2021-08-25T00:46:34Z",
              "updatedAt": "2021-08-25T00:50:06Z"
            },
            {
              "originalPosition": 243,
              "body": "We already suggest that such a scheme exists:\r\n>  each aggregator only needs to store the aggregate output share for each possible batch interval,\r\nalong with the number of times the output share was used in a batch.\r\n\r\nI suggest we hold off on describing this until we've implemented it. This will give us a chance to validate any assumptions we're making here. If you'd like I can flag an OPEN ISSUE here.",
              "createdAt": "2021-08-25T00:48:21Z",
              "updatedAt": "2021-08-25T00:50:06Z"
            },
            {
              "originalPosition": 274,
              "body": "Yup, good call. Maybe this distinction would be more clear if we renamed \"max_report_lifetime\" to \"max_batch_lifetime\", since what we're really talking about is how many times a batch of reports can be queried.",
              "createdAt": "2021-08-25T00:49:44Z",
              "updatedAt": "2021-08-25T00:50:06Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzM3ODAzODA2",
          "commit": {
            "abbreviatedOid": "c28c713"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-08-25T00:50:24Z",
          "updatedAt": "2021-08-25T00:50:24Z",
          "comments": [
            {
              "originalPosition": 7,
              "body": "Yeah, I can do that.",
              "createdAt": "2021-08-25T00:50:24Z",
              "updatedAt": "2021-08-25T00:50:24Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzM4NTg0MzY0",
          "commit": {
            "abbreviatedOid": "c28c713"
          },
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "state": "CHANGES_REQUESTED",
          "body": "",
          "createdAt": "2021-08-25T16:38:49Z",
          "updatedAt": "2021-08-25T17:01:11Z",
          "comments": [
            {
              "originalPosition": 174,
              "body": "Yes, that seems better to me, though \"within\" and not \"withing\".",
              "createdAt": "2021-08-25T16:38:49Z",
              "updatedAt": "2021-08-25T17:01:11Z"
            },
            {
              "originalPosition": 168,
              "body": "On question 1, my intuition is that the amount of privacy budget consumed by a query should be decided by aggregator servicing the query. How to compute the amount of privacy consumed is part of the specification of a PPM scheme (so for Prio, you always consume one unit of privacy, and for Hits it's more complicated). However as you point out:\r\n>what's important is that [aggregators] agree on when to bail out.\r\n\r\nIf leader and aggregator disagree on how much privacy was consumed by queries, then they might not bail out in lockstep. But perhaps we can accommodate that thanks to the leader model? The helper could indicate to the leader in `AggregateSubResp` that the privacy budget for a report has been exhausted, at which point the leader can fail the corresponding `CollectResp`. Similarly if the leader decides a report's privacy budget is exhausted, then it can stop executing the aggregate protocol for that report with the helper.\r\n\r\nHowever I acknowledge that's more complicated, and it's not worth doing if we strongly believe that the coarse-grained privacy budgeting (i.e. one query always consumes one unit of privacy) will suffice for all or nearly all future schemes.\r\n\r\nOn question 2: now I understand why you used the word lifetime. I still think that's the wrong term, for these reasons:\r\n\r\n- \"lifetime\" implies, well, time, and there are several other places where we discuss spans of time or points in time (e.g., batch window or report timestamp, respectively), so I'd prefer to express this in a way that doesn't imply a relation to other time concepts in the protocol. Plus the unit of this lifetime isn't even measured in seconds but rather a number of queries.\r\n- I don't think PPM wants to specify anything about how long reports are retained, beyond the implicit requirement that they be available long enough to service all the collector's queries and a suggestion that implementations could delete them afterward. The observable behavior our protocol cares about is limiting how many queries may be made against a report, and I think message fields should be named accordingly. For that reason, `privacy_budget` makes more sense to me than `max_report_lifetime`.",
              "createdAt": "2021-08-25T16:57:26Z",
              "updatedAt": "2021-08-26T22:31:43Z"
            },
            {
              "originalPosition": 243,
              "body": "Good point. Plus privacy budgets and their efficient representations will vary with PPM schemes, so such discussion should perhaps be in the Prio or Hits specific docs.",
              "createdAt": "2021-08-25T16:58:19Z",
              "updatedAt": "2021-08-25T17:01:11Z"
            },
            {
              "originalPosition": 169,
              "body": "We're discussing this name in a different comment thread, so resolving this one",
              "createdAt": "2021-08-25T16:59:31Z",
              "updatedAt": "2021-08-25T17:01:11Z"
            },
            {
              "originalPosition": 167,
              "body": ">Crucially, the storage increase does not depend on the number of reports.\r\n\r\nThis is the key property I am concerned with, and I agree that nothing in this text precludes this or suggests otherwise, so resolving this.",
              "createdAt": "2021-08-25T17:00:05Z",
              "updatedAt": "2021-09-08T20:49:04Z"
            },
            {
              "originalPosition": 66,
              "body": "Nothing further to say about this in this PR except: could you please make sure we have a GH issue with label parking-lot for this question?",
              "createdAt": "2021-08-25T17:00:59Z",
              "updatedAt": "2021-08-25T17:01:11Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzM4ODA0MTUw",
          "commit": {
            "abbreviatedOid": "c28c713"
          },
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-08-25T20:34:42Z",
          "updatedAt": "2021-08-25T20:34:43Z",
          "comments": [
            {
              "originalPosition": 168,
              "body": "On the question of naming the field: this might be one of those things that changes a few more times as we go through the standardization process and we get more eyes and commentators on the protocol, so if you disagree with me about `privacy_budget`, I'm happy to move forward with `max_report_lifetime` (or `max_batch_lifetime` as you suggested elsewhere).",
              "createdAt": "2021-08-25T20:34:42Z",
              "updatedAt": "2021-08-25T20:34:43Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzQ4NTEyMzIw",
          "commit": {
            "abbreviatedOid": "6aeb674"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-09-07T23:44:10Z",
          "updatedAt": "2021-09-08T00:12:48Z",
          "comments": [
            {
              "originalPosition": 168,
              "body": "> If leader and aggregator disagree on how much privacy was consumed by queries, then they might not bail out in lockstep. But perhaps we can accommodate that thanks to the leader model? The helper could indicate to the leader in `AggregateSubResp` that the privacy budget for a report has been exhausted, at which point the leader can fail the corresponding `CollectResp`. Similarly if the leader decides a report's privacy budget is exhausted, then it can stop executing the aggregate protocol for that report with the helper.\r\n\r\nYeah, this is basically what I mean by \"bail out at the same time\". I.e., an honest aggregator ensures the privacy budget isn't violated, even in the presence of a cheating peer.\r\n\r\n\r\n> However I acknowledge that's more complicated, and it's not worth doing if we strongly believe that the coarse-grained privacy budgeting (i.e. one query always consumes one unit of privacy) will suffice for all or nearly all future schemes.\r\n\r\nI don't think we have enough information to say for sure. I think it suffices to say that `max_report_lifetime` is an upperbound only.\r\n\r\n\r\n> On question 2: now I understand why you used the word lifetime. I still think that's the wrong term, for these reasons:\r\n> \r\n>     * \"lifetime\" implies, well, time, and there are several other places where we discuss spans of time or points in time (e.g., batch window or report timestamp, respectively), so I'd prefer to express this in a way that doesn't imply a relation to other time concepts in the protocol. Plus the unit of this lifetime isn't even measured in seconds but rather a number of queries.\r\n\r\nAgreed here.\r\n\r\n>     * I don't think PPM wants to specify anything about how long reports are retained, beyond the implicit requirement that they be available long enough to service all the collector's queries and a suggestion that implementations could delete them afterward. The observable behavior our protocol cares about is limiting how many queries may be made against a report, and I think message fields should be named accordingly. For that reason, `privacy_budget` makes more sense to me than `max_report_lifetime`.\r\n\r\nHere I disagree. This operational parameter is a kind of contract between collectors and aggregators that stipulates how long data has to be available. Without it, aggregators would have to keep state indefinitely. I suppose we could do this in a different way, but we'll need to have something like this in the spec.\r\n",
              "createdAt": "2021-09-07T23:44:10Z",
              "updatedAt": "2021-09-08T00:12:48Z"
            },
            {
              "originalPosition": 168,
              "body": "I'm going to rename it to `max_batch_lifetime` for now.",
              "createdAt": "2021-09-07T23:44:46Z",
              "updatedAt": "2021-09-08T00:12:48Z"
            },
            {
              "originalPosition": 7,
              "body": "Done.",
              "createdAt": "2021-09-07T23:51:33Z",
              "updatedAt": "2021-09-08T00:12:48Z"
            },
            {
              "originalPosition": 174,
              "body": "Done.",
              "createdAt": "2021-09-07T23:52:47Z",
              "updatedAt": "2021-09-08T00:12:48Z"
            },
            {
              "originalPosition": 274,
              "body": "Removed the line that caused confusion.",
              "createdAt": "2021-09-07T23:55:45Z",
              "updatedAt": "2021-09-08T00:12:48Z"
            },
            {
              "originalPosition": 66,
              "body": "IMO this is covered by https://github.com/abetterinternet/prio-documents/issues/89. Added a reference.",
              "createdAt": "2021-09-07T23:59:44Z",
              "updatedAt": "2021-09-08T00:12:48Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzQ5NjAwNzIw",
          "commit": {
            "abbreviatedOid": "a5d6356"
          },
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "A few more nits but basically LGTM once any occurrence of \"batch window\" is corrected.",
          "createdAt": "2021-09-08T20:48:08Z",
          "updatedAt": "2021-09-08T22:13:36Z",
          "comments": [
            {
              "originalPosition": 16,
              "body": "```suggestion\r\n: A parameter of the collect or output-share request that specifies the time\r\n  range of the reports in the batch.\r\n```",
              "createdAt": "2021-09-08T20:48:09Z",
              "updatedAt": "2021-09-08T22:13:36Z"
            },
            {
              "originalPosition": 64,
              "body": "```suggestion\r\n  boundaries with which the batch interval of each collect request must be\r\n```\r\nIIUC we should replace occurrences of \"batch window\" with \"batch interval\", right? I flagged a couple other misuses of \"batch window\" in this PR but we* should scrub the whole document for occurrences of that term.\r\n\r\n\\* you",
              "createdAt": "2021-09-08T20:53:52Z",
              "updatedAt": "2021-09-08T22:13:36Z"
            },
            {
              "originalPosition": 92,
              "body": "Not a blocker but maybe we should introduce a type:\r\n\r\n```\r\nstruct {\r\n  Time start;\r\n  Time End;\r\n} Interval;\r\n```\r\nAnd use it in `OutputShareReq` and other places where we represent time intervals.",
              "createdAt": "2021-09-08T20:55:53Z",
              "updatedAt": "2021-09-08T22:13:36Z"
            },
            {
              "originalPosition": 149,
              "body": "```suggestion\r\ninput shares that fall within the batch interval. Finally, it responds with HTTP\r\n```",
              "createdAt": "2021-09-08T20:57:10Z",
              "updatedAt": "2021-09-08T22:13:36Z"
            },
            {
              "originalPosition": 167,
              "body": "```suggestion\r\nthat `batch_end - batch_start >= min_batch_duration`. Unless both these\r\n```",
              "createdAt": "2021-09-08T21:00:13Z",
              "updatedAt": "2021-09-08T22:13:36Z"
            },
            {
              "originalPosition": 168,
              "body": ">Here I disagree. This operational parameter is a kind of contract between collectors and aggregators that stipulates how long data has to be available. Without it, aggregators would have to keep state indefinitely. I suppose we could do this in a different way, but we'll need to have something like this in the spec.\r\n\r\nI'm not arguing for getting rid of this parameter, just for changing its name to better reflect what its units are (a number of queries rather than a duration). I would phrase it as \"once a batch's `privacy_budget` is exhausted, aggregators MUST refuse further queries on the batch and MAY delete the inputs in the batch\" (note that the MUST part is something observable by other parties whereas it's not meaningfully possible for an aggregator to prove to other participants that it has deleted some input).\r\n\r\nBut as I said, we should move forward with `max_batch_lifetime`.",
              "createdAt": "2021-09-08T22:11:25Z",
              "updatedAt": "2021-09-08T22:13:36Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzUwNDA2MzQ5",
          "commit": {
            "abbreviatedOid": "f4168a1"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-09-09T14:11:30Z",
          "updatedAt": "2021-09-09T14:11:30Z",
          "comments": [
            {
              "originalPosition": 92,
              "body": "Done.",
              "createdAt": "2021-09-09T14:11:30Z",
              "updatedAt": "2021-09-09T14:11:30Z"
            }
          ]
        }
      ]
    },
    {
      "number": 142,
      "id": "MDExOlB1bGxSZXF1ZXN0NzIwMDY4Mzky",
      "title": "Harmonize `Encrypted(Input|Output)Share`",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/pull/142",
      "state": "CLOSED",
      "author": "tgeoghegan",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "These two structs are virually identical, so this commit makes their\r\nfield naming consistent.",
      "createdAt": "2021-08-25T23:30:00Z",
      "updatedAt": "2021-12-30T00:53:30Z",
      "baseRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "baseRefName": "timg/many-helpers",
      "baseRefOid": "b891bdd145fe2c46da04ae356efea79ddbb502cf",
      "headRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "headRefName": "timg/encrypted-share-fields",
      "headRefOid": "cad77b1e46439916a79ef16a7367f594add7726d",
      "closedAt": "2021-08-27T00:19:00Z",
      "mergedAt": null,
      "mergedBy": null,
      "mergeCommit": null,
      "comments": [
        {
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "body": "Stacked on #135, so marking as a draft for now.",
          "createdAt": "2021-08-25T23:30:15Z",
          "updatedAt": "2021-08-25T23:30:15Z"
        }
      ],
      "reviews": []
    },
    {
      "number": 143,
      "id": "MDExOlB1bGxSZXF1ZXN0NzIwMDc1MjI5",
      "title": "remove `struct Param`",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/pull/143",
      "state": "MERGED",
      "author": "tgeoghegan",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "`Param` is never transmitted over the wire, nor do we otherwise depend\r\non is structure, so this commit removes that struct definition and\r\ninstead enumerates the pre-negotiated task parameters each participant\r\nmust hold, leaving implementations free to store, represent and transmit\r\nthose parameters any way they wish. `TaskId` is still around, but\r\ninstead of being a SHA-256 over the serialiation of Param, it's now just\r\n32 random bytes.\r\n\r\nResolves #104",
      "createdAt": "2021-08-25T23:52:22Z",
      "updatedAt": "2021-12-30T00:53:34Z",
      "baseRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "baseRefName": "main",
      "baseRefOid": "81516b772789719fe3a3281abad7ad6e1edb6ea0",
      "headRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "headRefName": "timg/no-param",
      "headRefOid": "4e3482b0c88d6e7c1cffb452672c62bae49a7ece",
      "closedAt": "2021-09-15T20:20:51Z",
      "mergedAt": "2021-09-15T20:20:51Z",
      "mergedBy": "tgeoghegan",
      "mergeCommit": {
        "oid": "8609c88d63b6364378377e47e2f25a5db89caf2c"
      },
      "comments": [
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "Mind rebasing, @tgeoghegan?",
          "createdAt": "2021-09-08T00:16:35Z",
          "updatedAt": "2021-09-08T00:16:35Z"
        },
        {
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "body": "> This seems fine, although I'm a little concerned that the text is going to get a lot more confusing by dropping named parameters. PR #137 refers to the named parameters in `Param` quite a lot. Could we hold off on merging this until that PR is merged and see what it looks like after?\r\n\r\nSounds reasonable to me. I'll rebase after #137 is merged.",
          "createdAt": "2021-09-08T16:38:04Z",
          "updatedAt": "2021-09-08T16:38:04Z"
        },
        {
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "body": "Rebased on main to incorporate #137.",
          "createdAt": "2021-09-09T21:26:22Z",
          "updatedAt": "2021-09-09T21:26:22Z"
        }
      ],
      "reviews": [
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzQ4NTIzMzI4",
          "commit": {
            "abbreviatedOid": "7e98bfb"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-09-08T00:14:18Z",
          "updatedAt": "2021-09-08T00:25:44Z",
          "comments": [
            {
              "originalPosition": 68,
              "body": "```suggestion\r\nbe set to a random string output by a cryptographically secure pseudorandom\r\n```",
              "createdAt": "2021-09-08T00:14:18Z",
              "updatedAt": "2021-09-08T00:25:44Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzQ4NTM5NDM0",
          "commit": {
            "abbreviatedOid": "143cf83"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "This seems fine, although I'm a little concerned that the text is going to get a lot more confusing by dropping named parameters. PR https://github.com/abetterinternet/prio-documents/pull/137 refers to the named parameters in `Param` quite a lot. Could we hold off on merging this until that PR is merged and see what it looks like after?",
          "createdAt": "2021-09-08T01:00:19Z",
          "updatedAt": "2021-09-08T01:00:19Z",
          "comments": []
        },
        {
          "id": "PRR_kwDOFEJYQs4tBbkl",
          "commit": {
            "abbreviatedOid": "a90673b"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "A few nits, but otherwise I'm good with landing this.",
          "createdAt": "2021-09-15T16:30:53Z",
          "updatedAt": "2021-09-15T16:38:12Z",
          "comments": [
            {
              "originalPosition": 87,
              "body": "```suggestion\r\nPrior to the start of the protocol, each participant in the protocol must agree on\r\n```",
              "createdAt": "2021-09-15T16:30:54Z",
              "updatedAt": "2021-09-15T16:38:12Z"
            },
            {
              "originalPosition": 103,
              "body": "These requirements make me think we should define `struct` for the list of aggregators that defines the order and which endpoint is the leader.",
              "createdAt": "2021-09-15T16:32:47Z",
              "updatedAt": "2021-09-15T16:38:12Z"
            },
            {
              "originalPosition": 120,
              "body": "```suggestion\r\n* protocol: The core PPM protocol, e.g., Prio or Hits.\r\n```",
              "createdAt": "2021-09-15T16:34:28Z",
              "updatedAt": "2021-09-15T16:38:12Z"
            },
            {
              "originalPosition": 100,
              "body": "Bullets describing parameters with names used elsewhere in the doc should begin with the name. E.g.,:\r\n> * `max_batch_lifetime` is the ...",
              "createdAt": "2021-09-15T16:35:15Z",
              "updatedAt": "2021-09-15T16:38:12Z"
            },
            {
              "originalPosition": 181,
              "body": "```suggestion\r\n                          \"pda input share\" || task_id || server_role)\r\n```\r\nIf this is too long, consider reducing the size of the tab.",
              "createdAt": "2021-09-15T16:36:34Z",
              "updatedAt": "2021-09-15T16:38:12Z"
            },
            {
              "originalPosition": 120,
              "body": "This is a \"named parameter\".",
              "createdAt": "2021-09-15T16:37:43Z",
              "updatedAt": "2021-09-15T16:38:12Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs4tCSit",
          "commit": {
            "abbreviatedOid": "a90673b"
          },
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-09-15T20:10:15Z",
          "updatedAt": "2021-09-15T20:10:16Z",
          "comments": [
            {
              "originalPosition": 103,
              "body": "I think you're right, but I think that will come with #138 when we formalize the notion of aggregator roles. Once we have that, I think this language and the discussion of `Report` gets much simpler.",
              "createdAt": "2021-09-15T20:10:16Z",
              "updatedAt": "2021-09-15T20:10:16Z"
            }
          ]
        }
      ]
    },
    {
      "number": 145,
      "id": "MDExOlB1bGxSZXF1ZXN0NzIxNjE2OTEx",
      "title": "Charter and links",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/pull/145",
      "state": "MERGED",
      "author": "ekr",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "",
      "createdAt": "2021-08-27T21:12:50Z",
      "updatedAt": "2021-08-27T21:14:44Z",
      "baseRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "baseRefName": "main",
      "baseRefOid": "560afbee40ac7d13154d2ea536273e28ea319e7e",
      "headRepository": "ekr/ppm-specification",
      "headRefName": "bof-request2",
      "headRefOid": "fc407c624c75fe5ec7247779645d32d90defddd2",
      "closedAt": "2021-08-27T21:14:44Z",
      "mergedAt": "2021-08-27T21:14:44Z",
      "mergedBy": "chris-wood",
      "mergeCommit": {
        "oid": "6b91cb28c9713a41d65f858cbab3a1110cd406eb"
      },
      "comments": [],
      "reviews": [
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzQwODk4MDI5",
          "commit": {
            "abbreviatedOid": "fc407c6"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "",
          "createdAt": "2021-08-27T21:14:37Z",
          "updatedAt": "2021-08-27T21:14:37Z",
          "comments": []
        }
      ]
    },
    {
      "number": 147,
      "id": "MDExOlB1bGxSZXF1ZXN0NzI0NzE0Mjcz",
      "title": "Add share-counting attacks to threat model",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/pull/147",
      "state": "MERGED",
      "author": "csharrison",
      "authorAssociation": "CONTRIBUTOR",
      "assignees": [],
      "labels": [],
      "body": "Aggregators merely counting the number of input shares could compromise\r\nuser privacy in some circumstances (namely, it can break differential privacy\r\nif the number of records per user is not constant).\r\n\r\nThis attack only applies to aggregators who can count the number of shares,\r\nso any protection still holds on the collector side.\r\n\r\nTo address this attack, there are two possible mitigations, which both involve\r\nadding noise to the total number of input shares. This should be possible to\r\ndo with \"null\" shares that don't affect aggregate output (i.e. inserting 0 into\r\nsums).",
      "createdAt": "2021-09-01T17:34:47Z",
      "updatedAt": "2021-09-10T17:52:22Z",
      "baseRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "baseRefName": "main",
      "baseRefOid": "14625bf507ab723949271d78f4667d74aedfaaa7",
      "headRepository": "csharrison/prio-documents",
      "headRefName": "counting-attack",
      "headRefOid": "c8d1691b60aeff426371cf33904fc061cdcd6e66",
      "closedAt": "2021-09-10T17:51:52Z",
      "mergedAt": "2021-09-10T17:51:52Z",
      "mergedBy": "tgeoghegan",
      "mergeCommit": {
        "oid": "81516b772789719fe3a3281abad7ad6e1edb6ea0"
      },
      "comments": [
        {
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "body": "Specifically, this is about being able to count the number of contributions from an individual client, right? If so, this would also be mitigated by putting an anonymizing proxy between clients and the leader which would scrub identifying information from reports.",
          "createdAt": "2021-09-01T17:42:42Z",
          "updatedAt": "2021-09-01T17:42:42Z"
        },
        {
          "author": "csharrison",
          "authorAssociation": "CONTRIBUTOR",
          "body": "An anonymizing proxy mitigates attacks but not in the worst case. I didn't mention in the PR (I could if it is necessary), but the worst case attack involves the attackers having some side knowledge (e.g. via client collusion) such that if N reports arrive, then Tim did not contribute to this batch, and if N+1 reports arrive, then Tim did contribute to the batch. This is related to the Sybil style attacks which do the same thing but with the value embedded in the report. \r\n\r\nIn these kinds of attacks, no auxiliary information in the report (like IP, etc) is needed.\r\n\r\nIn practice, I don't believe this attack does much to meaningfully reduce user privacy. However, I think calling it out is important if we want to make differential privacy claims since DP requires us to think through worst-case attacks.",
          "createdAt": "2021-09-01T17:50:34Z",
          "updatedAt": "2021-09-01T17:50:34Z"
        },
        {
          "author": "csharrison",
          "authorAssociation": "CONTRIBUTOR",
          "body": "> Can you say more about what adding \"null\" shares does for DP? As a working example, suppose we're computing the sum of the inputs `S = X[1] + ... + X[m]`, where `X[i]` is an element of a finite field and `m` is the number of real inputs.\r\n> \r\n> It sounds like the scheme is to estimate `S` as\r\n> \r\n> ```\r\n>   S' = X[1] + ... + X[m] + // Real inputs\r\n>        e[1] + ... + e[m] + // error term for each real input\r\n>        e[m+1] ... + e[n]   // error term for each \"null\" input \r\n> ```\r\n> \r\n> where `n` is the number of inputs, including the \"null\" inputs generated by the clients (resp. the leader). So we are including an error term for each real input and generating an error team for each \"null\" (i.e., `0`-valued) input. Is that the idea?\r\n\r\nNo this is not what I am talking about. This issue is not necessarily about attacks on `S`, but rather about attacks on revealing `m` to the helpers. In some settings, `m` could be just as sensitive as `S`. In your example you are using some local noise for each input (just one possible way of implementing DP). I don't think we would need this to protect `S`. However, to protect `m` we would only need to add false shares that truly sum to 0 (i.e. no noise embedded in them at all). So that `m` is hard to learn from `n` the total # of input records.\r\n\r\n> > [T]he worst case attack involves the attackers having some side knowledge (e.g. via client collusion) such that if N reports arrive, then Tim did not contribute to this batch, and if N+1 reports arrive, then Tim did contribute to the batch. This is related to the Sybil style attacks which do the same thing but with the value embedded in the report.\r\n> \r\n> Suppose I have some a priori knowledge about the distribution of the inputs `X[i]`. (Maybe I have corrupted some small subset of the clients, and I know that each input is independently distributed.) Can't I make a pretty good guess about the value of `m` from `S'`? In fact, if i know that the expected value of `X[i]` is 1, and each `X[i]` is independent, then `S'` is going to be close to `m`.\r\n\r\nGreat question. Let's simplify this and say that you know for a fact that the true dataset contains either:\r\n- `m = N` records summing to `S = N`, OR\r\n- `m = N+1` records summing to `S = N+1`\r\ni.e. each record will always just have value 1. Also let's say that we've properly hidden `m` directly, and the adversary wants to learn `m` from `S`. I think it should be clear that if we can protect the true value of `S`, we can protect the true value of `m` as they are the same.\r\n\r\nTrue, `S` will be close to N or N+1, but the noise added to the sum will be enough that both cases are reasonably probable, protecting both `S` and `m`. For example (with Laplace noise with epsilon ln2):\r\n- `P(output >= N+1 | S = N) = 25%` ([link](https://www.wolframalpha.com/input/?i=LaplaceDistribution%5B0%2C+1%2FLog%5B2%5D%5D+%3E+1))\r\n- `P(output >= N+1 | S = N+1) = 50%`",
          "createdAt": "2021-09-08T16:08:28Z",
          "updatedAt": "2021-09-08T16:28:35Z"
        },
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "> No this is not what I am talking about. This issue is not necessarily about attacks on `S`, but rather about attacks on revealing `m` to the helpers. In some settings, `m` could be just as sensitive as `S`. In your example you are using some local noise for each input (just one possible way of implementing DP). I don't think we would need this to protect `S`. However, to protect `m` we would only need to add false shares that truly sum to 0 (i.e. no noise embedded in them at all). So that `m` is hard to learn from `n` the total # of input records.\r\n\r\nSharpening this a bit more: The concern is not whether the collector learns `m` but whether the aggregators learn `m`. The clients can add `n-m` bogus reports to hide `m` from the aggregators, or the leader can add `n-m` bogus reports to hide `m` from the helper. Is that right? \r\n\r\nThis would be a tad inconsistent with the current threat model, which assumes the collector may collude with an aggregator and, in particular, provide it with the final output. That said, I'm fine with adding it as a security consideration. We just want to make it clear that it only appears to be achievable under stronger non-collusion assumptions.\r\n\r\n\r\n> > Suppose I have some a priori knowledge about the distribution of the inputs `X[i]`. (Maybe I have corrupted some small subset of the clients, and I know that each input is independently distributed.) Can't I make a pretty good guess about the value of `m` from `S'`? In fact, if i know that the expected value of `X[i]` is 1, and each `X[i]` is independent, then `S'` is going to be close to `m`.\r\n> \r\n> Great question. Let's simplify this and say that you know for a fact that the true dataset contains either:\r\n> \r\n>     * `m = N` records summing to `S = N`, OR\r\n> \r\n>     * `m = N+1` records summing to `S = N+1`\r\n>       i.e. each record will always just have value 1. Also let's say that we've properly hidden `m` directly, and the adversary wants to learn `m` from `S`. I think it should be clear that if we can protect the true value of `S`, we can protect the true value of `m` as they are the same.\r\n> \r\n> True, `S` will be close to N or N+1, but the noise added to the sum will be enough that both cases are reasonably probable, protecting both `S` and `m`. For example (with Laplace noise with epsilon ln2):\r\n> \r\n>     * `P(output >= N+1 | S = N) = 25%`\r\n> \r\n>     * `P(output >= N+1 | S = N+1) = 50%`\r\n\r\nI see, thanks for clarifying. I think we need to be careful about what we mean when we say that the number of real (i.e., non-bogus) inputs is \"protected\". The output of the distributed aggregation function may be differentially private, but it doesn't hide the number of real inputs.",
          "createdAt": "2021-09-08T16:43:12Z",
          "updatedAt": "2021-09-08T16:43:12Z"
        },
        {
          "author": "csharrison",
          "authorAssociation": "CONTRIBUTOR",
          "body": "> > No this is not what I am talking about. This issue is not necessarily about attacks on `S`, but rather about attacks on revealing `m` to the helpers. In some settings, `m` could be just as sensitive as `S`. In your example you are using some local noise for each input (just one possible way of implementing DP). I don't think we would need this to protect `S`. However, to protect `m` we would only need to add false shares that truly sum to 0 (i.e. no noise embedded in them at all). So that `m` is hard to learn from `n` the total # of input records.\r\n> \r\n> Sharpening this a bit more: The concern is not whether the collector learns `m` but whether the aggregators learn `m`. The clients can add `n-m` bogus reports to hide `m` from the aggregators, or the leader can add `n-m` bogus reports to hide `m` from the helper. Is that right?\r\n\r\nYes that's right\r\n\r\n> This would be a tad inconsistent with the current threat model, which assumes the collector may collude with an aggregator and, in particular, provide it with the final output. That said, I'm fine with adding it as a security consideration. We just want to make it clear that it only appears to be achievable under stronger non-collusion assumptions.\r\n\r\nThe collector colluding with an aggregator and providing the final output should be OK (similarly, the aggregators providing the noisy count of raw records to the collector). In this case, the adversary has 2 views of the data (noisy count and noisy output). You should still be able to prove DP protections in this case if each view is protected with DP (this comes from the fact that DP composes well: https://en.wikipedia.org/wiki/Differential_privacy#Composability).\r\n\r\n> I see, thanks for clarifying. I think we need to be careful about what we mean when we say that the number of real (i.e., non-bogus) inputs is \"protected\". The output of the distributed aggregation function may be differentially private, but it doesn't hide the number of real inputs.\r\n\r\nYes, this is exactly the purpose of this PR. By default, we can't protect `m` from the aggregators unless we add the bogus records. However, if we can directly hide the number of real records (by adding bogus ones), _and also_ ensure `S` is DP, we can hide the true values of both `S` and `m`.",
          "createdAt": "2021-09-08T16:54:24Z",
          "updatedAt": "2021-09-08T16:54:24Z"
        },
        {
          "author": "csharrison",
          "authorAssociation": "CONTRIBUTOR",
          "body": "@cjpatton take another look. I've tried to keep this short + sweet but let me know if you think it can be compressed further.",
          "createdAt": "2021-09-08T18:17:21Z",
          "updatedAt": "2021-09-08T18:17:21Z"
        },
        {
          "author": "csharrison",
          "authorAssociation": "CONTRIBUTOR",
          "body": "This should be ready to go",
          "createdAt": "2021-09-10T17:42:16Z",
          "updatedAt": "2021-09-10T17:42:16Z"
        }
      ],
      "reviews": [
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzQ4NTMwMzA5",
          "commit": {
            "abbreviatedOid": "b187505"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "Can you say more about what adding \"null\" shares does for DP? As a working example, suppose we're computing the sum of the inputs `S = X[1] + ... + X[m]`, where `X[i]` is an element of a finite field and `m` is the number of real inputs.\r\n\r\nIt sounds like the scheme is to estimate `S` as\r\n```\r\n  S' = X[1] + ... + X[m] + // Real inputs\r\n       e[1] + ... + e[m] + // error term for each real input\r\n       e[m+1] ... + e[n]   // error term for each \"null\" input \r\n```\r\nwhere `n` is the number of inputs, including the \"null\" inputs generated by the clients (resp. the leader). So we are including an error term for each real input and generating an error team for each \"null\" (i.e., `0`-valued) input. Is that the idea?\r\n\r\n> [T]he worst case attack involves the attackers having some side knowledge (e.g. via client collusion) such that if N reports arrive, then Tim did not contribute to this batch, and if N+1 reports arrive, then Tim did contribute to the batch. This is related to the Sybil style attacks which do the same thing but with the value embedded in the report.\r\n\r\nSuppose I have some a priori knowledge about the distribution of the inputs `X[i]`. (Maybe I have corrupted some small subset of the clients, and I know that each input is independently distributed.) Can't I make a pretty good guess about the value of `m` from `S'`? In fact, if i know that the expected value of `X[i]` is 1, and each `X[i]` is independent, then `S'` is going to be close to `m`.\r\n",
          "createdAt": "2021-09-08T00:33:22Z",
          "updatedAt": "2021-09-08T00:55:53Z",
          "comments": [
            {
              "originalPosition": 17,
              "body": "- The idea is pretty clear if you're as deep into this as we are, but I think someone new would have a hard time figuring out what a `bogus \"null\" share` is. We might stipulate that the core PPM protocol define this. If you'd like we can leave it as an open issue for #98.\r\n- It sounds like what you want is that the clients or servers contribute \"null\" shares + some noise for DP. If this is correct, then let's say it.\r\n- Instead of `inject bogus \"null\" shares` let's say \"generate bogus reports that encode \"null\" shares`, as this is a bit more precise.",
              "createdAt": "2021-09-08T00:33:22Z",
              "updatedAt": "2021-09-08T00:55:53Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzQ5MzUxMTk4",
          "commit": {
            "abbreviatedOid": "b187505"
          },
          "author": "csharrison",
          "authorAssociation": "CONTRIBUTOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-09-08T16:12:31Z",
          "updatedAt": "2021-09-08T16:12:32Z",
          "comments": [
            {
              "originalPosition": 17,
              "body": "> It sounds like what you want is that the clients or servers contribute \"null\" shares + some noise for DP. If this is correct, then let's say it.\r\n\r\nNo, the null shares should be effectively \"no-ops\", and not introduce any change in the visible output. They only serve to protect the helpers from learning the true count.\r\n\r\nYour other suggestions sound good, I can make an update",
              "createdAt": "2021-09-08T16:12:32Z",
              "updatedAt": "2021-09-08T16:12:32Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzQ5NDg4MTE3",
          "commit": {
            "abbreviatedOid": "0509aa2"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "CHANGES_REQUESTED",
          "body": "Nice! Just a nit to add a reference to https://github.com/abetterinternet/prio-documents/issues/98.",
          "createdAt": "2021-09-08T18:35:13Z",
          "updatedAt": "2021-09-08T18:35:44Z",
          "comments": [
            {
              "originalPosition": 24,
              "body": "```suggestion\r\ninserting null shares into an aggregation is effectively a no-op. See issue#98.]\r\n```",
              "createdAt": "2021-09-08T18:35:13Z",
              "updatedAt": "2021-09-08T18:35:44Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzQ5NjA2MjAy",
          "commit": {
            "abbreviatedOid": "d7c0617"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "",
          "createdAt": "2021-09-08T20:54:45Z",
          "updatedAt": "2021-09-08T20:54:45Z",
          "comments": []
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzQ5NjkyNjkw",
          "commit": {
            "abbreviatedOid": "d7c0617"
          },
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "Left a couple of suggestions that I don't think should block merging. @csharrison let us know when you've rebased or otherwise finished with this and we can merge it for you.",
          "createdAt": "2021-09-08T23:06:46Z",
          "updatedAt": "2021-09-08T23:11:55Z",
          "comments": [
            {
              "originalPosition": 21,
              "body": "```suggestion\r\n       indistinguishable from true inputs (metadata, etc), especially when\r\n       constructing timestamps on reports.\r\n```\r\nThe size will necessarily be the same as a true input as we discussed earlier.",
              "createdAt": "2021-09-08T23:06:46Z",
              "updatedAt": "2021-09-08T23:11:55Z"
            },
            {
              "originalPosition": 15,
              "body": "```suggestion\r\n   input independently of user behavior. For example, a client should periodically\r\n   upload a report even if the event that the task is tracking has not occurred, so\r\n   that the absence of reports cannot be distinguished from their presence.\r\n```",
              "createdAt": "2021-09-08T23:10:47Z",
              "updatedAt": "2021-09-08T23:11:55Z"
            }
          ]
        },
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzQ5Nzc4MjY4",
          "commit": {
            "abbreviatedOid": "d7c0617"
          },
          "author": "csharrison",
          "authorAssociation": "CONTRIBUTOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-09-09T02:49:05Z",
          "updatedAt": "2021-09-09T02:49:06Z",
          "comments": [
            {
              "originalPosition": 21,
              "body": "Yes that's right",
              "createdAt": "2021-09-09T02:49:06Z",
              "updatedAt": "2021-09-09T02:49:06Z"
            }
          ]
        }
      ]
    },
    {
      "number": 149,
      "id": "MDExOlB1bGxSZXF1ZXN0NzMwODgzMDg5",
      "title": "update references to \"prio-documents\"",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/pull/149",
      "state": "MERGED",
      "author": "tgeoghegan",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "The repo was renamed to \"ppm-specification\". This commit replaces\r\nvarious occurences of the old repo's name, and also updated README.md to\r\nreflect the current name of the protocol.",
      "createdAt": "2021-09-09T19:47:36Z",
      "updatedAt": "2021-12-30T00:53:33Z",
      "baseRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "baseRefName": "main",
      "baseRefOid": "fc7dfe824f1586d76bde80aea403c98615a5ce92",
      "headRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "headRefName": "timg/rename-repo",
      "headRefOid": "58d5e3a65c5435b8ad24c7bc5208325710fb1096",
      "closedAt": "2021-09-09T19:51:03Z",
      "mergedAt": "2021-09-09T19:51:03Z",
      "mergedBy": "tgeoghegan",
      "mergeCommit": {
        "oid": "7a4f38b0984cf67a88e2ff9c0051d2bab3f79d92"
      },
      "comments": [],
      "reviews": [
        {
          "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NzUwNzU3ODA0",
          "commit": {
            "abbreviatedOid": "58d5e3a"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "",
          "createdAt": "2021-09-09T19:48:23Z",
          "updatedAt": "2021-09-09T19:48:23Z",
          "comments": []
        }
      ]
    },
    {
      "number": 151,
      "id": "PR_kwDOFEJYQs4sFmoA",
      "title": "House cleaning",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/pull/151",
      "state": "MERGED",
      "author": "cjpatton",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "Since there's no PR pending, I thought it would be a good time to fix up the doc a bit. No spec or even editorial changes, just some line breaks and a few typos.",
      "createdAt": "2021-09-21T22:04:31Z",
      "updatedAt": "2021-12-30T02:10:21Z",
      "baseRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "baseRefName": "main",
      "baseRefOid": "8609c88d63b6364378377e47e2f25a5db89caf2c",
      "headRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "headRefName": "cjpatton/editorial",
      "headRefOid": "9b061ace4aaecf63d589b1a13655d44d4835cb32",
      "closedAt": "2021-09-22T19:49:48Z",
      "mergedAt": "2021-09-22T19:49:48Z",
      "mergedBy": "cjpatton",
      "mergeCommit": {
        "oid": "7cf4db3f2ec7605a87ef79a52611eb544b0b0f33"
      },
      "comments": [
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "I'm assuming everyone trusts that this makes no substantive changes. time to merge.",
          "createdAt": "2021-09-22T19:49:45Z",
          "updatedAt": "2021-09-22T19:49:45Z"
        }
      ],
      "reviews": []
    },
    {
      "number": 152,
      "id": "PR_kwDOFEJYQs4sKJKU",
      "title": "Specify the protocol in terms of VDAF evaluation",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/pull/152",
      "state": "CLOSED",
      "author": "cjpatton",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "Closes #98.\r\n\r\nAlong the way, this commit cleans up some ambiguous language that allows\r\nfor multiple helpers, but without fully specifying the protocol flow.",
      "createdAt": "2021-09-22T20:49:07Z",
      "updatedAt": "2021-09-28T18:20:42Z",
      "baseRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "baseRefName": "main",
      "baseRefOid": "7cf4db3f2ec7605a87ef79a52611eb544b0b0f33",
      "headRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "headRefName": "cjpatton/vdaf",
      "headRefOid": "69c7d0d9aea2b5741a7847ef36a673c636f15b24",
      "closedAt": "2021-09-24T00:13:27Z",
      "mergedAt": null,
      "mergedBy": null,
      "mergeCommit": null,
      "comments": [
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "Hi @tgeoghegan, @ekr, thanks for the super useful feedback! Based on your feedback, and in light of a super helpful conversation with @chris-wood today, I'm going to close this PR and open a new one after some major revisions. Specifically, @chris-wood came up with some changes to the VDAF syntax that will make the PPM spec a lot cleaner. I'll get cracking on this next Tuesday.",
          "createdAt": "2021-09-24T00:13:27Z",
          "updatedAt": "2021-09-24T00:13:27Z"
        }
      ],
      "reviews": [
        {
          "id": "PRR_kwDOFEJYQs4tYmNP",
          "commit": {
            "abbreviatedOid": "69c7d0d"
          },
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "state": "CHANGES_REQUESTED",
          "body": "I'm pleased to see the `protocol` named parameter go away as that simplifies several protocol messages.",
          "createdAt": "2021-09-22T21:26:21Z",
          "updatedAt": "2021-09-22T21:52:41Z",
          "comments": [
            {
              "originalPosition": 59,
              "body": "Is this an appropriate place to discuss the PPM meta-protocol that would capture Prio's query randomness exchange, or is that a later PR?",
              "createdAt": "2021-09-22T21:26:21Z",
              "updatedAt": "2021-09-22T21:52:41Z"
            },
            {
              "originalPosition": 146,
              "body": "```suggestion\r\naggregate requests to the helper, the first of which contains the helper's\r\n```",
              "createdAt": "2021-09-22T21:28:43Z",
              "updatedAt": "2021-09-22T21:52:41Z"
            },
            {
              "originalPosition": 394,
              "body": "I think this only makes sense if changed to:\r\n```suggestion\r\nto compute their share of the output. Alternately, if `output_param` is empty or\r\n```\r\nAlso, what should the collector put in `output_param` if it is \"empty or a well-known value\"? Empty byte sequence?",
              "createdAt": "2021-09-22T21:38:09Z",
              "updatedAt": "2021-09-22T21:52:41Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs4tYwm6",
          "commit": {
            "abbreviatedOid": "69c7d0d"
          },
          "author": "ekr",
          "authorAssociation": "COLLABORATOR",
          "state": "CHANGES_REQUESTED",
          "body": "I think it would be helpful to separate out the change to talk about VBAF from the other technical changes you have made here.",
          "createdAt": "2021-09-22T22:35:23Z",
          "updatedAt": "2021-09-22T22:44:41Z",
          "comments": [
            {
              "originalPosition": 113,
              "body": "Can we instead make this the index in the array?",
              "createdAt": "2021-09-22T22:35:23Z",
              "updatedAt": "2021-09-22T22:44:41Z"
            },
            {
              "originalPosition": 99,
              "body": "This kind of comes out of nowhere. I think you need a section describing the functions in the VDAF in overview.",
              "createdAt": "2021-09-22T22:35:53Z",
              "updatedAt": "2021-09-22T22:44:41Z"
            },
            {
              "originalPosition": 146,
              "body": "```suggestion\r\naggregate requests to the helper, the first of which contains the helper's\r\n```",
              "createdAt": "2021-09-22T22:36:07Z",
              "updatedAt": "2021-09-22T22:44:41Z"
            },
            {
              "originalPosition": 146,
              "body": "Why are you writing this as if it were one helper? Let's write all this text as if it were many and then have a single place where we say it's not.",
              "createdAt": "2021-09-22T22:36:47Z",
              "updatedAt": "2021-09-22T22:44:41Z"
            },
            {
              "originalPosition": 155,
              "body": "This seems like an unnecessary assumption.",
              "createdAt": "2021-09-22T22:37:10Z",
              "updatedAt": "2021-09-22T22:44:41Z"
            },
            {
              "originalPosition": 149,
              "body": "I think this clearly reveals that these subsequent ones just shouldn't be aggregate requests but something else.\r\n\r\nAggregateContinue perhaps.",
              "createdAt": "2021-09-22T22:38:38Z",
              "updatedAt": "2021-09-22T22:44:41Z"
            },
            {
              "originalPosition": 158,
              "body": "Is this the first time a \"collect\" request has been mentioned.",
              "createdAt": "2021-09-22T22:39:03Z",
              "updatedAt": "2021-09-22T22:44:41Z"
            },
            {
              "originalPosition": 157,
              "body": "I would not call this \"output\" but rather \"state\"",
              "createdAt": "2021-09-22T22:39:19Z",
              "updatedAt": "2021-09-22T22:44:41Z"
            },
            {
              "originalPosition": 178,
              "body": "Why are we letting this span multiple batches? That seems weird.",
              "createdAt": "2021-09-22T22:39:57Z",
              "updatedAt": "2021-09-22T22:44:41Z"
            },
            {
              "originalPosition": 185,
              "body": "See above about cardinality.",
              "createdAt": "2021-09-22T22:40:14Z",
              "updatedAt": "2021-09-22T22:44:41Z"
            },
            {
              "originalPosition": 199,
              "body": "See above. I think these should just be different messages.",
              "createdAt": "2021-09-22T22:40:32Z",
              "updatedAt": "2021-09-22T22:44:41Z"
            },
            {
              "originalPosition": 240,
              "body": "I don't understand \"each sub-request for a given report\". Is there some other structure?\r\n\r\n\"Each subrequest corresponds to a single report\"",
              "createdAt": "2021-09-22T22:42:39Z",
              "updatedAt": "2021-09-22T22:44:41Z"
            },
            {
              "originalPosition": 244,
              "body": "This is not the first sub-request in the list but rather the first time you send one.",
              "createdAt": "2021-09-22T22:43:06Z",
              "updatedAt": "2021-09-22T22:44:41Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs4tY3JF",
          "commit": {
            "abbreviatedOid": "69c7d0d"
          },
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-09-22T23:34:05Z",
          "updatedAt": "2021-09-22T23:34:06Z",
          "comments": [
            {
              "originalPosition": 178,
              "body": "I agree with Chris here. I think there's no reason to require leaders to construct `AggregateReq`s around batch boundaries, and doing it this way enables really simple leader implementations that send an `AggregateReq` to helper every time some fixed number of reports is received.\r\n\r\nA helper will consider all the `AggregateSubReq`s independently, and it's easy for it to decide what batch a particular subreq belongs to (it just has to truncate the subreq timestamp to the batch interval) so there's no need for all the subreqs in a req to belong to the same batch.",
              "createdAt": "2021-09-22T23:34:05Z",
              "updatedAt": "2021-09-22T23:34:06Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs4tY48I",
          "commit": {
            "abbreviatedOid": "69c7d0d"
          },
          "author": "ekr",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-09-22T23:53:08Z",
          "updatedAt": "2021-09-22T23:53:08Z",
          "comments": [
            {
              "originalPosition": 178,
              "body": "I don't understand the alleged semantics of this. Suppose that I send reqs from batch 1 and batch 2, what does the helper do?\r\n",
              "createdAt": "2021-09-22T23:53:08Z",
              "updatedAt": "2021-09-22T23:53:08Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs4tY7y8",
          "commit": {
            "abbreviatedOid": "69c7d0d"
          },
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-09-23T00:24:48Z",
          "updatedAt": "2021-09-23T00:24:48Z",
          "comments": [
            {
              "originalPosition": 178,
              "body": "Let's say it's Prio, in which scenario the aggregators can sum inputs as soon as the proofs check out without waiting for the collect protocol to begin. Further let's say an aggregator sends an `AggregateReq` that contains `AggregateSubReq`s whose timestamps span multiple batches.\r\n\r\nA helper implementation would have a map where the keys are batch intervals and the values are the accumulated value for that batch window. Upon receipt of an `AggregateReq`, the helper iterates over the `AggregateSubReq`s and for each:\r\n\r\n- decrypts the input share and proof share;\r\n- verifies the proof (it has its own proof share and got leader's proof share in the `AggregateSubReq`);\r\n- truncates the report timestamp to the batch interval (e.g. with [`chrono::DurationRound::duration_trunc`](https://docs.rs/chrono/0.4.19/chrono/trait.DurationRound.html#tymethod.duration_trunc) or [`time.Time.Truncate`](https://pkg.go.dev/time#Time.Truncate)) to figure out what batch the input belongs to;\r\n- sums the input share into  the accumulated value for the batch interval from the map described earlier.\r\n\r\nLater, a collector issues a `CollectReq` to the leader which specifies some `batch_interval`, and the leader sends a corresponding `OutputShareReq` to helper. Helper just looks up the `batch_interval` in its map of accumulators and responds with the value.\r\n\r\nEnabling this kind of eager aggregation is a design goal, and I don't see that it requires that `AggregateReq`s be constructed on batch interval boundaries.",
              "createdAt": "2021-09-23T00:24:48Z",
              "updatedAt": "2021-09-23T00:24:48Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs4tY8KD",
          "commit": {
            "abbreviatedOid": "69c7d0d"
          },
          "author": "ekr",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-09-23T00:28:51Z",
          "updatedAt": "2021-09-23T00:28:51Z",
          "comments": [
            {
              "originalPosition": 178,
              "body": "This is going to interact very badly with any kind of state offloading because you will end up with the state token containing multiple batches and it will be very unclear when you can abandon it or do anything in parallel.\r\n\r\nMore apropos to the current moment, the current text has an open issue here and this PR just decides that in the middle of making some other totally orthogonal change. If people want there to be an open issue where we discuss this design issue, then fine, but it doesn't belong in this PR.\r\n\r\n\r\n",
              "createdAt": "2021-09-23T00:28:51Z",
              "updatedAt": "2021-09-23T00:28:51Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs4tY9Kj",
          "commit": {
            "abbreviatedOid": "69c7d0d"
          },
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-09-23T00:42:25Z",
          "updatedAt": "2021-09-23T00:42:26Z",
          "comments": [
            {
              "originalPosition": 178,
              "body": ">This is going to interact very badly with any kind of state offloading because you will end up with the state token containing multiple batches and it will be very unclear when you can abandon it or do anything in parallel.\r\n\r\nYes, I encountered this when implementing a prototype of this and tried to capture these questions in #150. My conclusion is that the opaque `helper_state` blob has to be per-task, and we need the PPM protocol to make that explicit so that the leader knows which state blob to send to which helper in which aggregate request.\r\n\r\nYour point about parallelism is a really good one, though. My 2c is that we should put `OPEN ISSUE: And the same batch, right?` back and hash this question out in #150 + a later PR.",
              "createdAt": "2021-09-23T00:42:25Z",
              "updatedAt": "2021-09-23T00:42:26Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs4tpSN6",
          "commit": {
            "abbreviatedOid": "69c7d0d"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-09-28T18:06:23Z",
          "updatedAt": "2021-09-28T18:06:23Z",
          "comments": [
            {
              "originalPosition": 59,
              "body": "This comment is solved by having the outputs of the VDAF setup algorithm be part of the task parameters.",
              "createdAt": "2021-09-28T18:06:23Z",
              "updatedAt": "2021-09-28T18:06:23Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs4tpSv9",
          "commit": {
            "abbreviatedOid": "69c7d0d"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-09-28T18:08:43Z",
          "updatedAt": "2021-09-28T18:08:43Z",
          "comments": [
            {
              "originalPosition": 155,
              "body": "It's not an assumption. This follows from the VDAF definition and how its execution for two aggregators is specified here.",
              "createdAt": "2021-09-28T18:08:43Z",
              "updatedAt": "2021-09-28T18:08:43Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs4tpTDd",
          "commit": {
            "abbreviatedOid": "69c7d0d"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-09-28T18:10:05Z",
          "updatedAt": "2021-09-28T18:10:05Z",
          "comments": [
            {
              "originalPosition": 178,
              "body": "I'm reverting this change and we'll punt.",
              "createdAt": "2021-09-28T18:10:05Z",
              "updatedAt": "2021-09-28T18:10:05Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs4tpTK6",
          "commit": {
            "abbreviatedOid": "69c7d0d"
          },
          "author": "ekr",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-09-28T18:10:35Z",
          "updatedAt": "2021-09-28T18:10:35Z",
          "comments": [
            {
              "originalPosition": 155,
              "body": "\"Assumption\" in this case means \"that's how you've defined VDAF\". But suppose I define a VDAF' which is like VDAF but has an indeterminate number of rounds.\r\n\r\n",
              "createdAt": "2021-09-28T18:10:35Z",
              "updatedAt": "2021-09-28T18:10:35Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs4tpUdw",
          "commit": {
            "abbreviatedOid": "69c7d0d"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-09-28T18:16:18Z",
          "updatedAt": "2021-09-28T18:16:18Z",
          "comments": [
            {
              "originalPosition": 149,
              "body": "This will be a somewhat major refactor, so I'll wait to address until the next PR.",
              "createdAt": "2021-09-28T18:16:18Z",
              "updatedAt": "2021-09-28T18:16:18Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs4tpUqJ",
          "commit": {
            "abbreviatedOid": "69c7d0d"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-09-28T18:17:09Z",
          "updatedAt": "2021-09-28T18:17:09Z",
          "comments": [
            {
              "originalPosition": 158,
              "body": "No, it's mentioned above. I think it should already be mentioned in the overview section.",
              "createdAt": "2021-09-28T18:17:09Z",
              "updatedAt": "2021-09-28T18:17:09Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs4tpUxa",
          "commit": {
            "abbreviatedOid": "69c7d0d"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-09-28T18:17:37Z",
          "updatedAt": "2021-09-28T18:17:37Z",
          "comments": [
            {
              "originalPosition": 157,
              "body": "\"Output parameter\" is the same term used in the VDAF syntax. \"State\" refers to the aggregator's state.",
              "createdAt": "2021-09-28T18:17:37Z",
              "updatedAt": "2021-09-28T18:17:37Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs4tpVDs",
          "commit": {
            "abbreviatedOid": "69c7d0d"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-09-28T18:18:38Z",
          "updatedAt": "2021-09-28T18:18:38Z",
          "comments": [
            {
              "originalPosition": 240,
              "body": "Good catch. Should be \"Each sub-request includes the report's ...\"",
              "createdAt": "2021-09-28T18:18:38Z",
              "updatedAt": "2021-09-28T18:18:38Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs4tpVO4",
          "commit": {
            "abbreviatedOid": "69c7d0d"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-09-28T18:19:25Z",
          "updatedAt": "2021-09-28T18:19:25Z",
          "comments": [
            {
              "originalPosition": 244,
              "body": "I think this might be fixed by splitting up the first aggregate request from the others, as you suggested above.",
              "createdAt": "2021-09-28T18:19:25Z",
              "updatedAt": "2021-09-28T18:19:25Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs4tpVYl",
          "commit": {
            "abbreviatedOid": "69c7d0d"
          },
          "author": "ekr",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-09-28T18:20:06Z",
          "updatedAt": "2021-09-28T18:20:07Z",
          "comments": [
            {
              "originalPosition": 157,
              "body": "I don't really think you can refer to whatever choices you happen to have made in the VDAF draft -- which has even less consensus than this document -- as authoritative for this kind of issue. My point is that this is misleading nomenclature and we should change it both here and in that document. It would be a different situation of the VDAF document were an RFC and so we were trying to conform to that, but it's not.",
              "createdAt": "2021-09-28T18:20:07Z",
              "updatedAt": "2021-09-28T18:20:07Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs4tpVhz",
          "commit": {
            "abbreviatedOid": "69c7d0d"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-09-28T18:20:42Z",
          "updatedAt": "2021-09-28T18:20:42Z",
          "comments": [
            {
              "originalPosition": 146,
              "body": "Punting this discussion to the new PR.",
              "createdAt": "2021-09-28T18:20:42Z",
              "updatedAt": "2021-09-28T18:20:42Z"
            }
          ]
        }
      ]
    },
    {
      "number": 154,
      "id": "PR_kwDOFEJYQs4saOfn",
      "title": "Specify the protocol in terms of VDAF evaluation",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/pull/154",
      "state": "CLOSED",
      "author": "cjpatton",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "Closes #98.\r\n\r\n",
      "createdAt": "2021-09-28T18:39:19Z",
      "updatedAt": "2021-12-30T02:09:26Z",
      "baseRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "baseRefName": "main",
      "baseRefOid": "2112f391f64b13f209b26cdd8721f05d070c2d28",
      "headRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "headRefName": "cjpatton/vdaf-2",
      "headRefOid": "04bb97cd3aa9cf450a21caa7278af48b106366f0",
      "closedAt": "2021-12-09T15:24:21Z",
      "mergedAt": null,
      "mergedBy": null,
      "mergeCommit": null,
      "comments": [
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "@tgeoghegan note that I'm closing this in favor of #168. Let me know if you'd like me to recreate it so that we have something to reference for abetterinternet/ppm-prototype.",
          "createdAt": "2021-12-09T15:24:21Z",
          "updatedAt": "2021-12-09T15:24:21Z"
        }
      ],
      "reviews": [
        {
          "id": "PRR_kwDOFEJYQs4tut85",
          "commit": {
            "abbreviatedOid": "cad4c63"
          },
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "state": "CHANGES_REQUESTED",
          "body": "First bunch of comments. I want to (re-)read https://github.com/cjpatton/ppm and then possibly comment some more!",
          "createdAt": "2021-09-29T21:51:29Z",
          "updatedAt": "2021-09-29T22:33:22Z",
          "comments": [
            {
              "originalPosition": 137,
              "body": "The remainder of the text uses 0x00 for leader and 0x01 for helper, which I think is a good change because it aligns the server role values with the position at which each server's share appears in `Report.encrypted_input_shares`.",
              "createdAt": "2021-09-29T21:56:30Z",
              "updatedAt": "2021-09-29T22:33:22Z"
            },
            {
              "originalPosition": 192,
              "body": "```suggestion\r\nrequests to the helper, the first of which contains the helper's encrypted input\r\n```",
              "createdAt": "2021-09-29T21:57:28Z",
              "updatedAt": "2021-09-29T22:33:22Z"
            },
            {
              "originalPosition": 263,
              "body": "```suggestion\r\nThe *verify-start request* is used by the leader to send a set of\r\n```",
              "createdAt": "2021-09-29T21:59:30Z",
              "updatedAt": "2021-09-29T22:33:22Z"
            },
            {
              "originalPosition": 265,
              "body": "A link to #150 would be appropriate in the `[[OPEN ISSUE]]`",
              "createdAt": "2021-09-29T22:00:11Z",
              "updatedAt": "2021-09-29T22:33:22Z"
            },
            {
              "originalPosition": 280,
              "body": "Are there any risks with letting the leader insert arbitrary `output_param` into requests sent to helper? In the Priov3 case, it seems this should always be empty or absent (because the output param is already known to all the parties participating in a task).\r\n\r\nIn the Hits case, though, a leader could tamper with the string prefixes in the collector's queries. This might be beyond the scope of this particular PR, but maybe the helper and collector should establish a mutually authenticated channel using each other's HPKE configs to ensure leader can't tamper with the output param.",
              "createdAt": "2021-09-29T22:06:19Z",
              "updatedAt": "2021-09-29T22:33:22Z"
            },
            {
              "originalPosition": 320,
              "body": "```suggestion\r\nwith `leader_share.aggregator_config_id`. Next, it runs\r\n```",
              "createdAt": "2021-09-29T22:08:15Z",
              "updatedAt": "2021-09-29T22:33:22Z"
            },
            {
              "originalPosition": 489,
              "body": "```suggestion\r\noutput_share = vdaf_finish(state, inbound_message)\r\n```\r\n",
              "createdAt": "2021-09-29T22:13:02Z",
              "updatedAt": "2021-09-29T22:33:22Z"
            },
            {
              "originalPosition": 484,
              "body": "The helper has nowhere but the `helper_state` blob to keep track of how many rounds have been executed. How does it know whether to execute `vdaf_next` or `vdaf_finish` for any `VerifyNextSubReq`? Perhaps we are missing something like `vdaf_is_finished(state) -> int` (but with a good name instead of that bad one)?",
              "createdAt": "2021-09-29T22:20:16Z",
              "updatedAt": "2021-09-29T22:33:22Z"
            },
            {
              "originalPosition": 599,
              "body": "```suggestion\r\nDepending on the VDAF and how the leader is configured, the collect request may\r\n```",
              "createdAt": "2021-09-29T22:23:48Z",
              "updatedAt": "2021-09-29T22:33:22Z"
            },
            {
              "originalPosition": 580,
              "body": "What should a collector put here in the Prio case? Empty string?",
              "createdAt": "2021-09-29T22:27:12Z",
              "updatedAt": "2021-09-29T22:33:22Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs4txUxD",
          "commit": {
            "abbreviatedOid": "cad4c63"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-09-30T14:00:41Z",
          "updatedAt": "2021-09-30T14:00:41Z",
          "comments": [
            {
              "originalPosition": 137,
              "body": "Good catch.",
              "createdAt": "2021-09-30T14:00:41Z",
              "updatedAt": "2021-09-30T14:00:42Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs4txVlm",
          "commit": {
            "abbreviatedOid": "cad4c63"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-09-30T14:03:09Z",
          "updatedAt": "2021-09-30T14:12:26Z",
          "comments": [
            {
              "originalPosition": 580,
              "body": "Yes.",
              "createdAt": "2021-09-30T14:03:09Z",
              "updatedAt": "2021-09-30T14:12:26Z"
            },
            {
              "originalPosition": 484,
              "body": "The VDAF fixes the number of rounds. The first round uses vdaf_start and subsequent rounds use vdaf_next.",
              "createdAt": "2021-09-30T14:04:34Z",
              "updatedAt": "2021-09-30T14:12:26Z"
            },
            {
              "originalPosition": 280,
              "body": "In terms of soundness, there is a risk of a network attacker tampering with this. For that we'll need some sort of sender authentication in the leader<->helper channel. (We've discussed this type of threat before, but I'm not sure we have a ticket for it.)\r\n\r\nIn terms of privacy, mutual authentication doesn't buy us anything because the leader can still cheat. That said, privacy ought to hold here regardless of what the cheating leader does (so long as the helper itself is honest). Of course, we need to prove this for every VDAF we want to implement. (For Prio this is trivial since the only valid output parameter is \"\".)",
              "createdAt": "2021-09-30T14:11:15Z",
              "updatedAt": "2021-09-30T14:12:26Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs4txjj-",
          "commit": {
            "abbreviatedOid": "80e23fe"
          },
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-09-30T14:45:19Z",
          "updatedAt": "2021-09-30T14:45:20Z",
          "comments": [
            {
              "originalPosition": 280,
              "body": "I wrote this up in #155. I think we should just put a TODO or a NOTE here referencing this issue and move on with this PR.",
              "createdAt": "2021-09-30T14:45:19Z",
              "updatedAt": "2021-09-30T14:45:20Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs4txlkS",
          "commit": {
            "abbreviatedOid": "80e23fe"
          },
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-09-30T14:51:26Z",
          "updatedAt": "2021-09-30T14:51:27Z",
          "comments": [
            {
              "originalPosition": 484,
              "body": "I buy that the number of rounds is a constant determined by the VDAF. But how does helper know what round it's on when it receives a `VerifyNextReq`? Implicitly a helper would have to keep a count of executed rounds in its `helper_state`, or we could require the VDAF to encode that into the `state` that gets passed into `vdaf_next`.",
              "createdAt": "2021-09-30T14:51:26Z",
              "updatedAt": "2021-09-30T14:51:27Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs4txlt2",
          "commit": {
            "abbreviatedOid": "80e23fe"
          },
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-09-30T14:51:54Z",
          "updatedAt": "2021-09-30T14:51:55Z",
          "comments": [
            {
              "originalPosition": 580,
              "body": "Sounds fine, but I think we should have explicit text instructing implementations to do this.",
              "createdAt": "2021-09-30T14:51:54Z",
              "updatedAt": "2021-09-30T14:51:55Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs4txoF_",
          "commit": {
            "abbreviatedOid": "80e23fe"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-09-30T14:58:40Z",
          "updatedAt": "2021-09-30T14:58:40Z",
          "comments": [
            {
              "originalPosition": 484,
              "body": "I'd also be fine with adding a \"round_number\" field to the request body.",
              "createdAt": "2021-09-30T14:58:40Z",
              "updatedAt": "2021-09-30T14:58:40Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs4txoZw",
          "commit": {
            "abbreviatedOid": "80e23fe"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-09-30T14:59:37Z",
          "updatedAt": "2021-09-30T14:59:37Z",
          "comments": [
            {
              "originalPosition": 580,
              "body": "The instruction is \"the leader copies the output parameter verbatim from the collect request to verify-start request\". Is that not already explicitly there?",
              "createdAt": "2021-09-30T14:59:37Z",
              "updatedAt": "2021-09-30T14:59:37Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs4txra5",
          "commit": {
            "abbreviatedOid": "80e23fe"
          },
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-09-30T15:09:08Z",
          "updatedAt": "2021-09-30T15:09:08Z",
          "comments": [
            {
              "originalPosition": 484,
              "body": "That could work, but then we have to consider what if any risks there are to allowing the leader to control the round number. If we put it in helper-controlled state, then it's protected by the encryption we already require from helper implementations.",
              "createdAt": "2021-09-30T15:09:08Z",
              "updatedAt": "2021-09-30T15:09:08Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs4txr-P",
          "commit": {
            "abbreviatedOid": "80e23fe"
          },
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-09-30T15:10:57Z",
          "updatedAt": "2021-09-30T15:10:57Z",
          "comments": [
            {
              "originalPosition": 580,
              "body": "So it is! I did notice one typo in the paragraph below. Resolving this thread.",
              "createdAt": "2021-09-30T15:10:57Z",
              "updatedAt": "2021-09-30T15:10:57Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs4txsCb",
          "commit": {
            "abbreviatedOid": "80e23fe"
          },
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-09-30T15:11:08Z",
          "updatedAt": "2021-09-30T15:11:09Z",
          "comments": [
            {
              "originalPosition": 602,
              "body": "```suggestion\r\ntheir share of the output. Alternately, if `output_param` is empty or a\r\n```",
              "createdAt": "2021-09-30T15:11:09Z",
              "updatedAt": "2021-09-30T15:11:09Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs4tyQMF",
          "commit": {
            "abbreviatedOid": "80e23fe"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-09-30T17:27:53Z",
          "updatedAt": "2021-09-30T17:27:53Z",
          "comments": [
            {
              "originalPosition": 484,
              "body": "Good point! Either way the helper is going to have to keep track of its state, and thus what message to expect next. I think we should make no changes here and just make it clear that the helper has to keep track of this.",
              "createdAt": "2021-09-30T17:27:53Z",
              "updatedAt": "2021-09-30T17:27:53Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs4t7EIr",
          "commit": {
            "abbreviatedOid": "848d112"
          },
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "",
          "createdAt": "2021-10-04T15:34:08Z",
          "updatedAt": "2021-10-04T15:35:36Z",
          "comments": [
            {
              "originalPosition": 345,
              "body": "Do we not need a parameter indicating whether the entity running `vdaf_start` is the leader or helper, so that it can tell whether the input share is compressed or not (if the VDAF is Prio)? Or do we encode that information into `input_share`?",
              "createdAt": "2021-10-04T15:34:08Z",
              "updatedAt": "2021-10-04T15:35:37Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs4uEoOn",
          "commit": {
            "abbreviatedOid": "848d112"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-10-06T16:26:14Z",
          "updatedAt": "2021-10-06T16:26:15Z",
          "comments": [
            {
              "originalPosition": 345,
              "body": "It's encoded by the `input_share`. I know you didn't like this redundancy, but it makes the VDAF syntax a lot simpler.",
              "createdAt": "2021-10-06T16:26:14Z",
              "updatedAt": "2021-10-06T16:26:15Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs4uErQW",
          "commit": {
            "abbreviatedOid": "848d112"
          },
          "author": "ekr",
          "authorAssociation": "COLLABORATOR",
          "state": "CHANGES_REQUESTED",
          "body": "Only got partway through, but I have a number of comments.",
          "createdAt": "2021-10-06T16:37:39Z",
          "updatedAt": "2021-10-06T16:54:10Z",
          "comments": [
            {
              "originalPosition": 61,
              "body": "Please file an issue for this rounds question. I am not convinced that we should commit to a fixed number of rounds as a protocol invariant.",
              "createdAt": "2021-10-06T16:37:40Z",
              "updatedAt": "2021-10-06T16:54:10Z"
            },
            {
              "originalPosition": 84,
              "body": "This restriction should appear in precisely one place so that we do not have to change it everywhere if we add multiple helpers. The first location is probably the right one.",
              "createdAt": "2021-10-06T16:38:21Z",
              "updatedAt": "2021-10-06T16:54:10Z"
            },
            {
              "originalPosition": 97,
              "body": "```suggestion\r\n  The client uses the public parameter to split its input into input shares, and\r\n```",
              "createdAt": "2021-10-06T16:38:36Z",
              "updatedAt": "2021-10-06T16:54:10Z"
            },
            {
              "originalPosition": 101,
              "body": "It's quite hard to understand the role of the verification parameter without a description of the vdaf system",
              "createdAt": "2021-10-06T16:39:24Z",
              "updatedAt": "2021-10-06T16:54:10Z"
            },
            {
              "originalPosition": 125,
              "body": "```suggestion\r\ntransforms the measurement into a set of input shares, one for each aggregator. To encrypt each input share,\r\nthe client first generates an HPKE {{!I-D.irtf-cfrg-hpke}} context for the\r\n```",
              "createdAt": "2021-10-06T16:40:10Z",
              "updatedAt": "2021-10-06T16:54:10Z"
            },
            {
              "originalPosition": 139,
              "body": "```suggestion\r\n`server_role` is a byte whose value is the index of the aggregator in the aggregator list. The bytestring `enc` is the\r\n```\r\n\r\nOr some such...",
              "createdAt": "2021-10-06T16:41:13Z",
              "updatedAt": "2021-10-06T16:54:10Z"
            },
            {
              "originalPosition": 191,
              "body": "```suggestion\r\nhelper(s) begin verifying and aggregating them. In order to enable the system to\r\n```",
              "createdAt": "2021-10-06T16:42:03Z",
              "updatedAt": "2021-10-06T16:54:11Z"
            },
            {
              "originalPosition": 194,
              "body": "```suggestion\r\nrequests to the helpers, the first of which contains the helper's encrypted input\r\n```",
              "createdAt": "2021-10-06T16:42:14Z",
              "updatedAt": "2021-10-06T16:54:11Z"
            },
            {
              "originalPosition": 195,
              "body": "```suggestion\r\nshares. After a number of successful requests, the aggregators have recovered\r\n```",
              "createdAt": "2021-10-06T16:42:33Z",
              "updatedAt": "2021-10-06T16:54:11Z"
            },
            {
              "originalPosition": 271,
              "body": "This is a regression. Please don't hardcode that it's two all over this PR.",
              "createdAt": "2021-10-06T16:51:28Z",
              "updatedAt": "2021-10-06T16:54:11Z"
            },
            {
              "originalPosition": 327,
              "body": "Isn't this operation the same for every endpoint? Why have it be leader-specific.",
              "createdAt": "2021-10-06T16:52:48Z",
              "updatedAt": "2021-10-06T16:54:11Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs4uE0zj",
          "commit": {
            "abbreviatedOid": "848d112"
          },
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-10-06T17:15:26Z",
          "updatedAt": "2021-10-06T17:15:27Z",
          "comments": [
            {
              "originalPosition": 345,
              "body": "If I complained about it in the past I have forgotten why! I'm OK with a VDAF-specific detail like this being encoded into `input_share`, i.e. in a way that's opaque to the PPM layer.",
              "createdAt": "2021-10-06T17:15:27Z",
              "updatedAt": "2021-10-06T17:15:27Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs4uJMde",
          "commit": {
            "abbreviatedOid": "848d112"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-10-07T16:47:45Z",
          "updatedAt": "2021-10-07T17:00:00Z",
          "comments": [
            {
              "originalPosition": 84,
              "body": "Good call. I removed this MUST here and the paranthetical above saying the protocol is only defined for two aggregators. I added a MUST for this at the end of {{task-configuration}}.",
              "createdAt": "2021-10-07T16:47:45Z",
              "updatedAt": "2021-10-07T17:00:00Z"
            },
            {
              "originalPosition": 61,
              "body": "Before I do, I'd like to chat in person about the implication of this restriction and why I feel it's a safe assumption. Just to be clear: the intention is that the VDAF scheme determines the number of rounds, not the wrapper protocol (i.e., this specification).",
              "createdAt": "2021-10-07T16:48:55Z",
              "updatedAt": "2021-10-07T17:00:00Z"
            },
            {
              "originalPosition": 139,
              "body": "Works for me, I thought we were still blocking on this change.",
              "createdAt": "2021-10-07T16:50:36Z",
              "updatedAt": "2021-10-07T17:00:00Z"
            },
            {
              "originalPosition": 191,
              "body": "I think if we're going to make this change, we'll have to actually specify how multiple helpers works. We can do this here, but my preference would be to wait for antoher PR.",
              "createdAt": "2021-10-07T16:51:44Z",
              "updatedAt": "2021-10-07T17:00:00Z"
            },
            {
              "originalPosition": 327,
              "body": "`SetupBaseR` has a different info string, but yeah, we should unify this when we allow for multiple helpers.",
              "createdAt": "2021-10-07T16:52:40Z",
              "updatedAt": "2021-10-07T17:00:00Z"
            },
            {
              "originalPosition": 101,
              "body": "Ack, I'll add a description of VDAFs in the overview for this PR.",
              "createdAt": "2021-10-07T16:56:52Z",
              "updatedAt": "2021-10-07T17:00:00Z"
            },
            {
              "originalPosition": 194,
              "body": "This is not currently specified.",
              "createdAt": "2021-10-07T16:57:41Z",
              "updatedAt": "2021-10-07T17:00:00Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs4uNqy9",
          "commit": {
            "abbreviatedOid": "6afbda1"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-10-08T19:12:05Z",
          "updatedAt": "2021-10-08T19:12:06Z",
          "comments": [
            {
              "originalPosition": 61,
              "body": "Changed \"constant\" to \"maximum\" number of rounds throughtout the doc.",
              "createdAt": "2021-10-08T19:12:06Z",
              "updatedAt": "2021-10-08T19:12:06Z"
            }
          ]
        }
      ]
    },
    {
      "number": 156,
      "id": "PR_kwDOFEJYQs4sm2d6",
      "title": "Clarify timing of report aggregations & purpose of anti-replay.",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/pull/156",
      "state": "MERGED",
      "author": "BranLwyd",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "As previously written, the timing of report aggregations would allow\r\naggregation of reports with timestamps far into the future, which would\r\nallow a single client reporting a timestamp of INT_MAX to DOS the\r\naggregation system due to the way timestamps are used in the anti-replay\r\nmechanism. Given the severity of not following this portion of the\r\nspecification, I upgrade the SHOULD to a MUST as well.\r\n\r\nFixes #153.",
      "createdAt": "2021-10-03T18:54:54Z",
      "updatedAt": "2021-10-25T19:54:13Z",
      "baseRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "baseRefName": "main",
      "baseRefOid": "7cf4db3f2ec7605a87ef79a52611eb544b0b0f33",
      "headRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "headRefName": "clarify-replay-and-buffering",
      "headRefOid": "fcbdb035a113897b4f131598a781bca6527388bc",
      "closedAt": "2021-10-25T19:54:13Z",
      "mergedAt": "2021-10-25T19:54:13Z",
      "mergedBy": "ekr",
      "mergeCommit": {
        "oid": "d1e323f806d499760818619aa6223fc9b59c9879"
      },
      "comments": [
        {
          "author": "ekr",
          "authorAssociation": "COLLABORATOR",
          "body": "At a high level, there are two ways for this to work:\r\n\r\n1. The leader and the helper agree precisely on which reports are acceptable, in which case (a) they need to have agreement on how much slack there is and (b) have precisely synchronized clocks. If the leader sends the helper an invalid share, then this can be a fatal error.\r\n2. The leader and the helper. In this case, they do not need to have agreement on slack or have synchronized clocks, but we then need to deal with the situation in which some shares are unacceptable. This requires a way for the helper to report that and then to know how the leader handles that.",
          "createdAt": "2021-10-06T17:26:15Z",
          "updatedAt": "2021-10-06T17:26:15Z"
        },
        {
          "author": "BranLwyd",
          "authorAssociation": "COLLABORATOR",
          "body": "> At a high level, there are two ways for this to work:\r\n> \r\n> 1. The leader and the helper agree precisely on which reports are acceptable, in which case (a) they need to have agreement on how much slack there is and (b) have precisely synchronized clocks. If the leader sends the helper an invalid share, then this can be a fatal error.\r\n> 2. The leader and the helper. In this case, they do not need to have agreement on slack or have synchronized clocks, but we then need to deal with the situation in which some shares are unacceptable. This requires a way for the helper to report that and then to know how the leader handles that.\r\n\r\nI took another look at the spec and I think we can actually get away without any new agreed-upon parameters, nor synchronized clocks; nor is there a requirement for (new) agreement on shares being unacceptable. (Sorry, I should have caught this during the discussion yesterday.)\r\n\r\nWith the changes in this PR, the leader now needs to know two new parameters: (a) how long into the past to keep reports before including them in an aggregate request, (b) how far into the future a client-provided timestamp can be.\r\n\r\nThe leader uses these parameters to decide, respectively, (a) which client reports to include in a given aggregate request, and (b) which client reports to drop at time of reception. It is capable of performing both of these functions on its own, without need for communication/coordination with the helper.\r\n\r\nThe helper's function for this part of the protocol is to receive aggregate requests, perform the existing anti-replay mechanism (based on ordering of `(timestamp, nonce)`) to avoid the leader being able to replay reports, then do whatever aggregation is necessary based on the VDAF in use. The helper does not actually need to know the parameters the leader is using to perform client report selection/filtering, nor does it need to have a clock synchronized with the leader (unless the VDAF needs a clock, I suppose the helper does not need a clock at all for the aggregation portion of the protocol!). Malformed aggregation requests, including (by my reading) those that trigger the anti-replay mechanism, ~~are handled as per section 3.1~~. [edit: actually, currently out-of-order reports are silently dropped: \"[The helper] then filters out out-of-order sub-requests by ignoring any sub-request that does not follow the previous one (See Section 4.4.2.)\"]",
          "createdAt": "2021-10-07T18:17:51Z",
          "updatedAt": "2021-10-07T19:46:31Z"
        },
        {
          "author": "BranLwyd",
          "authorAssociation": "COLLABORATOR",
          "body": "There was some discussion of whether we need to accept client reports timestamped in the future during yesterday's meeting. I wanted to circle back on this.\r\n\r\nFirst: an implementation can choose not to accept client timestamps that are in the future. The tradeoff is that clients whose clocks have skewed even a small amount of time into the future will no longer be able to provide reports.\r\n\r\nFor that reason, I think implementations should accept reports timestamped into the future, for a time period on the order of \"minutes\" or \"hours\" (but perhaps not \"days\" or \"weeks\"?). The leader does have to store these reports -- but since the leader already has to store all reports for some time to allow reports to arrive out-of-order, this is not a totally new requirement.\r\n\r\nThe text in the PR suggests accepting reports timestamped into the future up to a \"time proportional to the batch window size\"; to be honest, I simply copied forward the previous text's suggestion here. Perhaps there is a better suggestion to be made?",
          "createdAt": "2021-10-07T18:25:46Z",
          "updatedAt": "2021-10-07T18:25:46Z"
        },
        {
          "author": "BranLwyd",
          "authorAssociation": "COLLABORATOR",
          "body": "Based on last week's discussion, I dropped the `grace_window` behavior from a `MUST` to a `SHOULD`.\r\n\r\nPlease note this now-allowed bad behavior, copied from the commit message:\r\n> Specifically, an implementation that chooses to ignore the `grace_window` SHOULD, and accepts reports clock-skewed a few minutes in the future, could end up dropping non-skewed reports if a skewed report arrives just before an aggregate request is made.\r\n\r\nI don't think this caveat is bad enough to be worthy of specifying grace_window with a MUST, I only note it for posterity.",
          "createdAt": "2021-10-20T00:01:30Z",
          "updatedAt": "2021-10-20T00:01:30Z"
        },
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "I won't have time to look at this by noon, so please merge without my approval.",
          "createdAt": "2021-10-25T16:45:55Z",
          "updatedAt": "2021-10-25T16:45:55Z"
        },
        {
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "body": "LGTM! I'll merge at noon unless someone adds a review asking for more changes.",
          "createdAt": "2021-10-25T18:36:26Z",
          "updatedAt": "2021-10-25T18:36:26Z"
        },
        {
          "author": "ekr",
          "authorAssociation": "COLLABORATOR",
          "body": "I'd like to look first.\n\nOn Mon, Oct 25, 2021 at 11:36 AM Tim Geoghegan ***@***.***>\nwrote:\n\n> LGTM! I'll merge at noon unless someone adds a review asking for more\n> changes.\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/abetterinternet/ppm-specification/pull/156#issuecomment-951197698>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/AAIPLIJZ2AT6XUETLILVI2LUIWPTJANCNFSM5FH42HCQ>\n> .\n> Triage notifications on the go with GitHub Mobile for iOS\n> <https://apps.apple.com/app/apple-store/id1477376905?ct=notification-email&mt=8&pt=524675>\n> or Android\n> <https://play.google.com/store/apps/details?id=com.github.android&referrer=utm_campaign%3Dnotification-email%26utm_medium%3Demail%26utm_source%3Dgithub>.\n>\n>\n",
          "createdAt": "2021-10-25T18:37:31Z",
          "updatedAt": "2021-10-25T18:37:31Z"
        }
      ],
      "reviews": [
        {
          "id": "PRR_kwDOFEJYQs4uEo69",
          "commit": {
            "abbreviatedOid": "b0d536b"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "Yup, I agree this is a good idea. ",
          "createdAt": "2021-10-06T16:28:43Z",
          "updatedAt": "2021-10-06T16:28:43Z",
          "comments": []
        },
        {
          "id": "PRR_kwDOFEJYQs4uEplP",
          "commit": {
            "abbreviatedOid": "b0d536b"
          },
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "",
          "createdAt": "2021-10-06T16:31:14Z",
          "updatedAt": "2021-10-06T16:31:14Z",
          "comments": []
        },
        {
          "id": "PRR_kwDOFEJYQs4uE2L5",
          "commit": {
            "abbreviatedOid": "b0d536b"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "CHANGES_REQUESTED",
          "body": "@ekr pointed out on that the call that this needs to be more prescriptive for interop.",
          "createdAt": "2021-10-06T17:21:10Z",
          "updatedAt": "2021-10-06T17:21:10Z",
          "comments": []
        },
        {
          "id": "PRR_kwDOFEJYQs4uSY8B",
          "commit": {
            "abbreviatedOid": "b0d536b"
          },
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "state": "CHANGES_REQUESTED",
          "body": "",
          "createdAt": "2021-10-11T18:41:39Z",
          "updatedAt": "2021-10-11T19:04:00Z",
          "comments": [
            {
              "originalPosition": 27,
              "body": "nit: I liked the explicit mention of \"privacy violation\", because in the \"Security Considerations\" section, we discuss the \"privacy\" and \"soundness\" properties which are provided by the secret sharing and distributed proof components of the system, respectively. I think it's helpful to highlight where we can which of those properties is protected by a particular part of the protocol.",
              "createdAt": "2021-10-11T18:41:39Z",
              "updatedAt": "2021-10-11T19:04:00Z"
            },
            {
              "originalPosition": 12,
              "body": "I think we can be more prescriptive here and simply state that reports whose timestamps are in the future MUST be rejected, while allowing for clock skew. My rationale is that rejecting reports from the future is simple to specify and simple to implement, and lets us unambiguously specify behavior, except with respect to clock skew.\r\n\r\nI found some precedent for discussing clock skew this way. [RFC7519 section 4.1.4 and 4.1.5](https://datatracker.ietf.org/doc/html/rfc7519#section-4.1.4) discusses clock skew in the context of token expiration and not-before:\r\n```\r\nThe \"exp\" (expiration time) claim identifies the expiration time on\r\n   or after which the JWT MUST NOT be accepted for processing.  The\r\n   processing of the \"exp\" claim requires that the current date/time\r\n   MUST be before the expiration date/time listed in the \"exp\" claim.\r\n   Implementers MAY provide for some small leeway, usually no more than\r\n   a few minutes, to account for clock skew.\r\n```\r\n\r\nSimilarly in [the section of RFC7523 discussing expiration of JWTs in Oauth 2.0](https://www.rfc-editor.org/rfc/rfc7523.html#section-3):\r\n```\r\nThe JWT MUST contain an \"exp\" (expiration time) claim that\r\n        limits the time window during which the JWT can be used.  The\r\n        authorization server MUST reject any JWT with an expiration time\r\n        that has passed, subject to allowable clock skew between\r\n        systems.\r\n```\r\n\r\nMy takeaway is that it's acceptable for a standard to acknowledge clock skew but not be totally specific about what to do about it.",
              "createdAt": "2021-10-11T18:50:24Z",
              "updatedAt": "2021-10-11T19:04:00Z"
            },
            {
              "originalPosition": 9,
              "body": "Given that this is a `MUST`, I'd like us to be more explicit than saying \"proportional\". I wonder if we should have an explicit grace period parameter, or perhaps a submission deadline, so that clients can decide how long to hold onto inputs before uploading them. I can imagine clients wanting to defer uploads until they are on a WiFi network, or maybe until they are not drawing power from a battery, but if they know that the deadline is just about to elapse then they might opt to do the uploads a little sooner.\r\n\r\nI also wonder if we should define an error code and error document so that the leader can explicitly reject a report for being too old, and then tell the client what the oldest report it would accept is. This would allow the client to skip over potentially many queued reports that will be rejected by leader for being too old.",
              "createdAt": "2021-10-11T19:03:25Z",
              "updatedAt": "2021-10-11T19:04:00Z"
            },
            {
              "originalPosition": 9,
              "body": "I'm open to punting some or all of the above to a later PR in the interest of getting this change merged.",
              "createdAt": "2021-10-11T19:03:57Z",
              "updatedAt": "2021-10-11T19:04:00Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs4uWb6f",
          "commit": {
            "abbreviatedOid": "b0d536b"
          },
          "author": "BranLwyd",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-10-12T16:50:04Z",
          "updatedAt": "2021-10-12T16:50:04Z",
          "comments": [
            {
              "originalPosition": 27,
              "body": "Ah, I agree that it would be good to keep this explicit -- I didn't realize the intended reference here. I added some wording that is as clear as possible.",
              "createdAt": "2021-10-12T16:50:04Z",
              "updatedAt": "2021-10-12T16:50:04Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs4uWeI2",
          "commit": {
            "abbreviatedOid": "b0d536b"
          },
          "author": "BranLwyd",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-10-12T16:59:31Z",
          "updatedAt": "2021-10-12T16:59:31Z",
          "comments": [
            {
              "originalPosition": 12,
              "body": "Thanks for digging up the prior art -- I like both of these better than what's written, since the intent is to protect against clock skew specifically (and the previous wording in the PR didn't make that clear). I went with something like the first, since I want to make the \"clock skew leeway\" as hard to miss as possible for implementers, since I suspect it will be practically necessary to avoid unnecessarily dropping a nontrivial fraction of client reports.",
              "createdAt": "2021-10-12T16:59:31Z",
              "updatedAt": "2021-10-12T17:50:31Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs4uWtWQ",
          "commit": {
            "abbreviatedOid": "b0d536b"
          },
          "author": "BranLwyd",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-10-12T18:08:29Z",
          "updatedAt": "2021-10-12T18:08:30Z",
          "comments": [
            {
              "originalPosition": 9,
              "body": "I like the idea of an explicit task parameter: even though only the leader _needs_ to know this parameter for the protocol to work, as you point out, clients might wish to know the parameter to make decisions about which reports are worthy of submission. With an explicit `grace_window` parameter, clients could assume that any reports more than a `grace_window` into the past is unlikely to be accepted and drop them, without dropping too many reports that would have been accepted.\r\n\r\nAn explicit error type would work too, and would permit clients to make more precise report-or-drop decisions at the cost of more coordination/specification. I'll punt on specifying that unless someone objects.",
              "createdAt": "2021-10-12T18:08:29Z",
              "updatedAt": "2021-10-12T18:08:30Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs4u_KkI",
          "commit": {
            "abbreviatedOid": "2ff8c56"
          },
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "state": "CHANGES_REQUESTED",
          "body": "",
          "createdAt": "2021-10-25T15:49:31Z",
          "updatedAt": "2021-10-25T15:49:36Z",
          "comments": [
            {
              "originalPosition": 23,
              "body": "The consensus in the call the other week was to not prescribe much of anything around this, so I think we should remove the explicit `grace_window` parameter (which I know I asked for in the first place, so sorry to demand its deletion now) and go back to the SHOULD text we had (though we should keep your MUST NOT about future timestamps and MAY about clock skew).",
              "createdAt": "2021-10-25T15:49:31Z",
              "updatedAt": "2021-10-25T15:49:36Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs4u_WbB",
          "commit": {
            "abbreviatedOid": "fcbdb03"
          },
          "author": "BranLwyd",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-10-25T16:32:17Z",
          "updatedAt": "2021-10-25T16:32:18Z",
          "comments": [
            {
              "originalPosition": 23,
              "body": "Done -- effectively, this drops the explicit `grace_window` parameter for the implicit \"time period proportional to the batch window\", and choosing such a window means that we effectively won't ever aggregate something with a future timestamp even if we have a clock-skew grace window, so no complaints from me.\r\n\r\nI kept the wording as \"...before including them in an aggregate request\" rather than the original \"...before issuing the first aggregate request\". I _think_ this is what's intended (since a given report will only be included in a single successful aggregate request). Let me know if I'm missing something there.",
              "createdAt": "2021-10-25T16:32:18Z",
              "updatedAt": "2021-10-25T16:32:18Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs4u_z8c",
          "commit": {
            "abbreviatedOid": "fcbdb03"
          },
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "",
          "createdAt": "2021-10-25T18:35:47Z",
          "updatedAt": "2021-10-25T18:35:47Z",
          "comments": []
        }
      ]
    },
    {
      "number": 157,
      "id": "PR_kwDOFEJYQs4s9h5i",
      "title": "Some proposed edits",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/pull/157",
      "state": "MERGED",
      "author": "coopdanger",
      "authorAssociation": "CONTRIBUTOR",
      "assignees": [],
      "labels": [],
      "body": "I think this could still use some more words about what is meant by \"configuration\" but I was not sure myself so I didn't suggest anything.",
      "createdAt": "2021-10-08T20:50:20Z",
      "updatedAt": "2021-10-08T20:52:33Z",
      "baseRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "baseRefName": "main",
      "baseRefOid": "7cf4db3f2ec7605a87ef79a52611eb544b0b0f33",
      "headRepository": "coopdanger/ppm-specification",
      "headRefName": "patch-1",
      "headRefOid": "d02f24b453a0677774abf442d3f69ffdefde76b7",
      "closedAt": "2021-10-08T20:52:33Z",
      "mergedAt": "2021-10-08T20:52:33Z",
      "mergedBy": "ekr",
      "mergeCommit": {
        "oid": "5e866c1225bf679c8e46a3464833f36b3cb44239"
      },
      "comments": [],
      "reviews": []
    },
    {
      "number": 159,
      "id": "PR_kwDOFEJYQs4s9ieZ",
      "title": "Clarify configuration",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/pull/159",
      "state": "MERGED",
      "author": "ekr",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "",
      "createdAt": "2021-10-08T20:55:38Z",
      "updatedAt": "2021-10-12T12:25:27Z",
      "baseRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "baseRefName": "main",
      "baseRefOid": "5e866c1225bf679c8e46a3464833f36b3cb44239",
      "headRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "headRefName": "configuration",
      "headRefOid": "006dedd6a9ec05e11374c52192b44b5ec90d8f72",
      "closedAt": "2021-10-12T12:25:27Z",
      "mergedAt": "2021-10-12T12:25:27Z",
      "mergedBy": "chris-wood",
      "mergeCommit": {
        "oid": "6602a39dc70fcf9bcf57b8acb50144d784a1ab09"
      },
      "comments": [],
      "reviews": [
        {
          "id": "PRR_kwDOFEJYQs4uROWc",
          "commit": {
            "abbreviatedOid": "e6c9fa4"
          },
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-10-11T13:55:46Z",
          "updatedAt": "2021-10-11T13:56:07Z",
          "comments": [
            {
              "originalPosition": 9,
              "body": "```suggestion\r\nare configured with each other's identities and details of the types of\r\n```",
              "createdAt": "2021-10-11T13:55:46Z",
              "updatedAt": "2021-10-11T13:56:07Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs4uRSI8",
          "commit": {
            "abbreviatedOid": "e6c9fa4"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "LGTM pending Tim's nit",
          "createdAt": "2021-10-11T14:08:54Z",
          "updatedAt": "2021-10-11T14:08:54Z",
          "comments": []
        },
        {
          "id": "PRR_kwDOFEJYQs4uReI4",
          "commit": {
            "abbreviatedOid": "006dedd"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-10-11T14:51:47Z",
          "updatedAt": "2021-10-11T14:51:47Z",
          "comments": [
            {
              "originalPosition": 8,
              "body": "s/PRIV/PPM/? This is a new acronym to me",
              "createdAt": "2021-10-11T14:51:47Z",
              "updatedAt": "2021-10-11T14:51:47Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs4uRgIH",
          "commit": {
            "abbreviatedOid": "006dedd"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-10-11T14:57:33Z",
          "updatedAt": "2021-10-11T14:57:33Z",
          "comments": [
            {
              "originalPosition": 8,
              "body": "Some IETF leadership folks objected to the collision with IPPM, so PRIV was a fallback: https://datatracker.ietf.org/group/priv/about/",
              "createdAt": "2021-10-11T14:57:33Z",
              "updatedAt": "2021-10-11T14:57:33Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs4uRnvh",
          "commit": {
            "abbreviatedOid": "006dedd"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-10-11T15:10:30Z",
          "updatedAt": "2021-10-11T15:10:30Z",
          "comments": [
            {
              "originalPosition": 8,
              "body": "Ack, thanks!",
              "createdAt": "2021-10-11T15:10:30Z",
              "updatedAt": "2021-10-11T15:10:30Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs4uRn2A",
          "commit": {
            "abbreviatedOid": "006dedd"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "",
          "createdAt": "2021-10-11T15:10:41Z",
          "updatedAt": "2021-10-11T15:10:41Z",
          "comments": []
        },
        {
          "id": "PRR_kwDOFEJYQs4uSYaW",
          "commit": {
            "abbreviatedOid": "006dedd"
          },
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "",
          "createdAt": "2021-10-11T18:38:19Z",
          "updatedAt": "2021-10-11T18:38:19Z",
          "comments": []
        }
      ]
    },
    {
      "number": 160,
      "id": "PR_kwDOFEJYQs4tpSgk",
      "title": "Rename again",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/pull/160",
      "state": "MERGED",
      "author": "ekr",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "",
      "createdAt": "2021-10-25T20:04:02Z",
      "updatedAt": "2021-10-25T20:15:12Z",
      "baseRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "baseRefName": "main",
      "baseRefOid": "d1e323f806d499760818619aa6223fc9b59c9879",
      "headRepository": "ekr/ppm-specification",
      "headRefName": "rename_again",
      "headRefOid": "68eab4c1c5375079cf2d3bc11119948324acd24b",
      "closedAt": "2021-10-25T20:15:12Z",
      "mergedAt": "2021-10-25T20:15:12Z",
      "mergedBy": "ekr",
      "mergeCommit": {
        "oid": "bb88916823c47966f2ef139c248a17d7fb5d2170"
      },
      "comments": [],
      "reviews": [
        {
          "id": "PRR_kwDOFEJYQs4vAJIH",
          "commit": {
            "abbreviatedOid": "27e710f"
          },
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "This should update `.gitignore` to replace `draft-ppm-protocol.xml` with `draft-gpew-priv-ppm.xml` but otherwise LGTM",
          "createdAt": "2021-10-25T20:12:58Z",
          "updatedAt": "2021-10-25T20:12:58Z",
          "comments": []
        }
      ]
    },
    {
      "number": 162,
      "id": "PR_kwDOFEJYQs4uGNiT",
      "title": "Editorial clean-up",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/pull/162",
      "state": "MERGED",
      "author": "coopdanger",
      "authorAssociation": "CONTRIBUTOR",
      "assignees": [],
      "labels": [],
      "body": "",
      "createdAt": "2021-11-04T14:41:38Z",
      "updatedAt": "2021-11-04T15:51:38Z",
      "baseRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "baseRefName": "main",
      "baseRefOid": "bb88916823c47966f2ef139c248a17d7fb5d2170",
      "headRepository": "coopdanger/ppm-specification",
      "headRefName": "patch-2",
      "headRefOid": "1ad7bfc85df5aaefb44bffdc32a55319a05beeeb",
      "closedAt": "2021-11-04T15:51:38Z",
      "mergedAt": "2021-11-04T15:51:38Z",
      "mergedBy": "chris-wood",
      "mergeCommit": {
        "oid": "7e2fbd9e671c0bd31868a06e1f257c6ed9b83223"
      },
      "comments": [],
      "reviews": [
        {
          "id": "PRR_kwDOFEJYQs4vj3g2",
          "commit": {
            "abbreviatedOid": "1ad7bfc"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "",
          "createdAt": "2021-11-04T15:51:34Z",
          "updatedAt": "2021-11-04T15:51:34Z",
          "comments": []
        }
      ]
    },
    {
      "number": 164,
      "id": "PR_kwDOFEJYQs4uPpi5",
      "title": "Ietf112 slides",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/pull/164",
      "state": "MERGED",
      "author": "ekr",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "",
      "createdAt": "2021-11-08T18:41:09Z",
      "updatedAt": "2021-11-12T15:57:51Z",
      "baseRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "baseRefName": "main",
      "baseRefOid": "de1b61b1d6480a965648dcfad52879d9b7a9997b",
      "headRepository": "ekr/ppm-specification",
      "headRefName": "ietf112-slides",
      "headRefOid": "a6d6d9a513cd95c23b739b595a42b4b1b2f2832a",
      "closedAt": "2021-11-12T15:57:51Z",
      "mergedAt": "2021-11-12T15:57:51Z",
      "mergedBy": "chris-wood",
      "mergeCommit": {
        "oid": "2112f391f64b13f209b26cdd8721f05d070c2d28"
      },
      "comments": [
        {
          "author": "ekr",
          "authorAssociation": "COLLABORATOR",
          "body": "I'm going to claim they are encrypted, with a one time pad.\n\nOn Mon, Nov 8, 2021 at 1:52 PM Tim Geoghegan ***@***.***>\nwrote:\n\n> ***@***.**** commented on this pull request.\n> ------------------------------\n>\n> In ietf112-slides/ppm-ietf-112.tex\n> <https://github.com/abetterinternet/ppm-specification/pull/164#discussion_r745120762>\n> :\n>\n> > +\n> +\\begin{frame}{What about bogus data?}\n> +\n> +  \\begin{itemize}\n> +  \\item Plausible but false\n> +    \\begin{itemize}\n> +    \\item ``I am 180cm tall'' when I am actually 175cm\n> +    \\item A problem with any surveying technique\n> +    \\item Solution: live with somewhat noisy data\n> +    \\end{itemize}\n> +  \\item Completely ridiculous\n> +    \\begin{itemize}\n> +    \\item ``I am 1km tall'' (or worse, ``I am -1km tall'')\n> +    \\item Easy to remove with standard systems by filtering\n> +      \\begin{itemize}\n> +      \\item ... but with Prio the data is encrypted\n>\n> \"encrypted\" isn't the right word here, especially since the secret shares\n> constructed by clients *do* get encrypted, but not to conceal them from\n> aggregators. I can't come up with a better single word to express this,\n> though.\n>\n> \u2014\n> You are receiving this because you authored the thread.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/abetterinternet/ppm-specification/pull/164#pullrequestreview-800643076>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/AAIPLIPKEINCRXOPLIVT2TDULBBB3ANCNFSM5HTMIKPA>\n> .\n> Triage notifications on the go with GitHub Mobile for iOS\n> <https://apps.apple.com/app/apple-store/id1477376905?ct=notification-email&mt=8&pt=524675>\n> or Android\n> <https://play.google.com/store/apps/details?id=com.github.android&referrer=utm_campaign%3Dnotification-email%26utm_medium%3Demail%26utm_source%3Dgithub>.\n>\n>\n",
          "createdAt": "2021-11-08T21:54:02Z",
          "updatedAt": "2021-11-08T21:54:02Z"
        }
      ],
      "reviews": [
        {
          "id": "PRR_kwDOFEJYQs4vuNgE",
          "commit": {
            "abbreviatedOid": "ecb2ead"
          },
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-11-08T21:52:17Z",
          "updatedAt": "2021-11-08T21:52:17Z",
          "comments": [
            {
              "originalPosition": 329,
              "body": "\"encrypted\" isn't the right word here, especially since the secret shares constructed by clients *do* get encrypted, but not to conceal them from aggregators. I can't come up with a better single word to express this, though.",
              "createdAt": "2021-11-08T21:52:17Z",
              "updatedAt": "2021-11-08T21:52:17Z"
            }
          ]
        }
      ]
    },
    {
      "number": 165,
      "id": "PR_kwDOFEJYQs4ucIME",
      "title": "Update charter.md",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/pull/165",
      "state": "MERGED",
      "author": "ShivanKaul",
      "authorAssociation": "CONTRIBUTOR",
      "assignees": [],
      "labels": [],
      "body": "Amend charter to allow for alternative privacy-preserving measurement techniques that address some desired use cases.",
      "createdAt": "2021-11-12T06:29:48Z",
      "updatedAt": "2021-11-29T20:12:49Z",
      "baseRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "baseRefName": "main",
      "baseRefOid": "de1b61b1d6480a965648dcfad52879d9b7a9997b",
      "headRepository": "ShivanKaul/ppm-specification",
      "headRefName": "patch-1",
      "headRefOid": "c6c435333b50ebdd9c3a85bc215a951484418e32",
      "closedAt": "2021-11-29T20:12:49Z",
      "mergedAt": "2021-11-29T20:12:49Z",
      "mergedBy": "tgeoghegan",
      "mergeCommit": {
        "oid": "892ad83780df387bd0ffbb2916ebbfd79f5a3e1b"
      },
      "comments": [],
      "reviews": [
        {
          "id": "PRR_kwDOFEJYQs4v-sXx",
          "commit": {
            "abbreviatedOid": "39ca0bd"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "",
          "createdAt": "2021-11-12T15:57:41Z",
          "updatedAt": "2021-11-12T15:57:41Z",
          "comments": []
        },
        {
          "id": "PRR_kwDOFEJYQs4wOBMJ",
          "commit": {
            "abbreviatedOid": "39ca0bd"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "",
          "createdAt": "2021-11-17T18:20:53Z",
          "updatedAt": "2021-11-17T18:20:53Z",
          "comments": []
        },
        {
          "id": "PRR_kwDOFEJYQs4wUwt-",
          "commit": {
            "abbreviatedOid": "39ca0bd"
          },
          "author": "ekr",
          "authorAssociation": "COLLABORATOR",
          "state": "CHANGES_REQUESTED",
          "body": "LGTM with one change ",
          "createdAt": "2021-11-19T04:23:03Z",
          "updatedAt": "2021-11-19T04:23:17Z",
          "comments": [
            {
              "originalPosition": 20,
              "body": "```suggestion\r\n- Client submission of individual measurements, potentially along with proofs of validity\r\n```\r\n\r\nAvoiding the non sequiter later.",
              "createdAt": "2021-11-19T04:23:03Z",
              "updatedAt": "2021-11-19T04:23:17Z"
            }
          ]
        }
      ]
    },
    {
      "number": 167,
      "id": "PR_kwDOFEJYQs4uue9n",
      "title": "Abuse cases",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/pull/167",
      "state": "MERGED",
      "author": "ekr",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "",
      "createdAt": "2021-11-18T16:56:25Z",
      "updatedAt": "2021-11-18T17:06:16Z",
      "baseRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "baseRefName": "main",
      "baseRefOid": "2112f391f64b13f209b26cdd8721f05d070c2d28",
      "headRepository": "ekr/ppm-specification",
      "headRefName": "abuse_cases",
      "headRefOid": "5657790aecc1f84f8d2bcfce530316ca61cfd0fa",
      "closedAt": "2021-11-18T17:06:16Z",
      "mergedAt": "2021-11-18T17:06:16Z",
      "mergedBy": "ekr",
      "mergeCommit": {
        "oid": "65ff82c2cd9e5ef05e3b2e1b0c6a7fb716e3d2c5"
      },
      "comments": [
        {
          "author": "ekr",
          "authorAssociation": "COLLABORATOR",
          "body": "@coopdanger ",
          "createdAt": "2021-11-18T16:56:31Z",
          "updatedAt": "2021-11-18T16:56:31Z"
        },
        {
          "author": "coopdanger",
          "authorAssociation": "CONTRIBUTOR",
          "body": "LGTM, thanks",
          "createdAt": "2021-11-18T17:05:43Z",
          "updatedAt": "2021-11-18T17:05:43Z"
        }
      ],
      "reviews": [
        {
          "id": "PRR_kwDOFEJYQs4wSto9",
          "commit": {
            "abbreviatedOid": "5657790"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "",
          "createdAt": "2021-11-18T17:05:36Z",
          "updatedAt": "2021-11-18T17:05:36Z",
          "comments": []
        }
      ]
    },
    {
      "number": 168,
      "id": "PR_kwDOFEJYQs4vhdci",
      "title": "Refer to VDAF instead of \"PPM scheme\"",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/pull/168",
      "state": "MERGED",
      "author": "cjpatton",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "The spec vaguely refers to the \"concrete PPM scheme\" whenever we need to talk about protocol specific parameters. This change replaces each such reference with a reference to VDAF. It also adds the aggregation parameter to the aggregate request, which will be needed for hits.\r\n\r\nThis is an alternative #154 that aims to be less invasive. Partially addresses #98.",
      "createdAt": "2021-12-07T22:06:45Z",
      "updatedAt": "2021-12-29T17:45:42Z",
      "baseRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "baseRefName": "main",
      "baseRefOid": "892ad83780df387bd0ffbb2916ebbfd79f5a3e1b",
      "headRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "headRefName": "cjpatton/vdaf-unspecified",
      "headRefOid": "1378cbd94f2c318bb6bfa5a1bb173e595125ab90",
      "closedAt": "2021-12-09T15:23:24Z",
      "mergedAt": "2021-12-09T15:23:24Z",
      "mergedBy": "cjpatton",
      "mergeCommit": {
        "oid": "93032f7f3e1ed8cd1d785e68598d680a344c9813"
      },
      "comments": [
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "Squashed.",
          "createdAt": "2021-12-09T15:22:46Z",
          "updatedAt": "2021-12-09T15:22:46Z"
        }
      ],
      "reviews": [
        {
          "id": "PRR_kwDOFEJYQs4xRKCQ",
          "commit": {
            "abbreviatedOid": "0629e12"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "Much cleaner \ud83d\udc4d ",
          "createdAt": "2021-12-08T15:27:01Z",
          "updatedAt": "2021-12-08T15:27:01Z",
          "comments": []
        },
        {
          "id": "PRR_kwDOFEJYQs4xRl8A",
          "commit": {
            "abbreviatedOid": "0629e12"
          },
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "LGTM, modulo one typo",
          "createdAt": "2021-12-08T17:00:39Z",
          "updatedAt": "2021-12-08T17:01:27Z",
          "comments": [
            {
              "originalPosition": 167,
              "body": "```suggestion\r\n  opaque agg_param<0..2^16-1>;  // VDAF aggregation parameter\r\n```",
              "createdAt": "2021-12-08T17:00:40Z",
              "updatedAt": "2021-12-08T17:01:27Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs4xTAws",
          "commit": {
            "abbreviatedOid": "0629e12"
          },
          "author": "ekr",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "This is generally good.\r\n\r\n@cjpatton can you somehow the F(p, ...) thing before you land?",
          "createdAt": "2021-12-08T23:43:13Z",
          "updatedAt": "2021-12-08T23:49:49Z",
          "comments": [
            {
              "originalPosition": 9,
              "body": "I think you need to say something more about \"p\" here. Like, what is it?\r\n\r\nAnd why can't we just bury that in F. I.e., \\mathcal{F} is a family of functions parametrized by p and F is a specific instance?\r\n\r\n",
              "createdAt": "2021-12-08T23:43:13Z",
              "updatedAt": "2021-12-08T23:49:49Z"
            },
            {
              "originalPosition": 13,
              "body": "```suggestion\r\nschemes that implement the VDAF\r\n```",
              "createdAt": "2021-12-08T23:44:35Z",
              "updatedAt": "2021-12-08T23:49:49Z"
            },
            {
              "originalPosition": 56,
              "body": "Can we remove the semicolons here?",
              "createdAt": "2021-12-08T23:45:10Z",
              "updatedAt": "2021-12-08T23:49:49Z"
            },
            {
              "originalPosition": 84,
              "body": "```suggestion\r\nthe input's validity [BBCGGI19] which the aggregators can jointly verify\r\n```",
              "createdAt": "2021-12-08T23:47:35Z",
              "updatedAt": "2021-12-08T23:49:49Z"
            },
            {
              "originalPosition": 85,
              "body": "```suggestion\r\nreject the report if it cannot be verified. However, they do not\r\n```",
              "createdAt": "2021-12-08T23:47:45Z",
              "updatedAt": "2021-12-08T23:49:49Z"
            },
            {
              "originalPosition": 213,
              "body": "```suggestion\r\nencodes the nonce and a VDAF-specific `message`:\r\n```",
              "createdAt": "2021-12-08T23:48:40Z",
              "updatedAt": "2021-12-09T01:03:59Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs4xTKMH",
          "commit": {
            "abbreviatedOid": "0629e12"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-12-09T01:04:33Z",
          "updatedAt": "2021-12-09T01:15:24Z",
          "comments": [
            {
              "originalPosition": 213,
              "body": "Took this but merged \"timestamp\" into \"nonce\".",
              "createdAt": "2021-12-09T01:04:33Z",
              "updatedAt": "2021-12-09T01:15:24Z"
            },
            {
              "originalPosition": 56,
              "body": "Replaced with periods.",
              "createdAt": "2021-12-09T01:05:59Z",
              "updatedAt": "2021-12-09T01:15:24Z"
            },
            {
              "originalPosition": 9,
              "body": "Two reasons not to bury this:\r\n1. `F` is implied by the VDAF in use\r\n2. `p` is a parameter chosen by the collector and distributed to the aggregators.\r\n\r\nI agree we should say more about what this is. I've added a paragraph to add a bit more color.\r\n\r\nBy the way, the canonical example of an aggregation parameter is the set of candidate prefixes for each round of heavy hitters.",
              "createdAt": "2021-12-09T01:11:40Z",
              "updatedAt": "2021-12-09T01:15:24Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs4xTVal",
          "commit": {
            "abbreviatedOid": "edede2b"
          },
          "author": "ekr",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "",
          "createdAt": "2021-12-09T02:47:40Z",
          "updatedAt": "2021-12-09T02:48:11Z",
          "comments": [
            {
              "originalPosition": 9,
              "body": "I can live with your text here, but I don't really agree with this rationale. This is introductory text and doesn't need to map 1:1 with the VDAF spec.",
              "createdAt": "2021-12-09T02:47:40Z",
              "updatedAt": "2021-12-09T02:48:11Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs4xV6lj",
          "commit": {
            "abbreviatedOid": "edede2b"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-12-09T15:21:44Z",
          "updatedAt": "2021-12-09T15:21:44Z",
          "comments": [
            {
              "originalPosition": 9,
              "body": "Yeah I agree. Happy to iterate on it later on.",
              "createdAt": "2021-12-09T15:21:44Z",
              "updatedAt": "2021-12-09T15:21:44Z"
            }
          ]
        }
      ]
    },
    {
      "number": 169,
      "id": "PR_kwDOFEJYQs4vhlq-",
      "title": "Revise anti-replay mechanism",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/pull/169",
      "state": "MERGED",
      "author": "cjpatton",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "As proposed on the list: https://mailarchive.ietf.org/arch/msg/ppm/WP7PF6y_dr_VY9yHWc8hZOuIZWQ/",
      "createdAt": "2021-12-07T23:16:45Z",
      "updatedAt": "2022-01-15T00:20:15Z",
      "baseRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "baseRefName": "main",
      "baseRefOid": "48bc21ce7f1c7e446618bfe53cd9470511e130bc",
      "headRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "headRefName": "cjpatton/replay",
      "headRefOid": "6b5c09b0dcc92698d0b0630dd41f46bda7a2ab66",
      "closedAt": "2022-01-15T00:20:15Z",
      "mergedAt": "2022-01-15T00:20:15Z",
      "mergedBy": "cjpatton",
      "mergeCommit": {
        "oid": "47c5b696a0c12e9c5da9cfc12c40d1786e0ce1fc"
      },
      "comments": [
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "> If we're revisiting the helper's storage capabilities to the extent of expecting them to maintain a set of nonces, should we also revisit the notion of the leader storing the helper's encrypted input shares, too?\r\n\r\nYeah, I think we could do that, but let's punt to a future PR.",
          "createdAt": "2021-12-08T15:15:22Z",
          "updatedAt": "2021-12-08T15:15:22Z"
        },
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "Rebased and squashed.",
          "createdAt": "2021-12-10T20:42:00Z",
          "updatedAt": "2021-12-10T20:42:00Z"
        },
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "Removed the time-sensitive parameters",
          "createdAt": "2021-12-10T22:57:58Z",
          "updatedAt": "2021-12-10T22:57:58Z"
        },
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "There seems to be consensus for the main change introduced by this PR, which is to not require the Leader to sort reports. The only outstanding question is how to mitigate data loss that results from aggregators ignoring reports \"at will\". This is definitely a solvable problem, but there's not yet consensus on how to solve it. I'd like to suggest that we merge this PR and open an issue to hash out this problem.\r\n\r\n@chris-wood, @ekr: Please review and approve.",
          "createdAt": "2022-01-10T18:26:24Z",
          "updatedAt": "2022-01-10T18:26:24Z"
        },
        {
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "body": "> First, as a practical matter, if clocks aren't roughly synced, then we are going to have some serious problems about out of window rejection.\r\n\r\nI'm not sure I agree with this. My understanding of the design principle here -- which I support -- is that aggregators just agree on a list of timestamps, just like they agree on other parameters for configuration of a measurement task. That means the only real requirement for clock sync then falls on the leader, as they control what is effectively \"the current batch.\" The leader controls what things are sent to the aggregators, so they can track the current batch based on what the leader asks them to aggregate and then output. (I _think_ they could do this without any notion of a clock whatsoever, but I may be missing something.)",
          "createdAt": "2022-01-14T23:08:56Z",
          "updatedAt": "2022-01-14T23:08:56Z"
        },
        {
          "author": "ekr",
          "authorAssociation": "COLLABORATOR",
          "body": "@chris-wood I think you may be correct, at least in the \"everything gets sent to the leader\" model. The helper can just accept whatever the leader says as the \"right edge\" of the window. And if the leader is dumb enough to do something way in the future, then it can't aggregate for a long time.\r\n",
          "createdAt": "2022-01-14T23:16:07Z",
          "updatedAt": "2022-01-14T23:16:07Z"
        },
        {
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "body": "Yeah, this seems like it gets more complicated if we move to the \"send directly to aggregators\" model. \ud83e\udd37 ",
          "createdAt": "2022-01-14T23:17:14Z",
          "updatedAt": "2022-01-14T23:17:14Z"
        },
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "For my part, I actually think @ekr's suggestion is quite nice. However not everyone agrees that we should require the aggregators to be roughly time-synced, and we'll need to discuss it further. I'm trying to avoid scope creep with the current PR. @ekr I've addressed your inline comments ...  please let me know if you're happy merging this without your suggestion and we can discuss it in a new issue.",
          "createdAt": "2022-01-14T23:28:27Z",
          "updatedAt": "2022-01-14T23:28:27Z"
        },
        {
          "author": "ekr",
          "authorAssociation": "COLLABORATOR",
          "body": "I'm not sure why it makes sense to land a PR changing things when we\ndon't have consensus.\n\nI would suggest instead that we just land the protocol piece that\nincludes the nonce and say that the precise replay suppression\nalgorithm is out of scope. As a practical matter, this will just mean\nthat interop is a little messy because the helper may silently\nreject, but that can happen anyway for other reasons, and none\nof this will be much of a problem if clocks are synced, which we\ncan just do for now.\n\n\n\nOn Fri, Jan 14, 2022 at 3:28 PM Christopher Patton ***@***.***>\nwrote:\n\n> For my part, I actually think @ekr <https://github.com/ekr>'s suggestion\n> is quite nice. However not everyone agrees that we should require the\n> aggregators to be roughly time-synced, and we'll need to discuss it\n> further. I'm trying to avoid scope creep with the current PR. @ekr\n> <https://github.com/ekr> I've addressed your inline comments ... please\n> let me know if you're happy merging this without your suggestion and we can\n> discuss it in a new issue.\n>\n> \u2014\n> Reply to this email directly, view it on GitHub\n> <https://github.com/abetterinternet/ppm-specification/pull/169#issuecomment-1013540322>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/AAIPLIKQZHTH4ADMI7QDWQTUWCWSNANCNFSM5JSNFTXQ>\n> .\n> Triage notifications on the go with GitHub Mobile for iOS\n> <https://apps.apple.com/app/apple-store/id1477376905?ct=notification-email&mt=8&pt=524675>\n> or Android\n> <https://play.google.com/store/apps/details?id=com.github.android&referrer=utm_campaign%3Dnotification-email%26utm_medium%3Demail%26utm_source%3Dgithub>.\n>\n> You are receiving this because you were mentioned.Message ID:\n> ***@***.***>\n>\n",
          "createdAt": "2022-01-14T23:32:39Z",
          "updatedAt": "2022-01-14T23:32:39Z"
        },
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "I don't think we disagree on the replay-suppression algorithm. In fact, the only piece we haven't converged on is how to avoid storing nonce sets indefinitely while minimizing data loss.\r\n\r\nWe already require that the nonces be stored as long as they might be used (i.e., for as long as a batch isn't collected) It seems like all we need to do is remove the following text:\r\n\r\n> Depending on the rate of upload requests, the size of the nonce set can grow to     \r\n> be quite large. To ensure they do not need to store these indefinitely, each     \r\n> aggregator MAY at its own discretion ignore reports with timestamps that are too     \r\n> far in the past or too far in the future (see {{batch-parameter-validation}}).     \r\n\r\nand replace it with an open issue where we discuss this problem.\r\n",
          "createdAt": "2022-01-14T23:54:54Z",
          "updatedAt": "2022-01-14T23:54:54Z"
        },
        {
          "author": "ekr",
          "authorAssociation": "COLLABORATOR",
          "body": "> I don't think we disagree on the replay-suppression algorithm. In fact, the only piece we haven't converged on is how to avoid storing nonce sets indefinitely while minimizing data loss.\r\n\r\nI was including that as part of the algorithm, but OK.\r\n\r\n\r\n> We already require that the nonces be stored as long as they might be used (i.e., for as long as a batch isn't collected) It seems like all we need to do is remove the following text:\r\n> \r\n> > Depending on the rate of upload requests, the size of the nonce set can grow to\r\n> > be quite large. To ensure they do not need to store these indefinitely, each\r\n> > aggregator MAY at its own discretion ignore reports with timestamps that are too\r\n> > far in the past or too far in the future (see {{batch-parameter-validation}}).\r\n> \r\n> and replace it with an open issue where we discuss this problem.\r\n\r\nSeems like you should also remove the rest of the OPEN ISSUE text following.\r\n\r\n",
          "createdAt": "2022-01-14T23:57:55Z",
          "updatedAt": "2022-01-14T23:57:55Z"
        },
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "Done, and squashed the commits.",
          "createdAt": "2022-01-15T00:01:21Z",
          "updatedAt": "2022-01-15T00:01:21Z"
        },
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "Here's the issue: https://github.com/abetterinternet/ppm-specification/issues/180\r\nI'll merge this once @ekr approves.",
          "createdAt": "2022-01-15T00:14:06Z",
          "updatedAt": "2022-01-15T00:14:06Z"
        },
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "Done.",
          "createdAt": "2022-01-15T00:18:46Z",
          "updatedAt": "2022-01-15T00:18:46Z"
        }
      ],
      "reviews": [
        {
          "id": "PRR_kwDOFEJYQs4xOf4o",
          "commit": {
            "abbreviatedOid": "e709ef8"
          },
          "author": "BranLwyd",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-12-07T23:58:19Z",
          "updatedAt": "2021-12-08T00:06:33Z",
          "comments": [
            {
              "originalPosition": 192,
              "body": "The previous strategy had the \"nonce time window evaluation\" (i.e. checking that each client report is not too new/too old) done solely by the leader; if I'm reading this PR correctly, now this time window evaluation is done on a per-aggregator basis.\r\n\r\nThis means that skewed clocks (or non-zero network latency) between different aggregators could lead to the aggregators disagreeing about which reports are acceptable and which should be ignored. My understanding is that such a disagreement can be catastrophic to the accuracy of the eventual aggregation.\r\n\r\nTo avoid the need to keep precisely-synchronized clocks between the leader & helper, I propose that the time-based filtering continue to be done by the leader alone. (The nonce-based filtering can/should still be done by both the leader & the helper.)",
              "createdAt": "2021-12-07T23:58:19Z",
              "updatedAt": "2021-12-08T00:06:33Z"
            },
            {
              "originalPosition": 184,
              "body": "nit: `noncee` -> `nonces`",
              "createdAt": "2021-12-07T23:58:41Z",
              "updatedAt": "2021-12-08T00:06:33Z"
            },
            {
              "originalPosition": 193,
              "body": "In previous discussion, the \"look-back\" window we considered was on the order of a few hours; the \"look-forward\" window was effectively as small as tolerable given likely clock skews between the clients & the leader, on the order of a few minutes.\r\n\r\nIn this PR, the look-forward & look-back are identical (i.e. `max_report_offset`).\r\n\r\nWDYT about making the look-forward and look-back windows into two separate parameters, or otherwise not prescribing that they be identical?",
              "createdAt": "2021-12-08T00:02:05Z",
              "updatedAt": "2021-12-08T00:07:16Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs4xOjB-",
          "commit": {
            "abbreviatedOid": "e709ef8"
          },
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "If we're revisiting the helper's storage capabilities to the extent of expecting them to maintain a set of nonces, should we also revisit the notion of the leader storing the helper's encrypted input shares, too?",
          "createdAt": "2021-12-08T00:25:09Z",
          "updatedAt": "2021-12-08T00:26:59Z",
          "comments": [
            {
              "originalPosition": 199,
              "body": "```suggestion\r\nstrategy may result in dropping reports that happen to have the same nonce.\r\n```\r\nThis is unlikely given that the nonce is a 64 bit integer though, right?",
              "createdAt": "2021-12-08T00:25:09Z",
              "updatedAt": "2021-12-08T00:26:59Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs4xOqKu",
          "commit": {
            "abbreviatedOid": "e709ef8"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-12-08T01:30:01Z",
          "updatedAt": "2021-12-08T01:38:16Z",
          "comments": [
            {
              "originalPosition": 192,
              "body": "> This means that skewed clocks (or non-zero network latency) between different aggregators could lead to the aggregators disagreeing about which reports are acceptable and which should be ignored. My understanding is that such a disagreement can be catastrophic to the accuracy of the eventual aggregation.\r\n\r\nClock skew is indeed a problem, but the worst that can happen if a clock is off is that a report gets dropped needlessly. The kind of catastrophic failure you're talking about would happen only if one aggregator decided to aggregate its input share but the other did not. If a report is ignored, then an input share cannot be validated and therefore cannot be aggregated.\r\n\r\n> To avoid the need to keep precisely-synchronized clocks between the leader & helper, I propose that the time-based filtering continue to be done by the leader alone. (The nonce-based filtering can/should still be done by both the leader & the helper.)\r\n\r\nBoth aggregators need to enforce anti-replay, so the helper would have to store the entire nonce set for the task indefinitely. This is the main problem we're trying to avoid with time-based filtering.",
              "createdAt": "2021-12-08T01:30:01Z",
              "updatedAt": "2021-12-08T01:38:16Z"
            },
            {
              "originalPosition": 193,
              "body": "Good catch, I forgot about this! (This is why we have reviews!) I'll break this into two parameters.",
              "createdAt": "2021-12-08T01:30:47Z",
              "updatedAt": "2021-12-08T01:38:16Z"
            },
            {
              "originalPosition": 199,
              "body": "It's not terribly unlikely. Say you have an upload rate of 10,000,000 reports/sec. Then the probability of a nonce collision is roughly 1,000,000^2/2^64, i.e., not negligible.",
              "createdAt": "2021-12-08T01:37:37Z",
              "updatedAt": "2021-12-08T01:38:16Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs4xRfWA",
          "commit": {
            "abbreviatedOid": "7b906f0"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-12-08T16:37:28Z",
          "updatedAt": "2021-12-08T16:37:29Z",
          "comments": [
            {
              "originalPosition": 187,
              "body": "I suppose we could make this a MAY.",
              "createdAt": "2021-12-08T16:37:28Z",
              "updatedAt": "2021-12-08T16:37:29Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs4xc-Nr",
          "commit": {
            "abbreviatedOid": "73d7673"
          },
          "author": "martinthomson",
          "authorAssociation": "CONTRIBUTOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-12-12T22:35:07Z",
          "updatedAt": "2021-12-12T22:48:02Z",
          "comments": [
            {
              "originalPosition": 5,
              "body": "You shouldn't be checking this file in.  Especially as it is listed in .gitignore.",
              "createdAt": "2021-12-12T22:35:07Z",
              "updatedAt": "2021-12-12T22:48:02Z"
            },
            {
              "originalPosition": 182,
              "body": "This note being attached to the AAD statement is confusing.  It's a note about the whole scheme, not the AAD construction.",
              "createdAt": "2021-12-12T22:40:36Z",
              "updatedAt": "2021-12-12T22:48:02Z"
            },
            {
              "originalPosition": 147,
              "body": "The point isn't that it is too far into the future, it is that you either track nonces, or you reject the input.",
              "createdAt": "2021-12-12T22:47:53Z",
              "updatedAt": "2021-12-12T22:48:02Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs4xh094",
          "commit": {
            "abbreviatedOid": "73d7673"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-12-14T02:22:14Z",
          "updatedAt": "2021-12-14T02:22:23Z",
          "comments": [
            {
              "originalPosition": 5,
              "body": "Ugh, thanks for flagging! Reverted.\r\n\r\nHowever, after `make clean && make` I see the file in `git status`, despite the fact that it's listed as ignored:\r\n```\r\n$ git status\r\nOn branch cjpatton/replay\r\nYour branch is up to date with 'origin/cjpatton/replay'.\r\n\r\nChanges not staged for commit:\r\n  (use \"git add <file>...\" to update what will be committed)\r\n  (use \"git restore <file>...\" to discard changes in working directory)\r\n\tmodified:   .targets.mk\r\n\r\nno changes added to commit (use \"git add\" and/or \"git commit -a\")\r\n```",
              "createdAt": "2021-12-14T02:22:14Z",
              "updatedAt": "2021-12-14T02:22:23Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs4xh1v4",
          "commit": {
            "abbreviatedOid": "0b0eb0c"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-12-14T02:29:36Z",
          "updatedAt": "2021-12-14T02:33:18Z",
          "comments": [
            {
              "originalPosition": 182,
              "body": "Good call. I replaced this with a paragraph that, hopefully, makes it more clear what we're trying to accomplish here.",
              "createdAt": "2021-12-14T02:29:36Z",
              "updatedAt": "2021-12-14T02:33:18Z"
            },
            {
              "originalPosition": 147,
              "body": "Fair enough, but this text isn't new to this PR. What's changed here is the need to re-order reports.",
              "createdAt": "2021-12-14T02:32:03Z",
              "updatedAt": "2021-12-14T02:33:18Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs4yKjYj",
          "commit": {
            "abbreviatedOid": "b884da9"
          },
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "state": "CHANGES_REQUESTED",
          "body": "",
          "createdAt": "2021-12-29T21:23:47Z",
          "updatedAt": "2021-12-29T21:49:06Z",
          "comments": [
            {
              "originalPosition": 56,
              "body": "Do we need to spell out how a `struct Nonce` gets mashed into an HPKE context? i.e. endianness",
              "createdAt": "2021-12-29T21:23:47Z",
              "updatedAt": "2021-12-29T21:49:06Z"
            },
            {
              "originalPosition": 71,
              "body": "```suggestion\r\nhas been aggregated at least once. Otherwise, comparing the aggregate result to\r\n```",
              "createdAt": "2021-12-29T21:24:00Z",
              "updatedAt": "2021-12-29T21:49:06Z"
            },
            {
              "originalPosition": 124,
              "body": "```suggestion\r\ninterval that has been aggregated at least once.\r\n```",
              "createdAt": "2021-12-29T21:35:40Z",
              "updatedAt": "2021-12-29T21:49:06Z"
            },
            {
              "originalPosition": 71,
              "body": "What does it mean for a *batch interval* to have been *aggregated*? I don't think that verb is defined for that noun in the protocol right now. As a reader, if I want to see where things become \"aggregated\", then the `AggregateReq/AggregateResp` exchange seems like the obvious place, but an `AggregateReq` is not defined in terms of a batch interval. `AggregateSubReq` does include parameters that uniquely identify a `Report`, which I think lets us conclude that a `Report` is aggregated when the leader gets an `AggregateSubResp` from the helper for a `Report`. `OutputShareReq` does have a `batch_interval` member, so is the receipt of the corresponding `EncryptedOutputShare` when a batch interval becomes \"aggregated\"?\r\n\r\nI think we should write out a state machine for reports and batch intervals, especially since it seems like they enter the \"aggregated\" state at different moments. We maybe want to use a different verb than \"aggregate\" for batch interval to avoid confusion, too. How about \"collect\", since the `OutputShareReq/EncryptedOutputShare` process should be triggered by a collector issuing `CollectReq` to leader?\r\n\r\nAlso I think we should not do something like add a `batch_interval` member to `AggregateReq` and declare that receipt of `AggregateResp` is when a batch interval is aggregated, because I think that would prevent leaders and helpers from summing Prio inputs ahead of receipt of all the reports in a batch interval.",
              "createdAt": "2021-12-29T21:43:37Z",
              "updatedAt": "2021-12-29T21:49:06Z"
            },
            {
              "originalPosition": 202,
              "body": "Similarly to my point about the verb \"aggregate\" and the noun \"batch interval\", I think the notion of a report being \"processed\" is ambiguous. Given that there are two processing stages for an aggregator, the `AggregateReq` process and then the `OutputShareReq` process, when is a report \"processed\"? I suspect it's the former. Once again I think spelling out the state machine for reports and batch intervals would be helpful.",
              "createdAt": "2021-12-29T21:46:53Z",
              "updatedAt": "2021-12-29T21:49:06Z"
            },
            {
              "originalPosition": 223,
              "body": "Could you write up a GH issue for this for visibility?",
              "createdAt": "2021-12-29T21:47:31Z",
              "updatedAt": "2021-12-29T21:49:07Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs4yKm70",
          "commit": {
            "abbreviatedOid": "b884da9"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-12-29T22:16:06Z",
          "updatedAt": "2021-12-29T22:16:06Z",
          "comments": [
            {
              "originalPosition": 56,
              "body": "TLS-syntax specifies the byte encoding of `struct Nonce`, including endianness. See also my comment here: https://github.com/abetterinternet/ppm-specification/issues/139#issuecomment-1002795321. (If I've understood you correctly, we should be able to close that issue without action.)",
              "createdAt": "2021-12-29T22:16:06Z",
              "updatedAt": "2021-12-29T22:16:07Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs4yKmVH",
          "commit": {
            "abbreviatedOid": "b884da9"
          },
          "author": "ekr",
          "authorAssociation": "COLLABORATOR",
          "state": "CHANGES_REQUESTED",
          "body": "",
          "createdAt": "2021-12-29T22:06:32Z",
          "updatedAt": "2021-12-29T22:19:45Z",
          "comments": [
            {
              "originalPosition": 56,
              "body": "I don't think so. The HPKE function takes a blob and the TLS language specifies a bigendian serialization.",
              "createdAt": "2021-12-29T22:06:32Z",
              "updatedAt": "2021-12-29T22:19:46Z"
            },
            {
              "originalPosition": 71,
              "body": "Why are you saying \"ignore\" as opposed to \"generate error\"",
              "createdAt": "2021-12-29T22:11:05Z",
              "updatedAt": "2021-12-29T22:19:46Z"
            },
            {
              "originalPosition": 124,
              "body": "Again, why ignore and not error?",
              "createdAt": "2021-12-29T22:14:11Z",
              "updatedAt": "2021-12-29T22:19:46Z"
            },
            {
              "originalPosition": 217,
              "body": "It's not unbounded. It's of size 2^{96}.",
              "createdAt": "2021-12-29T22:18:03Z",
              "updatedAt": "2021-12-29T22:19:46Z"
            },
            {
              "originalPosition": 221,
              "body": "It's not at your discretion whether you ignore those which have been aggregated.",
              "createdAt": "2021-12-29T22:19:01Z",
              "updatedAt": "2021-12-29T22:19:46Z"
            },
            {
              "originalPosition": 234,
              "body": "Why is it useful not to require clock sync? The leader and the helper are servers, and they're quite capable of having accurate clocks.",
              "createdAt": "2021-12-29T22:19:37Z",
              "updatedAt": "2021-12-29T22:19:46Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs4yKnN3",
          "commit": {
            "abbreviatedOid": "b884da9"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-12-29T22:20:53Z",
          "updatedAt": "2021-12-29T22:20:53Z",
          "comments": [
            {
              "originalPosition": 223,
              "body": "Sure thing, however I want to wait until folks are happy with this change. After all, the issue is triggered by this PR and only makes sense if it's merged.",
              "createdAt": "2021-12-29T22:20:53Z",
              "updatedAt": "2021-12-29T22:20:53Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs4yKn4G",
          "commit": {
            "abbreviatedOid": "e0b8fc9"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-12-29T22:32:42Z",
          "updatedAt": "2021-12-29T22:32:43Z",
          "comments": [
            {
              "originalPosition": 71,
              "body": "@tgeoghegan good call. I've changed \"aggregated\" to be more precise. (Similarly below.)",
              "createdAt": "2021-12-29T22:32:43Z",
              "updatedAt": "2021-12-29T22:32:43Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs4yKn5s",
          "commit": {
            "abbreviatedOid": "e0b8fc9"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-12-29T22:33:10Z",
          "updatedAt": "2021-12-29T22:33:10Z",
          "comments": [
            {
              "originalPosition": 202,
              "body": "I made this more precise along the same lines as above.",
              "createdAt": "2021-12-29T22:33:10Z",
              "updatedAt": "2021-12-29T22:33:11Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs4xh7re",
          "commit": {
            "abbreviatedOid": "6effbf2"
          },
          "author": "martinthomson",
          "authorAssociation": "CONTRIBUTOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-12-14T03:26:49Z",
          "updatedAt": "2021-12-29T22:34:01Z",
          "comments": [
            {
              "originalPosition": 147,
              "body": "My point is that you need to be very clear about what your anti-replay protections are doing and how.  This requirement without that context is not going to help people understand what the rule exists for and how it provides that protection.",
              "createdAt": "2021-12-14T03:26:49Z",
              "updatedAt": "2021-12-29T22:34:01Z"
            },
            {
              "originalPosition": 234,
              "body": "Good sync != perfect sync.  Aggregation will fail if anti-replay is independently enforced by helpers (which is something I argue we want) and any amount of relative skew could produce disagreements.",
              "createdAt": "2021-12-29T22:25:51Z",
              "updatedAt": "2021-12-29T22:34:01Z"
            },
            {
              "originalPosition": 238,
              "body": "I don't see how this is difficult.  The leader starts a run and tells helpers what t_min and t_max are as part of that.",
              "createdAt": "2021-12-29T22:26:24Z",
              "updatedAt": "2021-12-29T22:34:01Z"
            },
            {
              "originalPosition": 221,
              "body": "Definitely.  This is an important point on which all helpers (and the leader) need to agree.  Discretion can't come into it or aggregation will fail.",
              "createdAt": "2021-12-29T22:27:30Z",
              "updatedAt": "2021-12-29T22:34:01Z"
            },
            {
              "originalPosition": 75,
              "body": "```suggestion\r\n```\r\n\r\nThis is not a helpful statement.  It could be misinterpreted as saying that differential privacy is enough.  But anti-replay is critical to ensuring that differential privacy protections are adequate.  This says the exact opposite.",
              "createdAt": "2021-12-29T22:31:04Z",
              "updatedAt": "2021-12-29T22:34:01Z"
            },
            {
              "originalPosition": 124,
              "body": "You should include all the anti-replay text in the one place.  I read the previous piece and guessed that only the leader looks at timestamps.  But that isn't it.\r\n\r\nNote also s/timestamp/nonce or \"nonce contains a timestamp that\"",
              "createdAt": "2021-12-29T22:32:20Z",
              "updatedAt": "2021-12-29T22:34:01Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs4yKoAU",
          "commit": {
            "abbreviatedOid": "b7400d6"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-12-29T22:35:07Z",
          "updatedAt": "2021-12-29T22:43:49Z",
          "comments": [
            {
              "originalPosition": 217,
              "body": "Actually it's 2^128, but point well taken! Fixed to not imply unboundedness.",
              "createdAt": "2021-12-29T22:35:07Z",
              "updatedAt": "2021-12-29T22:43:49Z"
            },
            {
              "originalPosition": 221,
              "body": "Nice catch.",
              "createdAt": "2021-12-29T22:36:28Z",
              "updatedAt": "2021-12-29T22:43:49Z"
            },
            {
              "originalPosition": 234,
              "body": "> The leader and the helper are servers, and they're quite capable of having accurate clocks.\r\n\r\nI tend to agree. If we align `d_max` and `d_min` with `min_batch_duration`, then all they have to do is ensure their clocks are within `min_batch_duration` seconds of one another. However I think @martinthomson's broader point is this requirement isn't strictly necessary. The true requirement is that they agree on what set of nonces they have to track at any given time.\r\n\r\nThis was discussed extensively here: https://mailarchive.ietf.org/arch/msg/ppm/oDCOJ-cUR8NQFG6At3byH1fdcd4/",
              "createdAt": "2021-12-29T22:42:23Z",
              "updatedAt": "2021-12-29T22:43:49Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs4yKo60",
          "commit": {
            "abbreviatedOid": "b7400d6"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-12-29T22:53:42Z",
          "updatedAt": "2021-12-29T22:53:42Z",
          "comments": [
            {
              "originalPosition": 71,
              "body": "@ekr good question.\r\n\r\nOne reason to not *require* an error here is that, if we did, the leader would have to check if the batch has been collected before completing the HTTP request. The current text allows it to make this determination later on.\r\n\r\nOne reason to *not permit* an error at all is that it volunteers information to the client that the client doesn't really need, namely, that the collector has requested the aggregate result for the interval. This doesn't seem all that damaging right now, but who knows.",
              "createdAt": "2021-12-29T22:53:42Z",
              "updatedAt": "2021-12-29T22:53:42Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs4yKpIY",
          "commit": {
            "abbreviatedOid": "c17a911"
          },
          "author": "ekr",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-12-29T22:58:11Z",
          "updatedAt": "2021-12-29T22:58:12Z",
          "comments": [
            {
              "originalPosition": 71,
              "body": "And one reason to provide an error is so clients can debug themselves.",
              "createdAt": "2021-12-29T22:58:12Z",
              "updatedAt": "2021-12-29T22:58:12Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs4yKpOG",
          "commit": {
            "abbreviatedOid": "b7400d6"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-12-29T23:00:01Z",
          "updatedAt": "2021-12-29T23:00:02Z",
          "comments": [
            {
              "originalPosition": 234,
              "body": "@martinthomson AFAICT a disagreement only results in needlessly dropping reports, I don't see how it can result in a replay (i.e., privacy violation). I'm probably missing something though.",
              "createdAt": "2021-12-29T23:00:02Z",
              "updatedAt": "2021-12-29T23:13:10Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs4yKpSM",
          "commit": {
            "abbreviatedOid": "c17a911"
          },
          "author": "ekr",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-12-29T23:01:06Z",
          "updatedAt": "2021-12-29T23:01:06Z",
          "comments": [
            {
              "originalPosition": 234,
              "body": "I'm not sure what you mean by \"perfect sync\". NTP is capable of providing 10ms error. Given that these timestamps are in seconds, this seems fine. I don't see a real problem here.",
              "createdAt": "2021-12-29T23:01:06Z",
              "updatedAt": "2021-12-29T23:01:06Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs4yKpVM",
          "commit": {
            "abbreviatedOid": "b7400d6"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-12-29T23:01:58Z",
          "updatedAt": "2021-12-29T23:01:58Z",
          "comments": [
            {
              "originalPosition": 75,
              "body": "Great point, I will just axe this.\r\n\r\nThe broader point is that we've uncovered a number of potential \"batch faults\", all of which fall more or less into the umbrella of privacy leaks that DP aims to mitigate. To be clear, I don't think we should *require* DP to be used in the core PPM protocol, but I thought it might be worth noting the connection for later on when we really think through how to incorporate DP.",
              "createdAt": "2021-12-29T23:01:58Z",
              "updatedAt": "2021-12-29T23:01:58Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs4yKpVu",
          "commit": {
            "abbreviatedOid": "c17a911"
          },
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "state": "CHANGES_REQUESTED",
          "body": "",
          "createdAt": "2021-12-29T23:02:09Z",
          "updatedAt": "2021-12-29T23:06:24Z",
          "comments": [
            {
              "originalPosition": 125,
              "body": "```suggestion\r\ninterval for which it has received at least one output-share request from the\r\n```",
              "createdAt": "2021-12-29T23:02:09Z",
              "updatedAt": "2021-12-29T23:06:24Z"
            },
            {
              "originalPosition": 202,
              "body": "Is there perhaps a change here you forgot to push here? This text is unchanged since I reviewed. I think at least we should change \"processed\" to \"aggregated\".",
              "createdAt": "2021-12-29T23:06:20Z",
              "updatedAt": "2021-12-29T23:06:24Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs4yKpnR",
          "commit": {
            "abbreviatedOid": "52926db"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-12-29T23:07:51Z",
          "updatedAt": "2021-12-29T23:07:59Z",
          "comments": [
            {
              "originalPosition": 238,
              "body": "Shouldn't be too bad, but you do have to negotiate `t_min, t_max` that works for all of the helpers. You have to make sure that whatever `t_min` you pick is newer than than the oldest value that is tolerated by any aggregator. (Similarly for `t_max`, you'd have to pick it so that it's older than the newest value tolerated by any aggregator.)",
              "createdAt": "2021-12-29T23:07:51Z",
              "updatedAt": "2021-12-29T23:07:59Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs4yKprV",
          "commit": {
            "abbreviatedOid": "52926db"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-12-29T23:08:53Z",
          "updatedAt": "2021-12-29T23:08:53Z",
          "comments": [
            {
              "originalPosition": 71,
              "body": "The bug in this case is clockskew, right? ",
              "createdAt": "2021-12-29T23:08:53Z",
              "updatedAt": "2021-12-29T23:08:53Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs4yKpyc",
          "commit": {
            "abbreviatedOid": "ec6274a"
          },
          "author": "ekr",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-12-29T23:11:20Z",
          "updatedAt": "2021-12-29T23:11:20Z",
          "comments": [
            {
              "originalPosition": 71,
              "body": "Or any number of other things that cause the clock to be wrong.",
              "createdAt": "2021-12-29T23:11:20Z",
              "updatedAt": "2021-12-29T23:11:20Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs4yKp1l",
          "commit": {
            "abbreviatedOid": "8c82034"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-12-29T23:12:26Z",
          "updatedAt": "2021-12-29T23:12:26Z",
          "comments": [
            {
              "originalPosition": 202,
              "body": "Woops, totally missed this. I thought this was about something else. s/processed/aggregated/g is the right change here.",
              "createdAt": "2021-12-29T23:12:26Z",
              "updatedAt": "2021-12-29T23:12:26Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs4yKqQX",
          "commit": {
            "abbreviatedOid": "8c82034"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-12-29T23:21:40Z",
          "updatedAt": "2021-12-29T23:21:40Z",
          "comments": [
            {
              "originalPosition": 124,
              "body": "> You should include all the anti-replay text in the one place. I read the previous piece and guessed that only the leader looks at timestamps. But that isn't it.\r\n\r\nAgreed. I tried but couldn't figure out how to do so without a more major refactor. One idea I had was to change the {{anti-replay}} section to speak more generally about \"batch faults\", i.e., instances where a report was included or excluded from a batch in a way that leaked more information about the measurement than I intended.\r\n\r\nWhat I did instead was note above that the helper enforces the same thing.\r\n\r\nNote that this text gets de-duplicated in https://github.com/abetterinternet/ppm-specification/pull/174.\r\n\r\n> Note also s/timestamp/nonce or \"nonce contains a timestamp that\"\r\n\r\nDone.",
              "createdAt": "2021-12-29T23:21:40Z",
              "updatedAt": "2021-12-29T23:21:40Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs4yKq4G",
          "commit": {
            "abbreviatedOid": "57ffdc3"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2021-12-29T23:37:30Z",
          "updatedAt": "2021-12-29T23:37:30Z",
          "comments": [
            {
              "originalPosition": 71,
              "body": "In any case, the benefit seems marginal to me. But I don't feel that strongly about it. I'd go for permitting an error here if you'd prefer that, but I don't think we should require it.",
              "createdAt": "2021-12-29T23:37:30Z",
              "updatedAt": "2021-12-29T23:38:12Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs4yPkHu",
          "commit": {
            "abbreviatedOid": "82fc2c7"
          },
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "A few editorial nits but this LGTM.",
          "createdAt": "2022-01-03T18:14:27Z",
          "updatedAt": "2022-01-03T18:29:26Z",
          "comments": [
            {
              "originalPosition": 35,
              "body": "nit: since the `Nonce` type appears in a few places, I think the discussion of its `time` and `rand` members should be moved to the definition of `struct Nonce`, around line 417.",
              "createdAt": "2022-01-03T18:14:27Z",
              "updatedAt": "2022-01-03T18:29:26Z"
            },
            {
              "originalPosition": 73,
              "body": "nit: this adjective suggests that we have some kind of classification of privacy violations.\r\n```suggestion\r\nthe previous aggregate result may result in a privacy violation.\r\n```",
              "createdAt": "2022-01-03T18:17:23Z",
              "updatedAt": "2022-01-03T18:29:26Z"
            },
            {
              "originalPosition": 111,
              "body": "I find this confusing because the leader should be applying the anti-replay logic at the time of receiving uploads. By the time it gets to constructing an `AggregateReq`, it should already have discarded any reports with duplicate nonces by this point. It's also confusing to state that the leader should \"preprocess the set of reports carried by the AggregateReq\" because the leader constructs the `AggregateReq`.",
              "createdAt": "2022-01-03T18:19:43Z",
              "updatedAt": "2022-01-03T18:29:26Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs4yPxjU",
          "commit": {
            "abbreviatedOid": "7f3b319"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2022-01-03T19:46:09Z",
          "updatedAt": "2022-01-03T19:46:20Z",
          "comments": [
            {
              "originalPosition": 111,
              "body": "Addressed the latter request. For the former, an implementation of the leader might opt to wait to filter reports until it's ready to begin the aggregation flow. This makes sense if it wants to limit the amount of work it has to do for each upload request, where latency matters a lot more.",
              "createdAt": "2022-01-03T19:46:09Z",
              "updatedAt": "2022-01-03T19:46:20Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs4y2Qhh",
          "commit": {
            "abbreviatedOid": "0406fa0"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "_Really sorry_ for the delay here. This LGTM. I think we need to address #141 next.",
          "createdAt": "2022-01-14T15:59:00Z",
          "updatedAt": "2022-01-14T16:13:56Z",
          "comments": [
            {
              "originalPosition": 73,
              "body": "```suggestion\r\n(Note that the helpers enforce this as well; see {{aggregate-request}}.)\r\nThe leader responds to ignored requests with status 400 and an error of\r\ntype 'staleReport'.\r\n```",
              "createdAt": "2022-01-14T15:59:00Z",
              "updatedAt": "2022-01-14T16:13:56Z"
            },
            {
              "originalPosition": 123,
              "body": "```suggestion\r\noutput-share request from the leader. (See {{output-share-request}}.)\r\nThis means leaders cannot interleave a sequence of aggregate and \r\noutput-share requests for a single batch.\r\n```\r\n\r\nWe should probably add guidance for the leader here as to _when_ they should issue their output-share request. If they do it as soon as the minimum batch count is hit, then nothing else in the batch can be aggregated. (We can do this in a followup PR, I think.)",
              "createdAt": "2022-01-14T16:07:59Z",
              "updatedAt": "2022-01-14T16:13:56Z"
            },
            {
              "originalPosition": 171,
              "body": "```suggestion\r\nleader SHOULD NOT accept reports whose timestamps are too far in the future.\r\n```\r\n\r\nI don't see how we can enforce a MUST without a specific definition of \"too far in the future.\"",
              "createdAt": "2022-01-14T16:08:40Z",
              "updatedAt": "2022-01-14T16:13:56Z"
            },
            {
              "originalPosition": 234,
              "body": "I agree with @martinthomson here -- it's best if we can simply avoid skew altogether, and that seems doable with the agreed upon min/max limits.",
              "createdAt": "2022-01-14T16:12:07Z",
              "updatedAt": "2022-01-14T16:13:56Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs4y2VCq",
          "commit": {
            "abbreviatedOid": "0406fa0"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2022-01-14T16:14:15Z",
          "updatedAt": "2022-01-14T16:14:15Z",
          "comments": [
            {
              "originalPosition": 73,
              "body": "(And we would need to add this new error, if this suggestion lands.)",
              "createdAt": "2022-01-14T16:14:15Z",
              "updatedAt": "2022-01-14T16:14:15Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs4y3j5C",
          "commit": {
            "abbreviatedOid": "0406fa0"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2022-01-14T22:15:09Z",
          "updatedAt": "2022-01-14T22:23:18Z",
          "comments": [
            {
              "originalPosition": 234,
              "body": "I'm not convinced is as easy as that. Would you be OK with merging without a change and moving the discussion to an issue? (As I proposed above.)",
              "createdAt": "2022-01-14T22:15:09Z",
              "updatedAt": "2022-01-14T22:23:18Z"
            },
            {
              "originalPosition": 171,
              "body": "I agree, but the spec currently says MUST here, so this isn't something that's changed in this PR. Can we resolve this by leaving an OPEN ISSUE here?",
              "createdAt": "2022-01-14T22:16:31Z",
              "updatedAt": "2022-01-14T22:23:19Z"
            },
            {
              "originalPosition": 73,
              "body": "This is a duplicate of @ekr's point here: https://github.com/abetterinternet/ppm-specification/pull/169#discussion_r776503058. ",
              "createdAt": "2022-01-14T22:22:35Z",
              "updatedAt": "2022-01-14T22:23:19Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs4y3nwt",
          "commit": {
            "abbreviatedOid": "9a0f719"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2022-01-14T22:44:22Z",
          "updatedAt": "2022-01-14T22:44:22Z",
          "comments": [
            {
              "originalPosition": 171,
              "body": "Why not just make the change here? It's obviously related to this PR.",
              "createdAt": "2022-01-14T22:44:22Z",
              "updatedAt": "2022-01-14T22:44:22Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs4y3n2S",
          "commit": {
            "abbreviatedOid": "9a0f719"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2022-01-14T22:45:13Z",
          "updatedAt": "2022-01-14T22:45:13Z",
          "comments": [
            {
              "originalPosition": 73,
              "body": "I agree, and I think we need to be clear with the protocol interaction here. I am not supportive of \"ignore behavior is left unspecified.\"",
              "createdAt": "2022-01-14T22:45:13Z",
              "updatedAt": "2022-01-14T22:45:13Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs4y3oIo",
          "commit": {
            "abbreviatedOid": "9a0f719"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2022-01-14T22:47:43Z",
          "updatedAt": "2022-01-14T22:47:43Z",
          "comments": [
            {
              "originalPosition": 171,
              "body": "People often ask to keep spec PRs minimal, but I don't think anyone will object so I'll just change this. Done.",
              "createdAt": "2022-01-14T22:47:43Z",
              "updatedAt": "2022-01-14T22:47:43Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs4y3oKs",
          "commit": {
            "abbreviatedOid": "9a0f719"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2022-01-14T22:48:03Z",
          "updatedAt": "2022-01-14T22:48:03Z",
          "comments": [
            {
              "originalPosition": 71,
              "body": "I see no reason to just let this behavior go unspecified. What if some leaders reply with 200 OK and some reply with an error in this case? At the end of the day, the report upload was unsuccessful, and the signal sent back to the client should not be 200 OK.",
              "createdAt": "2022-01-14T22:48:03Z",
              "updatedAt": "2022-01-14T22:48:03Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs4y3oTQ",
          "commit": {
            "abbreviatedOid": "9a0f719"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2022-01-14T22:49:14Z",
          "updatedAt": "2022-01-14T22:49:14Z",
          "comments": [
            {
              "originalPosition": 234,
              "body": "I don't really see how it would be complicated. This is the same as aggregators agreeing on batch interval boundaries, no? In any case, yes, I'm fine merging while this is an OPEN ISSUE.",
              "createdAt": "2022-01-14T22:49:14Z",
              "updatedAt": "2022-01-14T22:49:35Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs4y3olz",
          "commit": {
            "abbreviatedOid": "9a0f719"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2022-01-14T22:51:15Z",
          "updatedAt": "2022-01-14T22:51:16Z",
          "comments": [
            {
              "originalPosition": 73,
              "body": "I'm going to close this thread and quote you in the other thread. That way we don't have two threads on the same topic.",
              "createdAt": "2022-01-14T22:51:15Z",
              "updatedAt": "2022-01-14T22:51:16Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs4y3jE4",
          "commit": {
            "abbreviatedOid": "0406fa0"
          },
          "author": "ekr",
          "authorAssociation": "COLLABORATOR",
          "state": "CHANGES_REQUESTED",
          "body": "OK. I've gone through this again and I'm no more convinced than I was the last time.\r\n\r\nI think the basic structure of the nonce as time + random ID is fine,\r\nbut the actual description of how endpoints are supposed to behave is\r\nnot.\r\n\r\nFirst, as a practical matter, if clocks aren't roughly synced, then we\r\nare going to have some serious problems about out of window\r\nrejection. So, I don't think trying to avoid clock sync is\r\nhelpful. Second, I think we can simply not worry about a small rate of\r\nlossage from data too far in the future. IOW,\r\n\r\nI think this leads to a simpler design in which only the leader needs\r\nto keep buffered state outside of its window.\r\n\r\n1. Aggregators are expected to have accurate, synced clocks.\r\n\r\n2. You can't aggregate an event of time T till T + epsilon. This is\r\n   enforced by the helper, which rejects if it sees it. The leader\r\n   needs to wait till T + epsilon + skew where skew is the allowed\r\n   clock skew.\r\n\r\n3. You can't aggregate the block T1 - T2 after T3 - T4 where T3 > T2.\r\n\r\nThis means that the leader buffers data between the end of the last\r\naggregation block and now() + Buffer where Buffer is configurable, but\r\non the order of the minimum aggregation block window. The helper\r\ndoesn't know Buffer because it will never see anything that's out of\r\nwindow. The helper just needs to know when the last aggregation block\r\nended, the data it is currently working on, and the current time and\r\nreject (with an error) anything out of that window or that is\r\nduplicated.\r\n\r\nThis is a more straightforward design and also detect errors, whereas\r\nthe current design just fails silently.\r\n\r\n\r\nIf we want to allow data to be sent directly to the helper. In that\r\ncase, each aggregator needs to buffer data between the end of the\r\nlast aggregation block and now + Buffer(). This means that there\r\nis some possibility of disagreement on both edges (because of\r\nrace conditions and clock sync). This means that we need a way\r\nfor each side to tell the other that there was an error, and we\r\njust need a \"rejected because too early\" or \"rejected because too late\"\r\nerror, just like for any other error. However, with this much buffer,\r\nthis should occur infrequently. Note that this easily handles the\r\ncase where the helper rejects but if the leader does, it may never\r\nlearn there is something the helper accepted.\r\n",
          "createdAt": "2022-01-14T22:09:17Z",
          "updatedAt": "2022-01-14T23:00:19Z",
          "comments": [
            {
              "originalPosition": 71,
              "body": "This seems like a recipe for silent failure in case of clock skew.",
              "createdAt": "2022-01-14T22:09:17Z",
              "updatedAt": "2022-01-14T22:51:28Z"
            },
            {
              "originalPosition": 122,
              "body": "This also is a recipe for silent error.",
              "createdAt": "2022-01-14T22:10:26Z",
              "updatedAt": "2022-01-14T22:51:28Z"
            },
            {
              "originalPosition": 171,
              "body": "+1",
              "createdAt": "2022-01-14T22:10:38Z",
              "updatedAt": "2022-01-14T22:51:28Z"
            },
            {
              "originalPosition": 234,
              "body": "This seems much more complicated than simply having sync.",
              "createdAt": "2022-01-14T22:12:25Z",
              "updatedAt": "2022-01-14T22:51:28Z"
            },
            {
              "originalPosition": 238,
              "body": "This just seems unspecified.",
              "createdAt": "2022-01-14T22:13:04Z",
              "updatedAt": "2022-01-14T22:51:28Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs4y3pEf",
          "commit": {
            "abbreviatedOid": "9a0f719"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2022-01-14T22:55:30Z",
          "updatedAt": "2022-01-14T22:55:30Z",
          "comments": [
            {
              "originalPosition": 71,
              "body": "@chris-wood supports the idea of having the leader issue an error here. Quote: \r\n> I agree, and I think we need to be clear with the protocol interaction here. I am not supportive of \"ignore behavior is left unspecified.\"\r\n\r\nAs I mentioned above, it may not always be feasible for the leader to check for the error condition on-the-fly. It requires less internal-state coordination to just ingest the report and prune it later. I am fine with a MAY or even a SHOULD here but I don't think it should be a MUST. I'm fine being in the rough, just let me know if you think this absolutely needs to be a MUST and I will change it.",
              "createdAt": "2022-01-14T22:55:30Z",
              "updatedAt": "2022-01-14T22:56:39Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs4y3pUH",
          "commit": {
            "abbreviatedOid": "9a0f719"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2022-01-14T22:57:44Z",
          "updatedAt": "2022-01-14T22:57:44Z",
          "comments": [
            {
              "originalPosition": 71,
              "body": "Sure, I'm operating under the assumption that the leader can detect this immediately upon upload. If the leader defers the check to some point later on, then obviously it can't reply with an error on the fly. A SHOULD seems like it'd work here.",
              "createdAt": "2022-01-14T22:57:44Z",
              "updatedAt": "2022-01-14T22:57:45Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs4y3qGV",
          "commit": {
            "abbreviatedOid": "9950b87"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2022-01-14T23:04:34Z",
          "updatedAt": "2022-01-14T23:04:34Z",
          "comments": [
            {
              "originalPosition": 71,
              "body": "Updated so that the leader SHOULD send an error.",
              "createdAt": "2022-01-14T23:04:34Z",
              "updatedAt": "2022-01-14T23:04:34Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs4y3qUG",
          "commit": {
            "abbreviatedOid": "9950b87"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2022-01-14T23:06:23Z",
          "updatedAt": "2022-01-14T23:06:24Z",
          "comments": [
            {
              "originalPosition": 71,
              "body": "Added text saying the leader SHOULD reply with an error. As I noted in a previous thread, it may not be feasible for the leader to decide if the batch interval has been collected. It's much simpler if all the server has to do is ingest the report at this step and wait to prune it when it's ready to start aggregating.",
              "createdAt": "2022-01-14T23:06:24Z",
              "updatedAt": "2022-01-14T23:06:24Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs4y3sHX",
          "commit": {
            "abbreviatedOid": "9950b87"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2022-01-14T23:25:56Z",
          "updatedAt": "2022-01-14T23:25:56Z",
          "comments": [
            {
              "originalPosition": 122,
              "body": "Yeah I think you're right that failing silently here is a bad idea. There are other ways in which the helper might fail for a given report, and all of these should be handled by relaying an error back to the leader. I have an idea for how to address this in a way that handles all such errors in a uniform manner (see #179 if you're curious), but it would be hard to specify very concretely given the state the document is in. I've updated the text to make sure the helper sends an error here. It's a bit awkward, but it'll do the job for now.",
              "createdAt": "2022-01-14T23:25:56Z",
              "updatedAt": "2022-01-14T23:25:56Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs4y3sj-",
          "commit": {
            "abbreviatedOid": "0f20c7a"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2022-01-14T23:31:12Z",
          "updatedAt": "2022-01-14T23:31:12Z",
          "comments": [
            {
              "originalPosition": 122,
              "body": "Totally agree here. I've added some text saying that the helper MUST reply with an error in this case rather than its next VDAF message. The text is a bit awkward, but I think it's hard to do much better in the current state of the document. In fact, there are a number of errors that might happen between now and when the helper is ready to reply. In #179 I've tried to solve this problem in a more generic way.",
              "createdAt": "2022-01-14T23:31:12Z",
              "updatedAt": "2022-01-14T23:31:13Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs4y3wBl",
          "commit": {
            "abbreviatedOid": "3f61b0a"
          },
          "author": "ekr",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "LGTM but can you put in an open issue marker for #180. Just like one line should be fine.",
          "createdAt": "2022-01-15T00:16:41Z",
          "updatedAt": "2022-01-15T00:16:41Z",
          "comments": []
        }
      ]
    },
    {
      "number": 170,
      "id": "PR_kwDOFEJYQs4vn3bS",
      "title": "Simplify overview text about the aggregation function",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/pull/170",
      "state": "MERGED",
      "author": "cjpatton",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "",
      "createdAt": "2021-12-09T16:14:05Z",
      "updatedAt": "2021-12-29T17:45:41Z",
      "baseRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "baseRefName": "main",
      "baseRefOid": "93032f7f3e1ed8cd1d785e68598d680a344c9813",
      "headRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "headRefName": "cjpatton/vdaf-unspecified-nits",
      "headRefOid": "6c17491f8a165cf60f3652c72904ffd2613e21df",
      "closedAt": "2021-12-09T16:32:29Z",
      "mergedAt": "2021-12-09T16:32:29Z",
      "mergedBy": "ekr",
      "mergeCommit": {
        "oid": "09f78f242bc708fbc0005c242f9e226058267375"
      },
      "comments": [],
      "reviews": [
        {
          "id": "PRR_kwDOFEJYQs4xWRpT",
          "commit": {
            "abbreviatedOid": "6c17491"
          },
          "author": "ekr",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "LGTM",
          "createdAt": "2021-12-09T16:32:25Z",
          "updatedAt": "2021-12-09T16:32:25Z",
          "comments": []
        }
      ]
    },
    {
      "number": 171,
      "id": "PR_kwDOFEJYQs4vxPY0",
      "title": "Reformat charter.md and ignore more files",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/pull/171",
      "state": "MERGED",
      "author": "cjpatton",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "No changes to the text (modulo one spelling correction).",
      "createdAt": "2021-12-13T16:17:51Z",
      "updatedAt": "2021-12-29T17:45:34Z",
      "baseRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "baseRefName": "main",
      "baseRefOid": "09f78f242bc708fbc0005c242f9e226058267375",
      "headRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "headRefName": "cjpatton/charter-edit",
      "headRefOid": "782d21baaef6026d1298584c916445c18f9930da",
      "closedAt": "2021-12-13T16:22:41Z",
      "mergedAt": "2021-12-13T16:22:41Z",
      "mergedBy": "cjpatton",
      "mergeCommit": {
        "oid": "b497a64adbebb70581832e13e438a9c30dcb63b8"
      },
      "comments": [],
      "reviews": [
        {
          "id": "PRR_kwDOFEJYQs4xf9pj",
          "commit": {
            "abbreviatedOid": "782d21b"
          },
          "author": "ekr",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "LGTM",
          "createdAt": "2021-12-13T16:22:10Z",
          "updatedAt": "2021-12-13T16:22:10Z",
          "comments": []
        }
      ]
    },
    {
      "number": 172,
      "id": "PR_kwDOFEJYQs4wBi-T",
      "title": "Final edits for Roman",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/pull/172",
      "state": "MERGED",
      "author": "ekr",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "PRIV -> PPM\r\nAdd abuse cases language",
      "createdAt": "2021-12-17T22:27:50Z",
      "updatedAt": "2021-12-17T22:35:39Z",
      "baseRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "baseRefName": "main",
      "baseRefOid": "b497a64adbebb70581832e13e438a9c30dcb63b8",
      "headRepository": "ekr/ppm-specification",
      "headRefName": "charter_final",
      "headRefOid": "e1e9cebd2515b4a678d5273de818eea61193534d",
      "closedAt": "2021-12-17T22:35:38Z",
      "mergedAt": "2021-12-17T22:35:38Z",
      "mergedBy": "ekr",
      "mergeCommit": {
        "oid": "4b45f71a6c631db33d23ae21ceb6fcbb9a8a2536"
      },
      "comments": [],
      "reviews": [
        {
          "id": "PRR_kwDOFEJYQs4xz4QS",
          "commit": {
            "abbreviatedOid": "e1e9ceb"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "",
          "createdAt": "2021-12-17T22:32:03Z",
          "updatedAt": "2021-12-17T22:32:03Z",
          "comments": []
        }
      ]
    },
    {
      "number": 174,
      "id": "PR_kwDOFEJYQs4wYWzU",
      "title": "Have clients upload report shares to helpers",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/pull/174",
      "state": "OPEN",
      "author": "cjpatton",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "Closes #130 (cc/ @hostirosti).\r\nAddresses a bug pointed out in https://github.com/abetterinternet/ppm-specification/issues/183#issuecomment-1016975853 (cc/ @ekr).\r\n\r\nTaking #169 effectively increases the storage requirements for the helper to `O(n)`, where `n` is the number of reports. This PR would increase storage requirements for the helper by a constant factor, but would reduce the leader <-> helper communication overhead by the same factor.\r\n\r\n2022-05-06: Moved back to draft. There is not yet consensus on this change.\r\n2022-01-24: Moved from draft to review. The consensus reached on [this thread](https://mailarchive.ietf.org/arch/msg/ppm/sCJ1oKR0KMHlZ65FCPUbw3FrGxY/) seems to be to take this change.\r\n2021-12-29: This PR is currently marked as \"Draft\" because I don't yet intend for it to be merged. Rather the goal of this PR is to make the discussion about this trade-off more concrete.",
      "createdAt": "2021-12-29T21:56:16Z",
      "updatedAt": "2022-05-11T14:29:47Z",
      "baseRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "baseRefName": "main",
      "baseRefOid": "557b887eb02c641608e9e5eaab34615744fc0c57",
      "headRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "headRefName": "cjpatton/split-upload",
      "headRefOid": "18baafb6dfcd7fdd4f3da9b4a234a58797320ee9",
      "closedAt": null,
      "mergedAt": null,
      "mergedBy": null,
      "mergeCommit": null,
      "comments": [],
      "reviews": [
        {
          "id": "PRR_kwDOFEJYQs4zV4L2",
          "commit": {
            "abbreviatedOid": "458bf8d"
          },
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2022-01-24T18:39:12Z",
          "updatedAt": "2022-01-24T19:18:56Z",
          "comments": [
            {
              "originalPosition": 33,
              "body": "Seems like this should replace the diagram on line 232.",
              "createdAt": "2022-01-24T18:39:12Z",
              "updatedAt": "2022-01-24T19:18:56Z"
            },
            {
              "originalPosition": 46,
              "body": "```suggestion\r\n   phase of the protocol as requested by the collector.\r\n```",
              "createdAt": "2022-01-24T18:39:28Z",
              "updatedAt": "2022-01-24T19:18:56Z"
            },
            {
              "originalPosition": 61,
              "body": "```suggestion\r\nreport shares are handled by an intermediary, that intermediary cannot recover\r\n```",
              "createdAt": "2022-01-24T18:39:50Z",
              "updatedAt": "2022-01-24T19:18:56Z"
            },
            {
              "originalPosition": 69,
              "body": "nit: not particularly clear what \"them\" refers to\r\n```suggestion\r\nThe leader orchestrates the process of verifying reports (see\r\n```",
              "createdAt": "2022-01-24T18:40:51Z",
              "updatedAt": "2022-01-24T19:18:56Z"
            },
            {
              "originalPosition": 73,
              "body": "nit: It seems like what matters isn't having all the reports in a batch in hand but rather receiving the aggregation parameter from the collector. Is it possible to define a VDAF where verification of an individual report depends on other reports?",
              "createdAt": "2022-01-24T18:42:37Z",
              "updatedAt": "2022-01-24T19:18:56Z"
            },
            {
              "originalPosition": 119,
              "body": "```suggestion\r\nClients periodically upload report shares to the aggregators. This involves two\r\nHTTP requests, one to retrieve the aggregator's HPKE configuration and\r\nanother to upload its report share.\r\n```",
              "createdAt": "2022-01-24T18:44:10Z",
              "updatedAt": "2022-01-24T19:18:56Z"
            },
            {
              "originalPosition": 129,
              "body": "```suggestion\r\nBefore the client can upload a report share to an aggregator, it must first\r\nobtain the aggregator's public key. This is retrieved by sending a request to\r\n```",
              "createdAt": "2022-01-24T18:44:40Z",
              "updatedAt": "2022-01-24T19:18:56Z"
            },
            {
              "originalPosition": 143,
              "body": "```suggestion\r\nReport shares are usually uploaded by clients directly, but MAY instead be\r\n```",
              "createdAt": "2022-01-24T18:45:09Z",
              "updatedAt": "2022-01-24T19:18:56Z"
            },
            {
              "originalPosition": 145,
              "body": "Do we have an issue for defining an upload message with multiple reports in it, to allow intermediaries to efficiently submit many reports at once? I think we should do that independently from this change, though.",
              "createdAt": "2022-01-24T18:47:24Z",
              "updatedAt": "2022-01-24T19:18:56Z"
            },
            {
              "originalPosition": 145,
              "body": "I'm not sure \"on behalf of the collector\" is helpful here. I think what you have in mind is a case where the intermediary and the collector are the same real world entity, but I can imagine deployments where an intermediary is used for reasons having nothing to do with the collector.",
              "createdAt": "2022-01-24T18:49:39Z",
              "updatedAt": "2022-01-24T19:18:56Z"
            },
            {
              "originalPosition": 170,
              "body": "```suggestion\r\n  {{anti-replay}}.) Each share of a report MUST have the same nonce.\r\n```",
              "createdAt": "2022-01-24T18:51:00Z",
              "updatedAt": "2022-01-24T19:18:56Z"
            },
            {
              "originalPosition": 227,
              "body": "```suggestion\r\nTo prevent reports from being misused, the aggregators filter out replayed or\r\n```",
              "createdAt": "2022-01-24T18:54:11Z",
              "updatedAt": "2022-01-24T19:18:56Z"
            },
            {
              "originalPosition": 233,
              "body": "The reason we had upload extensions in the first place was so that they could be tunnelled through the leader into the helper. Now that we do direct uploads, can we remove these? The obvious remaining use case is tunnelling extensions through a client proxy/intermediary/batching client, but if deployments use OHTTP as we recommend, then PPM shouldn't need to specify anything as things like HTTP request headers will get securely relayed.",
              "createdAt": "2022-01-24T19:00:04Z",
              "updatedAt": "2022-01-24T19:18:56Z"
            },
            {
              "originalPosition": 278,
              "body": "Now that the helper is responsible for its own nonce, report and aggregate accumulator storage, do we need aggregate requests to not span batch intervals anymore? I'm not sure but I think the reason we had this constraint on aggregate requests was so that the state blob could be \"sharded\" by batch interval and allow parallelism in the helper. Now, though, we might expect the helper to have its own storage where it keeps track of aggregate accumulators for several different batch intervals.",
              "createdAt": "2022-01-24T19:06:27Z",
              "updatedAt": "2022-01-24T19:18:56Z"
            },
            {
              "originalPosition": 341,
              "body": "```suggestion\r\nsub-response rather than its next VDAF message.\r\n```\r\nTo make it clear that filtering out an individual report does not fail the overall aggregate transaction.",
              "createdAt": "2022-01-24T19:08:33Z",
              "updatedAt": "2022-01-24T19:18:56Z"
            },
            {
              "originalPosition": 389,
              "body": "nit: \"extracting its aggregate share from its state\" implies the helper will have an aggregate share ready to go in its state, which won't be true for `poplar1`. We could just say \"The helper responds to this request with its aggregate share, encrypted under the collector's HPKE public key.\"",
              "createdAt": "2022-01-24T19:10:30Z",
              "updatedAt": "2022-01-24T19:18:56Z"
            },
            {
              "originalPosition": 418,
              "body": "```suggestion\r\nerror for the leader to issue any more aggregate requests for reports in the\r\n```",
              "createdAt": "2022-01-24T19:11:06Z",
              "updatedAt": "2022-01-24T19:18:56Z"
            },
            {
              "originalPosition": 420,
              "body": "It's an error for the leader to issue more than `max_batch_lifetime` requests for a given batch interval, right? As written this states the leader can issue exactly one request.",
              "createdAt": "2022-01-24T19:12:14Z",
              "updatedAt": "2022-01-24T19:18:56Z"
            },
            {
              "originalPosition": 463,
              "body": "```suggestion\r\n  been collected, then the aggregator MUST ignore it. This prevents additional\r\n  reports from being aggregated after their batch has already been collected.\r\n```",
              "createdAt": "2022-01-24T19:13:18Z",
              "updatedAt": "2022-01-24T19:18:56Z"
            },
            {
              "originalPosition": 467,
              "body": "I think but am not certain that this needs to reference the task's `max_batch_lifetime` rather than allowing exactly once, because successive collector queries will change the aggregation parameter (e.g., different prefixes in `poplar1`).",
              "createdAt": "2022-01-24T19:15:48Z",
              "updatedAt": "2022-01-24T19:18:56Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs4zXQaR",
          "commit": {
            "abbreviatedOid": "6109832"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2022-01-25T02:58:23Z",
          "updatedAt": "2022-01-25T04:33:37Z",
          "comments": [
            {
              "originalPosition": 33,
              "body": "That's the intent, but they show slightly different things so I thought it should be discussed. Would you prefer this diagram or something like the one above?",
              "createdAt": "2022-01-25T02:58:23Z",
              "updatedAt": "2022-01-25T04:33:37Z"
            },
            {
              "originalPosition": 73,
              "body": "No that's not possible. Yeah, it's the aggregation parameter that matters, but here (in the overview) we have so far avoided talking about the aggregation parameter.\r\n\r\nNote that this change isn't new to this PR.",
              "createdAt": "2022-01-25T04:20:37Z",
              "updatedAt": "2022-01-25T04:33:37Z"
            },
            {
              "originalPosition": 145,
              "body": "IMO this is out-of-scope. The way we should try to spell this PR is to allow either clients to upload report shares directly or allow report shares to be uploaded by an intermediary. How the report shares get to the intermediary isn't relevant for us.",
              "createdAt": "2022-01-25T04:22:23Z",
              "updatedAt": "2022-01-25T04:33:37Z"
            },
            {
              "originalPosition": 145,
              "body": "Good point, that's just one possible case. I dropped \"on behalf of the collector\".",
              "createdAt": "2022-01-25T04:23:26Z",
              "updatedAt": "2022-01-25T04:33:38Z"
            },
            {
              "originalPosition": 233,
              "body": "#89 will likely make use of upload extensions, hence we'll need to keep them around.",
              "createdAt": "2022-01-25T04:25:59Z",
              "updatedAt": "2022-01-25T04:33:38Z"
            },
            {
              "originalPosition": 278,
              "body": "Yeah, it may not be strictly necessary. However I think we should keep this as-is for now in order to keep this PR minimal. Plus, it may be helpful for something we're not seeing right now.",
              "createdAt": "2022-01-25T04:27:15Z",
              "updatedAt": "2022-01-25T04:33:38Z"
            },
            {
              "originalPosition": 389,
              "body": "Actually at this point it will have computed an aggregate share. However I took your suggestion because your text is a lot clearer.",
              "createdAt": "2022-01-25T04:29:22Z",
              "updatedAt": "2022-01-25T04:33:38Z"
            },
            {
              "originalPosition": 467,
              "body": "I don't think want to change the batch after it has been collected with *any* aggregation parameter. Imagine, for example, that the collector requests the aggregate for candidate prefixes [\"ab\"]. Then add another measurement and re-run with candidate prefixes [\"abc\"]. Then I know immediately whether the additional measurement was prefixed by \"abc\".",
              "createdAt": "2022-01-25T04:33:21Z",
              "updatedAt": "2022-01-25T04:33:38Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs4zbFi2",
          "commit": {
            "abbreviatedOid": "2634b20"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "Thanks, @cjpatton! I have a couple questions and comments. The biggest unknown for me is the new set of report processing requirements, but I think we can work through that.",
          "createdAt": "2022-01-25T19:04:12Z",
          "updatedAt": "2022-01-25T19:34:33Z",
          "comments": [
            {
              "originalPosition": 33,
              "body": "Agree with Tim here -- I'm not seeing the value of keeping both.",
              "createdAt": "2022-01-25T19:04:12Z",
              "updatedAt": "2022-01-25T19:34:33Z"
            },
            {
              "originalPosition": 107,
              "body": "Is this requirement necessary anymore? It seems like the client doesn't need to care which aggregator is the leader if both are treated as separate aggregators to store shares.",
              "createdAt": "2022-01-25T19:06:11Z",
              "updatedAt": "2022-01-25T19:34:33Z"
            },
            {
              "originalPosition": 129,
              "body": "```suggestion\r\nBefore the client can upload a report share to an aggregator, it first fetches\r\nthe aggregator's public key. This is done by sending a request to\r\n```",
              "createdAt": "2022-01-25T19:11:21Z",
              "updatedAt": "2022-01-25T19:34:33Z"
            },
            {
              "originalPosition": 233,
              "body": "We may also need general extensibility outside of new VDAFs in the future -- a lesson learned from TLS. ",
              "createdAt": "2022-01-25T19:13:30Z",
              "updatedAt": "2022-01-25T19:34:33Z"
            },
            {
              "originalPosition": 145,
              "body": "This seems to preclude sending both reports to the same endpoint, even though they're encrypted under separate aggregator public keys. We could address this by allowing the task configuration to specify the upload endpoint(s) _separately_ from the aggregation endpoints. Would that work?",
              "createdAt": "2022-01-25T19:21:13Z",
              "updatedAt": "2022-01-25T19:34:33Z"
            },
            {
              "originalPosition": 278,
              "body": "Agreed. Let's note this and revisit in a followup change. (Good catch, Tim!)",
              "createdAt": "2022-01-25T19:23:23Z",
              "updatedAt": "2022-01-25T19:34:33Z"
            },
            {
              "originalPosition": 318,
              "body": "Hmm, now that the nonce<>client uniqueness is no longer enforced by a single party, what happens if, say, two benign clients happen to generate colliding nonce values, and each aggregator picks a different one while filtering for anti-replay? We could maybe increase the width of the nonce random value to hedge against this collision, but it's not clear to me that's sufficient. ",
              "createdAt": "2022-01-25T19:28:47Z",
              "updatedAt": "2022-01-25T19:34:33Z"
            },
            {
              "originalPosition": 470,
              "body": "This new requirement is pretty subtle to me. Can we drop an open issue here to further investigate if this is indeed the correct thing to do?",
              "createdAt": "2022-01-25T19:33:37Z",
              "updatedAt": "2022-01-25T19:34:33Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs4zb4IY",
          "commit": {
            "abbreviatedOid": "b5ba4d0"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2022-01-25T22:42:39Z",
          "updatedAt": "2022-01-25T22:42:39Z",
          "comments": [
            {
              "originalPosition": 420,
              "body": "Duplicate of https://github.com/abetterinternet/ppm-specification/pull/174#discussion_r791074329?",
              "createdAt": "2022-01-25T22:42:39Z",
              "updatedAt": "2022-01-25T22:42:39Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs4zb57S",
          "commit": {
            "abbreviatedOid": "18baafb"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2022-01-25T22:48:17Z",
          "updatedAt": "2022-01-25T23:17:47Z",
          "comments": [
            {
              "originalPosition": 107,
              "body": "Fair point, although depending on the VDAF, the leader may need to know if it's a leader or a helper. This is true of prio3 and poplar1, for instance. In both of these schemes there are big, \"uncompressed\" shares that are sent to the leader. The helpers only get short, \"compressed\" shares.\r\n\r\nThere must be a better way to spell this requirement.",
              "createdAt": "2022-01-25T22:48:17Z",
              "updatedAt": "2022-01-25T23:17:47Z"
            },
            {
              "originalPosition": 145,
              "body": "If an ingestor is doing the uploading, it still needs to upload to the individual aggregator endpoints. The intention of this PR is that the client's interaction with the ingestor is out-of-scope. Perhaps this isn't clear enough? Or maybe you think this should be in-scope? ",
              "createdAt": "2022-01-25T22:53:41Z",
              "updatedAt": "2022-01-25T23:17:47Z"
            },
            {
              "originalPosition": 318,
              "body": "Oh interesting! To be clear, before #169 we still had both aggregators enforce anti-replay. The difference is that we no longer of single party pick the set of reports that are processed. Nice catch.\r\n\r\nThis basically amounts to an attack on correctness. What will happen for prio3 or poplar1 is that the aggregators will derive different verification randomness, which will cause them to deem the report invalid and reject it (with high probability).\r\n\r\nHowever, where this edge case *would* matter is if a VDAF were used that didn't have any verifiability. (We should probably not get in the habbit of calling such a scheme a VDAF: see https://github.com/cjpatton/vdaf/issues/20.) This was already requested in #45, so it's within the realm of possibility.\r\n\r\nNote that a collision fairly likely, since the nonce only contains 64 random bits. (The remaining bits are a timestamp.) We may consider bumping this to 128 just to be on the safe side.\r\n\r\nHow about addressing this by leaving an OPEN ISSUE in the text? It would reference #45 and we would leave a note there to make sure we keep track of this.\r\n\r\n",
              "createdAt": "2022-01-25T23:16:01Z",
              "updatedAt": "2022-01-25T23:17:47Z"
            },
            {
              "originalPosition": 470,
              "body": "I agree it's subtle. I'd be good with that outcome, although it was already discussed here in a different context: https://github.com/abetterinternet/ppm-specification/issues/183#issuecomment-1016978627.",
              "createdAt": "2022-01-25T23:17:34Z",
              "updatedAt": "2022-01-25T23:17:47Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs4zb_wg",
          "commit": {
            "abbreviatedOid": "18baafb"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2022-01-25T23:24:37Z",
          "updatedAt": "2022-01-25T23:24:38Z",
          "comments": [
            {
              "originalPosition": 470,
              "body": "Let's at least leave an OPEN ISSUE referencing #183, then, since that's still open. (I will review #183 more carefully soon.)",
              "createdAt": "2022-01-25T23:24:38Z",
              "updatedAt": "2022-01-25T23:24:38Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs4zb_96",
          "commit": {
            "abbreviatedOid": "18baafb"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2022-01-25T23:26:09Z",
          "updatedAt": "2022-01-25T23:26:09Z",
          "comments": [
            {
              "originalPosition": 318,
              "body": "That's a fine resolution, yep. Let's also note that this type of collision will cause verification failures with overwhelming probability?",
              "createdAt": "2022-01-25T23:26:09Z",
              "updatedAt": "2022-01-25T23:26:10Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs4zcAQz",
          "commit": {
            "abbreviatedOid": "18baafb"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2022-01-25T23:28:19Z",
          "updatedAt": "2022-01-25T23:28:20Z",
          "comments": [
            {
              "originalPosition": 145,
              "body": "Well, consider the case where there is an ingestor service. Certainly, that ingestor service can't be the _client_ in PPM, since that would require it see inputs and then encrypt them under the aggregator public keys. Rather, the ingestor sees encrypted things that it then relays onward to the aggregator endpoints. What we're specifying here is the client behavior, and I think we need to make sure that we the client can send both its encrypted shares to a single ingestor if needed. Right now that seems prohibited?",
              "createdAt": "2022-01-25T23:28:20Z",
              "updatedAt": "2022-01-25T23:28:20Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs4zcAZB",
          "commit": {
            "abbreviatedOid": "18baafb"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2022-01-25T23:29:20Z",
          "updatedAt": "2022-01-25T23:29:21Z",
          "comments": [
            {
              "originalPosition": 107,
              "body": "Oh, yeah, that was totally not clear to me! How is this expressed in the VDAF draft?",
              "createdAt": "2022-01-25T23:29:20Z",
              "updatedAt": "2022-01-25T23:29:28Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs4zcGX3",
          "commit": {
            "abbreviatedOid": "18baafb"
          },
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2022-01-26T00:17:58Z",
          "updatedAt": "2022-01-26T00:17:58Z",
          "comments": [
            {
              "originalPosition": 73,
              "body": "OK -- there's enough to chew on in this PR that we don't have to wordsmith this right now.",
              "createdAt": "2022-01-26T00:17:58Z",
              "updatedAt": "2022-01-26T00:17:58Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs4zcGiL",
          "commit": {
            "abbreviatedOid": "18baafb"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2022-01-26T00:19:23Z",
          "updatedAt": "2022-01-26T00:19:24Z",
          "comments": [
            {
              "originalPosition": 318,
              "body": "Will do.",
              "createdAt": "2022-01-26T00:19:24Z",
              "updatedAt": "2022-01-26T00:19:24Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs4zcG2-",
          "commit": {
            "abbreviatedOid": "18baafb"
          },
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2022-01-26T00:22:18Z",
          "updatedAt": "2022-01-26T00:22:19Z",
          "comments": [
            {
              "originalPosition": 145,
              "body": "This PR, sure, but I'm not the only person left wondering whether or how intermediates can batch up reports: ekr asked about this on the PPM list. Anyway, I filed #188 so we don't lose track of the idea.",
              "createdAt": "2022-01-26T00:22:19Z",
              "updatedAt": "2022-01-26T00:22:19Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs4zcHt2",
          "commit": {
            "abbreviatedOid": "18baafb"
          },
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2022-01-26T00:30:02Z",
          "updatedAt": "2022-01-26T00:30:03Z",
          "comments": [
            {
              "originalPosition": 233,
              "body": "Well, I don't want to open the can of worms of client attestation in the margins of this PR, but I'm happy to accept TLS as a precedent.",
              "createdAt": "2022-01-26T00:30:03Z",
              "updatedAt": "2022-01-26T00:30:03Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs4zcI_x",
          "commit": {
            "abbreviatedOid": "18baafb"
          },
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2022-01-26T00:42:11Z",
          "updatedAt": "2022-01-26T00:42:11Z",
          "comments": [
            {
              "originalPosition": 467,
              "body": "Then I think there's something I must not be understanding about how `max_batch_lifetime` works, or how PPM is meant to solve t-heavy-hitters, which I thought involved the collector sending a series of collect requests with longer candidate prefixes each time. But that doesn't need to be solved in this PR.",
              "createdAt": "2022-01-26T00:42:11Z",
              "updatedAt": "2022-01-26T00:42:11Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs4zetuV",
          "commit": {
            "abbreviatedOid": "18baafb"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2022-01-26T15:17:06Z",
          "updatedAt": "2022-01-26T15:17:07Z",
          "comments": [
            {
              "originalPosition": 467,
              "body": "You understand correctly how PPM is supposed to solve heavy hitters. All `max_batch_lifetime` is supposed to say is that you can't make any more collect requests than `max_batch_lifetime`. Otherwise it doesn't make any restrictions on the aggregation parameter. In particular, Poplar can be implemented as you describe.\r\n\r\nAll that this line is saying is that you can't change the set of reports in a batch after you've collected it. Otherwise, this could lead to a privacy violation, regardless of the VDAF in use.",
              "createdAt": "2022-01-26T15:17:06Z",
              "updatedAt": "2022-01-26T15:17:07Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs4zeuSC",
          "commit": {
            "abbreviatedOid": "18baafb"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2022-01-26T15:18:44Z",
          "updatedAt": "2022-01-26T15:18:44Z",
          "comments": [
            {
              "originalPosition": 107,
              "body": "It's not explicit in the syntax, but for schemes that needs to differentiate aggregator roles, they can do so via the verification parameter. For example, see https://cjpatton.github.io/vdaf/draft-patton-cfrg-vdaf.html#name-setup-2",
              "createdAt": "2022-01-26T15:18:44Z",
              "updatedAt": "2022-01-26T15:18:44Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs4zevBf",
          "commit": {
            "abbreviatedOid": "18baafb"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2022-01-26T15:20:50Z",
          "updatedAt": "2022-01-26T15:20:50Z",
          "comments": [
            {
              "originalPosition": 145,
              "body": "Ok I see. Then I think this section would need to be clear that it specifies both the behavior of the client generating report shares and the entity (either the client or someone else) that uploads shares to the aggregators. Would you prefer these be different sections perhaps?",
              "createdAt": "2022-01-26T15:20:50Z",
              "updatedAt": "2022-01-26T15:20:50Z"
            }
          ]
        }
      ]
    },
    {
      "number": 175,
      "id": "PR_kwDOFEJYQs4wYddx",
      "title": "nits",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/pull/175",
      "state": "MERGED",
      "author": "cjpatton",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "",
      "createdAt": "2021-12-29T23:51:36Z",
      "updatedAt": "2021-12-30T02:09:23Z",
      "baseRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "baseRefName": "main",
      "baseRefOid": "4b45f71a6c631db33d23ae21ceb6fcbb9a8a2536",
      "headRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "headRefName": "cjpatton/nit",
      "headRefOid": "6884897b8ebc25b5f1a1b6a8e297666c8682b9c9",
      "closedAt": "2021-12-29T23:53:32Z",
      "mergedAt": "2021-12-29T23:53:32Z",
      "mergedBy": "ekr",
      "mergeCommit": {
        "oid": "5b46fbb96828ab4edf6222dca1cfd3e58d2dfab9"
      },
      "comments": [],
      "reviews": [
        {
          "id": "PRR_kwDOFEJYQs4yKrc7",
          "commit": {
            "abbreviatedOid": "6884897"
          },
          "author": "ekr",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "LGTM",
          "createdAt": "2021-12-29T23:53:28Z",
          "updatedAt": "2021-12-29T23:53:28Z",
          "comments": []
        }
      ]
    },
    {
      "number": 177,
      "id": "PR_kwDOFEJYQs4wiBQ9",
      "title": "Rename \"Heavy Hitters\" to \"Poplar\"",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/pull/177",
      "state": "MERGED",
      "author": "cjpatton",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "Closes #176.\r\n\r\nThe corresponding change in the VDAF draft is here: https://github.com/cjpatton/vdaf/pull/16",
      "createdAt": "2022-01-04T21:46:41Z",
      "updatedAt": "2022-01-06T18:48:38Z",
      "baseRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "baseRefName": "main",
      "baseRefOid": "5b46fbb96828ab4edf6222dca1cfd3e58d2dfab9",
      "headRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "headRefName": "cjpatton/issue176",
      "headRefOid": "894cfdda72ef0ba4622f2bff637484793d1091d3",
      "closedAt": "2022-01-06T18:48:37Z",
      "mergedAt": "2022-01-06T18:48:37Z",
      "mergedBy": "cjpatton",
      "mergeCommit": {
        "oid": "50af0f5d48b849ba7aeca1e31b44f55eab6d82f7"
      },
      "comments": [
        {
          "author": "ekr",
          "authorAssociation": "COLLABORATOR",
          "body": "SGTM.\n\nOn Tue, Jan 4, 2022 at 3:33 PM Christopher Patton ***@***.***>\nwrote:\n\n> ***@***.**** commented on this pull request.\n> ------------------------------\n>\n> In draft-gpew-priv-ppm.md\n> <https://github.com/abetterinternet/ppm-specification/pull/177#discussion_r778455672>\n> :\n>\n> > @@ -205,10 +205,11 @@ schemes that implement the VDAF interface specified in\n>    etc. This class of VDAFs is based on Prio [CGB17] and includes improvements\n>    described in [BBCGGI19].\n>\n> -* `hits`, which allows for finding the most common strings among a collection\n> +* `pops`, which allows for finding the most popular strings among a collection\n>\n> I like your thinking @eriktaubeneck <https://github.com/eriktaubeneck>\n> and @csharrison <https://github.com/csharrison> ! I vote for poplar1.\n>\n> \u2014\n> Reply to this email directly, view it on GitHub\n> <https://github.com/abetterinternet/ppm-specification/pull/177#discussion_r778455672>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/AAIPLILIXK7RLQXNMU6LNODUUN7UZANCNFSM5LINY26Q>\n> .\n> Triage notifications on the go with GitHub Mobile for iOS\n> <https://apps.apple.com/app/apple-store/id1477376905?ct=notification-email&mt=8&pt=524675>\n> or Android\n> <https://play.google.com/store/apps/details?id=com.github.android&referrer=utm_campaign%3Dnotification-email%26utm_medium%3Demail%26utm_source%3Dgithub>.\n>\n> You are receiving this because your review was requested.Message ID:\n> ***@***.***>\n>\n",
          "createdAt": "2022-01-04T23:34:37Z",
          "updatedAt": "2022-01-04T23:34:37Z"
        },
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "s/pops/poplar1/ as discussed. @tgeoghegan and @ekr can I get you to approve this?",
          "createdAt": "2022-01-06T18:39:54Z",
          "updatedAt": "2022-01-06T18:39:54Z"
        },
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "s/Hits/Poplar/. Thanks @tgeoghegan !",
          "createdAt": "2022-01-06T18:45:41Z",
          "updatedAt": "2022-01-06T18:45:41Z"
        }
      ],
      "reviews": [
        {
          "id": "PRR_kwDOFEJYQs4yTwrK",
          "commit": {
            "abbreviatedOid": "d95249f"
          },
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "state": "CHANGES_REQUESTED",
          "body": "",
          "createdAt": "2022-01-04T21:54:40Z",
          "updatedAt": "2022-01-04T21:54:44Z",
          "comments": [
            {
              "originalPosition": 5,
              "body": "As @bifurcation noted in https://github.com/cjpatton/vdaf/pull/16, I think `poplar` is nicer.",
              "createdAt": "2022-01-04T21:54:40Z",
              "updatedAt": "2022-01-04T21:54:44Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs4yTxQU",
          "commit": {
            "abbreviatedOid": "d95249f"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2022-01-04T21:58:08Z",
          "updatedAt": "2022-01-04T21:58:08Z",
          "comments": [
            {
              "originalPosition": 5,
              "body": "\"Poplar\" is the name of the full-blown heavy hitters protocol, whereas this name is supposed to refer to the underlying VDAF. I'd like to avoid conflating the two.",
              "createdAt": "2022-01-04T21:58:08Z",
              "updatedAt": "2022-01-04T21:58:22Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs4yTyQI",
          "commit": {
            "abbreviatedOid": "d95249f"
          },
          "author": "ekr",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2022-01-04T22:04:08Z",
          "updatedAt": "2022-01-04T22:04:09Z",
          "comments": [
            {
              "originalPosition": 5,
              "body": "I guess we're just voting now, but I would prefer poplar.",
              "createdAt": "2022-01-04T22:04:09Z",
              "updatedAt": "2022-01-04T22:04:09Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs4yT0ND",
          "commit": {
            "abbreviatedOid": "d95249f"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2022-01-04T22:16:26Z",
          "updatedAt": "2022-01-04T22:16:27Z",
          "comments": [
            {
              "originalPosition": 5,
              "body": "Well then, this just got interesting. I wonder if others have an opinion or ideas for alternatives. I don't care much about the name for the VDAF, my only criterion is that it is distinct from \"Poplar\". A more verbose possibility is `poplar-vdaf`. \r\ncc/ @csharrison @eriktaubeneck @martinthomson @stpeter @bifurcation @BranLwyd ",
              "createdAt": "2022-01-04T22:16:26Z",
              "updatedAt": "2022-01-04T22:16:27Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs4yT7mu",
          "commit": {
            "abbreviatedOid": "d95249f"
          },
          "author": "csharrison",
          "authorAssociation": "CONTRIBUTOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2022-01-04T23:07:10Z",
          "updatedAt": "2022-01-04T23:07:10Z",
          "comments": [
            {
              "originalPosition": 5,
              "body": "You could align with the naming scheme for the Prio VDAF and call it `poplar1` :) Other than that I don't have a strong opinion.",
              "createdAt": "2022-01-04T23:07:10Z",
              "updatedAt": "2022-01-04T23:07:10Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs4yT-aM",
          "commit": {
            "abbreviatedOid": "d95249f"
          },
          "author": "eriktaubeneck",
          "authorAssociation": "NONE",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2022-01-04T23:30:53Z",
          "updatedAt": "2022-01-04T23:30:53Z",
          "comments": [
            {
              "originalPosition": 5,
              "body": "Keeping it consistent with the naming scheme for Prio seems positive, and a version number doesn't seem like a terrible addition as it seems likely the VDAF may evolve like the prio VDAF did.",
              "createdAt": "2022-01-04T23:30:53Z",
              "updatedAt": "2022-01-04T23:30:53Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs4yT-pP",
          "commit": {
            "abbreviatedOid": "d95249f"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2022-01-04T23:33:21Z",
          "updatedAt": "2022-01-04T23:33:21Z",
          "comments": [
            {
              "originalPosition": 5,
              "body": "I like your thinking @eriktaubeneck  and @csharrison ! I vote for `poplar1`. ",
              "createdAt": "2022-01-04T23:33:21Z",
              "updatedAt": "2022-01-04T23:33:21Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs4yUonb",
          "commit": {
            "abbreviatedOid": "d95249f"
          },
          "author": "henrycg",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "Looks good! Thanks.",
          "createdAt": "2022-01-05T07:04:18Z",
          "updatedAt": "2022-01-05T07:04:18Z",
          "comments": []
        },
        {
          "id": "PRR_kwDOFEJYQs4ybArC",
          "commit": {
            "abbreviatedOid": "3e12842"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2022-01-06T18:40:12Z",
          "updatedAt": "2022-01-06T18:40:13Z",
          "comments": [
            {
              "originalPosition": 5,
              "body": "s/pops/poplar1/.",
              "createdAt": "2022-01-06T18:40:12Z",
              "updatedAt": "2022-01-06T18:40:13Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs4ybA6d",
          "commit": {
            "abbreviatedOid": "3e12842"
          },
          "author": "ekr",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "LGTM",
          "createdAt": "2022-01-06T18:41:20Z",
          "updatedAt": "2022-01-06T18:41:20Z",
          "comments": []
        },
        {
          "id": "PRR_kwDOFEJYQs4ybBYO",
          "commit": {
            "abbreviatedOid": "3e12842"
          },
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "This change is good and consistent with the corresponding change to vdaf. However I see there are two other occurrences of \"Hits\" in the doc, on lines 1335 and 1356:\r\n\r\n```\r\nThe PPM parameters also specify the maximum number of times a report can be\r\nused. Some protocols, such as *Hits*, require reports to be used in multiple\r\nbatches spanning multiple collect requests.\r\n<...>\r\nMost PPM protocols, including Prio and *Hits*, are robust against malicious\r\nclients, but are not robust against malicious servers.\r\n```\r\nI think we could change those to \"Poplar\"",
          "createdAt": "2022-01-06T18:43:30Z",
          "updatedAt": "2022-01-06T18:43:30Z",
          "comments": []
        },
        {
          "id": "PRR_kwDOFEJYQs4ybCDr",
          "commit": {
            "abbreviatedOid": "894cfdd"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "",
          "createdAt": "2022-01-06T18:46:50Z",
          "updatedAt": "2022-01-06T18:46:50Z",
          "comments": []
        }
      ]
    },
    {
      "number": 178,
      "id": "PR_kwDOFEJYQs4wn3VZ",
      "title": "Poplar, with one 'o'",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/pull/178",
      "state": "MERGED",
      "author": "tgeoghegan",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "",
      "createdAt": "2022-01-06T18:51:51Z",
      "updatedAt": "2022-01-06T18:57:32Z",
      "baseRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "baseRefName": "main",
      "baseRefOid": "50af0f5d48b849ba7aeca1e31b44f55eab6d82f7",
      "headRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "headRefName": "timg/pooplar",
      "headRefOid": "550a583bb43ba48dacb0cc138b380972c9e06153",
      "closedAt": "2022-01-06T18:57:32Z",
      "mergedAt": "2022-01-06T18:57:32Z",
      "mergedBy": "tgeoghegan",
      "mergeCommit": {
        "oid": "48bc21ce7f1c7e446618bfe53cd9470511e130bc"
      },
      "comments": [],
      "reviews": [
        {
          "id": "PRR_kwDOFEJYQs4ybESC",
          "commit": {
            "abbreviatedOid": "550a583"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "",
          "createdAt": "2022-01-06T18:57:25Z",
          "updatedAt": "2022-01-06T18:57:25Z",
          "comments": []
        }
      ]
    },
    {
      "number": 179,
      "id": "PR_kwDOFEJYQs4xD_Nt",
      "title": "DO NOT MERGE Proposed interop target",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/pull/179",
      "state": "CLOSED",
      "author": "cjpatton",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "The current version of the protocol cannot be implemented in the sense\r\nthat it does not specify a mapping from the VDAF execution to HTTP\r\nrequests. The goal of this PR is to flesh out one possible mapping so\r\nthat we can begin work on implementation, with the understanding of\r\ncourse that the overall shape and the details are still subject to\r\nchange.\r\n\r\nThe design presumes we have reached consensus on a variety of open\r\nissues, all of which still need to be discussed. The purpose of this PR\r\nis *not* to facilitate these discussions, but instead to ensure sure\r\nthere is a solution to each issue that we're confident we can implement.\r\nThese issues include:\r\n\r\n* PR #169 will be merged, i.e., the anti-replay mechanism will be\r\nrelaxed to require the helper to store nonce sets.\r\n\r\n* PR #174 will not be merged, i.e., clients will continue to upload\r\nreports to the leader (and not the helpers). However, if we end up\r\nchoosing to take this PR, it shouldn't be too bad to change course.\r\n\r\n* Issue #45 will be resolved by adding support for VDAFs w/o\r\nverifiability. (We should probably call these \"DAFs\".)\r\n\r\n* Issue #68 will be resolved by adding support for multiple helpers (for\r\napplicable VDAFs). We don't do this quite yet, but the aggregate flow is\r\nmeant to be easily extendable to accommodate this.\r\n\r\n* Messages sent between aggregators need to be authenticated.\r\n\r\nWe have an answer for each of these, but we will discuss and merge PRs\r\nfor each of them separately.\r\n\r\n**Tips for reviewing:** Rather than look at the diff, I would read the\r\ndocument from /Work begins here/ to /Work ends here/. There is a big new\r\nsection in the middle, and GH didn't do a very good job of showing the\r\nchange.",
      "createdAt": "2022-01-14T22:07:24Z",
      "updatedAt": "2022-05-11T14:25:27Z",
      "baseRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "baseRefName": "main",
      "baseRefOid": "c7ad24e2ea42dc9d3b125cb8228aaa4384ccc8b5",
      "headRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "headRefName": "cjpatton-tgeoghegan/draft-interop-target",
      "headRefOid": "79462d9f8703f908b6d4d21d9297cffb626b3ce2",
      "closedAt": "2022-05-11T14:25:27Z",
      "mergedAt": null,
      "mergedBy": null,
      "mergeCommit": null,
      "comments": [
        {
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "body": "@cjpatton @tgeoghegan, I believe we can now close this. Thanks for driving this work and teeing things up to land in `main`!",
          "createdAt": "2022-05-11T11:11:01Z",
          "updatedAt": "2022-05-11T11:11:01Z"
        }
      ],
      "reviews": [
        {
          "id": "PRR_kwDOFEJYQs4zLuz0",
          "commit": {
            "abbreviatedOid": "7a76a72"
          },
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "Reviewed! I have three categories of comments here:\r\n\r\n- trivial typos (hopefully these are self-evident)\r\n- editorial remarks that don't affect the viability of these changes as an implementable interop target (i.e. we can discuss them if and when we merge this to main) (these are tagged with \"EDITORIAL\")\r\n- actual discussion points\r\n\r\nI think we only need to dig into the last category immediately.",
          "createdAt": "2022-01-20T19:29:29Z",
          "updatedAt": "2022-01-21T04:12:59Z",
          "comments": [
            {
              "originalPosition": 88,
              "body": "EDITORIAL\r\n```suggestion\r\n* `vdaf_verify_param`: The aggregator's VDAF verification parameter output by\r\n  the setup algorithm computed jointly by the aggregators before the start of the \r\n  PPM protocol {{?I-D.draft-cfrg-patton-vdaf}}).\r\n```\r\nI keep having to remind myself that the verify param is the result of a multiparty computation separate from the one being standardized in PPM so I think it's helpful to accentuate that here.",
              "createdAt": "2022-01-20T19:29:29Z",
              "updatedAt": "2022-01-21T04:12:17Z"
            },
            {
              "originalPosition": 133,
              "body": "The endpoint `[leader]` is already understood to be the endpoint for a task's leader. What does the extra `/leader` path component achieve?",
              "createdAt": "2022-01-20T23:05:54Z",
              "updatedAt": "2022-01-21T04:12:17Z"
            },
            {
              "originalPosition": 165,
              "body": "EDITORIAL\r\n```suggestion\r\n  opaque context<1..2^16-1>;\r\n  opaque ciphertext<1..2^16-1>;\r\n```\r\nThis is unrelated to your change but I feel like `enc` is ambiguous since it could be an abbreviation of either \"encapsulated context\" or \"encrypted text\".",
              "createdAt": "2022-01-20T23:09:49Z",
              "updatedAt": "2022-01-21T04:12:17Z"
            },
            {
              "originalPosition": 165,
              "body": "EDITORIAL\r\nI think it's a good idea to generalize the `HpkeCiphertext` structure and use it in several places. We should also hoist it up to the common definitions section with `Duration`.",
              "createdAt": "2022-01-20T23:11:11Z",
              "updatedAt": "2022-01-21T04:12:18Z"
            },
            {
              "originalPosition": 184,
              "body": "EDITORIAL\r\nWe should explicitly state that the client needs to create a _new_ HPKE context for each report it uploads. When I first implemented this in `ppm-prototype`, I figured that since all the parameters used in the context generation are fixed for a given task, a client could re-use the same HPKE context for multiple messages. But of course HPKE includes a [message sequence number](https://www.ietf.org/archive/id/draft-irtf-cfrg-hpke-12.html#name-encryption-and-decryption) in its AEAD parameters so you can't do that without keeping track of the sequence number on both sides.\r\n\r\nAnyway, I think we can spare implementors the little journey of learning I went on by explicitly telling them to make a new HPKE context every time they upload a report.",
              "createdAt": "2022-01-20T23:23:39Z",
              "updatedAt": "2022-01-21T04:12:17Z"
            },
            {
              "originalPosition": 190,
              "body": "EDITORIAL\r\nI'm not crazy about the `0x03` notation because it's not as clear as it could be that what should be concatenated into the context string is the 1 byte wide integer 3, not a 4 or 2 byte integer, nor the string \"0x03\". But that's orthogonal to what this PR is about and I don't have a better suggestion.",
              "createdAt": "2022-01-21T00:05:51Z",
              "updatedAt": "2022-01-21T04:12:17Z"
            },
            {
              "originalPosition": 226,
              "body": "```suggestion\r\nindicated by `HpkeCiphertext.config_id`, with status 400 and an error of\r\n```",
              "createdAt": "2022-01-21T00:08:29Z",
              "updatedAt": "2022-01-21T04:12:17Z"
            },
            {
              "originalPosition": 242,
              "body": "```suggestion\r\nalert the client with error \"staleReport\".\r\n```\r\nAlso the table of error types should be updated to include this.",
              "createdAt": "2022-01-21T00:09:58Z",
              "updatedAt": "2022-01-21T04:12:17Z"
            },
            {
              "originalPosition": 240,
              "body": "We've talked about this elsewhere, but if we defined a state machine for reports and batch intervals, then we could rephrase stuff like this as \"the leader ignores any report whose nonce contains a timestamp that falls in a batch interval that is in the `COLLECTED` state.\" That's not needed in this change though.",
              "createdAt": "2022-01-21T00:11:34Z",
              "updatedAt": "2022-01-21T04:12:17Z"
            },
            {
              "originalPosition": 254,
              "body": "Given that helpers must now store the full set of observed report nonces, is this true anymore? IIRC the problem with reports from the future was that it would advance the helper's last seen nonce and cause it to reject reports, but that's not the case anymore.",
              "createdAt": "2022-01-21T00:14:43Z",
              "updatedAt": "2022-01-21T04:12:17Z"
            },
            {
              "originalPosition": 267,
              "body": "```suggestion\r\nwith multiple sets of reports in parallel. To aggregate a set of reports, the\r\n```",
              "createdAt": "2022-01-21T00:15:23Z",
              "updatedAt": "2022-01-21T04:12:17Z"
            },
            {
              "originalPosition": 268,
              "body": "```suggestion\r\nleader sends a request to each helper containing those report shares. Each helper\r\n```",
              "createdAt": "2022-01-21T00:15:33Z",
              "updatedAt": "2022-01-21T04:12:17Z"
            },
            {
              "originalPosition": 283,
              "body": "EDITORIAL\r\n```suggestion\r\n* Aggregating a set of reports -- especially validating them -- may require\r\n```\r\nI feel we should use more specific verbs than \"processing\" where possible",
              "createdAt": "2022-01-21T00:18:04Z",
              "updatedAt": "2022-01-21T04:12:17Z"
            },
            {
              "originalPosition": 309,
              "body": "Some discussion of helper state scope and parallelism is in #150. IMO now that we have accepted that helpers have to persistently store nonces, we should make them persistently store reports, too, and axe the helper state. I think it would simplify leader implementations and the protocol text considerably.",
              "createdAt": "2022-01-21T00:23:23Z",
              "updatedAt": "2022-01-21T04:12:17Z"
            },
            {
              "originalPosition": 322,
              "body": "Should we have `AggregateFinishReq` for symmetry? Such a message could be a good way to implement #141",
              "createdAt": "2022-01-21T00:24:39Z",
              "updatedAt": "2022-01-21T04:12:17Z"
            },
            {
              "originalPosition": 361,
              "body": "EDITORIAL\r\n```suggestion\r\nshares\", one for each aggregator besides itself:\r\n```\r\nor it could say \"one for each helper\".",
              "createdAt": "2022-01-21T00:25:49Z",
              "updatedAt": "2022-01-21T04:12:17Z"
            },
            {
              "originalPosition": 389,
              "body": "```suggestion\r\nIn order to aggregate its report share, an aggregator must first decrypt the\r\ninput share and then interact with the other aggregators. This involves executing the\r\n```",
              "createdAt": "2022-01-21T00:32:42Z",
              "updatedAt": "2022-01-21T04:12:17Z"
            },
            {
              "originalPosition": 391,
              "body": "```suggestion\r\neach aggregator recovers and verifies the validity of its output share. Output\r\n```\r\n",
              "createdAt": "2022-01-21T00:35:05Z",
              "updatedAt": "2022-01-21T04:12:17Z"
            },
            {
              "originalPosition": 415,
              "body": "When rendering this to a .txt, we get\r\n```\r\n[CP: To implement.] ~~~ struct { Nonce nonce; TransitionType\r\n   tran_type; select (Transition.tran_type) { case continued: opaque\r\n   payload<0..2^16-1>; // VDAF message case finished: Empty; case\r\n   failed: TransitionError; } } Transition; ~~~\r\n```\r\nand I _think_ it's because there's no newline.\r\n```suggestion\r\n[CP: To implement.]\r\n\r\n~~~\r\nstruct {\r\n```\r\n",
              "createdAt": "2022-01-21T00:36:55Z",
              "updatedAt": "2022-01-21T04:12:17Z"
            },
            {
              "originalPosition": 397,
              "body": "EDITORIAL\r\nnitty nit: this implies that the entire helper or leader is in one of these states, but in fact a server will have many of these state machines running concurrently, one for each report being aggregated. Maybe:\r\n\r\n```suggestion\r\n{{prep-leader}} and {{prep-helper}} specify the state machines of a report in the leader\r\nand helper respectively. Both state machines consist of the same five states:\r\n```",
              "createdAt": "2022-01-21T00:41:45Z",
              "updatedAt": "2022-01-21T04:12:17Z"
            },
            {
              "originalPosition": 475,
              "body": "AFAICT the helper would never receive `vdaf-prep-init-error` because if the leader errors out during prep, it just won't send that `ReportShare` to helper. Would the leader do anything differently if it received `vdaf-prep-init-error` or `vdaf-prep-next-error`? I think it just goes from `WAITING` to `FAILED` in either case.\r\n\r\nMore generally, I think we should avoid defining error codes unless we expect the recipient of the error code to do something specific with them, because otherwise we are just introducing ways that implementations can deviate from the protocol. If an error code is informative, then it could just as easily go into an opaque error message to get logged and observed by humans. ",
              "createdAt": "2022-01-21T00:45:21Z",
              "updatedAt": "2022-01-21T04:12:17Z"
            },
            {
              "originalPosition": 499,
              "body": "```suggestion\r\n* If the report has been collected at least once, then the aggregator fails with error\r\n```",
              "createdAt": "2022-01-21T01:12:41Z",
              "updatedAt": "2022-01-21T04:12:17Z"
            },
            {
              "originalPosition": 535,
              "body": "EDITORIAL:\r\n```suggestion\r\ninput_share = context.Open(ReportShare.nonce || ReportShare.extensions,\r\n                           ReportShare.encrypted_input_share.payload)\r\n```\r\nFor consistency with the specification of how the client uses `context.Seal`",
              "createdAt": "2022-01-21T01:17:02Z",
              "updatedAt": "2022-01-21T04:12:17Z"
            },
            {
              "originalPosition": 545,
              "body": "EDITORIAL:\r\n```suggestion\r\nVariable `server_role` is the Role of the intended recipient,\r\n```\r\nThe `Role` enum already specifies the byte value, right?",
              "createdAt": "2022-01-21T01:17:53Z",
              "updatedAt": "2022-01-21T04:12:17Z"
            },
            {
              "originalPosition": 549,
              "body": "EDITORIAL:\r\nWe don't introduce the aggregation parameter until the definition of `AggregateInitReq`, a few hundred lines below. A forward reference and/or some explanatory text explaining where it comes from would be helpful. As a reader, I have to admit I have trouble keeping the verification and aggregation parameters straight, so inline reminders of their provenance are helpful.",
              "createdAt": "2022-01-21T01:21:17Z",
              "updatedAt": "2022-01-21T04:12:17Z"
            },
            {
              "originalPosition": 569,
              "body": "EDITORIAL:\r\nIf the aggregator that fails during preparation is the leader, what happens? Does it just never instruct the helper to aggregate the pertinent `ReportShare`?\r\n\r\nThis is stated explicitly in 4.3.2.3. Leader",
              "createdAt": "2022-01-21T01:23:14Z",
              "updatedAt": "2022-01-21T04:12:17Z"
            },
            {
              "originalPosition": 596,
              "body": "EDITORIAL:\r\nI have a hard time reading these conditionals. It's not obvious whether the `failed` label applies to the vertical or horizontal edge, except that I can work backward from the `FAILED` vertex. How about:\r\n\r\n```suggestion\r\n                         |\r\n                         |\r\n                         V\r\n +----------failed--- prep_start <---------------------+\r\n |                    success                prep_next |\r\n |                       |             send Transition |\r\n```\r\n\r\nThough if this complies with a standard notation for RFC state machines then I can live with it.",
              "createdAt": "2022-01-21T01:31:05Z",
              "updatedAt": "2022-01-21T04:12:17Z"
            },
            {
              "originalPosition": 618,
              "body": "```suggestion\r\na report share for aggregation.\"}\r\n```",
              "createdAt": "2022-01-21T01:35:55Z",
              "updatedAt": "2022-01-21T04:12:17Z"
            },
            {
              "originalPosition": 627,
              "body": "```suggestion\r\nAfter this initial step, the following procedure is repeated until the leader\r\n```",
              "createdAt": "2022-01-21T01:36:06Z",
              "updatedAt": "2022-01-21T04:12:17Z"
            },
            {
              "originalPosition": 629,
              "body": "I wonder if we should define a timeout for this state. If no transition message for the report arrives within X seconds, leader should transition to the failed state (perhaps after an appropriate number of retries).\r\n\r\nWe could declare the helper timing out to be equivalent to the helper sending a transition with type `FAILED`. I think that keeps the state machine simpler than adding dedicated timeout edges.",
              "createdAt": "2022-01-21T01:37:05Z",
              "updatedAt": "2022-01-21T04:12:17Z"
            },
            {
              "originalPosition": 678,
              "body": "```suggestion\r\nwithout sending a message to the helper. Otherwise it interprets `out` as follows.\r\n```",
              "createdAt": "2022-01-21T01:40:20Z",
              "updatedAt": "2022-01-21T04:12:17Z"
            },
            {
              "originalPosition": 735,
              "body": "```suggestion\r\nUpon receiving a Transition message from the leader, proceed as follows. If the\r\n```",
              "createdAt": "2022-01-21T01:43:12Z",
              "updatedAt": "2022-01-21T04:12:17Z"
            },
            {
              "originalPosition": 762,
              "body": "```suggestion\r\nOnce processing of a report share reaches the FINISHED state, the aggregator\r\n```",
              "createdAt": "2022-01-21T01:44:13Z",
              "updatedAt": "2022-01-21T04:12:17Z"
            },
            {
              "originalPosition": 763,
              "body": "```suggestion\r\nstores the the recovered output share until the batch to which it pertains is\r\n```",
              "createdAt": "2022-01-21T01:46:33Z",
              "updatedAt": "2022-01-21T04:12:17Z"
            },
            {
              "originalPosition": 764,
              "body": "```suggestion\r\ncollected. To aggregate the output shares, the aggregator runs the aggregation\r\n```",
              "createdAt": "2022-01-21T01:47:18Z",
              "updatedAt": "2022-01-21T04:12:17Z"
            },
            {
              "originalPosition": 785,
              "body": "```suggestion\r\nnumber of reports simultaneously:\r\n```",
              "createdAt": "2022-01-21T01:48:14Z",
              "updatedAt": "2022-01-21T04:12:17Z"
            },
            {
              "originalPosition": 793,
              "body": "EDITORIAL:\r\nWe use `kebab-case` in `enum TransitionError`, so I think we should be consistent. That said, It seems like we're using Rust case convention in most places (i.e., `BumpyCase` for types and `snake_case` for names) and so continuing from that convention, both this and `TransitionError` should be in `BumpyCase`:\r\n\r\n```suggestion\r\n  AggInitReq(0),\r\n  AggReq(1),\r\n  AggResp(2),\r\n  AggShareReq(3),\r\n  AggShareResp(4),\r\n```\r\nHowever if there's an existing convention informed by the TLS RFC, we should do that.",
              "createdAt": "2022-01-21T01:51:10Z",
              "updatedAt": "2022-01-21T04:12:17Z"
            },
            {
              "originalPosition": 815,
              "body": "If/when we merge this we should file a TODO to define this error.",
              "createdAt": "2022-01-21T01:55:31Z",
              "updatedAt": "2022-01-21T04:12:17Z"
            },
            {
              "originalPosition": 811,
              "body": "Given that these messages will be transmitted over TLS, why do we need an additional MAC? My best guess is that it's to prove to the recipient that the message came from the other aggregator, but since the aggregators are already aware of each other's HPKE configs, could we use HPKE to [mutually authenticate](https://www.ietf.org/archive/id/draft-irtf-cfrg-hpke-12.html#name-authentication-using-an-asy)?\r\n\r\nMore broadly it feels wrong to put a transport level concern like integrity or authenticity in the message. Though I acknowledge that we need to do something about authenticating leader<->helper interactions and I'm now astonished we didn't think about this sooner! I think there's an analogy here to the problem of client<->aggregator authentication, in that I think the details of how a leader and helper authenticate to each other will be deployment specific and maybe we shouldn't try to specify it in PPM, but instead just abstractly declare that helper and leader must communicate over a confidential and mutually authenticated channel. mTLS works, but they could also use a PSK, or use a common identity provider, or who knows what.",
              "createdAt": "2022-01-21T01:59:50Z",
              "updatedAt": "2022-01-21T04:12:17Z"
            },
            {
              "originalPosition": 850,
              "body": "EDITORIAL:\r\n\ud83d\udc4d\ud83c\udffb . I think we would benefit from formalizing the definition of a batch as well as a few verbs that go with it (i.e., what does it mean for a batch to be _collected_).",
              "createdAt": "2022-01-21T02:56:55Z",
              "updatedAt": "2022-01-21T04:12:18Z"
            },
            {
              "originalPosition": 862,
              "body": "```suggestion\r\n{{aggregate-message-auth}}, the helper handles the AggregateInitReq by computing\r\n```",
              "createdAt": "2022-01-21T02:58:14Z",
              "updatedAt": "2022-01-21T04:12:18Z"
            },
            {
              "originalPosition": 878,
              "body": "I don't think that's necessary -- the `AggregateResp` is explicitly the response to an `Aggregate` message, so the leader should have the appropriate context when handling the response. However this gets trickier if we solve #111 by having helpers post `AggregateResp`s asynchronously to an endpoint exposed by the leader. Then your question becomes a case of #146.",
              "createdAt": "2022-01-21T03:01:03Z",
              "updatedAt": "2022-01-21T04:12:18Z"
            },
            {
              "originalPosition": 881,
              "body": "Each `Transition` message contains a `Nonce` that would allow the leader to figure out which of its own `ReportShare`s it goes with. In many cases, a leader might store its `ReportShare`s in a key-value store keyed on the `Nonce`, so getting the responses in order might not make a difference. I wonder if we could relax this restriction.",
              "createdAt": "2022-01-21T03:04:01Z",
              "updatedAt": "2022-01-21T04:12:18Z"
            },
            {
              "originalPosition": 881,
              "body": "Additionally:\r\n```suggestion\r\nthe AggregateInitReq. The order of these sequences MUST be the same (i.e.,\r\n```",
              "createdAt": "2022-01-21T03:04:16Z",
              "updatedAt": "2022-01-21T04:12:18Z"
            },
            {
              "originalPosition": 884,
              "body": "```suggestion\r\nkeep track of state across aggregate requests. The helper's response to the\r\n```",
              "createdAt": "2022-01-21T03:04:37Z",
              "updatedAt": "2022-01-21T04:12:18Z"
            },
            {
              "originalPosition": 962,
              "body": "I said elsewhere I think we should remove the helper state blob unless we can prove it's necessary. However if we keep it, we should put in a _SHOULD_ or _RECOMMENDED_ about versioning inside the state blob, because what if the helper deploys a new version while the leader is holding onto a state blob?\r\n\r\nIn passing, absolving helpers of dealing with state blob versioning and format migration is another strong argument for removing that feature from the protocol.",
              "createdAt": "2022-01-21T03:23:32Z",
              "updatedAt": "2022-01-21T04:12:18Z"
            },
            {
              "originalPosition": 971,
              "body": "This doesn't sound right: the leader wouldn't emit an `AggregateShareReq` until it gets a `CollectReq`, would it? I can imagine that in a VDAF like `prio3`, the leader could eagerly send `AggregateShareReq`, but for `poplar1`, it can't do that until it gets the `agg_param`.",
              "createdAt": "2022-01-21T03:30:52Z",
              "updatedAt": "2022-01-21T04:12:18Z"
            },
            {
              "originalPosition": 996,
              "body": "EDITORIAL:\r\nThis is awkward because the paragraph on line 1235-1237 refers to a singular helper but the next paragraph refers to multiple aggregators besides the leader. At one point we decided to write the protocol in a way that doesn't explicitly support multiple helpers but admits the possibility in the future. I'm open to rewriting the protocol explicitly assuming exactly one helper, but we should be consistent.",
              "createdAt": "2022-01-21T03:33:52Z",
              "updatedAt": "2022-01-21T04:12:18Z"
            },
            {
              "originalPosition": 1004,
              "body": "```suggestion\r\n{{out-to-agg-share}}, obtaining an opaque byte string `agg_share` whose structure is\r\n```",
              "createdAt": "2022-01-21T03:36:14Z",
              "updatedAt": "2022-01-21T04:12:18Z"
            },
            {
              "originalPosition": 1033,
              "body": "```suggestion\r\nciphertext `encrypted_agg_share` computed above.\r\n```",
              "createdAt": "2022-01-21T03:38:59Z",
              "updatedAt": "2022-01-21T04:12:18Z"
            },
            {
              "originalPosition": 1040,
              "body": "```suggestion\r\nerror for the leader to issue any more aggregate or aggregate-init requests for\r\n```",
              "createdAt": "2022-01-21T03:40:00Z",
              "updatedAt": "2022-01-21T04:12:18Z"
            },
            {
              "originalPosition": 1046,
              "body": "```suggestion\r\nThe collector sends a CollectReq message to the leader in order to collect\r\n```",
              "createdAt": "2022-01-21T03:40:23Z",
              "updatedAt": "2022-01-21T04:12:18Z"
            },
            {
              "originalPosition": 1084,
              "body": "```suggestion\r\nfail, then the leader aborts with \"XXX\". [TODO: Maybe convey the reason for\r\n```",
              "createdAt": "2022-01-21T03:41:44Z",
              "updatedAt": "2022-01-21T04:12:18Z"
            },
            {
              "originalPosition": 1087,
              "body": "EDITORIAL:\r\nnit: the leader may just be retrieving the aggregate share it has already computed",
              "createdAt": "2022-01-21T03:42:14Z",
              "updatedAt": "2022-01-21T04:12:18Z"
            },
            {
              "originalPosition": 47,
              "body": "We have kind of been trying to keep the door open for multiple helpers in the future. If we were to add more helpers to this enum in the future, they would have to come after the client, which would introduce an inconsequential but slightly ugly discontinuity in the aggregator IDs. Maybe we should reorder this to:\r\n```\r\nenum {\r\n  collector(0),\r\n  client(1),\r\n  leader(2),\r\n  helper(3),\r\n} Role;\r\n```\r\n\r\nThat said (as noted elsewhere) I'm also comfortable with committing to exactly one helper and letting authors of some future RFC that obsoletes ours worry about this.",
              "createdAt": "2022-01-21T03:45:41Z",
              "updatedAt": "2022-01-21T04:12:18Z"
            },
            {
              "originalPosition": 1145,
              "body": "Participants should also check that `batch_interval.end >= batch_interval.start`. Maybe we should change the definition of `struct Interval` to\r\n\r\n```\r\nstruct {\r\n  Time start;\r\n  Duration length;\r\n} Interval;\r\n```\r\n\r\nThen, because `Duration` is an unsigned integer, it is impossible to define an invalid `Interval`.",
              "createdAt": "2022-01-21T03:49:55Z",
              "updatedAt": "2022-01-21T04:12:18Z"
            },
            {
              "originalPosition": 1162,
              "body": "EDITORIAL:\r\nultranit: if `X` is a set is `cardinality` or `size` more appropriate than `len`?",
              "createdAt": "2022-01-21T03:51:39Z",
              "updatedAt": "2022-01-21T04:12:18Z"
            },
            {
              "originalPosition": 1164,
              "body": "```suggestion\r\n* The aggregator keeps track of the number of times each report was aggregated.\r\n```",
              "createdAt": "2022-01-21T03:52:05Z",
              "updatedAt": "2022-01-21T04:12:18Z"
            },
            {
              "originalPosition": 1174,
              "body": "```suggestion\r\nshould keep it here until we figure out how to deal with nonce set\r\n```",
              "createdAt": "2022-01-21T03:52:28Z",
              "updatedAt": "2022-01-21T04:12:18Z"
            },
            {
              "originalPosition": 1195,
              "body": "```suggestion\r\n[OPEN ISSUE: This has the potential to require aggregators to store nonce sets\r\n```",
              "createdAt": "2022-01-21T03:53:01Z",
              "updatedAt": "2022-01-21T04:12:18Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs4zPman",
          "commit": {
            "abbreviatedOid": "d878ff7"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2022-01-21T16:01:38Z",
          "updatedAt": "2022-01-21T17:36:52Z",
          "comments": [
            {
              "originalPosition": 88,
              "body": "Whether we need to do something fancy here is TBD: https://github.com/abetterinternet/ppm-specification/issues/161. However, I like this suggestion, I'll just also add a pointer to the issue.",
              "createdAt": "2022-01-21T16:01:38Z",
              "updatedAt": "2022-01-21T17:36:52Z"
            },
            {
              "originalPosition": 47,
              "body": "Great idea. I don't think this closes the door for multiple helpers, as long as their role in the PPM protocol is identical. However it does close the door on their being multiple \"types\" of helpers, which is still a possibility.",
              "createdAt": "2022-01-21T16:09:53Z",
              "updatedAt": "2022-01-21T17:36:52Z"
            },
            {
              "originalPosition": 133,
              "body": "My thinking here is that the same endpoint might implement different roles (but never the same role for a given task). This allows the same domain to implement several roles.",
              "createdAt": "2022-01-21T16:20:10Z",
              "updatedAt": "2022-01-21T17:36:52Z"
            },
            {
              "originalPosition": 165,
              "body": "I moved the HpkeCipertext to the section above. As for the suggested renaming: I agree that `enc` is ambiguous, but this naming convention matches other applications of HPKE, such as ECH and OHTTP. Consistent use of HPKE across specs is useful",
              "createdAt": "2022-01-21T16:24:34Z",
              "updatedAt": "2022-01-21T17:36:52Z"
            },
            {
              "originalPosition": 184,
              "body": "Added \"Clients MUST NOT use the same `enc` for multiple reports.\" below.\r\n\r\nFYI, strictly speaking this comment isn't editorial, since it's somewhat normative.",
              "createdAt": "2022-01-21T16:27:36Z",
              "updatedAt": "2022-01-21T17:36:52Z"
            },
            {
              "originalPosition": 190,
              "body": "I think it's reasonably clear that \"0x03\" isn't a byte string because it's not in quotes. Note that we're following the conventions of the TLS presentation language here. (Search \"0x0303\" in RFC 8446.)",
              "createdAt": "2022-01-21T16:32:00Z",
              "updatedAt": "2022-01-21T17:36:52Z"
            },
            {
              "originalPosition": 254,
              "body": "This is still true: We don't have to require aggregators to keep around reports for the 24th century.",
              "createdAt": "2022-01-21T16:37:57Z",
              "updatedAt": "2022-01-21T17:36:52Z"
            },
            {
              "originalPosition": 283,
              "body": "Ack. While I agree, this is somewhat out of scope for this PR.",
              "createdAt": "2022-01-21T16:39:12Z",
              "updatedAt": "2022-01-21T17:36:52Z"
            },
            {
              "originalPosition": 309,
              "body": "I'd like to keep the helper state around, at least for the aggregation flow. In my own implementation, I'm using the helper state as a \"cookie\" that the helper uses to look up the state for the previous aggregate request.",
              "createdAt": "2022-01-21T16:40:57Z",
              "updatedAt": "2022-01-21T17:36:52Z"
            },
            {
              "originalPosition": 322,
              "body": "Yeah, @chris-wood and I have discussed something like this. Let's see if we can't work it out on the call today and tack on a commit.",
              "createdAt": "2022-01-21T16:41:54Z",
              "updatedAt": "2022-01-21T17:36:52Z"
            },
            {
              "originalPosition": 475,
              "body": "The protocol should specify exactly how any of these errors is to be handled. (If this isn't true then we need to fix it.) What the error codes are useful for is telemetry: It's good to know what errors are occuring because it gives you a starting point for diagnosing issues with your service. For instance, if I'm seeing `vdaf-prep-next-error` more than normal, this might indicate that the clients are misconfigured.\r\n\r\nNote that TLS does something similar: https://datatracker.ietf.org/doc/html/rfc8446#section-6",
              "createdAt": "2022-01-21T16:48:29Z",
              "updatedAt": "2022-01-21T17:36:52Z"
            },
            {
              "originalPosition": 499,
              "body": "In the current context, \"at least once\" is implied by \"collected\".",
              "createdAt": "2022-01-21T16:49:10Z",
              "updatedAt": "2022-01-21T17:36:52Z"
            },
            {
              "originalPosition": 569,
              "body": "That's right, though this will need to change if we go with #174. I've tried to minimize explanatory text that depends on decisions that haven't been made yet.",
              "createdAt": "2022-01-21T16:54:11Z",
              "updatedAt": "2022-01-21T17:36:52Z"
            },
            {
              "originalPosition": 596,
              "body": "There's no \"standard\" here AFAIK. Feel free to hack on this. (just keep both state machines consistent.)",
              "createdAt": "2022-01-21T16:54:58Z",
              "updatedAt": "2022-01-21T17:36:52Z"
            },
            {
              "originalPosition": 629,
              "body": "This would be need to be handled at the request level. A timeout is fatal, not only for a single report transition but for the entire aggregate request.",
              "createdAt": "2022-01-21T16:59:49Z",
              "updatedAt": "2022-01-21T17:36:52Z"
            },
            {
              "originalPosition": 793,
              "body": "This follows the TLS presentation language.",
              "createdAt": "2022-01-21T17:03:18Z",
              "updatedAt": "2022-01-21T17:36:52Z"
            },
            {
              "originalPosition": 811,
              "body": "> Given that these messages will be transmitted over TLS, why do we need an additional MAC? My best guess is that it's to prove to the recipient that the message came from the other aggregator, but since the aggregators are already aware of each other's HPKE configs, could we use HPKE to [mutually authenticate](https://www.ietf.org/archive/id/draft-irtf-cfrg-hpke-12.html#name-authentication-using-an-asy)?\r\n\r\nSome form of message authentication is needed because we don't assume mutually authenticated TLS. Yes, we could use one of the mutual auth modes for HPKE, but at the end of the day we would just use this to derive a MAC key.\r\n\r\n> More broadly it feels wrong to put a transport level concern like integrity or authenticity in the message.\r\n\r\nWhen we started working on this stuff, this was my inclination as well. However, conversations with Chris W., EKR, and others have lead me to think that there's value in minimizing the assumptions we make about what the underlying transport does, since it's evolution isn't tied to the evolution of our protocol.\r\n\r\n> I think there's an analogy here to the problem of client<->aggregator authentication, in that I think the details of how a leader and helper authenticate to each other will be deployment specific and maybe we shouldn't try to specify it in PPM, but instead just abstractly declare that helper and leader must communicate over a confidential and mutually authenticated channel. mTLS works, but they could also use a PSK, or use a common identity provider, or who knows what.\r\n\r\nI definitely see the value in keeping PPM agnostic about this. Many solutions are possible and not everyone is going to agree that a MAC is the best one. To be clear, I stuck a MAC here because the VDAF already requires distributing a shared secret key, so adding a MAC is cheap and convenient.",
              "createdAt": "2022-01-21T17:16:48Z",
              "updatedAt": "2022-01-21T17:36:52Z"
            },
            {
              "originalPosition": 815,
              "body": "In draft PRs I write \"XXX\" as a placeholder for something I want to fill in before merging.",
              "createdAt": "2022-01-21T17:17:37Z",
              "updatedAt": "2022-01-21T17:36:52Z"
            },
            {
              "originalPosition": 850,
              "body": "Agreed.",
              "createdAt": "2022-01-21T17:18:14Z",
              "updatedAt": "2022-01-21T17:36:52Z"
            },
            {
              "originalPosition": 878,
              "body": "Another thing to consider: The leader's architecture might be a PubSub or Kafka queue that ingests AggregateResp's over multiple aggregation flows over multiple tasks. I suppose the HTTP client could just add the task ID?",
              "createdAt": "2022-01-21T17:20:01Z",
              "updatedAt": "2022-01-21T17:36:52Z"
            },
            {
              "originalPosition": 881,
              "body": "The intention of this text is to allow implementations to parse and handle each Transition in-place, without sticking them in some intermediate data structure. ",
              "createdAt": "2022-01-21T17:25:59Z",
              "updatedAt": "2022-01-21T17:36:52Z"
            },
            {
              "originalPosition": 971,
              "body": "Right, it's true that in general that you need to know the agg parameter before this point. But for prio3 there is no agg parameter (or, more precisely, the only valid agg parameter is the empty string).",
              "createdAt": "2022-01-21T17:27:56Z",
              "updatedAt": "2022-01-21T17:36:52Z"
            },
            {
              "originalPosition": 996,
              "body": "I agree this is awkward, but EKR previously pushed back on changing any text to solve this ambiguity, which he viewed as a regression. We're just going to have to live with it until we make a decision about if/how to support multiple helpers.",
              "createdAt": "2022-01-21T17:29:06Z",
              "updatedAt": "2022-01-21T17:36:52Z"
            },
            {
              "originalPosition": 1087,
              "body": "Changed \"computes\" to \"retrieves\".",
              "createdAt": "2022-01-21T17:31:47Z",
              "updatedAt": "2022-01-21T17:36:52Z"
            },
            {
              "originalPosition": 1145,
              "body": "Ha, nice catch. Would you mind sending a PR for the main branch?",
              "createdAt": "2022-01-21T17:33:29Z",
              "updatedAt": "2022-01-21T17:36:52Z"
            },
            {
              "originalPosition": 1162,
              "body": "I don't think so, I think it's clear. ",
              "createdAt": "2022-01-21T17:34:03Z",
              "updatedAt": "2022-01-21T17:36:52Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs4zQz1Q",
          "commit": {
            "abbreviatedOid": "830228f"
          },
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2022-01-21T21:26:01Z",
          "updatedAt": "2022-01-21T21:26:02Z",
          "comments": [
            {
              "originalPosition": 815,
              "body": "Yeah we can deal with these before merging to main",
              "createdAt": "2022-01-21T21:26:01Z",
              "updatedAt": "2022-01-21T21:26:02Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs4zQ0b-",
          "commit": {
            "abbreviatedOid": "830228f"
          },
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2022-01-21T21:29:32Z",
          "updatedAt": "2022-01-21T21:29:32Z",
          "comments": [
            {
              "originalPosition": 309,
              "body": "x-posting from another comment about helper state:\r\n\r\nI said elsewhere I think we should remove the helper state blob unless we can prove it's necessary. However if we keep it, we should put in a SHOULD or RECOMMENDED about versioning inside the state blob, because what if the helper deploys a new version while the leader is holding onto a state blob?\r\n\r\nIn passing, absolving helpers of dealing with state blob versioning and format migration is another strong argument for removing that feature from the protocol.",
              "createdAt": "2022-01-21T21:29:32Z",
              "updatedAt": "2022-01-21T21:29:33Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs4zQ0eD",
          "commit": {
            "abbreviatedOid": "830228f"
          },
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2022-01-21T21:29:45Z",
          "updatedAt": "2022-01-21T21:29:46Z",
          "comments": [
            {
              "originalPosition": 962,
              "body": "Resolving this so we have a single thread about helper state",
              "createdAt": "2022-01-21T21:29:46Z",
              "updatedAt": "2022-01-21T21:29:46Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs4zQ203",
          "commit": {
            "abbreviatedOid": "830228f"
          },
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2022-01-21T21:43:51Z",
          "updatedAt": "2022-01-21T21:43:52Z",
          "comments": [
            {
              "originalPosition": 1145,
              "body": "Here we are: https://github.com/abetterinternet/ppm-specification/pull/184",
              "createdAt": "2022-01-21T21:43:52Z",
              "updatedAt": "2022-01-21T21:43:52Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs4zRE4B",
          "commit": {
            "abbreviatedOid": "1870a9d"
          },
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2022-01-21T23:27:13Z",
          "updatedAt": "2022-01-21T23:27:14Z",
          "comments": [
            {
              "originalPosition": 309,
              "body": "We agreed to deal with this out of band from this specific PR. I will file an issue about this. Resolving this particular item.",
              "createdAt": "2022-01-21T23:27:13Z",
              "updatedAt": "2022-01-21T23:27:14Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs4zRJBs",
          "commit": {
            "abbreviatedOid": "1870a9d"
          },
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2022-01-22T00:13:41Z",
          "updatedAt": "2022-01-22T00:13:41Z",
          "comments": [
            {
              "originalPosition": 811,
              "body": "We're going to do the MAC with a pre shared secret for now, and will revisit this as #161 and other issues related to sharing entropy between aggregators mature.",
              "createdAt": "2022-01-22T00:13:41Z",
              "updatedAt": "2022-01-22T00:13:41Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs4zRPmE",
          "commit": {
            "abbreviatedOid": "1870a9d"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2022-01-22T02:42:57Z",
          "updatedAt": "2022-01-22T02:42:57Z",
          "comments": [
            {
              "originalPosition": 322,
              "body": "We decided to park this. It's not clear that the extra round trip is needed, at least for the current set of VDAFs.",
              "createdAt": "2022-01-22T02:42:57Z",
              "updatedAt": "2022-01-22T02:42:57Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs4zcJsm",
          "commit": {
            "abbreviatedOid": "a9f6ed0"
          },
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2022-01-26T00:48:37Z",
          "updatedAt": "2022-01-26T00:48:37Z",
          "comments": [
            {
              "originalPosition": 77,
              "body": "Do we need separate `aggregate` and `aggregate_init` endpoints? `struct Aggregate` contains an `AggregateType` selector that allows the recipient to tell an `AggregateInitReq` from an `AggregateReq` anyway.",
              "createdAt": "2022-01-26T00:48:37Z",
              "updatedAt": "2022-01-26T00:48:37Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs4zewBK",
          "commit": {
            "abbreviatedOid": "a9f6ed0"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2022-01-26T15:23:37Z",
          "updatedAt": "2022-01-26T15:23:38Z",
          "comments": [
            {
              "originalPosition": 77,
              "body": "Right, this doesn't seem strictly necessary. In fact the same is true for /aggregate_share.",
              "createdAt": "2022-01-26T15:23:37Z",
              "updatedAt": "2022-01-26T15:24:35Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs40ffZ6",
          "commit": {
            "abbreviatedOid": "b787cdd"
          },
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2022-02-11T20:55:30Z",
          "updatedAt": "2022-02-11T21:12:30Z",
          "comments": [
            {
              "originalPosition": 92,
              "body": "I changed this to 16 because (1) I have a hard time imagining we'll ever get close to 65,536 input shares and (2) implementing encoding/decoding for `u24` is awkward!",
              "createdAt": "2022-02-11T20:55:31Z",
              "updatedAt": "2022-02-11T21:12:30Z"
            },
            {
              "originalPosition": 101,
              "body": "I keep going back and forth on whether there should be a separate endpoints for `aggreagate_init`, `aggregate` and `aggregate_share`. I think there's a disconnect between having separate endpoints, but having them all take `struct Aggregate`. The thing is, the only valid message to send to `[helper]/aggregate_init` is an `AggregateInitReq`, and the only valid response to send is `AggregateResp`, so why do we have a wrapper that allows sending or responding with any of `AggregateReq`, `AggregateReq`, `AggregateResp`, `AggregateShareReq` or `HpkeCiphertext`? I think the reason is so that we can specify the `opaque tag[32]` for the HMAC-SHA256 in one place but I don't think it's worth the extra error cases introduced by the enum wrapper.\r\n\r\nI think we should have:\r\n- `[helper]/aggregate_init` which _only_ accepts `AggregateInitReq` and _only_ responds with `AggregateResp`\r\n- `[helper]/aggregate` which _only_ accepts `AggregateReq` and _only_ responds with `AggregateResp`\r\n- `[helper]/aggregate_share` which _only_ accepts `AggregateShareReq` and _only_ responds with `HpkeCiphertext`\r\n- add `opaque tag [32]` fields to `AggregateInitReq`, `AggregateReq` and `AggregateShareReq` so that helper can verify that the message came from the leader.\r\n\r\nFinally, here's something spicy: do we need the HMAC tag on `AggregateResp` or the `HpkeCiphertext` that the helper responds to the leader with? If the leader connects to helper over TLS, then that provides sufficient authentication for responses.",
              "createdAt": "2022-02-11T21:04:26Z",
              "updatedAt": "2022-02-11T21:12:30Z"
            },
            {
              "originalPosition": 128,
              "body": "Let's say we are running a two round VDAF. In round 1, leader sends helper an `AggregateInitReq` over five reports ordered by nonce (each composed of `(time, rand)`) thus: `(1,1), (2,2), (3,3), (4,4), (5,5)`. Upon receipt, the helper extracts its prepare message and records that it has seen those nonces. The leader can verify that the `Transitions` in the `AggregateResp` it gets appear in the same order. So far so good.\r\n\r\nSuppose in the next round, the leader sends the next flight of prepare messages in a different order: `(5,5), (4,4), (3,3), (2,2), (1,1)`. How is helper supposed to know that this is \"out of order\" with respect to the previous round? Besides keeping track of whether or not it has ever seen an individual nonce, helper would have to keep track of the order in which they ever appeared in an `AggregateInitReq`. Is that reasonable? Instead of letting the leader dictate the order of reports/transitions, should we define a canonical order for reports and transitions (i.e., ascending order by nonce) so that both aggregators can statelessly enforce the desired ordering?",
              "createdAt": "2022-02-11T21:12:21Z",
              "updatedAt": "2022-02-11T21:12:30Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs41iO61",
          "commit": {
            "abbreviatedOid": "3046435"
          },
          "author": "divergentdave",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2022-03-02T21:02:20Z",
          "updatedAt": "2022-03-02T21:02:20Z",
          "comments": [
            {
              "originalPosition": 665,
              "body": "This doesn't match the pseudocode below\r\n```suggestion\r\nfollows. Let `leader_payload` denote the last VDAF message it computed and let\r\n`helper_payload` denote the last VDAF message it received from the helper. The\r\n```",
              "createdAt": "2022-03-02T21:02:20Z",
              "updatedAt": "2022-03-02T21:02:20Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs41ijJ0",
          "commit": {
            "abbreviatedOid": "3046435"
          },
          "author": "BranLwyd",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2022-03-02T22:29:53Z",
          "updatedAt": "2022-03-02T22:30:02Z",
          "comments": [
            {
              "originalPosition": 787,
              "body": "There are currently two structures called `AggregateReq`: this one, and another defined on L1176 (which is embedded in this message if `msg_type == aqq_req`).\r\n\r\nMy strawman suggestion would be to keep this one named `AggregateReq`, and name the sub-message `AggregateContinueReq`. TBH I'm not super-happy with that name, maybe something better is apparent -- I don't care too much as long as they're named separately.",
              "createdAt": "2022-03-02T22:29:53Z",
              "updatedAt": "2022-03-02T22:30:02Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs41w2is",
          "commit": {
            "abbreviatedOid": "d8c6677"
          },
          "author": "divergentdave",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2022-03-07T17:14:30Z",
          "updatedAt": "2022-03-07T17:14:30Z",
          "comments": [
            {
              "originalPosition": 809,
              "body": "This requirement that the tag must be verified before interpreting the rest of the `AggregateReq` is impractical given our current structures and serializations of authenticated messages. The recipient must read a discriminant byte and one or two length fields inside the inner struct before it knows where the tag will be.\r\n\r\nPerhaps we should redefine the authenticated structures to contain two opaque fields, one with the encoded contents of a new inner struct, and one with the authentication tag over it. Then, we can read one length (of the `opaque inner<0..2^16-1>` field) and perform tag verification before parsing the nested contents.",
              "createdAt": "2022-03-07T17:14:30Z",
              "updatedAt": "2022-03-07T17:14:30Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs4118su",
          "commit": {
            "abbreviatedOid": "d8c6677"
          },
          "author": "BranLwyd",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2022-03-08T17:17:42Z",
          "updatedAt": "2022-03-08T17:17:43Z",
          "comments": [
            {
              "originalPosition": 809,
              "body": "Indeed. We could also add a requirement that the size of the encoded values must be known (which is true for the top-layer messages that are being tagged, since they are being passed around as HTTP requests/responses); then the `tag` is just the last 32 bytes.",
              "createdAt": "2022-03-08T17:17:42Z",
              "updatedAt": "2022-03-08T17:17:43Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs42DFO7",
          "commit": {
            "abbreviatedOid": "b787cdd"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2022-03-11T05:24:22Z",
          "updatedAt": "2022-03-11T05:24:23Z",
          "comments": [
            {
              "originalPosition": 92,
              "body": "It's not 65,536 input shares, it's 65,536 *bytes* worth of input shares. I think it this should be kicked back up to 24.",
              "createdAt": "2022-03-11T05:24:22Z",
              "updatedAt": "2022-03-11T05:24:23Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs42DFo0",
          "commit": {
            "abbreviatedOid": "d8c6677"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2022-03-11T05:27:48Z",
          "updatedAt": "2022-03-11T05:27:48Z",
          "comments": [
            {
              "originalPosition": 809,
              "body": "The same pattern exists for TLS, I don't think this is a big problem. On the other hand I would advocate for being conservative about what we MAC. In particular I wouldn't want the disccriminator or length bits to not be covered by the MAC.",
              "createdAt": "2022-03-11T05:27:48Z",
              "updatedAt": "2022-03-11T05:27:48Z"
            }
          ]
        }
      ]
    },
    {
      "number": 181,
      "id": "PR_kwDOFEJYQs4xN2On",
      "title": "Align some terminology with the VDAF draft",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/pull/181",
      "state": "MERGED",
      "author": "cjpatton",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "What PPM calls an \"output share\" is called an \"aggregate share\" in the\r\nVDAF draft. Furthermore, in the VDAF draft, an \"output share\" is what\r\nan aggregator recovers from running the MPC with its peers. This change\r\nfixes this ambiguity without changing the PPM protocol itself (modulo\r\nchanging the info string for HPKE).",
      "createdAt": "2022-01-18T17:20:33Z",
      "updatedAt": "2022-01-19T18:39:52Z",
      "baseRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "baseRefName": "main",
      "baseRefOid": "47c5b696a0c12e9c5da9cfc12c40d1786e0ce1fc",
      "headRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "headRefName": "cjpatton/editorial-agg-share",
      "headRefOid": "58f903236300d61189d91fa1d739ab6c76c81068",
      "closedAt": "2022-01-19T18:39:52Z",
      "mergedAt": "2022-01-19T18:39:52Z",
      "mergedBy": "cjpatton",
      "mergeCommit": {
        "oid": "b202eaaa4c5544bd3f9cac19af37bcdcadcf7996"
      },
      "comments": [
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "Squashed.",
          "createdAt": "2022-01-19T18:38:03Z",
          "updatedAt": "2022-01-19T18:38:03Z"
        },
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "Thanks fellas!",
          "createdAt": "2022-01-19T18:39:48Z",
          "updatedAt": "2022-01-19T18:39:48Z"
        }
      ],
      "reviews": [
        {
          "id": "PRR_kwDOFEJYQs4zBvN-",
          "commit": {
            "abbreviatedOid": "421753c"
          },
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "LGTM, modulo typos",
          "createdAt": "2022-01-18T23:39:46Z",
          "updatedAt": "2022-01-18T23:56:36Z",
          "comments": [
            {
              "originalPosition": 114,
              "body": "```suggestion\r\nbatch interval for which it has completed at least one aggregate-share request\r\n```",
              "createdAt": "2022-01-18T23:39:46Z",
              "updatedAt": "2022-01-18T23:56:36Z"
            },
            {
              "originalPosition": 30,
              "body": "```suggestion\r\nAggregate result:\r\n```\r\nTo be consistent with other glossary entries",
              "createdAt": "2022-01-18T23:46:26Z",
              "updatedAt": "2022-01-18T23:56:36Z"
            },
            {
              "originalPosition": 69,
              "body": "```suggestion\r\nthe beginning of this computation, each aggregator is in possession of an input\r\n```",
              "createdAt": "2022-01-18T23:54:22Z",
              "updatedAt": "2022-01-18T23:56:36Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs4zE3gj",
          "commit": {
            "abbreviatedOid": "6f14a03"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "",
          "createdAt": "2022-01-19T14:54:40Z",
          "updatedAt": "2022-01-19T14:55:12Z",
          "comments": [
            {
              "originalPosition": 77,
              "body": "```suggestion\r\ndistributed zero-knowledge proof of the input's validity {{BBCGGI19}} which the\r\n```",
              "createdAt": "2022-01-19T14:54:40Z",
              "updatedAt": "2022-01-19T14:55:12Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs4zE7Xr",
          "commit": {
            "abbreviatedOid": "6f14a03"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2022-01-19T15:05:13Z",
          "updatedAt": "2022-01-19T15:05:14Z",
          "comments": [
            {
              "originalPosition": 77,
              "body": "Hmm, the tool that renders the markdown into XML seems to interpret this correctly. Plus we've been using `{{XXX}}` rather than `{{blah}}` for paper references fairly consistently throughout the doc. Do you think, we should change this back?",
              "createdAt": "2022-01-19T15:05:13Z",
              "updatedAt": "2022-01-19T15:05:14Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs4zE8W-",
          "commit": {
            "abbreviatedOid": "6f14a03"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2022-01-19T15:07:58Z",
          "updatedAt": "2022-01-19T15:07:58Z",
          "comments": [
            {
              "originalPosition": 77,
              "body": "`[..]` does nothing in the translation process. It literally duplicates the text inline. You could write `[bananas]` and it would render `[bananas]` in the XML/TXT/HTML output. `{{...}}` actually invokes the translation process to cite things correctly. So, yeah, we should be using `{{...}}`. It helps us catch unused or missing references.",
              "createdAt": "2022-01-19T15:07:58Z",
              "updatedAt": "2022-01-19T15:08:49Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs4zE-5-",
          "commit": {
            "abbreviatedOid": "6f14a03"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2022-01-19T15:15:16Z",
          "updatedAt": "2022-01-19T15:15:16Z",
          "comments": [
            {
              "originalPosition": 77,
              "body": "That's not true, as far as I can tell. take a look at the rendered HTML. A link is put there that navigates to the informational references at the bottom. And we don't use the `{{...}}` syntax anywhere for this particular reference.",
              "createdAt": "2022-01-19T15:15:16Z",
              "updatedAt": "2022-01-19T15:15:16Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs4zE_KK",
          "commit": {
            "abbreviatedOid": "6f14a03"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2022-01-19T15:16:00Z",
          "updatedAt": "2022-01-19T15:16:01Z",
          "comments": [
            {
              "originalPosition": 77,
              "body": "Maybe there's more that's happening that I don't see? Regardless, I'm happy to make this change to all links in a follow-up PR.",
              "createdAt": "2022-01-19T15:16:01Z",
              "updatedAt": "2022-01-19T15:16:01Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs4zFBfx",
          "commit": {
            "abbreviatedOid": "6f14a03"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2022-01-19T15:22:38Z",
          "updatedAt": "2022-01-19T15:22:38Z",
          "comments": [
            {
              "originalPosition": 77,
              "body": "As discussed offline, I'll follow up with a PR that changes all the [...] style references with {{...}} style references.",
              "createdAt": "2022-01-19T15:22:38Z",
              "updatedAt": "2022-01-19T15:22:38Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs4zF1L9",
          "commit": {
            "abbreviatedOid": "c22133b"
          },
          "author": "ekr",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "Generally looks good. I would change the \"agg\" in the label if you can as it is confusing.",
          "createdAt": "2022-01-19T18:03:55Z",
          "updatedAt": "2022-01-19T18:23:11Z",
          "comments": [
            {
              "originalPosition": 42,
              "body": "This may be the VDAF term, but it seems kind of unfortunate. Why  isn't this called \"input\"?",
              "createdAt": "2022-01-19T18:03:56Z",
              "updatedAt": "2022-01-19T18:23:11Z"
            },
            {
              "originalPosition": 93,
              "body": "```suggestion\r\nvalidate their corresponding output shares. For example, `prio3` includes a\r\n```\r\n\r\nI think this might help",
              "createdAt": "2022-01-19T18:13:07Z",
              "updatedAt": "2022-01-19T18:23:11Z"
            },
            {
              "originalPosition": 89,
              "body": "```suggestion\r\nindication that a valid output share could not be computed.\r\n```\r\n\"recovered\" is a weird word.",
              "createdAt": "2022-01-19T18:13:33Z",
              "updatedAt": "2022-01-19T18:23:11Z"
            },
            {
              "originalPosition": 198,
              "body": "Is \"aggregate\" not gonna fit?",
              "createdAt": "2022-01-19T18:15:48Z",
              "updatedAt": "2022-01-19T18:23:11Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs4zF8h0",
          "commit": {
            "abbreviatedOid": "8fb3ba5"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2022-01-19T18:32:02Z",
          "updatedAt": "2022-01-19T18:32:03Z",
          "comments": [
            {
              "originalPosition": 198,
              "body": "So I'm thinking it might simplify analysis if we make the info string the same length for each invocation of HPKE the same length. I'm thinking \"ppm inp share\" for the encrypted input shares and \"ppm agg share\" for the encrypted aggregate shares. I sort of half-assed it here, but I was planning on doing this in a future PR. I'll just change it to \"aggregate\" in this PR and defer that discussion.",
              "createdAt": "2022-01-19T18:32:03Z",
              "updatedAt": "2022-01-19T18:32:03Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs4zF9HX",
          "commit": {
            "abbreviatedOid": "bca1a15"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2022-01-19T18:34:25Z",
          "updatedAt": "2022-01-19T18:34:25Z",
          "comments": [
            {
              "originalPosition": 198,
              "body": "Done",
              "createdAt": "2022-01-19T18:34:25Z",
              "updatedAt": "2022-01-19T18:34:25Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs4zF-Xw",
          "commit": {
            "abbreviatedOid": "58f9032"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2022-01-19T18:39:28Z",
          "updatedAt": "2022-01-19T18:39:29Z",
          "comments": [
            {
              "originalPosition": 42,
              "body": "As discussed offline, the \"prepare step\" is the MPC that maps input shares to output shares (using the aggregation parameter to control the output).",
              "createdAt": "2022-01-19T18:39:28Z",
              "updatedAt": "2022-01-19T18:39:29Z"
            }
          ]
        }
      ]
    },
    {
      "number": 182,
      "id": "PR_kwDOFEJYQs4xRzJg",
      "title": "Convert [..]-style refs to {{..}}",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/pull/182",
      "state": "MERGED",
      "author": "cjpatton",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "Based on #181 (merge that first).\r\n\r\n@chris-wood pointed out that, if there is no reference for \"banana\",\r\nthen `[banana]` gets rendered as text. On the other hand `{{banana}}`\r\nwill fail to build because the reference is missing. The latter behavior\r\nis preferable.",
      "createdAt": "2022-01-19T17:39:43Z",
      "updatedAt": "2022-01-19T18:03:00Z",
      "baseRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "baseRefName": "cjpatton/editorial-agg-share",
      "baseRefOid": "6f14a03feb3c7c0d44a3d15f051d9c32509eb4be",
      "headRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "headRefName": "cjpatton/editorial-fix-links",
      "headRefOid": "e1a91b530c2d920d76d0175e6f7837c0bccc1239",
      "closedAt": "2022-01-19T18:03:00Z",
      "mergedAt": "2022-01-19T18:03:00Z",
      "mergedBy": "ekr",
      "mergeCommit": {
        "oid": "c22133be23c391406d1dabfca602561057038eaa"
      },
      "comments": [
        {
          "author": "ekr",
          "authorAssociation": "COLLABORATOR",
          "body": "LGTM",
          "createdAt": "2022-01-19T18:02:55Z",
          "updatedAt": "2022-01-19T18:02:55Z"
        }
      ],
      "reviews": [
        {
          "id": "PRR_kwDOFEJYQs4zFuwh",
          "commit": {
            "abbreviatedOid": "e1a91b5"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "",
          "createdAt": "2022-01-19T17:40:08Z",
          "updatedAt": "2022-01-19T17:40:08Z",
          "comments": []
        }
      ]
    },
    {
      "number": 184,
      "id": "PR_kwDOFEJYQs4xaP-4",
      "title": "Redefine `Interval` to invalid values impossible",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/pull/184",
      "state": "MERGED",
      "author": "tgeoghegan",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "While reviewing #179, @cjpatton and I figured out a way to redefine\r\n`struct Interval` so that invalid values cannot be represented[1].\r\n\r\nThe existing representation contains `Time start` and `Time end`, which\r\nmeans an interval could be defined with `end < start`, which is invalid.\r\nRedefining `Interval` as a start instant and a duration makes it\r\nimpossible to represent invalid `Interval`s (since `Duration` is an\r\nunsigned integer).\r\n\r\nAdditionally, this implicitly fixes a bug in the batch interval validation\r\nlogic: we asserted that `batch_interval.end` should be divisible by\r\n`min_batch_interval`, but since `end` is _excluded_ from the `Interval`, I\r\nthink that was incorrect. Instead, `batch_interval.end - 1` should be divisible\r\nby `min_batch_duration`. In any case, this is simpler with the new\r\ndefinition of `Interval`: `Interval.duration` needs to be a multiple of\r\n`min_batch_duration`.\r\n\r\n[1]: https://github.com/abetterinternet/ppm-specification/pull/179#discussion_r789340693",
      "createdAt": "2022-01-21T21:43:40Z",
      "updatedAt": "2022-01-22T15:05:24Z",
      "baseRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "baseRefName": "main",
      "baseRefOid": "b202eaaa4c5544bd3f9cac19af37bcdcadcf7996",
      "headRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "headRefName": "timg/errorproof-duration",
      "headRefOid": "a619f04a96ea7606addc38ebe677af5841509148",
      "closedAt": "2022-01-22T15:05:24Z",
      "mergedAt": "2022-01-22T15:05:24Z",
      "mergedBy": "chris-wood",
      "mergeCommit": {
        "oid": "0f0a2a22b6ee02c12244beb2e08b50699bd31214"
      },
      "comments": [],
      "reviews": [
        {
          "id": "PRR_kwDOFEJYQs4zQ43z",
          "commit": {
            "abbreviatedOid": "a619f04"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "",
          "createdAt": "2022-01-21T21:56:13Z",
          "updatedAt": "2022-01-21T21:56:13Z",
          "comments": []
        },
        {
          "id": "PRR_kwDOFEJYQs4zQ7Bw",
          "commit": {
            "abbreviatedOid": "a619f04"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "Nice!",
          "createdAt": "2022-01-21T22:09:44Z",
          "updatedAt": "2022-01-21T22:09:44Z",
          "comments": []
        }
      ]
    },
    {
      "number": 186,
      "id": "PR_kwDOFEJYQs4xci3z",
      "title": "Remove .targets.mk",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/pull/186",
      "state": "MERGED",
      "author": "cjpatton",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "This never needed to be checked, and `make` overwrites it every time you\r\nbuild the doc.",
      "createdAt": "2022-01-22T17:43:42Z",
      "updatedAt": "2022-01-24T16:08:49Z",
      "baseRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "baseRefName": "main",
      "baseRefOid": "0f0a2a22b6ee02c12244beb2e08b50699bd31214",
      "headRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "headRefName": "cjpatton/remove-targets-mk",
      "headRefOid": "9d7b073ae063a77132154d309a03f184c9bdb178",
      "closedAt": "2022-01-24T16:08:49Z",
      "mergedAt": "2022-01-24T16:08:49Z",
      "mergedBy": "cjpatton",
      "mergeCommit": {
        "oid": "557b887eb02c641608e9e5eaab34615744fc0c57"
      },
      "comments": [],
      "reviews": [
        {
          "id": "PRR_kwDOFEJYQs4zRgcW",
          "commit": {
            "abbreviatedOid": "9d7b073"
          },
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "",
          "createdAt": "2022-01-22T17:47:24Z",
          "updatedAt": "2022-01-22T17:47:24Z",
          "comments": []
        }
      ]
    },
    {
      "number": 193,
      "id": "PR_kwDOFEJYQs4zssV8",
      "title": "Make collect requests asynchronous",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/pull/193",
      "state": "MERGED",
      "author": "tgeoghegan",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "Make the handling of collect requests on the leader asynchronous, since\r\nservicing a collect request could entail running the preparation\r\nprotocol over all the reports that fall into the batch interval,\r\nespecially in VDAFs like poplar1 where the aggregation parameter is not\r\navailable until the collector provides it.\r\n\r\nI've only made the collect request handling asynchronous. My reasoning is that handling other requests synchronously should be feasible:\r\n\r\n- upload requests should only contain shares of a single report and thus never be all that big. Additionally, the client needs an explicit acknowledgement from the aggregator that the uploaded report was accepted and has been persisted.\r\n- the requests in the aggregation/preparation sub-protocol should also never get that big: even when preparing a large number of reports, the leader can choose to carve that work up into any number of aggregation jobs, each of which covers a small enough number of reports that the message sizes and processing times should be reasonable to handle in synchronous request/response exchanges. \r\n\r\nResolves #111",
      "createdAt": "2022-03-01T01:32:56Z",
      "updatedAt": "2022-03-07T18:52:42Z",
      "baseRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "baseRefName": "main",
      "baseRefOid": "29ce456d5b49020ab5af519ede0ab434f20c3827",
      "headRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "headRefName": "timg/async-collect",
      "headRefOid": "845207083f9622125ad22167b5ee3a1dc31ec599",
      "closedAt": "2022-03-07T18:52:42Z",
      "mergedAt": "2022-03-07T18:52:42Z",
      "mergedBy": "tgeoghegan",
      "mergeCommit": {
        "oid": "cb397732fa9edaba3050660927d81a9793d64377"
      },
      "comments": [
        {
          "author": "divergentdave",
          "authorAssociation": "COLLABORATOR",
          "body": "With this change, we will have two differing definitions of structs named `CollectResp`. My understanding is that clients will know which one to expect based on the URL of the request, and the status code in the response. (they will receive a URL from /collect on success, and the `collect_job` URL will return a URL with status code 202, or shares with status code 200) I think we should change one of these for clarity to the reader, i.e. `CollectCompleteResp` or `CollectJobResp`.",
          "createdAt": "2022-03-01T21:53:39Z",
          "updatedAt": "2022-03-01T21:53:39Z"
        }
      ],
      "reviews": [
        {
          "id": "PRR_kwDOFEJYQs41dl9E",
          "commit": {
            "abbreviatedOid": "6367e49"
          },
          "author": "BranLwyd",
          "authorAssociation": "COLLABORATOR",
          "state": "CHANGES_REQUESTED",
          "body": "",
          "createdAt": "2022-03-01T23:46:33Z",
          "updatedAt": "2022-03-01T23:58:31Z",
          "comments": [
            {
              "originalPosition": 52,
              "body": "Q: what's the practical reason for allowing the `collect_job` to change?",
              "createdAt": "2022-03-01T23:46:33Z",
              "updatedAt": "2022-03-01T23:58:31Z"
            },
            {
              "originalPosition": 69,
              "body": "This seems low -- do we really only want to support shares of up to 255 bytes? Notably, each EncryptedAggregateShare structure has several fields (`enc`, `payload`) that may be up to 64 KiB each, so currently a maximally-sized EncryptedAggregateShare may not fit in this vector.",
              "createdAt": "2022-03-01T23:52:42Z",
              "updatedAt": "2022-03-01T23:58:31Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs41doBc",
          "commit": {
            "abbreviatedOid": "6367e49"
          },
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2022-03-02T00:01:59Z",
          "updatedAt": "2022-03-02T00:01:59Z",
          "comments": [
            {
              "originalPosition": 69,
              "body": "Ah, that's the second time I've made that mistake! I thought this meant up to 2^8-1 `EncryptedAggregateShare` structures, but you're right, it means number of bytes. I'll make this 2^24-1 to be safe.",
              "createdAt": "2022-03-02T00:01:59Z",
              "updatedAt": "2022-03-02T00:01:59Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs41doN7",
          "commit": {
            "abbreviatedOid": "6367e49"
          },
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2022-03-02T00:03:30Z",
          "updatedAt": "2022-03-02T00:03:31Z",
          "comments": [
            {
              "originalPosition": 52,
              "body": "I didn't see a reason to require that it be the same, but I suppose we could instead insist that it always be the same. Or we could say nothing, implicitly permitting `collect_job` to change.",
              "createdAt": "2022-03-02T00:03:30Z",
              "updatedAt": "2022-03-02T00:03:31Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs41dpU6",
          "commit": {
            "abbreviatedOid": "6367e49"
          },
          "author": "BranLwyd",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "",
          "createdAt": "2022-03-02T00:12:15Z",
          "updatedAt": "2022-03-02T00:12:59Z",
          "comments": [
            {
              "originalPosition": 52,
              "body": "WDYT about having the `collect_job` handler return an HTTP 202 with an unspecified (or empty) body if the results aren't yet available? This removes the unnecessary flexibility of changing `collect_jobs` without requiring specification language.\r\n\r\nThis is pretty nit-picky; I'd personally go with an unspecified body to leave things maximally flexible while allowing us to specify later, but LGTM either way.",
              "createdAt": "2022-03-02T00:12:15Z",
              "updatedAt": "2022-03-02T00:12:59Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs41rJeK",
          "commit": {
            "abbreviatedOid": "838334e"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "CHANGES_REQUESTED",
          "body": "Mostly editorial changes. One substantive question: Would it be more appropriate to add the collect job URL as an HTTP header?",
          "createdAt": "2022-03-04T17:19:30Z",
          "updatedAt": "2022-03-04T17:32:20Z",
          "comments": [
            {
              "originalPosition": 12,
              "body": "```suggestion\r\nguaranteed.  In fact, for some VDAFs, it is not be possible to begin preparing inputs\r\n```",
              "createdAt": "2022-03-04T17:19:30Z",
              "updatedAt": "2022-03-04T17:32:20Z"
            },
            {
              "originalPosition": 14,
              "body": "```suggestion\r\nthese reasons, collect requests are handled asynchronously.\r\n```",
              "createdAt": "2022-03-04T17:20:03Z",
              "updatedAt": "2022-03-04T17:32:20Z"
            },
            {
              "originalPosition": 61,
              "body": "```suggestion\r\nWhen both aggregator's shares are successfully obtained, the leader\r\n```",
              "createdAt": "2022-03-04T17:26:27Z",
              "updatedAt": "2022-03-04T17:32:20Z"
            },
            {
              "originalPosition": 36,
              "body": "Is sending a binary-encoded response with the URL necessary/desirable? What about just adding the URL as an HTTP header? What does ACME do here?",
              "createdAt": "2022-03-04T17:27:50Z",
              "updatedAt": "2022-03-04T17:32:20Z"
            },
            {
              "originalPosition": 52,
              "body": "Allowing the collect job URL to change seems to add some complexity. If we don't need this complexity, than I suggest we remove it. In particular,  I'd propose removing this optional behavior.",
              "createdAt": "2022-03-04T17:29:48Z",
              "updatedAt": "2022-03-04T17:32:20Z"
            },
            {
              "originalPosition": 69,
              "body": "Why the size increase here? It seems unlikely to me that we'll ever have aggregate shares larger than 2^16 - 1 bytes.",
              "createdAt": "2022-03-04T17:31:01Z",
              "updatedAt": "2022-03-04T17:32:20Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs41r2mT",
          "commit": {
            "abbreviatedOid": "838334e"
          },
          "author": "ekr",
          "authorAssociation": "COLLABORATOR",
          "state": "CHANGES_REQUESTED",
          "body": "",
          "createdAt": "2022-03-04T20:25:57Z",
          "updatedAt": "2022-03-04T20:56:52Z",
          "comments": [
            {
              "originalPosition": 36,
              "body": "I would add a TODO just to get this done.",
              "createdAt": "2022-03-04T20:25:57Z",
              "updatedAt": "2022-03-04T20:56:52Z"
            },
            {
              "originalPosition": 40,
              "body": "This SHOULD seems odd. If this is a real attack then there should be a MUST requiring high entropy.\r\n\r\nI'm also not clear what an \"enumeration\" attack is. Presumably the leader has an access control mechanism, so what does it matter if I try /results/1 and get permission denied? And if it's supposed to prevent me knowing how many jobs there are, then I think this needs to be entirely unpredictable.",
              "createdAt": "2022-03-04T20:30:14Z",
              "updatedAt": "2022-03-04T20:56:52Z"
            },
            {
              "originalPosition": 52,
              "body": "I prefer @BranLwyd's suggestion here. Note that otherwise we have weird race conditions.",
              "createdAt": "2022-03-04T20:31:49Z",
              "updatedAt": "2022-03-04T20:56:52Z"
            },
            {
              "originalPosition": 85,
              "body": "I see why you are doing this and you have to for E2E reasons, but this seems hard to operationalize. I sugegest that instead we want a delete.",
              "createdAt": "2022-03-04T20:56:43Z",
              "updatedAt": "2022-03-04T20:56:52Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs41rqgw",
          "commit": {
            "abbreviatedOid": "838334e"
          },
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2022-03-04T19:43:30Z",
          "updatedAt": "2022-03-04T21:11:09Z",
          "comments": [
            {
              "originalPosition": 36,
              "body": "ACME delivers such URLs in response bodies, but it uses JSON to encode messages. For example, see the [`Order` object](https://datatracker.ietf.org/doc/html/rfc8555#section-7.1.3), which contains URLs that the client can hit for authorizations, to finalize an order and to eventually get the certificate.\r\n\r\nI agree that binary encoding of the URL seems unfortunate here. Maybe we can use an HTTP redirect with a `Location` header. [HTTP 303 See Other](https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/303) seems it has the semantics we want. I'll read up on that and rewrite this to use that.",
              "createdAt": "2022-03-04T19:43:30Z",
              "updatedAt": "2022-03-04T21:11:09Z"
            },
            {
              "originalPosition": 52,
              "body": "I will incorporate Bran's idea.",
              "createdAt": "2022-03-04T21:10:10Z",
              "updatedAt": "2022-03-04T21:11:09Z"
            },
            {
              "originalPosition": 40,
              "body": "You're right, it makes more sense to assume this is authenticated. I'll delete this text.",
              "createdAt": "2022-03-04T21:10:30Z",
              "updatedAt": "2022-03-04T21:11:09Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs41sHrh",
          "commit": {
            "abbreviatedOid": "1c7d715"
          },
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "Per @chris-wood's observation, I put the `OPEN ISSUE` about collector to leader auth back in. I also went with HTTP 303 See Other over the previous CollectResp. I suspect we still need to say something about how long a leader should retain aggregate shares, in case the collector never sends the DELETE. @divergentdave suggested that we might put retention period parameters for reports, aggregate shares and other persistently stored data into a PPM task's parameters, which would allow us to punt the problem of picking retention problems to deployments and to write clear protocol text about what to do.",
          "createdAt": "2022-03-04T22:00:16Z",
          "updatedAt": "2022-03-04T22:06:29Z",
          "comments": [
            {
              "originalPosition": 85,
              "body": "I consulted ACME for inspiration here: [Section 7.4.2 Downloading the Certificate](https://datatracker.ietf.org/doc/html/rfc8555#section-7.4.2). ACME doesn't specify how long the certificate should be available for at all (and technically allows an ACME server to _never_ provide the cert). Maybe we can get away with saying nothing, too. In any case I wrote up the DELETE idea.",
              "createdAt": "2022-03-04T22:00:16Z",
              "updatedAt": "2022-03-04T22:06:29Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs41sLwD",
          "commit": {
            "abbreviatedOid": "fb3c3bd"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "Nicely done.",
          "createdAt": "2022-03-04T22:21:46Z",
          "updatedAt": "2022-03-04T22:21:46Z",
          "comments": []
        },
        {
          "id": "PRR_kwDOFEJYQs41w74u",
          "commit": {
            "abbreviatedOid": "fb3c3bd"
          },
          "author": "divergentdave",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "",
          "createdAt": "2022-03-07T17:29:59Z",
          "updatedAt": "2022-03-07T17:31:21Z",
          "comments": [
            {
              "originalPosition": 100,
              "body": "```suggestion\r\n- CollectResult {{pa-collect}}: \"message/ppm-collect-result\"\r\n```",
              "createdAt": "2022-03-07T17:29:59Z",
              "updatedAt": "2022-03-07T17:31:21Z"
            }
          ]
        }
      ]
    },
    {
      "number": 194,
      "id": "PR_kwDOFEJYQs4zwlwG",
      "title": "Add checksum & report_count to aggregation share requests.",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/pull/194",
      "state": "MERGED",
      "author": "BranLwyd",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "This is intended to allow PPM implementations to discover if the leader\r\n& helper(s) have fallen out-of-sync in their views of what shares are\r\nincluded in the aggregation.\r\n\r\n\r\nNotes: it would be trivial for an adversary to generate sets of nonces that collide with one another. Since the goal is to provide a check against server malfunction, rather than a security check against malicious clients or other actors in the system, I think this is acceptable. I evaluated a number of collision-resistant multiset-hash constructions[1], but none of them were currently standardized & specifying them would be more effort than seems necessary given the goals of this checksum.\r\n\r\n[1] the most promising of which was [`LtHash`](https://eprint.iacr.org/2019/227.pdf)\r\n\r\nCloses #163.",
      "createdAt": "2022-03-01T23:16:56Z",
      "updatedAt": "2022-03-04T22:18:06Z",
      "baseRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "baseRefName": "main",
      "baseRefOid": "557b887eb02c641608e9e5eaab34615744fc0c57",
      "headRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "headRefName": "checksum",
      "headRefOid": "ccc6bb42388de5edbeb8b0fd703b6fc799f0d0c7",
      "closedAt": "2022-03-04T22:18:05Z",
      "mergedAt": "2022-03-04T22:18:05Z",
      "mergedBy": "BranLwyd",
      "mergeCommit": {
        "oid": "29ce456d5b49020ab5af519ede0ab434f20c3827"
      },
      "comments": [
        {
          "author": "divergentdave",
          "authorAssociation": "COLLABORATOR",
          "body": "The hash function wouldn't matter in that setting, as the attacker could generate a pool of a few hundred/thousand nonces and their hashes, fix one set of nonces, and use a system of equations over GF(2)^(digest length) to determine what the other set of nonces should be to match the checksum. Equivalently, they could start with generating a pool of nonces and hashes, treat them as vectors in GF(2)^(digest length), put them in a matrix, and find the kernel of that matrix. Pick two unique vectors that are in the kernel and have the same Hamming weight, then each entry determines whether the corresponding nonce from the pool should be included. These two vectors will give you two unique sets of nonces from the pool, such that they form two batches of the same size with the same checksum.\r\n\r\nUsing a MAC would require sorting at some point, and would preclude accumulating the checksum as each prepare request comes in, like with LtHash or this XOR construction.\r\n\r\nLong term, we need to more rigorously handle ordering of prepare and collect interactions, gracefully handling communication failures and retries between the leader and helper, and agreement on reports to be collected, but I agree this is fine for now as an error heuristic.",
          "createdAt": "2022-03-04T18:54:58Z",
          "updatedAt": "2022-03-04T18:54:58Z"
        },
        {
          "author": "BranLwyd",
          "authorAssociation": "COLLABORATOR",
          "body": "> > Notes: it would be trivial for an adversary to generate sets of nonces that collide with one another. Since the goal is to provide a check against server malfunction, rather than a security check against malicious clients or other actors in the system, I think this is acceptable.\r\n> \r\n> I agree that we don't care about a malicious aggregator here, but we do care about malicious clients. We need to think through what an attacker can do if it controls a subset of the clients and can disrupt the transmission of messages between the aggregators.\r\n> \r\n> Specifically, suppose the leader has computed the checksum\r\n> \r\n> ```\r\n> chucksum_leader = hash(N1) ^ ... ^ hash(Nb)\r\n> ```\r\n> \r\n> and the helper has computed the checksum\r\n> \r\n> ```\r\n> checksum_helper = hash(M1) ^ ... ^ hash(Mc]\r\n> ```\r\n> \r\n> where `N1, ..., Nb` and `M1, ..., Mc` are distinct sets of nonces (i.e., they differ by at least one element). Suppose further that the attacker controls the values of the nonces. The attacker's goal is to choose the nonce sets so that `checksum_leader == checksum_helper`. Thus the question is what we need to assume about `hash` to ensure that this is hard.\r\n> \r\n> It's not clear to me that this amounts to a standard assumption about cryptographic hash functions like SHA256. We might be better off using a MAC here instead.\r\n> \r\n> That said, I think it would be best to keep this change as simple as possible. I would be OK with merging as-is, so long as we add a note about the attack above in an \"OPEN ISSUE\" in the text.\r\n\r\nI think any hash function would permit an attacker to create a collision. Treating the hash function as a random oracle, the attacker could try random nonces until they find hash values that produce a basis for `Z_2^n` (where `n` is the output size of the hash in bits). I think this is expected to take right around `n` hash computations if I remember my linear algebra correctly. Then they can use this basis to select a set of nonces producing any desired checksum value. By repeating the process and finding a different basis, they can then produce a distinct set of nonces producing any desired checksum value. (I think this is similar to/the same as David's argument above.)\r\n\r\nSwapping out SHA256 for HMAC-SHA256 with the key kept secret by the aggregators would fix that particular issue since clients could no longer predict how a given nonce would contribute to the checksum; but as far as I'm aware there are no security proofs for this construction so there may be other attacks.\r\n\r\nThe lack of collision-resistance may be acceptable for two reasons IMO: (a) there are other mechanisms in PPM to make sure the aggregators are aggregating the same set of client reports, this is intended as a check against server malfunction/distributed systems errors; (b) since we are currently implementing the client-uploads-to-leader-only model, clients can't provide different sets of nonces to different aggregators. I'm still not entirely happy with it, however.\r\n\r\nI added an OPEN ISSUE and I think we should revisit this later.",
          "createdAt": "2022-03-04T22:12:43Z",
          "updatedAt": "2022-03-04T22:12:43Z"
        }
      ],
      "reviews": [
        {
          "id": "PRR_kwDOFEJYQs41dpOc",
          "commit": {
            "abbreviatedOid": "e8f6dd7"
          },
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "This would close #163. This LGTM, though I'm eager to hear what @cjpatton thinks about using XORed SHA256 here.",
          "createdAt": "2022-03-02T00:11:29Z",
          "updatedAt": "2022-03-02T00:11:29Z",
          "comments": []
        },
        {
          "id": "PRR_kwDOFEJYQs41hI5v",
          "commit": {
            "abbreviatedOid": "e8f6dd7"
          },
          "author": "divergentdave",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "",
          "createdAt": "2022-03-02T17:03:45Z",
          "updatedAt": "2022-03-02T17:35:00Z",
          "comments": [
            {
              "originalPosition": 10,
              "body": "nit:\r\n```suggestion\r\nvalues with a bitwise-XOR operation.\r\n```",
              "createdAt": "2022-03-02T17:03:45Z",
              "updatedAt": "2022-03-02T17:35:00Z"
            },
            {
              "originalPosition": 45,
              "body": "I think we will want a separate error enumeration value to signify mismatches in either the report count or the checksum. However, I note that the rest of this aggregate share request section doesn't define how errors are signaled (i.e. for invalid batch parameters, or invalid helper state) so I think it's okay to punt on this for now.",
              "createdAt": "2022-03-02T17:32:05Z",
              "updatedAt": "2022-03-02T17:35:00Z"
            },
            {
              "originalPosition": 9,
              "body": "Slight rewording for clarity:\r\n```suggestion\r\nthe batch window. The checksum is computed by taking the SHA256 hash of each\r\nnonce from the client reports included in the aggregation, then combining the hash\r\n```",
              "createdAt": "2022-03-02T17:34:48Z",
              "updatedAt": "2022-03-02T17:35:00Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs41hrta",
          "commit": {
            "abbreviatedOid": "e8f6dd7"
          },
          "author": "BranLwyd",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2022-03-02T18:55:40Z",
          "updatedAt": "2022-03-02T18:55:40Z",
          "comments": [
            {
              "originalPosition": 45,
              "body": "Indeed, I worded this PR to continue to punt on error reporting as much as error reporting was previously punted on. (but FWIW, I agree we'd want to be able to discriminate the checksum/count-mismatch error case from other error cases)",
              "createdAt": "2022-03-02T18:55:40Z",
              "updatedAt": "2022-03-02T18:55:40Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs41hr7b",
          "commit": {
            "abbreviatedOid": "e8f6dd7"
          },
          "author": "BranLwyd",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2022-03-02T18:56:29Z",
          "updatedAt": "2022-03-02T18:56:29Z",
          "comments": [
            {
              "originalPosition": 10,
              "body": "Huh, I always thought \"bytewise\" was more common than \"bitwise\", but a quick Googling shows this is not the case.",
              "createdAt": "2022-03-02T18:56:29Z",
              "updatedAt": "2022-03-02T18:56:29Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs41rVuj",
          "commit": {
            "abbreviatedOid": "6791b15"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "> Notes: it would be trivial for an adversary to generate sets of nonces that collide with one another. Since the goal is to provide a check against server malfunction, rather than a security check against malicious clients or other actors in the system, I think this is acceptable.\r\n\r\nI agree that we don't care about a malicious aggregator here, but we do care about malicious clients. We need to think through what an attacker can do if it controls a subset of the clients and can disrupt the transmission of messages between the aggregators.\r\n\r\nSpecifically, suppose the leader has computed the checksum\r\n\r\n```\r\nchucksum_leader = hash(N1) ^ ... ^ hash(Nb)\r\n```\r\n\r\nand the helper has computed the checksum\r\n\r\n```\r\nchecksum_helper = hash(M1) ^ ... ^ hash(Mc]\r\n```\r\n\r\nwhere `N1, ..., Nb` and `M1, ..., Mc` are distinct sets of nonces (i.e., they differ by at least one element).  Suppose further that the attacker controls the values of the nonces. The attacker's goal is to choose the nonce sets so that `checksum_leader == checksum_helper`. Thus the question is what we need to assume about `hash` to ensure that this is hard.\r\n\r\nIt's not clear to me that this amounts to a standard assumption about cryptographic hash functions like SHA256. We might be better off using a MAC here instead.\r\n\r\nThat said, I think it would be best to keep this change as simple as possible. I would be OK with merging as-is, so long as we add a note about the attack above in an \"OPEN ISSUE\" in the text.",
          "createdAt": "2022-03-04T18:10:24Z",
          "updatedAt": "2022-03-04T18:10:24Z",
          "comments": []
        },
        {
          "id": "PRR_kwDOFEJYQs41sCOc",
          "commit": {
            "abbreviatedOid": "6791b15"
          },
          "author": "ekr",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "LGTM at least provisionally.",
          "createdAt": "2022-03-04T21:27:34Z",
          "updatedAt": "2022-03-04T21:28:06Z",
          "comments": [
            {
              "originalPosition": 10,
              "body": "I don't object to this, really, but it seems like kind of overkill to use SHA-256.",
              "createdAt": "2022-03-04T21:27:34Z",
              "updatedAt": "2022-03-04T21:28:06Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs41sKGc",
          "commit": {
            "abbreviatedOid": "6791b15"
          },
          "author": "BranLwyd",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2022-03-04T22:12:40Z",
          "updatedAt": "2022-03-04T22:12:40Z",
          "comments": [
            {
              "originalPosition": 10,
              "body": "I agree, a non-cryptographic hash would be fine here IMO since we think we don't need a collision-resistant checksum, since the overall construction permits attackers to produce collisions anyway, and since using a cryptographic hash may give the false impression that the overall construction is actually secure.\r\n\r\nI'm going to leave the OPEN ISSUE for now but we should consider addressing this -- either switching to a `checksum` algorithm that actually does provide collision-resistance over the set of nonces, or switch away from using cryptographic-strength primitives entirely.",
              "createdAt": "2022-03-04T22:12:40Z",
              "updatedAt": "2022-03-04T22:14:21Z"
            }
          ]
        }
      ]
    },
    {
      "number": 196,
      "id": "PR_kwDOFEJYQs4z-tEm",
      "title": "Small terminology fixes",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/pull/196",
      "state": "MERGED",
      "author": "divergentdave",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "Here are a few small editorial changes:\r\n\r\n- Refer to TLS's \"presentation language\", per section 3 of the RFC.\r\n- The output `enc` from the HPKE setup function is an encapsulated key, not an encapsulated context. The term context is defined as \"A context is an implementation-specific structure...\", whereas `enc` is alternately described as \"an encapsulated KEM shared secret\", an \"encapsulated key\", or a \"KEM encapsulated key\".\r\n- Remove stray whitespace from a hyphenated word.",
      "createdAt": "2022-03-04T23:08:28Z",
      "updatedAt": "2022-03-07T18:56:13Z",
      "baseRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "baseRefName": "main",
      "baseRefOid": "29ce456d5b49020ab5af519ede0ab434f20c3827",
      "headRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "headRefName": "david/terminology-fixes",
      "headRefOid": "ceb09e158daa239ddd127349efab2c54daf14bc2",
      "closedAt": "2022-03-07T18:53:09Z",
      "mergedAt": "2022-03-07T18:53:09Z",
      "mergedBy": "tgeoghegan",
      "mergeCommit": {
        "oid": "74d02295233c8d222a25be78b9828751ff3642b2"
      },
      "comments": [],
      "reviews": [
        {
          "id": "PRR_kwDOFEJYQs41sfCO",
          "commit": {
            "abbreviatedOid": "ceb09e1"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "One non-blocking comment.",
          "createdAt": "2022-03-05T01:37:50Z",
          "updatedAt": "2022-03-05T01:38:36Z",
          "comments": [
            {
              "originalPosition": 14,
              "body": "This is sometimes referred to as the \"encapsulated context\", since it's used to construct an HPKE context. That said, I'm fine with this change.",
              "createdAt": "2022-03-05T01:37:50Z",
              "updatedAt": "2022-03-05T01:38:36Z"
            }
          ]
        }
      ]
    },
    {
      "number": 197,
      "id": "PR_kwDOFEJYQs4z-wev",
      "title": "Add HMAC-SHA256 tag to all Request/Response messages.",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/pull/197",
      "state": "MERGED",
      "author": "BranLwyd",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "Previously these were inconsistently applied between different messages.\r\nI introduce a new `collect_auth_key`, distinct from the existing\r\n`agg_auth_key`, for collect messages.\r\n\r\nI think we could get away with only authenticating the request messages\r\n(leaning on TLS to provide authentication for the responses); I'd be\r\namenable to that, but my understanding is that we don't want to rely on\r\nthe properties of the underlying channel, so I went ahead and specified\r\nauthentication tags for both request & response messages.",
      "createdAt": "2022-03-04T23:49:37Z",
      "updatedAt": "2022-03-08T17:01:21Z",
      "baseRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "baseRefName": "cjpatton-tgeoghegan/draft-interop-target",
      "baseRefOid": "d8c6677eb02284721195643fb95f4b07eb7be6dd",
      "headRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "headRefName": "tags-for-everything",
      "headRefOid": "49110a3c3c77dc749e77fb76bb4d1908ec3969f1",
      "closedAt": "2022-03-08T17:01:21Z",
      "mergedAt": "2022-03-08T17:01:21Z",
      "mergedBy": "BranLwyd",
      "mergeCommit": {
        "oid": "71b7eced785a5dada6d9b581652070dba023325c"
      },
      "comments": [
        {
          "author": "BranLwyd",
          "authorAssociation": "COLLABORATOR",
          "body": "> Tagging the AggregateShareReq with the key shared by the aggregators makes sense. (The fact that this was missing was an oversight.)\r\n> \r\n> However I think we should sync up before making changes to the collect flow. I envisioned using mutual TLS for this, Mozilla might have a different idea.\r\n\r\nOK, I've removed the `tag` from the `Collect{Req,Resp}` for now. mTLS would work too, and I'll be happy to go with whatever is determined by group consensus.",
          "createdAt": "2022-03-07T17:14:23Z",
          "updatedAt": "2022-03-07T17:14:23Z"
        }
      ],
      "reviews": [
        {
          "id": "PRR_kwDOFEJYQs41sfF9",
          "commit": {
            "abbreviatedOid": "6e627fa"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "CHANGES_REQUESTED",
          "body": "Tagging the AggregateShareReq with the key shared by the aggregators makes sense. (The fact that this was missing was an oversight.)\r\n\r\nHowever I think we should sync up before making changes to the collect flow. I envisioned using mutual TLS for this, Mozilla might have a different idea.",
          "createdAt": "2022-03-05T01:39:23Z",
          "updatedAt": "2022-03-05T01:46:02Z",
          "comments": [
            {
              "originalPosition": 6,
              "body": "This key would only need to be shared by the collector and leader. The helper doesn't need this key, does it?",
              "createdAt": "2022-03-05T01:39:23Z",
              "updatedAt": "2022-03-05T01:46:02Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs41w1jK",
          "commit": {
            "abbreviatedOid": "6e627fa"
          },
          "author": "BranLwyd",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2022-03-07T17:11:17Z",
          "updatedAt": "2022-03-07T17:11:17Z",
          "comments": [
            {
              "originalPosition": 6,
              "body": "That's correct, this should have specified \"the leader and the collector\" rather than \"the aggregators and the collector\".",
              "createdAt": "2022-03-07T17:11:17Z",
              "updatedAt": "2022-03-07T17:11:17Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs41xCU8",
          "commit": {
            "abbreviatedOid": "49110a3"
          },
          "author": "divergentdave",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "",
          "createdAt": "2022-03-07T17:52:25Z",
          "updatedAt": "2022-03-07T17:52:25Z",
          "comments": []
        },
        {
          "id": "PRR_kwDOFEJYQs41xgVR",
          "commit": {
            "abbreviatedOid": "49110a3"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "",
          "createdAt": "2022-03-07T19:43:00Z",
          "updatedAt": "2022-03-07T19:43:00Z",
          "comments": []
        }
      ]
    },
    {
      "number": 198,
      "id": "PR_kwDOFEJYQs40M2Vd",
      "title": "fix HPKE info strings and specify agg share handling",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/pull/198",
      "state": "MERGED",
      "author": "tgeoghegan",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "The info strings used in HPKE context construction used the prefix\r\n\"pda\", referring to the old \"Private Data Aggregation\" name of this\r\nprotocol. This commit also adds text instructing the collector how to\r\ndecrypt the aggregate shares it receives and to use the VDAF's\r\nunsharding algorithm to obtain aggregate results.",
      "createdAt": "2022-03-09T22:15:52Z",
      "updatedAt": "2022-03-15T21:54:55Z",
      "baseRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "baseRefName": "main",
      "baseRefOid": "74d02295233c8d222a25be78b9828751ff3642b2",
      "headRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "headRefName": "timg/hpke-app-info",
      "headRefOid": "c62b2d3b69b493dcc332109a656a78e42114cedf",
      "closedAt": "2022-03-15T21:54:55Z",
      "mergedAt": "2022-03-15T21:54:55Z",
      "mergedBy": "cjpatton",
      "mergeCommit": {
        "oid": "f469f5ed1e24eafe00b6cf533158c0c97610bb88"
      },
      "comments": [
        {
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "body": "Question for the reviewers: VDAF defines labels like `vdaf-00 prio3` ([VDAF sharding spec](https://cjpatton.github.io/vdaf/draft-patton-cfrg-vdaf.html#section-6.2.2)). Should we include the draft version number in info strings like this? e.g. `ppm-01 input share`?",
          "createdAt": "2022-03-09T22:23:37Z",
          "updatedAt": "2022-03-09T22:23:37Z"
        }
      ],
      "reviews": [
        {
          "id": "PRR_kwDOFEJYQs418kCu",
          "commit": {
            "abbreviatedOid": "c62b2d3"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "LGTM!\r\n\r\n> Question for the reviewers: VDAF defines labels like `vdaf-00 prio3` ([VDAF sharding spec](https://cjpatton.github.io/vdaf/draft-patton-cfrg-vdaf.html#section-6.2.2)). Should we include the draft version number in info strings like this? e.g. `ppm-01 input share`?\r\n\r\nI'd be in favor of this, though we might want to go with `ppm-00` since `00` will be the first draft of the WG doc when it gets adopted.",
          "createdAt": "2022-03-09T22:35:02Z",
          "updatedAt": "2022-03-09T22:35:02Z",
          "comments": []
        },
        {
          "id": "PRR_kwDOFEJYQs418ka9",
          "commit": {
            "abbreviatedOid": "c62b2d3"
          },
          "author": "BranLwyd",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2022-03-09T22:35:48Z",
          "updatedAt": "2022-03-09T22:42:25Z",
          "comments": [
            {
              "originalPosition": 42,
              "body": "While this works, wouldn't it be more natural to specify `0x00` for the leader and `0x01` for the helper? This would permit a more natural extension to multiple helpers (which would be able to use `0x02`, `0x03`, ... without placing the leader between the first and second helpers) and would cause these role identifier numbers to match up with the ordering of the input shares in a client report, aggregate shares in an collect result, etc.\r\n\r\n(I think this may be somewhat beyond the scope of this individual PR, is this an issue that has been discussed? I notice the interop PR specifies a Role message that has not only the leader & helper but also the collector & client.)",
              "createdAt": "2022-03-09T22:35:48Z",
              "updatedAt": "2022-03-09T22:42:25Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs418mvT",
          "commit": {
            "abbreviatedOid": "c62b2d3"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2022-03-09T22:44:29Z",
          "updatedAt": "2022-03-09T22:44:29Z",
          "comments": [
            {
              "originalPosition": 42,
              "body": "Yeah I think this would be a good change, but it should go in a different PR as you suggest.",
              "createdAt": "2022-03-09T22:44:29Z",
              "updatedAt": "2022-03-09T22:44:30Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs418tQb",
          "commit": {
            "abbreviatedOid": "c62b2d3"
          },
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2022-03-09T23:23:21Z",
          "updatedAt": "2022-03-09T23:23:22Z",
          "comments": [
            {
              "originalPosition": 42,
              "body": "I'd be open to back-porting the language around this from PR #179. There we put leader and helper as `0x02` and `0x03` so that we can allow further helpers to be `0x04` and above, and also extend the info string to include the roles of both sender and recipient. I think that change should be fairly non-controversial, and it'll make it easier to eventually land #179 if we chip little bits of it out.",
              "createdAt": "2022-03-09T23:23:22Z",
              "updatedAt": "2022-03-09T23:23:22Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs418wAd",
          "commit": {
            "abbreviatedOid": "c62b2d3"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2022-03-09T23:30:24Z",
          "updatedAt": "2022-03-09T23:30:25Z",
          "comments": [
            {
              "originalPosition": 42,
              "body": "Good catch, @tgeoghegan ",
              "createdAt": "2022-03-09T23:30:24Z",
              "updatedAt": "2022-03-09T23:30:25Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs41_-KJ",
          "commit": {
            "abbreviatedOid": "c62b2d3"
          },
          "author": "divergentdave",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "",
          "createdAt": "2022-03-10T14:57:14Z",
          "updatedAt": "2022-03-10T15:08:41Z",
          "comments": [
            {
              "originalPosition": 41,
              "body": "```suggestion\r\n`server_role` is the role of the server that sent the aggregate share (`0x01`\r\n```",
              "createdAt": "2022-03-10T14:57:15Z",
              "updatedAt": "2022-03-10T15:08:41Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs42F6Wh",
          "commit": {
            "abbreviatedOid": "c62b2d3"
          },
          "author": "BranLwyd",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "",
          "createdAt": "2022-03-11T17:28:21Z",
          "updatedAt": "2022-03-11T17:28:26Z",
          "comments": [
            {
              "originalPosition": 42,
              "body": "Backporting this from the interop PR when it is merged into main SGTM.",
              "createdAt": "2022-03-11T17:28:21Z",
              "updatedAt": "2022-03-11T17:28:26Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs42SjPP",
          "commit": {
            "abbreviatedOid": "c62b2d3"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "",
          "createdAt": "2022-03-15T21:06:50Z",
          "updatedAt": "2022-03-15T21:06:50Z",
          "comments": []
        }
      ]
    },
    {
      "number": 199,
      "id": "PR_kwDOFEJYQs40NPJI",
      "title": "Editorial nits",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/pull/199",
      "state": "MERGED",
      "author": "cjpatton",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "Nits for the interop PR.",
      "createdAt": "2022-03-10T00:55:56Z",
      "updatedAt": "2022-03-10T16:00:50Z",
      "baseRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "baseRefName": "cjpatton-tgeoghegan/draft-interop-target",
      "baseRefOid": "71b7eced785a5dada6d9b581652070dba023325c",
      "headRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "headRefName": "cjpatotn/interop-nits",
      "headRefOid": "8bd1d91fea1421c05e89517347a51a45014700c0",
      "closedAt": "2022-03-10T16:00:50Z",
      "mergedAt": "2022-03-10T16:00:49Z",
      "mergedBy": "cjpatton",
      "mergeCommit": {
        "oid": "02ce5110e30ab34c1969bdfcd3fe618e1ff3468a"
      },
      "comments": [],
      "reviews": [
        {
          "id": "PRR_kwDOFEJYQs41_3dz",
          "commit": {
            "abbreviatedOid": "8bd1d91"
          },
          "author": "divergentdave",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "",
          "createdAt": "2022-03-10T14:40:30Z",
          "updatedAt": "2022-03-10T14:40:30Z",
          "comments": []
        }
      ]
    },
    {
      "number": 200,
      "id": "PR_kwDOFEJYQs40Ql33",
      "title": "Allow the extensions list to be empty",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/pull/200",
      "state": "MERGED",
      "author": "divergentdave",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "Currently, the minimum allowed length of the extensions vector is four bytes, which is exactly enough to encode one `Extension` containing a type and an `extension_data` of zero bytes. It appears this is in error, as we would like clients to be able to encode an empty vector of extensions in the normal case.",
      "createdAt": "2022-03-10T19:30:54Z",
      "updatedAt": "2022-03-10T21:11:01Z",
      "baseRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "baseRefName": "main",
      "baseRefOid": "74d02295233c8d222a25be78b9828751ff3642b2",
      "headRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "headRefName": "david/empty-extensions-list",
      "headRefOid": "49f7716f4800aa208871f290fa7436f06d9e65a3",
      "closedAt": "2022-03-10T21:10:57Z",
      "mergedAt": "2022-03-10T21:10:57Z",
      "mergedBy": "divergentdave",
      "mergeCommit": {
        "oid": "c7ad24e2ea42dc9d3b125cb8228aaa4384ccc8b5"
      },
      "comments": [],
      "reviews": [
        {
          "id": "PRR_kwDOFEJYQs42BymY",
          "commit": {
            "abbreviatedOid": "49f7716"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "",
          "createdAt": "2022-03-10T20:48:08Z",
          "updatedAt": "2022-03-10T20:48:08Z",
          "comments": []
        },
        {
          "id": "PRR_kwDOFEJYQs42B4CO",
          "commit": {
            "abbreviatedOid": "49f7716"
          },
          "author": "BranLwyd",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "",
          "createdAt": "2022-03-10T21:07:31Z",
          "updatedAt": "2022-03-10T21:07:31Z",
          "comments": []
        }
      ]
    },
    {
      "number": 201,
      "id": "PR_kwDOFEJYQs40Q1p2",
      "title": "Rename CollectResult to CollectResp.",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/pull/201",
      "state": "MERGED",
      "author": "BranLwyd",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "CollectResp is paired with CollectReq; naming things this way matches\r\nother {Req, Resp} message pairs.",
      "createdAt": "2022-03-10T20:56:23Z",
      "updatedAt": "2022-03-10T21:06:20Z",
      "baseRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "baseRefName": "main",
      "baseRefOid": "74d02295233c8d222a25be78b9828751ff3642b2",
      "headRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "headRefName": "collect-result-to-resp",
      "headRefOid": "defc48f8dbcd3e74dbaca3f23de9c6cd608ae77f",
      "closedAt": "2022-03-10T21:06:20Z",
      "mergedAt": "2022-03-10T21:06:20Z",
      "mergedBy": "BranLwyd",
      "mergeCommit": {
        "oid": "8de0e04f5ec474a5224554921e299018b58e1f54"
      },
      "comments": [],
      "reviews": [
        {
          "id": "PRR_kwDOFEJYQs42B2K_",
          "commit": {
            "abbreviatedOid": "defc48f"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "",
          "createdAt": "2022-03-10T21:01:24Z",
          "updatedAt": "2022-03-10T21:01:24Z",
          "comments": []
        }
      ]
    },
    {
      "number": 203,
      "id": "PR_kwDOFEJYQs40a2-B",
      "title": "Interop: Error handling and editorial things",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/pull/203",
      "state": "MERGED",
      "author": "cjpatton",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "",
      "createdAt": "2022-03-14T19:52:43Z",
      "updatedAt": "2022-03-15T21:54:28Z",
      "baseRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "baseRefName": "cjpatton-tgeoghegan/draft-interop-target",
      "baseRefOid": "97b6a3431b14953b1ea0ee19b5409cbcfb3b8faf",
      "headRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "headRefName": "cjpatton/interop-agg-order",
      "headRefOid": "0d7fdcc23cfc4ea8c4a2dfb671430171745d038e",
      "closedAt": "2022-03-15T21:54:28Z",
      "mergedAt": "2022-03-15T21:54:28Z",
      "mergedBy": "cjpatton",
      "mergeCommit": {
        "oid": "f7017a203f4fe7f13a710f7cb6491923eed925c3"
      },
      "comments": [],
      "reviews": [
        {
          "id": "PRR_kwDOFEJYQs42M7cZ",
          "commit": {
            "abbreviatedOid": "10e8ef9"
          },
          "author": "BranLwyd",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2022-03-14T20:31:11Z",
          "updatedAt": "2022-03-14T20:48:25Z",
          "comments": [
            {
              "originalPosition": 67,
              "body": "I'm not sure I agree with the change of wording from \"observed\" to \"aggregated\" here.\r\n\r\nThere will be a gap of time from when a client upload completes to when it is first included in an aggregation job; my interpretation would be that those reports were \"observed\" (or perhaps \"received\") but not yet \"aggregated\". I think we want this error logic to cover reports that have not yet been included in an aggregation job, right?",
              "createdAt": "2022-03-14T20:31:12Z",
              "updatedAt": "2022-03-14T20:48:25Z"
            },
            {
              "originalPosition": 85,
              "body": "```suggestion\r\naggregator does not have to maintain this storage indefinitely, it MAY instead\r\n```\r\n\r\n(nit, typo fix)",
              "createdAt": "2022-03-14T20:36:55Z",
              "updatedAt": "2022-03-14T20:48:25Z"
            },
            {
              "originalPosition": 131,
              "body": "This splitting of VDAF output into two parts is new to me -- how is this to be done? e.g. is the definition of how to split the output into a tuple part of the VDAF?",
              "createdAt": "2022-03-14T20:42:12Z",
              "updatedAt": "2022-03-14T20:48:25Z"
            },
            {
              "originalPosition": 177,
              "body": "```suggestion\r\nits new preparation state and `outbound` is its next VDAF messaage, and\r\n```\r\n\r\n(nit, typo fix)",
              "createdAt": "2022-03-14T20:44:10Z",
              "updatedAt": "2022-03-14T20:48:25Z"
            },
            {
              "originalPosition": 178,
              "body": "```suggestion\r\ncontinues with `outbound` as its next VDAF message. Either way, it moves to\r\n```\r\n\r\n(nit, typo fix)",
              "createdAt": "2022-03-14T20:44:56Z",
              "updatedAt": "2022-03-14T20:48:25Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs42NCs5",
          "commit": {
            "abbreviatedOid": "10e8ef9"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2022-03-14T20:58:27Z",
          "updatedAt": "2022-03-14T21:00:59Z",
          "comments": [
            {
              "originalPosition": 67,
              "body": "Right, \"observed\" (or \"received\") is a a weaker condition than \"aggregated\": If a report has been aggregated, then it has also been observed; but if a report has been observed, it has not necessarily been aggregated.\r\n\r\nI think what we want here is \"aggregated\", for two reasons. First, it's more specific. Second, I suspect it'll be easier for servers to verify that they have agrgregated a report than it'll be for servers to verify they've observed a report, in particular because this is the aggregation endpoint.",
              "createdAt": "2022-03-14T20:58:27Z",
              "updatedAt": "2022-03-14T21:00:59Z"
            },
            {
              "originalPosition": 131,
              "body": "Yeah, this is just a matter of aligning the notation with the current draft: https://cjpatton.github.io/vdaf/draft-patton-cfrg-vdaf.html#name-preparation",
              "createdAt": "2022-03-14T21:00:49Z",
              "updatedAt": "2022-03-14T21:00:59Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs42NPId",
          "commit": {
            "abbreviatedOid": "35b1c8a"
          },
          "author": "BranLwyd",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "",
          "createdAt": "2022-03-14T21:49:01Z",
          "updatedAt": "2022-03-14T21:53:30Z",
          "comments": [
            {
              "originalPosition": 67,
              "body": "That makes sense; my only note is that the client's Upload Request section (4.2.2) refers to this section as part of a `SHOULD`, so I suppose this logic may also apply to client upload endpoints. I think this is OK since the relevant bullet point (this one) is not meaningfully changed by the wording change. This would matter for the `report-replayed` point, but that's not mentioned by the client upload section for now; we might need to deal with it later but it's fine for now.",
              "createdAt": "2022-03-14T21:49:01Z",
              "updatedAt": "2022-03-14T21:53:30Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs42NM4G",
          "commit": {
            "abbreviatedOid": "35b1c8a"
          },
          "author": "divergentdave",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2022-03-14T21:38:36Z",
          "updatedAt": "2022-03-14T22:12:21Z",
          "comments": [
            {
              "originalPosition": 32,
              "body": "Should this be referring to the response here?\r\n```suggestion\r\n* If a fatal error is encountered while processing an HTTP response, the HTTP\r\n  client... [TODO: Figure out what behavior is called for here. An HTTP request\r\n```",
              "createdAt": "2022-03-14T21:38:36Z",
              "updatedAt": "2022-03-14T22:12:21Z"
            },
            {
              "originalPosition": 176,
              "body": "typo fix:\r\n```suggestion\r\ninterprets `out` as the tuple `(new_state, outbound)`, where `new_state` is\r\n```",
              "createdAt": "2022-03-14T21:55:53Z",
              "updatedAt": "2022-03-14T22:12:21Z"
            },
            {
              "originalPosition": 179,
              "body": "I think this is incorrect, the sentence two sentences prior is about the leader finishing. (and, moreover, it should probably say that the leader moves to state `FINISHED`)\r\n```suggestion\r\ncontinues with `outbound` as its next VDAF message, moving to state WAITING.\r\n```",
              "createdAt": "2022-03-14T21:59:55Z",
              "updatedAt": "2022-03-14T22:12:21Z"
            },
            {
              "originalPosition": 260,
              "body": "nit\r\n```suggestion\r\nNext, it checks that the sequence of Transition messages corresponds to\r\n```",
              "createdAt": "2022-03-14T22:02:23Z",
              "updatedAt": "2022-03-14T22:12:21Z"
            },
            {
              "originalPosition": 262,
              "body": "I believe that \"or is missing\" conflicts with section 4.4.4.1, assuming a multi-round VDAF. That section says that the leader will filter out reports that correspond to a state of FAILED, in which case the next AggregateContinueReq would have fewer transitions/nonces/reports than the AggregateInitReq and AggregateResp that came before it.",
              "createdAt": "2022-03-14T22:11:21Z",
              "updatedAt": "2022-03-14T22:12:21Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs42NoI1",
          "commit": {
            "abbreviatedOid": "35b1c8a"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2022-03-15T00:44:18Z",
          "updatedAt": "2022-03-15T00:53:46Z",
          "comments": [
            {
              "originalPosition": 32,
              "body": "Yes, good catch.",
              "createdAt": "2022-03-15T00:44:18Z",
              "updatedAt": "2022-03-15T00:53:46Z"
            },
            {
              "originalPosition": 179,
              "body": "For the leader, \"WAITING\" means I'm waiting for the helper's Transition before either (1) I can compute my next VDAF message or (2) I commit to the output share I've just computed. Does that make sense or am I misunderstanding something?",
              "createdAt": "2022-03-15T00:49:02Z",
              "updatedAt": "2022-03-15T00:53:46Z"
            },
            {
              "originalPosition": 262,
              "body": "Hmm, maybe we just need to sharpen this a little. This paragraph pertains to the leader processing `AggregateResp`. The helper is not allowed to change the sequence of nonces relative to the previous `AggregateReq`. In particular, if a nonce is missing (relative to the previous request), then we abort.",
              "createdAt": "2022-03-15T00:53:18Z",
              "updatedAt": "2022-03-15T00:53:46Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs42Nprm",
          "commit": {
            "abbreviatedOid": "10e8ef9"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2022-03-15T00:57:59Z",
          "updatedAt": "2022-03-15T00:57:59Z",
          "comments": [
            {
              "originalPosition": 67,
              "body": "Hmm, interesting. We should to try to work this out now, if possible. I think what we want to say that, before a batch is collected, two reports with the same nonce MUST NOT be aggregated twice. Furthermore, the leader SHOULD report to the client if it attempted to upload a report with a previously observed nonce.",
              "createdAt": "2022-03-15T00:57:59Z",
              "updatedAt": "2022-03-15T00:57:59Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs42RBpy",
          "commit": {
            "abbreviatedOid": "0d7fdcc"
          },
          "author": "divergentdave",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2022-03-15T15:48:15Z",
          "updatedAt": "2022-03-15T15:48:16Z",
          "comments": [
            {
              "originalPosition": 179,
              "body": "Yes, that makes sense, thank you.",
              "createdAt": "2022-03-15T15:48:16Z",
              "updatedAt": "2022-03-15T15:48:16Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs42RC65",
          "commit": {
            "abbreviatedOid": "35b1c8a"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2022-03-15T15:51:25Z",
          "updatedAt": "2022-03-15T15:51:26Z",
          "comments": [
            {
              "originalPosition": 179,
              "body": "Yw, maybe we can be describing the state machine better...",
              "createdAt": "2022-03-15T15:51:26Z",
              "updatedAt": "2022-03-15T15:51:26Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs42RKEe",
          "commit": {
            "abbreviatedOid": "10e8ef9"
          },
          "author": "BranLwyd",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2022-03-15T16:09:28Z",
          "updatedAt": "2022-03-15T16:09:28Z",
          "comments": [
            {
              "originalPosition": 67,
              "body": "Agreed, that behavior sounds reasonable.",
              "createdAt": "2022-03-15T16:09:28Z",
              "updatedAt": "2022-03-15T16:09:28Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs42NeLA",
          "commit": {
            "abbreviatedOid": "0d7fdcc"
          },
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "While implementing upload today, I also noticed some inconsistencies between the handling of reports in the leader during the upload protocol and the helper ",
          "createdAt": "2022-03-14T23:20:43Z",
          "updatedAt": "2022-03-15T19:18:20Z",
          "comments": [
            {
              "originalPosition": 29,
              "body": "We should be constructing HTTP problem documents: https://datatracker.ietf.org/doc/html/rfc7807",
              "createdAt": "2022-03-14T23:20:43Z",
              "updatedAt": "2022-03-15T19:18:20Z"
            },
            {
              "originalPosition": 77,
              "body": "I think we need something equivalent to this in the leader's handling of the `upload` request. This gets awkward because now we have redundancy between the errors defined for the aggregate sub-protocol (`enum TransitionError`) and the errors defined in section 3.1 that can be encoded as HTTP problem documents. We should try to unify these.",
              "createdAt": "2022-03-15T19:18:15Z",
              "updatedAt": "2022-03-15T19:18:21Z"
            }
          ]
        }
      ]
    },
    {
      "number": 204,
      "id": "PR_kwDOFEJYQs40f5R3",
      "title": "Extend HPKE info strings",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/pull/204",
      "state": "MERGED",
      "author": "tgeoghegan",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "When constructing HPKE contexts, we now include both sender and\r\nrecipient roles, and the application label also includes the PPM\r\nversion. I used `ppm-02` here because we recently submitted draft-01 of\r\n`draft-gpew-priv-ppm` and so the next submitted draft, which would include\r\nthis change, will be `-02`. I also backported the definition of `struct\r\nHpkeCiphertext` from the interop PR because it makes everything tidier\r\nand should be non-controversial we can get a head-start on bringing those\r\nchanges into main.",
      "createdAt": "2022-03-15T23:02:11Z",
      "updatedAt": "2022-03-16T18:01:06Z",
      "baseRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "baseRefName": "main",
      "baseRefOid": "f469f5ed1e24eafe00b6cf533158c0c97610bb88",
      "headRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "headRefName": "timg/info-strings",
      "headRefOid": "8f03d46e2922aff3f042c59f63d8bdb7ead224c8",
      "closedAt": "2022-03-16T18:01:06Z",
      "mergedAt": "2022-03-16T18:01:06Z",
      "mergedBy": "tgeoghegan",
      "mergeCommit": {
        "oid": "5379d3ba701d36dcdb3b31be84c935541b8fcfff"
      },
      "comments": [
        {
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "body": "> There's one more instance of `EncryptedInputShare.config_id` that needs to be changed to `HpkeCiphertext.config_id`. Otherwise, LGTM.\r\n\r\nFixed, thank you! I also rewrote the relevant paragraph to acknowledge that there's two encrypted input shares and that the leader should examine the HPKE config ID of the one intended for itself. Further, I recall @cjpatton pointing out to me that should this draft get adopted by the WG, we'll reset to something like `draft-authors-ppm-ppm-01`, so `ppm-01` is the more appropriate application label.",
          "createdAt": "2022-03-16T15:39:34Z",
          "updatedAt": "2022-03-16T15:39:34Z"
        }
      ],
      "reviews": [
        {
          "id": "PRR_kwDOFEJYQs42V4Xo",
          "commit": {
            "abbreviatedOid": "4b298e7"
          },
          "author": "divergentdave",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "There's one more instance of `EncryptedInputShare.config_id` that needs to be changed to `HpkeCiphertext.config_id`. Otherwise, LGTM.",
          "createdAt": "2022-03-16T14:16:22Z",
          "updatedAt": "2022-03-16T14:16:22Z",
          "comments": []
        },
        {
          "id": "PRR_kwDOFEJYQs42W5vD",
          "commit": {
            "abbreviatedOid": "f6e8758"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "Just a few minor things.",
          "createdAt": "2022-03-16T16:52:43Z",
          "updatedAt": "2022-03-16T16:55:02Z",
          "comments": [
            {
              "originalPosition": 70,
              "body": "Assuming this gets adopted by the WG, the first draft will be \"draft-ietf-ppm-00\" (or something like that). If you take this suggestion, don't forget to apply it below.\r\n\r\n```suggestion\r\nenc, context = SetupBaseS(pk, Report.task_id || \"ppm-00 input share\" ||\r\n```",
              "createdAt": "2022-03-16T16:52:43Z",
              "updatedAt": "2022-03-16T16:55:02Z"
            },
            {
              "originalPosition": 73,
              "body": "I don't think so. I think we can drop this.",
              "createdAt": "2022-03-16T16:53:30Z",
              "updatedAt": "2022-03-16T16:55:02Z"
            },
            {
              "originalPosition": 149,
              "body": "Might be good to remind the reader here that \"0x01\" stands for the client.",
              "createdAt": "2022-03-16T16:54:19Z",
              "updatedAt": "2022-03-16T16:55:02Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs42XL6E",
          "commit": {
            "abbreviatedOid": "5cbfabd"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "",
          "createdAt": "2022-03-16T17:49:58Z",
          "updatedAt": "2022-03-16T17:49:58Z",
          "comments": []
        }
      ]
    },
    {
      "number": 205,
      "id": "PR_kwDOFEJYQs40f_Mm",
      "title": "Define leader-to-helper abort procedure.",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/pull/205",
      "state": "OPEN",
      "author": "BranLwyd",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "This solution optimizes for the size of the specification edit; if it\r\nworks out well, we should clean it up & attempt to unify this abort\r\nprocedure with the helper-to-leader abort procedure.",
      "createdAt": "2022-03-15T23:51:33Z",
      "updatedAt": "2022-03-16T19:14:20Z",
      "baseRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "baseRefName": "cjpatton-tgeoghegan/draft-interop-target",
      "baseRefOid": "f7017a203f4fe7f13a710f7cb6491923eed925c3",
      "headRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "headRefName": "brandon/aggregate-abort",
      "headRefOid": "ac459acac1b4cf9140567c0f1dd0edc77c2b7dc6",
      "closedAt": null,
      "mergedAt": null,
      "mergedBy": null,
      "mergeCommit": null,
      "comments": [
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "So I had a thought about this this morning.  I'm questioning whether we actually need a mechanism for the Leader->Heper alert. IIUC the motivation for this signal that we discussed is that helper either (1) needs to tear down the HTTP session and all associated state or (2) \u201crevert\u201d any output shares it just accepted.\r\n\r\nFor (1) I wonder if a sufficient signal is that the HTTP session has been torn down, but the aggregation run isn\u2019t complete.\r\n\r\nWe\u2019re intentionally leaving (2) out of scope for now. Regardless, I think we would handle it similar to what we're doing here, but we don't need to do it now. What do y'all think?",
          "createdAt": "2022-03-16T15:05:42Z",
          "updatedAt": "2022-03-16T15:05:42Z"
        },
        {
          "author": "BranLwyd",
          "authorAssociation": "COLLABORATOR",
          "body": "> I'm questioning whether we actually need a mechanism for the Leader->Heper alert.\r\n\r\nI think we can \"do nothing\" & ignore leader->helper alerts as long as we're OK with the helper never finding out a given aggregation job has been aborted. I don't think that causes problems with the spec & I don't think it will cause serious problems in implementations -- it seems like, at worst, we'd end up with the helper holding on to its aggregation data longer than needed.",
          "createdAt": "2022-03-16T16:26:19Z",
          "updatedAt": "2022-03-16T16:26:19Z"
        },
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "What do @tgeoghegan and @divergentdave think?",
          "createdAt": "2022-03-16T16:50:40Z",
          "updatedAt": "2022-03-16T16:50:40Z"
        },
        {
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "body": "What we discussed yesterday is that in the scope of the interop target, the only thing a helper would do with this alert is log it. I'm comfortable with not doing anything for now, on the premise that the aggregate share checksums will let us detect mismatches and we'll have a tight communication loop between aggregator operators.\r\n\r\nI do think we should keep thinking about whether we need  a Leader->Helper `AggregateCommit` message, but part of the point of the interop experiment is to find out how valuable that would be.\r\n\r\nIf you need my vote one way or the other: I say let's do nothing for interop.",
          "createdAt": "2022-03-16T17:50:23Z",
          "updatedAt": "2022-03-16T17:50:23Z"
        },
        {
          "author": "divergentdave",
          "authorAssociation": "COLLABORATOR",
          "body": "Doing nothing is fine with me. Our underlying motivation is to resolve the issue that \"alert its peer\" is not implementable in the context of a leader processing an HTTP response from a helper, and I think not sending the error message to the helper at all would be a fine way to solve this for now. The only sensible action the helper could take is to delete some of its stored state. We can address deletion of saved prepare messages in the spec at a later point, when we address adding a \"time to live\" concept for reports, etc.",
          "createdAt": "2022-03-16T18:09:31Z",
          "updatedAt": "2022-03-16T18:09:31Z"
        },
        {
          "author": "BranLwyd",
          "authorAssociation": "COLLABORATOR",
          "body": "Doing nothing is fine for me too; retracting this PR, I'll leave it as a draft for a bit in case we want to pull something out of it in the future.",
          "createdAt": "2022-03-16T19:12:28Z",
          "updatedAt": "2022-03-16T19:12:28Z"
        }
      ],
      "reviews": [
        {
          "id": "PRR_kwDOFEJYQs42XK3p",
          "commit": {
            "abbreviatedOid": "ac459ac"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "Implementation looks good.",
          "createdAt": "2022-03-16T17:46:10Z",
          "updatedAt": "2022-03-16T17:46:10Z",
          "comments": []
        }
      ]
    },
    {
      "number": 206,
      "id": "PR_kwDOFEJYQs40jMN4",
      "title": "Interop nits",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/pull/206",
      "state": "MERGED",
      "author": "cjpatton",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "Minor changes/clarifications:\r\n\r\n* Clarify how to handle empty Transition sequences\r\n* Handle repeated nonces by aborting. While at it, this changes how the helper handles unrecognized nonces to be consistent with how the leader handles unrecognized nonces.\r\n* Move task/job ID to top of AggregateReq",
      "createdAt": "2022-03-16T17:44:42Z",
      "updatedAt": "2022-03-16T20:16:12Z",
      "baseRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "baseRefName": "cjpatton-tgeoghegan/draft-interop-target",
      "baseRefOid": "f7017a203f4fe7f13a710f7cb6491923eed925c3",
      "headRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "headRefName": "cjpatton/interop-nits",
      "headRefOid": "f736eb913110c1725b6ef5757d7ad2ea8121288d",
      "closedAt": "2022-03-16T20:16:12Z",
      "mergedAt": "2022-03-16T20:16:12Z",
      "mergedBy": "cjpatton",
      "mergeCommit": {
        "oid": "6400e6bdc58eaf25afff95024de26ad1ee229cd7"
      },
      "comments": [],
      "reviews": [
        {
          "id": "PRR_kwDOFEJYQs42XOOi",
          "commit": {
            "abbreviatedOid": "423b962"
          },
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "",
          "createdAt": "2022-03-16T17:58:24Z",
          "updatedAt": "2022-03-16T18:00:35Z",
          "comments": [
            {
              "originalPosition": 56,
              "body": "nit: the usages \"first\" and \"next\" are too prescriptive on how this should be done instead of stating what property is meant to be enforced. As written this suggests a helper has to iterate over `AggregateInitReq.seq` to check for duplicate nonces, and then again to compute initial preparation state, but an implementation could do both of these in a single pass through the `seq`, aborting and discarding any computed prep states if a duplicate nonce is found. Though I don't think we should wordsmith all that here; we can debate style and wording back on `main` in the months to come.",
              "createdAt": "2022-03-16T17:58:24Z",
              "updatedAt": "2022-03-16T18:00:35Z"
            },
            {
              "originalPosition": 82,
              "body": "```suggestion\r\ncorresponding state is FAILED and proceeds as described in the next section,\r\n```",
              "createdAt": "2022-03-16T17:58:49Z",
              "updatedAt": "2022-03-16T18:00:35Z"
            },
            {
              "originalPosition": 114,
              "body": "```suggestion\r\n{{aggregate-message-auth}}, the helper begins by scanning\r\n```",
              "createdAt": "2022-03-16T17:59:39Z",
              "updatedAt": "2022-03-16T18:00:35Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs42Xo5j",
          "commit": {
            "abbreviatedOid": "423b962"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2022-03-16T19:36:20Z",
          "updatedAt": "2022-03-16T19:36:20Z",
          "comments": [
            {
              "originalPosition": 56,
              "body": "Yeah this is a very important point, but one we want to address throughout. Happy to address it here, if you like. In any case let's keep this in mind.",
              "createdAt": "2022-03-16T19:36:20Z",
              "updatedAt": "2022-03-16T19:36:20Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs42XsDH",
          "commit": {
            "abbreviatedOid": "fcacf78"
          },
          "author": "divergentdave",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "",
          "createdAt": "2022-03-16T19:48:44Z",
          "updatedAt": "2022-03-16T19:54:55Z",
          "comments": [
            {
              "originalPosition": 13,
              "body": "nit: we can remove the note below this struct now",
              "createdAt": "2022-03-16T19:48:45Z",
              "updatedAt": "2022-03-16T19:54:55Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs42XuZ5",
          "commit": {
            "abbreviatedOid": "423b962"
          },
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2022-03-16T19:57:39Z",
          "updatedAt": "2022-03-16T19:57:39Z",
          "comments": [
            {
              "originalPosition": 56,
              "body": "I don't think it's worth making changes of that nature to the text in the interop branch because it'll make the eventual merge harder. Let's just keep this in mind.",
              "createdAt": "2022-03-16T19:57:39Z",
              "updatedAt": "2022-03-16T19:57:39Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs42Xyy2",
          "commit": {
            "abbreviatedOid": "fcacf78"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2022-03-16T20:14:20Z",
          "updatedAt": "2022-03-16T20:14:20Z",
          "comments": [
            {
              "originalPosition": 13,
              "body": "Done",
              "createdAt": "2022-03-16T20:14:20Z",
              "updatedAt": "2022-03-16T20:14:20Z"
            }
          ]
        }
      ]
    },
    {
      "number": 207,
      "id": "PR_kwDOFEJYQs40x_RJ",
      "title": "Ietf113 slides",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/pull/207",
      "state": "MERGED",
      "author": "ekr",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "My slides, just FYI",
      "createdAt": "2022-03-22T02:10:31Z",
      "updatedAt": "2022-04-05T19:51:26Z",
      "baseRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "baseRefName": "main",
      "baseRefOid": "5379d3ba701d36dcdb3b31be84c935541b8fcfff",
      "headRepository": "ekr/ppm-specification",
      "headRefName": "ietf113-slides",
      "headRefOid": "85f0427aae0fabb90b0bf7e69bd2c30c8e083dc3",
      "closedAt": "2022-04-05T19:51:26Z",
      "mergedAt": "2022-04-05T19:51:26Z",
      "mergedBy": "cjpatton",
      "mergeCommit": {
        "oid": "b1893aabd606f7dcecc1a8bece8027889821ec9e"
      },
      "comments": [
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "How's about merging all of ours slides into one PDF? cc/ @chris-wood , @tgeoghegan ",
          "createdAt": "2022-03-22T02:48:42Z",
          "updatedAt": "2022-03-22T02:48:42Z"
        },
        {
          "author": "ekr",
          "authorAssociation": "COLLABORATOR",
          "body": "I'd actually rather not because it makes it hard to make last minute changes. The Chairs are fine at handling multiple slides.",
          "createdAt": "2022-03-22T02:58:25Z",
          "updatedAt": "2022-03-22T02:58:25Z"
        }
      ],
      "reviews": []
    },
    {
      "number": 208,
      "id": "PR_kwDOFEJYQs404luA",
      "title": "base64-encode TaskID in problem details JSON object",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/pull/208",
      "state": "MERGED",
      "author": "divergentdave",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "Section 3.1 says to include the PPM task ID in a field on the problem details JSON object, but the task ID may be any 32 byte value, and may not be representable as a Unicode string. I propose that we base64-encode the task ID here to resolve this.",
      "createdAt": "2022-03-23T13:56:58Z",
      "updatedAt": "2022-04-01T15:58:58Z",
      "baseRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "baseRefName": "main",
      "baseRefOid": "5379d3ba701d36dcdb3b31be84c935541b8fcfff",
      "headRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "headRefName": "david/error-task-id-base64",
      "headRefOid": "078d474529ca83cf2c770b014521f38d93361ffa",
      "closedAt": "2022-04-01T15:58:48Z",
      "mergedAt": "2022-04-01T15:58:48Z",
      "mergedBy": "divergentdave",
      "mergeCommit": {
        "oid": "684f3604bd521878e79400de59c5a1705f7cfe10"
      },
      "comments": [],
      "reviews": [
        {
          "id": "PRR_kwDOFEJYQs43IwPr",
          "commit": {
            "abbreviatedOid": "00be804"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "Good call! One clarifying comment.",
          "createdAt": "2022-03-29T18:11:35Z",
          "updatedAt": "2022-03-29T18:11:47Z",
          "comments": [
            {
              "originalPosition": 7,
              "body": "I suppose we'd need to say whether we mean \"standard\" encoding, per https://datatracker.ietf.org/doc/html/rfc4648#section-4?",
              "createdAt": "2022-03-29T18:11:35Z",
              "updatedAt": "2022-03-29T18:11:47Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs43I1rw",
          "commit": {
            "abbreviatedOid": "00be804"
          },
          "author": "divergentdave",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2022-03-29T18:31:44Z",
          "updatedAt": "2022-03-29T18:31:45Z",
          "comments": [
            {
              "originalPosition": 7,
              "body": "I was leaning on \"This encoding may be referred to as 'base64'\" when I wrote this, but I'm open to other wording. \"encoded with base64 using the standard alphabet\"?",
              "createdAt": "2022-03-29T18:31:45Z",
              "updatedAt": "2022-03-29T18:31:45Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs43I3bA",
          "commit": {
            "abbreviatedOid": "00be804"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2022-03-29T18:38:17Z",
          "updatedAt": "2022-03-29T18:38:17Z",
          "comments": [
            {
              "originalPosition": 7,
              "body": "I think the latter will be more clear in the long run.",
              "createdAt": "2022-03-29T18:38:17Z",
              "updatedAt": "2022-03-29T18:38:17Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs43YOha",
          "commit": {
            "abbreviatedOid": "078d474"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "",
          "createdAt": "2022-04-01T15:26:16Z",
          "updatedAt": "2022-04-01T15:26:16Z",
          "comments": []
        }
      ]
    },
    {
      "number": 212,
      "id": "PR_kwDOFEJYQs41nUiq",
      "title": "add a `task_id` query parameter for `hpke_config`",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/pull/212",
      "state": "MERGED",
      "author": "tgeoghegan",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "# This PR targets the interop target branch\r\n\r\nAll protocol request messages contain a `task_id` field, which allows\r\naggregators to service multiple tasks from a single set of endpoints.\r\nThe exception is `hpke_config`: since it is an HTTP GET request, there\r\nis no body, and thus no place for the client to indicate the desired\r\n`task_id` to the aggregator. We don't want to introduce a request body\r\nto `hpke_config`, because then it would have to be a POST instead of a\r\nGET, and that would make it harder for implementations to cache HPKE\r\nconfig values. So instead we have clients encode the task ID in RFC 4648\r\nBase16 (a.k.a. hexadecimal) and provide it as a query parameter.\r\n\r\nSee issue #146",
      "createdAt": "2022-04-04T21:22:54Z",
      "updatedAt": "2022-04-06T23:03:21Z",
      "baseRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "baseRefName": "cjpatton-tgeoghegan/draft-interop-target",
      "baseRefOid": "aebe375f3f7b37d1e2c240739e7f0308e01a656e",
      "headRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "headRefName": "timg/interop-hpke-config-query-param",
      "headRefOid": "dddd1c4fa567cd720e85a1a564d357207bbd6a44",
      "closedAt": "2022-04-06T23:03:21Z",
      "mergedAt": "2022-04-06T23:03:21Z",
      "mergedBy": "tgeoghegan",
      "mergeCommit": {
        "oid": "b734ac2272e58b839b8c5d5511e518e42b324956"
      },
      "comments": [
        {
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "body": "My goal here is to enable our aggregator implementations in the interop target to use one HPKE config per task. The alternative to this would be for us to use aggregator endpoints that somehow incorporate the task ID, as I described [here](https://github.com/divviup/janus/issues/48#issuecomment-1085209198), which is already permitted by the spec as written.",
          "createdAt": "2022-04-04T21:25:54Z",
          "updatedAt": "2022-04-04T21:25:54Z"
        },
        {
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "body": "> SGTM, but why not base64 encode the taskID for consistency with #208?\r\n\r\nThe Base64 alphabet includes `/`, `+` and `=`, which means you have to URL encode (a.k.a. percent encode) Base64 strings before you can use them in a URL, which is a chore and yields less readable URLs (not that 64 character hex strings is especially user-friendly). An alternative would be to use RFC 4648's [`base64url` encoding](https://datatracker.ietf.org/doc/html/rfc4648#section-5), omitting the `=` padding characters as suggested in [RFC 4648 section 3.2](https://datatracker.ietf.org/doc/html/rfc4648#section-3.2) since task IDs are of a known length.",
          "createdAt": "2022-04-04T21:38:43Z",
          "updatedAt": "2022-04-04T21:40:38Z"
        },
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "> > SGTM, but why not base64 encode the taskID for consistency with #208?\r\n> \r\n> The Base64 alphabet includes `/`, `+` and `=`, which means you have to URL encode (a.k.a. percent encode) Base64 strings before you can use them in a URL, which is a chore and yields less readable URLs (not that 64 character hex strings is especially user-friendly). An alternative would be to use RFC 4648's [`base64url` encoding](https://datatracker.ietf.org/doc/html/rfc4648#section-5).\r\n\r\nGotcha. I think the main thing is to be consistent. I would either:\r\n\r\n1. Change this PR to use base64url; or\r\n2. Tack on a commit that makes all encodings of the taskID (except those that appear in the body, of course) the same (i.e., hexadecimal).\r\n\r\nI think (2.) would be my preference.",
          "createdAt": "2022-04-04T22:04:50Z",
          "updatedAt": "2022-04-04T22:04:50Z"
        },
        {
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "body": "I agree with the consistency argument. I'm leaning towards using `base64url` everywhere because it's more compact than Base16/hex, and also I think implementations are less likely to be surprised by case requirements in base64url (i.e., it's obvious that base64 is case sensitive, but you have to read RFC 4648 attentively to notice that it mandates uppercase hex strings).",
          "createdAt": "2022-04-05T00:36:45Z",
          "updatedAt": "2022-04-05T00:36:45Z"
        },
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "Base64Url sounds good to me. I took a quick look and it appears that most standard base64 libraries also support the URL encoding.",
          "createdAt": "2022-04-05T19:54:04Z",
          "updatedAt": "2022-04-05T19:54:04Z"
        },
        {
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "body": "I will clean this up and merge it once I have implemented it in Janus and convinced myself it's sound.",
          "createdAt": "2022-04-05T20:22:01Z",
          "updatedAt": "2022-04-05T20:22:01Z"
        }
      ],
      "reviews": [
        {
          "id": "PRR_kwDOFEJYQs43fX2v",
          "commit": {
            "abbreviatedOid": "03e2114"
          },
          "author": "BranLwyd",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "",
          "createdAt": "2022-04-04T21:26:04Z",
          "updatedAt": "2022-04-04T21:26:04Z",
          "comments": []
        },
        {
          "id": "PRR_kwDOFEJYQs43fZ9S",
          "commit": {
            "abbreviatedOid": "03e2114"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "SGTM, but why not base64 encode the taskID for consistency with https://github.com/abetterinternet/ppm-specification/pull/208?",
          "createdAt": "2022-04-04T21:36:35Z",
          "updatedAt": "2022-04-04T21:36:35Z",
          "comments": []
        },
        {
          "id": "PRR_kwDOFEJYQs43rtEp",
          "commit": {
            "abbreviatedOid": "92f79f3"
          },
          "author": "divergentdave",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2022-04-06T22:13:37Z",
          "updatedAt": "2022-04-06T22:13:37Z",
          "comments": [
            {
              "originalPosition": 32,
              "body": "FYI, typo here\r\n```suggestion\r\nencoded in Base 64 with URL and filename safe alphabet with no padding, as\r\n```",
              "createdAt": "2022-04-06T22:13:37Z",
              "updatedAt": "2022-04-06T22:13:37Z"
            }
          ]
        }
      ]
    },
    {
      "number": 213,
      "id": "PR_kwDOFEJYQs411lPc",
      "title": "Ignore .DS_Store",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/pull/213",
      "state": "MERGED",
      "author": "cjpatton",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "",
      "createdAt": "2022-04-07T21:56:20Z",
      "updatedAt": "2022-04-07T22:18:57Z",
      "baseRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "baseRefName": "main",
      "baseRefOid": "b1893aabd606f7dcecc1a8bece8027889821ec9e",
      "headRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "headRefName": "cjpatton/ds-store",
      "headRefOid": "92519bc28d40955fece38f63258bb759498ea65a",
      "closedAt": "2022-04-07T22:18:57Z",
      "mergedAt": "2022-04-07T22:18:57Z",
      "mergedBy": "cjpatton",
      "mergeCommit": {
        "oid": "13baf6f2051b5ede1aa8edd82eb0614463e9c378"
      },
      "comments": [],
      "reviews": [
        {
          "id": "PRR_kwDOFEJYQs43xhaN",
          "commit": {
            "abbreviatedOid": "92519bc"
          },
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "",
          "createdAt": "2022-04-07T22:13:35Z",
          "updatedAt": "2022-04-07T22:13:35Z",
          "comments": []
        }
      ]
    },
    {
      "number": 214,
      "id": "PR_kwDOFEJYQs411oW2",
      "title": "s/UploadReq/Report/",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/pull/214",
      "state": "MERGED",
      "author": "cjpatton",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "",
      "createdAt": "2022-04-07T22:18:39Z",
      "updatedAt": "2022-04-07T22:52:59Z",
      "baseRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "baseRefName": "main",
      "baseRefOid": "b1893aabd606f7dcecc1a8bece8027889821ec9e",
      "headRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "headRefName": "cjpatton/typo",
      "headRefOid": "aed9506bff0ff1359e7320e4ede259c02d035a72",
      "closedAt": "2022-04-07T22:52:59Z",
      "mergedAt": "2022-04-07T22:52:59Z",
      "mergedBy": "cjpatton",
      "mergeCommit": {
        "oid": "3fe22c7c3ab0e33d752a09736469c1ff52753a6b"
      },
      "comments": [],
      "reviews": [
        {
          "id": "PRR_kwDOFEJYQs43xiRJ",
          "commit": {
            "abbreviatedOid": "aed9506"
          },
          "author": "divergentdave",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "",
          "createdAt": "2022-04-07T22:19:35Z",
          "updatedAt": "2022-04-07T22:19:35Z",
          "comments": []
        }
      ]
    },
    {
      "number": 219,
      "id": "PR_kwDOFEJYQs42XaHL",
      "title": "First cut of editorial changes in prep for aggregation flow",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/pull/219",
      "state": "MERGED",
      "author": "chris-wood",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "Extracted and slightly modified from [chris-wood-cjpatton/agg-flow](https://github.com/abetterinternet/ppm-specification/tree/chris-wood-cjpatton/agg-flow).",
      "createdAt": "2022-04-18T14:51:50Z",
      "updatedAt": "2022-04-20T14:09:17Z",
      "baseRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "baseRefName": "main",
      "baseRefOid": "3fe22c7c3ab0e33d752a09736469c1ff52753a6b",
      "headRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "headRefName": "caw/agg-flow-1",
      "headRefOid": "6e2af65f5c2afff6e53ca17f6be32d3b306c90bd",
      "closedAt": "2022-04-20T14:09:17Z",
      "mergedAt": "2022-04-20T14:09:17Z",
      "mergedBy": "chris-wood",
      "mergeCommit": {
        "oid": "7e9e7a534cf14c945d68be3f092396dc9cb42227"
      },
      "comments": [
        {
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "body": "(Build failure appears to be some GitHub API issue.)",
          "createdAt": "2022-04-18T14:57:22Z",
          "updatedAt": "2022-04-18T14:57:22Z"
        },
        {
          "author": "divergentdave",
          "authorAssociation": "COLLABORATOR",
          "body": "Ah, this looks like we're hitting the patch for https://github.blog/2022-04-12-git-security-vulnerability-announced/. I'll check if the upstream template repository has a fix.",
          "createdAt": "2022-04-18T15:01:17Z",
          "updatedAt": "2022-04-18T15:01:17Z"
        },
        {
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "body": "Thanks @divergentdave!",
          "createdAt": "2022-04-18T15:06:16Z",
          "updatedAt": "2022-04-18T15:06:16Z"
        }
      ],
      "reviews": [
        {
          "id": "PRR_kwDOFEJYQs44Ybid",
          "commit": {
            "abbreviatedOid": "28ff036"
          },
          "author": "divergentdave",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "",
          "createdAt": "2022-04-19T15:43:11Z",
          "updatedAt": "2022-04-19T15:43:11Z",
          "comments": []
        },
        {
          "id": "PRR_kwDOFEJYQs44Y7bc",
          "commit": {
            "abbreviatedOid": "28ff036"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "\ud83d\udea2 !",
          "createdAt": "2022-04-19T17:24:57Z",
          "updatedAt": "2022-04-19T17:24:57Z",
          "comments": []
        },
        {
          "id": "PRR_kwDOFEJYQs44ZRPE",
          "commit": {
            "abbreviatedOid": "28ff036"
          },
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2022-04-19T18:44:42Z",
          "updatedAt": "2022-04-19T18:45:41Z",
          "comments": [
            {
              "originalPosition": 25,
              "body": "I think we need a bit more than this. Suppose that a PPM task executes [`Prio3Aes128Histogram`](https://github.com/divviup/libprio-rs/blob/1bd54185d01110ff4486b8d71ed8f17f1ea77b78/src/vdaf/prio3.rs#L123). Besides that label, everyone also needs to know what the bucket boundaries are. Perhaps the PPM text should refer to VDAF's description of a [`Measurement` type](https://github.com/cjpatton/vdaf/blob/6904d4a6295da82daf7ecd09c094326db4fb8ccd/draft-patton-cfrg-vdaf.md?plain=1#L404)?",
              "createdAt": "2022-04-19T18:44:43Z",
              "updatedAt": "2022-04-19T18:45:41Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs44dZqa",
          "commit": {
            "abbreviatedOid": "28ff036"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2022-04-20T14:08:20Z",
          "updatedAt": "2022-04-20T14:08:20Z",
          "comments": [
            {
              "originalPosition": 25,
              "body": "```suggestion\r\n* A unique identifier for the VDAF instance used for the task, including the type of measurement associated with the task.\r\n```",
              "createdAt": "2022-04-20T14:08:20Z",
              "updatedAt": "2022-04-20T14:08:20Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs44daBf",
          "commit": {
            "abbreviatedOid": "28ff036"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2022-04-20T14:09:04Z",
          "updatedAt": "2022-04-20T14:09:04Z",
          "comments": [
            {
              "originalPosition": 25,
              "body": "I think this needs to be \"something that fully defines the VDAF instance you're using, modulo the parameters generated from VDAF.setup() (since those change per invocation),\" so I elaborated on this a bit.",
              "createdAt": "2022-04-20T14:09:04Z",
              "updatedAt": "2022-04-20T14:09:04Z"
            }
          ]
        }
      ]
    },
    {
      "number": 220,
      "id": "PR_kwDOFEJYQs42g_6n",
      "title": "rename document",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/pull/220",
      "state": "MERGED",
      "author": "tgeoghegan",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "The draft has been adopted by the WG and now needs a new name.\r\nAdditionally, this commit replaces references to the old repository on\r\n`abetterinternet` with the current GitHub organization.",
      "createdAt": "2022-04-20T20:13:03Z",
      "updatedAt": "2022-05-06T07:34:12Z",
      "baseRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "baseRefName": "main",
      "baseRefOid": "004020f88c38785af23adfa909e4d0c646434bb1",
      "headRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "headRefName": "timg/rename-draft",
      "headRefOid": "b230a040196ae63958ceef21418bed80d5035e89",
      "closedAt": "2022-05-03T17:43:09Z",
      "mergedAt": "2022-05-03T17:43:09Z",
      "mergedBy": "chris-wood",
      "mergeCommit": {
        "oid": "9884610ca4102df6e370f3061f9d6223b3244d9c"
      },
      "comments": [
        {
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "body": "> The protocol name should change too, right? Though that can happen later so no need to do it here and now.\r\n\r\nI'm happy to do it if you can help me find all the places it needs to be updated. Do you mean the `title` line in `draft-ietf-ppm-dap.md`, where \"Privacy Preserving Measurement\" should become \"Privacy Preserving Measurement via Distributed Aggregation Functions\"?",
          "createdAt": "2022-05-03T16:36:13Z",
          "updatedAt": "2022-05-03T16:36:13Z"
        },
        {
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "body": "Well, I thought the outcome here was that the protocol name was \"Distributed Aggregation Protocol,\" so the title would be \"Distributed Aggregation Protocol for Privacy Preserving Measurement\" or whatever. I do not feel strongly about any of this. :) ",
          "createdAt": "2022-05-03T16:43:36Z",
          "updatedAt": "2022-05-03T16:43:36Z"
        }
      ],
      "reviews": [
        {
          "id": "PRR_kwDOFEJYQs44fUPU",
          "commit": {
            "abbreviatedOid": "eb97000"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "",
          "createdAt": "2022-04-20T20:35:27Z",
          "updatedAt": "2022-04-20T20:35:27Z",
          "comments": []
        },
        {
          "id": "PRR_kwDOFEJYQs44lB8N",
          "commit": {
            "abbreviatedOid": "eb97000"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "",
          "createdAt": "2022-04-21T21:24:28Z",
          "updatedAt": "2022-04-21T21:24:28Z",
          "comments": []
        },
        {
          "id": "PRR_kwDOFEJYQs45Qnaf",
          "commit": {
            "abbreviatedOid": "28fb578"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "The protocol name should change too, right? Though that can happen later so no need to do it here and now.",
          "createdAt": "2022-05-03T16:33:34Z",
          "updatedAt": "2022-05-03T16:33:54Z",
          "comments": []
        },
        {
          "id": "PRR_kwDOFEJYQs45Qrhr",
          "commit": {
            "abbreviatedOid": "28fb578"
          },
          "author": "bemasc",
          "authorAssociation": "NONE",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2022-05-03T16:44:11Z",
          "updatedAt": "2022-05-03T16:44:12Z",
          "comments": [
            {
              "originalPosition": 2,
              "body": "Please add \"Distributed Aggregation Protocol\" in some fashion.",
              "createdAt": "2022-05-03T16:44:11Z",
              "updatedAt": "2022-05-03T16:44:12Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs45QzKd",
          "commit": {
            "abbreviatedOid": "41a44ab"
          },
          "author": "ekr",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "Ship it",
          "createdAt": "2022-05-03T17:08:11Z",
          "updatedAt": "2022-05-03T17:08:11Z",
          "comments": []
        },
        {
          "id": "PRR_kwDOFEJYQs45Q1-c",
          "commit": {
            "abbreviatedOid": "41a44ab"
          },
          "author": "bemasc",
          "authorAssociation": "NONE",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2022-05-03T17:14:46Z",
          "updatedAt": "2022-05-03T17:14:46Z",
          "comments": [
            {
              "originalPosition": 4,
              "body": "I believe you're also going to want\r\n```suggestion\r\ntitle: \"Distributed Aggregation Protocol for Privacy Preserving Measurement\"\r\nabbrev: DAP-PPM\r\n```\r\nOther possibilities: \"PPM-DAP\", \"Distributed Aggregation Protocol\".",
              "createdAt": "2022-05-03T17:14:46Z",
              "updatedAt": "2022-05-03T17:14:46Z"
            }
          ]
        }
      ]
    },
    {
      "number": 222,
      "id": "PR_kwDOFEJYQs42hX_j",
      "title": "define error codes for batch interval validation",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/pull/222",
      "state": "MERGED",
      "author": "tgeoghegan",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "# This targets the interop branch\r\n\r\nAdds definitions of error codes to section 3.1 for validation of batch\r\nintervals in `CollectReq` or `AggregateShareReq`. Also adds an error\r\ncode for leader to use when rejecting a report from too far in the\r\nfuture.",
      "createdAt": "2022-04-20T22:24:17Z",
      "updatedAt": "2022-04-21T18:10:49Z",
      "baseRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "baseRefName": "cjpatton-tgeoghegan/draft-interop-target",
      "baseRefOid": "b734ac2272e58b839b8c5d5511e518e42b324956",
      "headRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "headRefName": "timg/error-codes",
      "headRefOid": "84c8321e9cdbbeecb1970ffa2cb0f91224253479",
      "closedAt": "2022-04-21T18:10:45Z",
      "mergedAt": "2022-04-21T18:10:44Z",
      "mergedBy": "tgeoghegan",
      "mergeCommit": {
        "oid": "87936b475e11402fa23bc924578f1a5b7c53fe28"
      },
      "comments": [
        {
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "body": "@BranLwyd I can't request review from you until you accept the invite to the ietf-wg-ppm organization but you should see this PR too!",
          "createdAt": "2022-04-21T17:58:18Z",
          "updatedAt": "2022-04-21T17:58:18Z"
        }
      ],
      "reviews": [
        {
          "id": "PRR_kwDOFEJYQs44gF0X",
          "commit": {
            "abbreviatedOid": "2ac6cca"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "CHANGES_REQUESTED",
          "body": "",
          "createdAt": "2022-04-21T01:05:55Z",
          "updatedAt": "2022-04-21T01:06:46Z",
          "comments": [
            {
              "originalPosition": 8,
              "body": "We don't want to overload the term \"privacy budget\", as this gets used in the context of DP.",
              "createdAt": "2022-04-21T01:05:55Z",
              "updatedAt": "2022-04-21T01:06:46Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs44kOgh",
          "commit": {
            "abbreviatedOid": "84c8321"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "",
          "createdAt": "2022-04-21T18:01:22Z",
          "updatedAt": "2022-04-21T18:01:22Z",
          "comments": []
        },
        {
          "id": "PRR_kwDOFEJYQs44kQMZ",
          "commit": {
            "abbreviatedOid": "84c8321"
          },
          "author": "divergentdave",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "",
          "createdAt": "2022-04-21T18:05:06Z",
          "updatedAt": "2022-04-21T18:05:06Z",
          "comments": []
        },
        {
          "id": "PRR_kwDOFEJYQs44kTp6",
          "commit": {
            "abbreviatedOid": "84c8321"
          },
          "author": "BranLwyd",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "",
          "createdAt": "2022-04-21T18:10:34Z",
          "updatedAt": "2022-04-21T18:10:49Z",
          "comments": [
            {
              "originalPosition": 33,
              "body": "Optional: this is a really tiny section -- would this sentence fit somewhere else, allowing this section to be dropped? Perhaps in the description of the `/upload` flow.",
              "createdAt": "2022-04-21T18:10:34Z",
              "updatedAt": "2022-04-21T18:10:49Z"
            }
          ]
        }
      ]
    },
    {
      "number": 223,
      "id": "PR_kwDOFEJYQs42j4jb",
      "title": "Add VDAF mapping for aggregation flow",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/pull/223",
      "state": "MERGED",
      "author": "chris-wood",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "This wires up PPM to drive the underlying VDAF state machine for individual reports. It splits the aggregate flow into three phases: initialization, progression (where the aggregators exchange messages to perform validation), and finalization. It also moves the process of fetching the aggregate share value for each aggregator to the collect flow, since that seems more closely aligned with the process of collection than it is about aggregation.\r\n\r\nOpen question (there may be more): Can we come up with a better name than `Process` for the message that conveys VDAF intermediate results?",
      "createdAt": "2022-04-21T13:47:34Z",
      "updatedAt": "2022-04-28T16:39:03Z",
      "baseRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "baseRefName": "main",
      "baseRefOid": "7e9e7a534cf14c945d68be3f092396dc9cb42227",
      "headRepository": "chris-wood/ppm-specification",
      "headRefName": "caw/agg-flow-2",
      "headRefOid": "d6bcb63d504af9ce76e1f86ec5cce1ac8ac7964d",
      "closedAt": "2022-04-28T16:39:02Z",
      "mergedAt": "2022-04-28T16:39:02Z",
      "mergedBy": "chris-wood",
      "mergeCommit": {
        "oid": "a1db69a015476da0b423cbb2af6ff53a14dd8c3a"
      },
      "comments": [],
      "reviews": [
        {
          "id": "PRR_kwDOFEJYQs44jlDi",
          "commit": {
            "abbreviatedOid": "1cba7bb"
          },
          "author": "ekr",
          "authorAssociation": "COLLABORATOR",
          "state": "CHANGES_REQUESTED",
          "body": "Technically this seems mostly OK. Editorially, I think it needs a lot of restructure to make it clear. At a higher level, it seems like the leader sends AggregateInitReq prior to engaging with the VDAF to compute the initial state? If so, I would restructure the text to show things in parallel. With that said, this is also a missed opportunity to save a round trip in some cases, I imagine\r\n\r\n\r\n\r\n",
          "createdAt": "2022-04-21T15:53:53Z",
          "updatedAt": "2022-04-21T16:34:53Z",
          "comments": [
            {
              "originalPosition": 26,
              "body": "```suggestion\r\nThe leader MUST buffer reports while waiting to aggregate them. The\r\n```",
              "createdAt": "2022-04-21T15:53:53Z",
              "updatedAt": "2022-04-21T16:34:54Z"
            },
            {
              "originalPosition": 107,
              "body": "```suggestion\r\n  by the underlying VDAF instance until aggregation completes or an error occurs. These messages do not replay the shares.\r\n```\r\n\r\n",
              "createdAt": "2022-04-21T15:54:44Z",
              "updatedAt": "2022-04-21T16:34:54Z"
            },
            {
              "originalPosition": 114,
              "body": "This text is a bit confusing. Is the idea here that there is a phase 2.1 where the helpers have assimilated the shares and so no more RTs are needed but you are not yet at the batch size?",
              "createdAt": "2022-04-21T15:55:57Z",
              "updatedAt": "2022-04-21T16:34:54Z"
            },
            {
              "originalPosition": 126,
              "body": "```suggestion\r\n* It is an error to include a new report in a batch that has already been collected. If the report would have belonged to a batch that has been collected, but the leader has not yet aggregated the report, then it MUST be excluded.\r\n```",
              "createdAt": "2022-04-21T15:56:37Z",
              "updatedAt": "2022-04-21T16:34:54Z"
            },
            {
              "originalPosition": 128,
              "body": "```suggestion\r\nAfter choosing the set of candidates, the leader begins aggregation by splitting each report into \"report\r\n```",
              "createdAt": "2022-04-21T15:57:24Z",
              "updatedAt": "2022-04-21T16:34:54Z"
            },
            {
              "originalPosition": 141,
              "body": "Should this be later or earlier? It seems odd here.",
              "createdAt": "2022-04-21T15:57:47Z",
              "updatedAt": "2022-04-21T16:34:54Z"
            },
            {
              "originalPosition": 171,
              "body": "I would restructure this so you have a separate section describing how to decrypt shares, as the leader and helper do much the same thing.",
              "createdAt": "2022-04-21T15:58:24Z",
              "updatedAt": "2022-04-21T16:34:54Z"
            },
            {
              "originalPosition": 247,
              "body": "How does it do that? Show the API call.",
              "createdAt": "2022-04-21T16:11:04Z",
              "updatedAt": "2022-04-21T16:34:54Z"
            },
            {
              "originalPosition": 223,
              "body": "Can we rename this to \"reports\"?",
              "createdAt": "2022-04-21T16:12:04Z",
              "updatedAt": "2022-04-21T16:34:54Z"
            },
            {
              "originalPosition": 271,
              "body": "Can we just merge this with the uniquness check above?",
              "createdAt": "2022-04-21T16:12:30Z",
              "updatedAt": "2022-04-21T16:34:54Z"
            },
            {
              "originalPosition": 297,
              "body": "See above about merging this.",
              "createdAt": "2022-04-21T16:14:00Z",
              "updatedAt": "2022-04-21T16:34:54Z"
            },
            {
              "originalPosition": 387,
              "body": "This section has gotten very long.",
              "createdAt": "2022-04-21T16:15:59Z",
              "updatedAt": "2022-04-21T16:34:54Z"
            },
            {
              "originalPosition": 409,
              "body": "Why are we both having order and the nonce? Seems like a great opportunity for things to go wrong.",
              "createdAt": "2022-04-21T16:17:04Z",
              "updatedAt": "2022-04-21T16:34:54Z"
            },
            {
              "originalPosition": 420,
              "body": "Can we get a forward ref to how things ifnish.",
              "createdAt": "2022-04-21T16:17:34Z",
              "updatedAt": "2022-04-21T16:34:54Z"
            },
            {
              "originalPosition": 426,
              "body": "Where is this defined?",
              "createdAt": "2022-04-21T16:18:27Z",
              "updatedAt": "2022-04-21T16:34:54Z"
            },
            {
              "originalPosition": 445,
              "body": "If it's invalid does it have to tell the helper?",
              "createdAt": "2022-04-21T16:21:43Z",
              "updatedAt": "2022-04-21T16:34:54Z"
            },
            {
              "originalPosition": 464,
              "body": "See comments above about ```seq```",
              "createdAt": "2022-04-21T16:22:04Z",
              "updatedAt": "2022-04-21T16:34:54Z"
            },
            {
              "originalPosition": 487,
              "body": "Is this \"after I processed it\" or \"this is what the leader says\"",
              "createdAt": "2022-04-21T16:22:32Z",
              "updatedAt": "2022-04-21T16:34:54Z"
            },
            {
              "originalPosition": 616,
              "body": "Why are we including the nonces and not the values?",
              "createdAt": "2022-04-21T16:28:39Z",
              "updatedAt": "2022-04-21T16:34:54Z"
            },
            {
              "originalPosition": 640,
              "body": "Here too, let's break out the crypto.",
              "createdAt": "2022-04-21T16:33:17Z",
              "updatedAt": "2022-04-21T16:34:54Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs44j3Gq",
          "commit": {
            "abbreviatedOid": "1cba7bb"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2022-04-21T16:49:50Z",
          "updatedAt": "2022-04-21T17:04:45Z",
          "comments": [
            {
              "originalPosition": 223,
              "body": "Or perhaps \"report_shares\"?",
              "createdAt": "2022-04-21T16:49:50Z",
              "updatedAt": "2022-04-21T17:04:45Z"
            },
            {
              "originalPosition": 409,
              "body": "Basically the requirement is: don't change the order of the nonces. Otherwise you force your peer to do more computation than necessary.",
              "createdAt": "2022-04-21T16:51:14Z",
              "updatedAt": "2022-04-21T17:04:45Z"
            },
            {
              "originalPosition": 616,
              "body": "Could do that, though strictly speaking may not be necessary. I don't think we've quite figured out what we need from this yet. Note, however, that the computation of the checksum hasn't changed here.",
              "createdAt": "2022-04-21T16:53:07Z",
              "updatedAt": "2022-04-21T17:04:45Z"
            },
            {
              "originalPosition": 445,
              "body": "Our thinking here is that the leader would just skip reports that can't be processed further. The motivation for this is to keep the helper simple. It also has the advantage of avoiding communication overhead for reports that can't be aggregated. One potential downside is that the helper doesn't get to find out *why* processing failed --- VDAF evaluation may fail in different ways, for example --- whereas the leader does.",
              "createdAt": "2022-04-21T17:03:29Z",
              "updatedAt": "2022-04-21T17:04:45Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs44j8CJ",
          "commit": {
            "abbreviatedOid": "1cba7bb"
          },
          "author": "ekr",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2022-04-21T17:08:28Z",
          "updatedAt": "2022-04-21T17:08:29Z",
          "comments": [
            {
              "originalPosition": 445,
              "body": "I don't think I understand how this works. If you don't tell them, and they are incrementally aggregating, it seems like a lot of work.",
              "createdAt": "2022-04-21T17:08:28Z",
              "updatedAt": "2022-04-21T17:08:29Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs44kVCU",
          "commit": {
            "abbreviatedOid": "1cba7bb"
          },
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "state": "CHANGES_REQUESTED",
          "body": "",
          "createdAt": "2022-04-21T18:15:06Z",
          "updatedAt": "2022-04-21T20:26:25Z",
          "comments": [
            {
              "originalPosition": 109,
              "body": "I don't think this happens until the helper gets an `AggregateShareReq` during the collect flow. The output of the aggregation flow is what VDAF calls \"output shares\", which are 1:1 to input shares.",
              "createdAt": "2022-04-21T18:15:06Z",
              "updatedAt": "2022-04-21T20:26:26Z"
            },
            {
              "originalPosition": 126,
              "body": "Perhaps insert something into the sentence to explain that the likely reason this would happen is a late upload.",
              "createdAt": "2022-04-21T18:19:03Z",
              "updatedAt": "2022-04-21T20:26:26Z"
            },
            {
              "originalPosition": 125,
              "body": "nit: wrap long lines please",
              "createdAt": "2022-04-21T18:20:44Z",
              "updatedAt": "2022-04-21T20:26:26Z"
            },
            {
              "originalPosition": 125,
              "body": "I don't understand \"but the report does not pertain to a batch that has been collected\". The implication is that the leader is allowed to aggregate a report twice if it is included in a batch that has been collected?",
              "createdAt": "2022-04-21T18:24:07Z",
              "updatedAt": "2022-04-21T20:26:26Z"
            },
            {
              "originalPosition": 193,
              "body": "Why do we have to dictate that the leader computes its first state transition before sending `AggregateInitReq` to helper?  The leader's first prepare message doesn't get transmitted to the helper until later, so a leader implementation could wait to do this until it gets the first `AggregateResp`. Is the idea to allow the leader to filter out those reports for which state initialization fails?",
              "createdAt": "2022-04-21T18:28:28Z",
              "updatedAt": "2022-04-21T20:26:26Z"
            },
            {
              "originalPosition": 339,
              "body": "I think this phrasing makes it the PPM implementation's problem to know how many rounds the VDAF it is executing has, and thus what it should expect the output of `VDAF.prep_next` to consist of. [The definition of `prep_next` in VDAF](https://github.com/cjpatton/vdaf/blob/6904d4a6295da82daf7ecd09c094326db4fb8ccd/draft-patton-cfrg-vdaf.md?plain=1#L537) returns a union type to enable the VDAF to express to its caller whether preparation is complete or if there are more rounds, so I believe it should be possible for a PPM implementation to avoid any special knowledge of what \"should\" happen when it calls `prep_next`.\r\n\r\nI'd suggest something like:\r\n\r\n```\r\nIf this is the last round of the VDAF, then `out` is the aggregator's output share,\r\nin which case the aggregator finishes and stores its output share for further\r\nprocessing as described in {{agg-complete}}. Otherwise, `out` is the pair\r\n`(new_state, agg_msg)`, where `new_state` is its updated state and `agg_msg`\r\nis its next VDAF message. For the latter case, the helper sets `prep_state` to\r\n`new_state`.\r\n```",
              "createdAt": "2022-04-21T18:40:06Z",
              "updatedAt": "2022-04-21T20:26:26Z"
            },
            {
              "originalPosition": 343,
              "body": "I think we should use \"prepare message\" or `prep_msg` to be consistent with the usage in the VDAF spec.",
              "createdAt": "2022-04-21T18:43:43Z",
              "updatedAt": "2022-04-21T20:26:26Z"
            },
            {
              "originalPosition": 423,
              "body": "I'm a little concerned that we're using the verbs \"prepare\", \"aggregate\" and \"process\" kind of loosely. I think we should converge on one verb with a clear definition we can put in a glossary. VDAF already uses \"prepare\" heavily to describe the transformation of an input share into an output share. Then, after preparation, an output share can be accumulated into an aggregate.",
              "createdAt": "2022-04-21T18:48:06Z",
              "updatedAt": "2022-04-21T20:26:26Z"
            },
            {
              "originalPosition": 523,
              "body": "```suggestion\r\n`new_state` is its updated preparation state and `agg_msg` is its next VDAF\r\n```",
              "createdAt": "2022-04-21T18:51:05Z",
              "updatedAt": "2022-04-21T20:26:26Z"
            },
            {
              "originalPosition": 545,
              "body": "```suggestion\r\nis the AggregateContinueResp and media type is \"message/ppm-aggregate-continue-resp\". The helper\r\n```",
              "createdAt": "2022-04-21T18:52:00Z",
              "updatedAt": "2022-04-21T20:26:26Z"
            },
            {
              "originalPosition": 559,
              "body": "```suggestion\r\nOnce processing of a report share is finished, each aggregator stores the\r\nrecovered output share until the batch to which it pertains is collected.\r\nTo aggregate the output shares, denoted `out_shares`, the aggregator runs\r\nthe aggregation algorithm specified by the VDAF:\r\n```\r\n\"output share\" should be singular to agree with \"report share\" on the line above, right?\r\n\r\nSeparately: I think there's a causality problem here: for Poplar1 or other VDAFs that have an aggregation parameter, you can't prepare/\"recover output shares\" (\"recover\" is another verb we casually use as a synonym for \"prepare\" and \"aggregate\") until the collector provides the agg_param in a CollectReq. So I think we need to be clear about what it means for a batch to be \"collected\". Does a batch become collected when the leader receives a `CollectReq`? Or when the collector successfully retrieves the aggregate shares produced in response to a `CollectReq`?\r\n\r\nI've argued before we should spell out the state machine for report shares and for batches. That shouldn't happen in this change, but since a lot of subtle stuff like anti-replay depends on the state of a report vs. the state of a batch, the document would benefit from more clarity about this.",
              "createdAt": "2022-04-21T19:51:48Z",
              "updatedAt": "2022-04-21T20:26:26Z"
            },
            {
              "originalPosition": 572,
              "body": "This is kind of awkward. The implication is that batch parameters don't need to be validated when using a VDAF without an aggregation parameter. Also I don't understand how validation of batch parameters informs which aggregate is used?",
              "createdAt": "2022-04-21T20:17:41Z",
              "updatedAt": "2022-04-21T20:26:26Z"
            },
            {
              "originalPosition": 594,
              "body": "This is identical to the definition of `checksum`, a couple paragraphs later. We should delete one.",
              "createdAt": "2022-04-21T20:19:05Z",
              "updatedAt": "2022-04-21T20:26:26Z"
            },
            {
              "originalPosition": 666,
              "body": "```suggestion\r\nThe leader MAY make multiple aggregate-share requests for a given batch interval\r\nand aggregation parameter and MUST get the same result each time.\r\n```\r\nThe intent here is that the helper should use the same set of reports to service multiple aggregate-share requests, right? Could that be stated explicitly.",
              "createdAt": "2022-04-21T20:20:30Z",
              "updatedAt": "2022-04-21T20:26:26Z"
            },
            {
              "originalPosition": 4,
              "body": "This error type doesn't seem to be used anywhere.",
              "createdAt": "2022-04-21T20:24:14Z",
              "updatedAt": "2022-04-21T20:26:26Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs44k2Bj",
          "commit": {
            "abbreviatedOid": "1cba7bb"
          },
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2022-04-21T20:30:14Z",
          "updatedAt": "2022-04-21T20:30:15Z",
          "comments": [
            {
              "originalPosition": 104,
              "body": "What is a \"public VDAF\"?",
              "createdAt": "2022-04-21T20:30:15Z",
              "updatedAt": "2022-04-21T20:30:15Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs44lDPi",
          "commit": {
            "abbreviatedOid": "ea9cb2e"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2022-04-21T21:31:45Z",
          "updatedAt": "2022-04-21T21:31:45Z",
          "comments": [
            {
              "originalPosition": 666,
              "body": "The intent here is that if the parameters of the aggregation request are the same then the output should be the same.",
              "createdAt": "2022-04-21T21:31:45Z",
              "updatedAt": "2022-04-21T21:31:45Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs44lD3c",
          "commit": {
            "abbreviatedOid": "2743ba7"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2022-04-21T21:35:18Z",
          "updatedAt": "2022-04-21T21:35:19Z",
          "comments": [
            {
              "originalPosition": 559,
              "body": "> \"output share\" should be singular to agree with \"report share\" on the line above, right?\r\n\r\nYep!\r\n\r\n> I've argued before we should spell out the state machine for report shares and for batches. That shouldn't happen in this change, but since a lot of subtle stuff like anti-replay depends on the state of a report vs. the state of a batch, the document would benefit from more clarity about this.\r\n\r\nI don't think we have a clear set of requirements for batch validation yet (https://github.com/ietf-wg-ppm/ppm-specification/issues/195), but once we do, yes, we should definitely add more detail.",
              "createdAt": "2022-04-21T21:35:19Z",
              "updatedAt": "2022-04-21T21:35:19Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs44lD7k",
          "commit": {
            "abbreviatedOid": "2455e36"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2022-04-21T21:35:41Z",
          "updatedAt": "2022-04-21T21:35:41Z",
          "comments": [
            {
              "originalPosition": 4,
              "body": "Leftover \ud83d\udc4d ",
              "createdAt": "2022-04-21T21:35:41Z",
              "updatedAt": "2022-04-21T21:35:41Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs44lEK7",
          "commit": {
            "abbreviatedOid": "2455e36"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2022-04-21T21:37:00Z",
          "updatedAt": "2022-04-21T21:37:00Z",
          "comments": [
            {
              "originalPosition": 104,
              "body": "Strange leftover. Deleting \"public\".",
              "createdAt": "2022-04-21T21:37:00Z",
              "updatedAt": "2022-04-21T21:37:00Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs44lEW3",
          "commit": {
            "abbreviatedOid": "2455e36"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2022-04-21T21:38:05Z",
          "updatedAt": "2022-04-21T21:38:06Z",
          "comments": [
            {
              "originalPosition": 109,
              "body": "Yep, good catch. This should be \"output shares.\"",
              "createdAt": "2022-04-21T21:38:05Z",
              "updatedAt": "2022-04-21T21:38:06Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs44lE51",
          "commit": {
            "abbreviatedOid": "bd95133"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2022-04-21T21:41:18Z",
          "updatedAt": "2022-04-21T21:41:18Z",
          "comments": [
            {
              "originalPosition": 193,
              "body": "That's right \ud83d\udc4d it would be pointless for the leader to kick off aggregation for any share that it would eventually throw away. ",
              "createdAt": "2022-04-21T21:41:18Z",
              "updatedAt": "2022-04-21T21:41:18Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs44lFXX",
          "commit": {
            "abbreviatedOid": "bd95133"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2022-04-21T21:43:54Z",
          "updatedAt": "2022-04-21T21:43:55Z",
          "comments": [
            {
              "originalPosition": 223,
              "body": "That's better!",
              "createdAt": "2022-04-21T21:43:54Z",
              "updatedAt": "2022-04-21T21:43:55Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs44lF1g",
          "commit": {
            "abbreviatedOid": "bd95133"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2022-04-21T21:46:35Z",
          "updatedAt": "2022-04-21T21:46:36Z",
          "comments": [
            {
              "originalPosition": 343,
              "body": "Yep, that's better!",
              "createdAt": "2022-04-21T21:46:36Z",
              "updatedAt": "2022-04-21T21:46:36Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs44lH4Z",
          "commit": {
            "abbreviatedOid": "7cbeda7"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2022-04-21T21:58:14Z",
          "updatedAt": "2022-04-21T21:58:15Z",
          "comments": [
            {
              "originalPosition": 445,
              "body": "Right now, they shouldn't actually aggregate until the leader issues an AggregateShareReq. We can change how that's done if we want to optimize things, but let's do so separately.",
              "createdAt": "2022-04-21T21:58:14Z",
              "updatedAt": "2022-04-21T21:58:15Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs44lIYw",
          "commit": {
            "abbreviatedOid": "7cbeda7"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2022-04-21T22:01:21Z",
          "updatedAt": "2022-04-21T22:01:21Z",
          "comments": [
            {
              "originalPosition": 487,
              "body": "It's \"do this check and then proceed accordingly to either continue processing, invalidate the report, or finish.\"",
              "createdAt": "2022-04-21T22:01:21Z",
              "updatedAt": "2022-04-21T22:01:21Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs44lJWi",
          "commit": {
            "abbreviatedOid": "e3973ec"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2022-04-21T22:07:50Z",
          "updatedAt": "2022-04-21T22:07:50Z",
          "comments": [
            {
              "originalPosition": 141,
              "body": "Yeah, I think you're right. I'll move it later.",
              "createdAt": "2022-04-21T22:07:50Z",
              "updatedAt": "2022-04-21T22:07:50Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs44lKUF",
          "commit": {
            "abbreviatedOid": "759edf3"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2022-04-21T22:13:48Z",
          "updatedAt": "2022-04-21T22:13:48Z",
          "comments": [
            {
              "originalPosition": 423,
              "body": "Yeah, this is a good suggestion. Let's converge on \"prepare\" as the verb of choice here.",
              "createdAt": "2022-04-21T22:13:48Z",
              "updatedAt": "2022-04-21T22:13:48Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs44lLqW",
          "commit": {
            "abbreviatedOid": "759edf3"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2022-04-21T22:22:56Z",
          "updatedAt": "2022-04-21T22:22:57Z",
          "comments": [
            {
              "originalPosition": 114,
              "body": "I think we can remove it, since this is prematurely describing the collect flow. ",
              "createdAt": "2022-04-21T22:22:57Z",
              "updatedAt": "2022-04-21T22:22:57Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs44lM6v",
          "commit": {
            "abbreviatedOid": "4f3fb89"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2022-04-21T22:31:02Z",
          "updatedAt": "2022-04-21T22:31:03Z",
          "comments": [
            {
              "originalPosition": 247,
              "body": "This is shown below.",
              "createdAt": "2022-04-21T22:31:02Z",
              "updatedAt": "2022-04-21T22:31:03Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs44lOAT",
          "commit": {
            "abbreviatedOid": "4f3fb89"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2022-04-21T22:39:18Z",
          "updatedAt": "2022-04-21T22:39:19Z",
          "comments": [
            {
              "originalPosition": 409,
              "body": "I think we can probably relax this. Let's address it in a followup issue.",
              "createdAt": "2022-04-21T22:39:18Z",
              "updatedAt": "2022-04-21T22:39:19Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs44lOCx",
          "commit": {
            "abbreviatedOid": "4f3fb89"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2022-04-21T22:39:29Z",
          "updatedAt": "2022-04-21T22:39:29Z",
          "comments": [
            {
              "originalPosition": 420,
              "body": "Yep, done.",
              "createdAt": "2022-04-21T22:39:29Z",
              "updatedAt": "2022-04-21T22:39:29Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs44pXMu",
          "commit": {
            "abbreviatedOid": "792d100"
          },
          "author": "BranLwyd",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2022-04-22T17:09:15Z",
          "updatedAt": "2022-04-22T17:50:08Z",
          "comments": [
            {
              "originalPosition": 409,
              "body": "Followup issue: https://github.com/ietf-wg-ppm/ppm-specification/issues/217 (FWIW, I agree this can be relaxed, I included some potential considerations in the issue.)",
              "createdAt": "2022-04-22T17:09:16Z",
              "updatedAt": "2022-04-22T17:50:08Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs44qq0r",
          "commit": {
            "abbreviatedOid": "792d100"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2022-04-22T23:29:33Z",
          "updatedAt": "2022-04-23T00:10:39Z",
          "comments": [
            {
              "originalPosition": 147,
              "body": "```suggestion\r\n1. For each valid report share, initialize the VDAF preparation process.\r\n```",
              "createdAt": "2022-04-22T23:29:33Z",
              "updatedAt": "2022-04-23T00:10:39Z"
            },
            {
              "originalPosition": 202,
              "body": "```suggestion\r\n1. Initialize VDAF preparation as described in {{input-share-prep}}.\r\n```",
              "createdAt": "2022-04-22T23:30:31Z",
              "updatedAt": "2022-04-23T00:10:39Z"
            },
            {
              "originalPosition": 207,
              "body": "```suggestion\r\nIf any step yields an invalid report share, the leader removes the report share from\r\n```",
              "createdAt": "2022-04-22T23:30:45Z",
              "updatedAt": "2022-04-23T00:10:39Z"
            },
            {
              "originalPosition": 244,
              "body": "```suggestion\r\nof candidate report shares obtained in aN `AggregateInitReq` message from the leader.\r\n```",
              "createdAt": "2022-04-22T23:32:14Z",
              "updatedAt": "2022-04-23T00:10:39Z"
            },
            {
              "originalPosition": 267,
              "body": "`PrepareResult` sounds like \"the result of the preparation process\", i.e., an output share. I think `PrepareStepType` would be more clear.",
              "createdAt": "2022-04-22T23:33:55Z",
              "updatedAt": "2022-04-23T00:10:40Z"
            },
            {
              "originalPosition": 276,
              "body": "IIRC this is the TLS-syntax you want:\r\n```suggestion\r\n    case finished:  Empty;\r\n```",
              "createdAt": "2022-04-22T23:34:45Z",
              "updatedAt": "2022-04-23T00:10:40Z"
            },
            {
              "originalPosition": 279,
              "body": "`PrepareShare` collides with terminology in the VDAF spec. (See \"prepare share\" in https://www.ietf.org/archive/id/draft-patton-cfrg-vdaf-01.html#name-preparation.) How about `PrepareStep`?",
              "createdAt": "2022-04-22T23:37:36Z",
              "updatedAt": "2022-04-23T00:10:40Z"
            },
            {
              "originalPosition": 305,
              "body": "```suggestion\r\nas finished if the VDAF preparation process is finished for the report share.\r\n```",
              "createdAt": "2022-04-22T23:38:27Z",
              "updatedAt": "2022-04-23T00:10:40Z"
            },
            {
              "originalPosition": 316,
              "body": "By \"bizarre\" I think you mean \"unspecified\" :) We discussed this a bit before but decided to punt. @BranLwyd did we file an issue to track this?",
              "createdAt": "2022-04-22T23:40:48Z",
              "updatedAt": "2022-04-23T00:10:40Z"
            },
            {
              "originalPosition": 321,
              "body": "```suggestion\r\ninput share. Let `nonce`, `extensions`, and `encrypted_input_share` denote these\r\n```",
              "createdAt": "2022-04-22T23:41:21Z",
              "updatedAt": "2022-04-23T00:10:40Z"
            },
            {
              "originalPosition": 322,
              "body": "```suggestion\r\nvalues, respectively. Given these values, an aggregator decrypts the input\r\n```",
              "createdAt": "2022-04-22T23:41:39Z",
              "updatedAt": "2022-04-23T00:10:40Z"
            },
            {
              "originalPosition": 333,
              "body": "where `server_role` is `0x02` if the aggregator is the leader and `0x03` if the aggregator is the helper.\r\n```suggestion\r\n                     \"ppm-00 input share\" || 0x01 || server_role)\r\n```",
              "createdAt": "2022-04-22T23:46:35Z",
              "updatedAt": "2022-04-23T00:10:40Z"
            },
            {
              "originalPosition": 132,
              "body": "This is now a bit redundant due to {{input-share-batch-validation}}. I wonder if, with a bit of word-smithing, we can replace this with a forward reference to that section?",
              "createdAt": "2022-04-22T23:49:21Z",
              "updatedAt": "2022-04-23T00:10:40Z"
            },
            {
              "originalPosition": 386,
              "body": "Can we also add this language here? https://github.com/ietf-wg-ppm/ppm-specification/blob/87936b475e11402fa23bc924578f1a5b7c53fe28/draft-gpew-priv-ppm.md?plain=1#L865-L869",
              "createdAt": "2022-04-22T23:51:50Z",
              "updatedAt": "2022-04-23T00:10:40Z"
            },
            {
              "originalPosition": 445,
              "body": "```suggestion\r\nThe leader begins each round of continuation for a report share based on its locally computed \r\nprepare message and the previous PrepareShare from the helper. If PrepareShare is of type \"failed\", \r\nthen the leader marks the report as failed and removes it from the candidate report set and does not\r\nprocess it further. If the type is \"finished\", then the leader aborts with \"unrecognizedMessage\".\r\n[[OPEN ISSUE: This behavior is not specified.]] If the type is \"continued\", then the leader proceeds as\r\nfollows.\r\n\r\nLet `leader_outbound` denote the leader's prepare message and `helper_outbound` denote the\r\nhelper's. The leader computes the next state transition as follows:\r\n```",
              "createdAt": "2022-04-23T00:05:40Z",
              "updatedAt": "2022-04-23T00:10:40Z"
            },
            {
              "originalPosition": 536,
              "body": "```suggestion\r\nwhere `inbound` is the previous VDAF preapre message sent by the leader and `prep_state` is\r\n```",
              "createdAt": "2022-04-23T00:07:27Z",
              "updatedAt": "2022-04-23T00:10:40Z"
            },
            {
              "originalPosition": 573,
              "body": "```suggestion\r\n[[OPEN ISSUE: consider relaxing this ordering constraint. See issue#217.]]\r\n```",
              "createdAt": "2022-04-23T00:08:22Z",
              "updatedAt": "2022-04-23T00:10:40Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs44xpXH",
          "commit": {
            "abbreviatedOid": "792d100"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2022-04-25T23:09:55Z",
          "updatedAt": "2022-04-25T23:09:55Z",
          "comments": [
            {
              "originalPosition": 132,
              "body": "Agreed that it's redundant. I think we can omit this text and the forward reference entirely.",
              "createdAt": "2022-04-25T23:09:55Z",
              "updatedAt": "2022-04-25T23:09:55Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs44xprt",
          "commit": {
            "abbreviatedOid": "5576090"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2022-04-25T23:12:27Z",
          "updatedAt": "2022-04-25T23:12:28Z",
          "comments": [
            {
              "originalPosition": 316,
              "body": "Indeed -- it's above.",
              "createdAt": "2022-04-25T23:12:28Z",
              "updatedAt": "2022-04-25T23:12:28Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs44xqkN",
          "commit": {
            "abbreviatedOid": "64cda01"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2022-04-25T23:19:41Z",
          "updatedAt": "2022-04-25T23:19:41Z",
          "comments": [
            {
              "originalPosition": 267,
              "body": "How about `PrepareStepResult`? (We can bike shed the name later)",
              "createdAt": "2022-04-25T23:19:41Z",
              "updatedAt": "2022-04-25T23:19:41Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs44xqqf",
          "commit": {
            "abbreviatedOid": "64cda01"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2022-04-25T23:20:27Z",
          "updatedAt": "2022-04-25T23:20:27Z",
          "comments": [
            {
              "originalPosition": 279,
              "body": "That works for me, and am happy to bike shed later.",
              "createdAt": "2022-04-25T23:20:27Z",
              "updatedAt": "2022-04-25T23:20:27Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs44yWwu",
          "commit": {
            "abbreviatedOid": "2bedc58"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2022-04-26T04:08:14Z",
          "updatedAt": "2022-04-26T04:08:14Z",
          "comments": [
            {
              "originalPosition": 387,
              "body": "Headers included!",
              "createdAt": "2022-04-26T04:08:14Z",
              "updatedAt": "2022-04-26T04:08:14Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs442vC7",
          "commit": {
            "abbreviatedOid": "2bedc58"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "Just a few editorial comments. Also, I'd like us to consider addressing https://github.com/ietf-wg-ppm/ppm-specification/pull/223/files#r856672481 here, but this can wait if you feel it needs discussion.",
          "createdAt": "2022-04-26T19:04:41Z",
          "updatedAt": "2022-04-26T19:20:14Z",
          "comments": [
            {
              "originalPosition": 248,
              "body": "```suggestion\r\nand eventually returns a response to the leader carrying a VDAF-specific message for each\r\n```",
              "createdAt": "2022-04-26T19:05:46Z",
              "updatedAt": "2022-04-26T19:20:14Z"
            },
            {
              "originalPosition": 386,
              "body": "Bump.",
              "createdAt": "2022-04-26T19:09:55Z",
              "updatedAt": "2022-04-26T19:20:14Z"
            },
            {
              "originalPosition": 595,
              "body": "nit: for consistency with similar abbreviation elsewhere\r\n```suggestion\r\n  PrepareStep prep_shares<1..2^16-1>;\r\n```",
              "createdAt": "2022-04-26T19:12:00Z",
              "updatedAt": "2022-04-26T19:20:14Z"
            },
            {
              "originalPosition": 767,
              "body": "I don't understand why this behaviour is useful. Is this new, or is this already in the spec?",
              "createdAt": "2022-04-26T19:15:26Z",
              "updatedAt": "2022-04-26T19:20:14Z"
            },
            {
              "originalPosition": 802,
              "body": "Replac\r\n```suggestion\r\n                              \"ppm-00 aggregate share\" || server_role || 0x00)\r\n```\r\nwhere `server_role` is `0x02` for the leader and `0x03` for a helper.",
              "createdAt": "2022-04-26T19:18:41Z",
              "updatedAt": "2022-04-26T19:20:14Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs442iI2",
          "commit": {
            "abbreviatedOid": "2bedc58"
          },
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "state": "CHANGES_REQUESTED",
          "body": "",
          "createdAt": "2022-04-26T18:16:05Z",
          "updatedAt": "2022-04-26T19:39:36Z",
          "comments": [
            {
              "originalPosition": 274,
              "body": "```suggestion\r\n  PrepareStepResult prepare_step_result;\r\n  select (PrepareStep.prepare_step_result) {\r\n```\r\nUnless the plural connotes something I missed?",
              "createdAt": "2022-04-26T18:16:05Z",
              "updatedAt": "2022-04-26T19:39:36Z"
            },
            {
              "originalPosition": 288,
              "body": "We renamed `AggregateInitReq.seq` to something more expressive. Could this be renamed too?\r\n```suggestion\r\n  PrepareStep prepare_steps<1..2^16-1>;\r\n```",
              "createdAt": "2022-04-26T18:17:03Z",
              "updatedAt": "2022-04-26T19:39:36Z"
            },
            {
              "originalPosition": 316,
              "body": "#217 is about relaxing ordering requirements in the various `Aggregate` messages. The question here is what the leader should do when it detects a malformed message from the helper, given that the helper isn't awaiting a reply from the leader (the helper message is delivered in a response to the leader's request). I think that in this case, the leader should abort handling of this aggregate job, but shouldn't tell the helper about it. The helper simply won't get the next `AggregateContinueReq`. ",
              "createdAt": "2022-04-26T18:22:02Z",
              "updatedAt": "2022-04-26T19:39:36Z"
            },
            {
              "originalPosition": 362,
              "body": "```suggestion\r\nEach report share has a corresponding task ID, nonce, list of extensions, and encrypted\r\ninput share. Let `task_id`, `nonce`, `extensions`, and `encrypted_input_share` denote these\r\nvalues, respectively. Given these values, an aggregator decrypts the input\r\n```\r\nSince `task_id` is used in the `SetupBaseR` call, below.",
              "createdAt": "2022-04-26T18:23:12Z",
              "updatedAt": "2022-04-26T19:39:36Z"
            },
            {
              "originalPosition": 387,
              "body": "The definitions of `task_id`, `nonce` and `extensions here are redundant with the paragraph above starting with \"Each report share has...\"",
              "createdAt": "2022-04-26T18:24:11Z",
              "updatedAt": "2022-04-26T19:39:36Z"
            },
            {
              "originalPosition": 394,
              "body": "```suggestion\r\n#### Input Share Validation {#input-share-validation}\r\n```\r\n\r\nThe phrasing here bothers me: it suggests that input shares arrive in batches, but what we're discussing here is validating an input share's timestamp against collection batches.",
              "createdAt": "2022-04-26T18:25:03Z",
              "updatedAt": "2022-04-26T19:39:36Z"
            },
            {
              "originalPosition": 387,
              "body": "I appreciate the sub-sections. This will make it easier to put references to the spec into implementations.",
              "createdAt": "2022-04-26T18:26:02Z",
              "updatedAt": "2022-04-26T19:39:36Z"
            },
            {
              "originalPosition": 389,
              "body": "This should spell out which `ReportShareError` variant to use (`hpke-unknown-config-id` or `hpke-decrypt-error` depending on the failure mode).",
              "createdAt": "2022-04-26T18:27:56Z",
              "updatedAt": "2022-04-26T19:39:36Z"
            },
            {
              "originalPosition": 398,
              "body": "Specifically, `vdaf-prep-error`, right?",
              "createdAt": "2022-04-26T18:28:16Z",
              "updatedAt": "2022-04-26T19:39:36Z"
            },
            {
              "originalPosition": 418,
              "body": "This last sentence (\"The helper also checks...\") is captured by bullet `1.`, isn't it?",
              "createdAt": "2022-04-26T18:29:21Z",
              "updatedAt": "2022-04-26T19:39:36Z"
            },
            {
              "originalPosition": 413,
              "body": "Is this correct in the `poplar1` case, where we expect multiple queries against the same set of reports with varying aggregation parameters? This text should account for tasks where `max_batch_lifetime > 1` (or refer to the `anti-replay` section which I believe already does).",
              "createdAt": "2022-04-26T18:31:39Z",
              "updatedAt": "2022-04-26T19:39:36Z"
            },
            {
              "originalPosition": 466,
              "body": "```suggestion\r\nOtherwise, the value `out` is interpreted as follows. If this is the last round of the VDAF,\r\nthen `out` is the aggregator's output share. Otherwise, `out` is the pair `(prep_state, prep_msg)`.\r\n```\r\nTo match the corresponding paragraph describing the leader's behavior on L952.",
              "createdAt": "2022-04-26T19:07:19Z",
              "updatedAt": "2022-04-26T19:39:36Z"
            },
            {
              "originalPosition": 578,
              "body": "```suggestion\r\nthe helper's current preparation state. If this operation fails, then the helper fails\r\n```\r\n\"its\" is ambiguous since the sentence earlier refers to the leader.",
              "createdAt": "2022-04-26T19:09:07Z",
              "updatedAt": "2022-04-26T19:39:36Z"
            },
            {
              "originalPosition": 604,
              "body": "```suggestion\r\nThe order of AggregateContinueResp.prepare_shares MUST match that of the PrepareStep values in\r\n`AggregateContinueReq.prepare_shares`. The helper's response to the leader is an HTTP 200 OK whose body\r\n```",
              "createdAt": "2022-04-26T19:10:09Z",
              "updatedAt": "2022-04-26T19:39:36Z"
            },
            {
              "originalPosition": 761,
              "body": "I think this discussion of how to populate the fields of `encrypted_aggregate_share` would be more clear in the `aggregate-share-encrypt` section, below.",
              "createdAt": "2022-04-26T19:35:49Z",
              "updatedAt": "2022-04-26T19:39:36Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs44256c",
          "commit": {
            "abbreviatedOid": "2bedc58"
          },
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2022-04-26T19:44:19Z",
          "updatedAt": "2022-04-26T19:44:20Z",
          "comments": [
            {
              "originalPosition": 767,
              "body": "I'm not sure if this is what Chris W. had in mind but I agree with this text. Suppose we have a task with `max_batch_lifetime = 1`. Consider:\r\n\r\n1. Leader makes an `AggregateShareReq` for some batch interval.\r\n2. Helper services the request, and marks that batch interval as having been collected once.\r\n3. Helper attempts to transmit an `AggregateShareResp` to leader, but the message is truncated.\r\n\r\nNow, if the leader retries its `AggregateShareReq`, the helper will refuse the request because the batch interval's lifetime has been consumed. So, to allow the leader to retry this request, the helper has to be willing to resend previously computed aggregate shares. ",
              "createdAt": "2022-04-26T19:44:19Z",
              "updatedAt": "2022-04-26T19:44:20Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs4426nu",
          "commit": {
            "abbreviatedOid": "b06c410"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2022-04-26T19:47:15Z",
          "updatedAt": "2022-04-26T19:47:15Z",
          "comments": [
            {
              "originalPosition": 387,
              "body": "Yep, that's right. I left it here to be specific. We can omit in the future if desired.",
              "createdAt": "2022-04-26T19:47:15Z",
              "updatedAt": "2022-04-26T19:47:15Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs4427R8",
          "commit": {
            "abbreviatedOid": "b06c410"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2022-04-26T19:49:48Z",
          "updatedAt": "2022-04-26T19:49:49Z",
          "comments": [
            {
              "originalPosition": 413,
              "body": "Let's address this in subsequent changes. We _still_ don't have batch validation requirements nailed down, so this is going to likely change anyway.",
              "createdAt": "2022-04-26T19:49:49Z",
              "updatedAt": "2022-04-26T19:49:49Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs4427aQ",
          "commit": {
            "abbreviatedOid": "b06c410"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2022-04-26T19:50:19Z",
          "updatedAt": "2022-04-26T19:50:19Z",
          "comments": [
            {
              "originalPosition": 418,
              "body": "Indeed, and it's also helper-specific, so I'll remove it.",
              "createdAt": "2022-04-26T19:50:19Z",
              "updatedAt": "2022-04-26T19:50:19Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs4427yF",
          "commit": {
            "abbreviatedOid": "f5f79a9"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2022-04-26T19:51:48Z",
          "updatedAt": "2022-04-26T19:51:49Z",
          "comments": [
            {
              "originalPosition": 386,
              "body": "Let's do this in a separate PR. We still don't have these requirements nailed down and the text is subject to change.",
              "createdAt": "2022-04-26T19:51:49Z",
              "updatedAt": "2022-04-26T19:51:49Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs4428Eo",
          "commit": {
            "abbreviatedOid": "7d5d665"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2022-04-26T19:52:57Z",
          "updatedAt": "2022-04-26T19:52:58Z",
          "comments": [
            {
              "originalPosition": 595,
              "body": "Keeping this as-is for now. We can bash the name in a followup change.",
              "createdAt": "2022-04-26T19:52:57Z",
              "updatedAt": "2022-04-26T19:52:58Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs4428te",
          "commit": {
            "abbreviatedOid": "fb27d3c"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2022-04-26T19:55:34Z",
          "updatedAt": "2022-04-26T19:55:34Z",
          "comments": [
            {
              "originalPosition": 767,
              "body": "Yanking this out to discuss in a separate issue: https://github.com/ietf-wg-ppm/ppm-specification/issues/226",
              "createdAt": "2022-04-26T19:55:34Z",
              "updatedAt": "2022-04-26T19:55:34Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs443gvG",
          "commit": {
            "abbreviatedOid": "cd67a25"
          },
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "",
          "createdAt": "2022-04-26T22:35:15Z",
          "updatedAt": "2022-04-26T22:35:15Z",
          "comments": []
        },
        {
          "id": "PRR_kwDOFEJYQs4470tM",
          "commit": {
            "abbreviatedOid": "cd67a25"
          },
          "author": "divergentdave",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2022-04-27T16:36:07Z",
          "updatedAt": "2022-04-27T16:36:08Z",
          "comments": [
            {
              "originalPosition": 728,
              "body": "Should we add this to the errors table above? (I see it says \"this list is not exhaustive\", but I'm not sure if that means other errors may be in the same URI namespace, or other errors would have entirely different URIs)",
              "createdAt": "2022-04-27T16:36:08Z",
              "updatedAt": "2022-04-27T16:36:08Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs448DkG",
          "commit": {
            "abbreviatedOid": "cd67a25"
          },
          "author": "ekr",
          "authorAssociation": "COLLABORATOR",
          "state": "CHANGES_REQUESTED",
          "body": "",
          "createdAt": "2022-04-27T17:15:15Z",
          "updatedAt": "2022-04-27T17:26:06Z",
          "comments": [
            {
              "originalPosition": 206,
              "body": "Does this have to be done serially? Could the leader instead send all of the shares and then discover later that one is bogus? Surely yes, because the proof could fail.",
              "createdAt": "2022-04-27T17:15:15Z",
              "updatedAt": "2022-04-27T17:26:06Z"
            },
            {
              "originalPosition": 234,
              "body": "...to which the share is being sent...",
              "createdAt": "2022-04-27T17:16:05Z",
              "updatedAt": "2022-04-27T17:26:06Z"
            },
            {
              "originalPosition": 249,
              "body": "I wonder if it would be better to factor out the common behaviors for all aggregators including the leader.",
              "createdAt": "2022-04-27T17:16:57Z",
              "updatedAt": "2022-04-27T17:26:06Z"
            },
            {
              "originalPosition": 258,
              "body": "For instance, this is common to leader and helper.",
              "createdAt": "2022-04-27T17:17:24Z",
              "updatedAt": "2022-04-27T17:26:06Z"
            },
            {
              "originalPosition": 269,
              "body": "Why is this called Prepare and above we call it Init?",
              "createdAt": "2022-04-27T17:17:51Z",
              "updatedAt": "2022-04-27T17:26:06Z"
            },
            {
              "originalPosition": 418,
              "body": "Shouldn't the nonce check go here?",
              "createdAt": "2022-04-27T17:20:01Z",
              "updatedAt": "2022-04-27T17:26:06Z"
            },
            {
              "originalPosition": 462,
              "body": "For the future, I think it would be better to make these clauses definition lists.",
              "createdAt": "2022-04-27T17:22:02Z",
              "updatedAt": "2022-04-27T17:26:06Z"
            },
            {
              "originalPosition": 489,
              "body": "\"Prepare\" seems like an odd term here. How about \"Process\"",
              "createdAt": "2022-04-27T17:23:34Z",
              "updatedAt": "2022-04-27T17:26:06Z"
            },
            {
              "originalPosition": 728,
              "body": ":+1:",
              "createdAt": "2022-04-27T17:24:36Z",
              "updatedAt": "2022-04-27T17:26:06Z"
            },
            {
              "originalPosition": 741,
              "body": "Does the vdaf have a function like ```VDAF.update_out_shares(tmp_output, out_shares)```",
              "createdAt": "2022-04-27T17:25:26Z",
              "updatedAt": "2022-04-27T17:26:06Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs448acu",
          "commit": {
            "abbreviatedOid": "cd67a25"
          },
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2022-04-27T18:23:49Z",
          "updatedAt": "2022-04-27T18:23:49Z",
          "comments": [
            {
              "originalPosition": 741,
              "body": "We're discussing adding a couple of methods to VDAF here: https://github.com/cjpatton/vdaf/issues/47",
              "createdAt": "2022-04-27T18:23:49Z",
              "updatedAt": "2022-04-27T18:23:49Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs448sub",
          "commit": {
            "abbreviatedOid": "cd67a25"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2022-04-27T19:29:54Z",
          "updatedAt": "2022-04-27T19:29:54Z",
          "comments": [
            {
              "originalPosition": 728,
              "body": "Yep, done.",
              "createdAt": "2022-04-27T19:29:54Z",
              "updatedAt": "2022-04-27T19:29:54Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs448tJA",
          "commit": {
            "abbreviatedOid": "cd67a25"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2022-04-27T19:31:29Z",
          "updatedAt": "2022-04-27T19:31:30Z",
          "comments": [
            {
              "originalPosition": 249,
              "body": "I think this done right now. The commonality is these steps, each of which have their own sections:\r\n\r\n```\r\n1. Decrypt the input share for each report share as described in {{input-share-decryption}}.\r\n1. Check that the resulting input share is valid as described in {{input-share-batch-validation}}.\r\n1. Initialize VDAF preparation and initial outputs as described in {{input-share-prep}}.\r\n```",
              "createdAt": "2022-04-27T19:31:30Z",
              "updatedAt": "2022-04-27T19:31:30Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs448tOn",
          "commit": {
            "abbreviatedOid": "cd67a25"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2022-04-27T19:31:51Z",
          "updatedAt": "2022-04-27T19:31:52Z",
          "comments": [
            {
              "originalPosition": 258,
              "body": "Right -- the section referenced details the common behavior in an aggregator-agnostic way.",
              "createdAt": "2022-04-27T19:31:51Z",
              "updatedAt": "2022-04-27T19:31:52Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs448tlS",
          "commit": {
            "abbreviatedOid": "cd67a25"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2022-04-27T19:33:08Z",
          "updatedAt": "2022-04-27T19:33:08Z",
          "comments": [
            {
              "originalPosition": 489,
              "body": "I think we had Process at some point in this PR, but that was confusing since it didn't align with the VDAF terminology. I suggest we punt this to the VDAF draft and then just use whatever term makes sense there.",
              "createdAt": "2022-04-27T19:33:08Z",
              "updatedAt": "2022-04-27T19:33:08Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs448t0g",
          "commit": {
            "abbreviatedOid": "cd67a25"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2022-04-27T19:34:03Z",
          "updatedAt": "2022-04-27T19:34:04Z",
          "comments": [
            {
              "originalPosition": 489,
              "body": "https://github.com/cjpatton/vdaf/issues/48",
              "createdAt": "2022-04-27T19:34:03Z",
              "updatedAt": "2022-04-27T19:34:04Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs448t30",
          "commit": {
            "abbreviatedOid": "cd67a25"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2022-04-27T19:34:17Z",
          "updatedAt": "2022-04-27T19:34:17Z",
          "comments": [
            {
              "originalPosition": 741,
              "body": "Cool! I'll resolve this then.",
              "createdAt": "2022-04-27T19:34:17Z",
              "updatedAt": "2022-04-27T19:34:17Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs448t6u",
          "commit": {
            "abbreviatedOid": "cd67a25"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2022-04-27T19:34:30Z",
          "updatedAt": "2022-04-27T19:34:30Z",
          "comments": [
            {
              "originalPosition": 269,
              "body": "Only to match VDAF. See https://github.com/cjpatton/vdaf/issues/48.",
              "createdAt": "2022-04-27T19:34:30Z",
              "updatedAt": "2022-04-27T19:34:30Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs448vJA",
          "commit": {
            "abbreviatedOid": "cd67a25"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2022-04-27T19:39:29Z",
          "updatedAt": "2022-04-27T19:39:29Z",
          "comments": [
            {
              "originalPosition": 206,
              "body": "Yep, it can. I added a note to that effect.",
              "createdAt": "2022-04-27T19:39:29Z",
              "updatedAt": "2022-04-27T19:39:29Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs448wP0",
          "commit": {
            "abbreviatedOid": "cd67a25"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2022-04-27T19:43:56Z",
          "updatedAt": "2022-04-27T19:43:56Z",
          "comments": [
            {
              "originalPosition": 418,
              "body": "~~Sorry, what nonce check?~~\r\n\r\nAh, the helper nonce check. That's not here because this is a list of checks to apply on each report individually, whereas the nonce check applies to the AggregateInitReq set of reports as a whole. It seemed better to keep that behavior separate, but I'll flag this as a consideration.",
              "createdAt": "2022-04-27T19:43:56Z",
              "updatedAt": "2022-04-27T19:46:15Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs448wkF",
          "commit": {
            "abbreviatedOid": "cd67a25"
          },
          "author": "ekr",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2022-04-27T19:45:12Z",
          "updatedAt": "2022-04-27T19:45:13Z",
          "comments": [
            {
              "originalPosition": 418,
              "body": "The check that the nonces aren't internally duplicated.",
              "createdAt": "2022-04-27T19:45:12Z",
              "updatedAt": "2022-04-27T19:45:13Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs45BpCV",
          "commit": {
            "abbreviatedOid": "9a7e36d"
          },
          "author": "divergentdave",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2022-04-28T16:27:31Z",
          "updatedAt": "2022-04-28T16:27:32Z",
          "comments": [
            {
              "originalPosition": 411,
              "body": "I think \"vdaf-prep-error\" here is incorrect. The two checks below each specify different ReportShareError codes. The next section, \"Input Share Preparation\", correctly says it may produce a \"vdaf-prep-error\" error.",
              "createdAt": "2022-04-28T16:27:32Z",
              "updatedAt": "2022-04-28T16:27:32Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs45Bp8h",
          "commit": {
            "abbreviatedOid": "9a7e36d"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2022-04-28T16:30:22Z",
          "updatedAt": "2022-04-28T16:30:23Z",
          "comments": [
            {
              "originalPosition": 411,
              "body": "```suggestion\r\nthe input share is marked as invalid with a corresponding ReportShareError error.\r\n```",
              "createdAt": "2022-04-28T16:30:22Z",
              "updatedAt": "2022-04-28T16:30:23Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs45Bqc0",
          "commit": {
            "abbreviatedOid": "9a7e36d"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2022-04-28T16:31:53Z",
          "updatedAt": "2022-04-28T16:31:53Z",
          "comments": [
            {
              "originalPosition": 411,
              "body": "Yep, resolved. Thanks!",
              "createdAt": "2022-04-28T16:31:53Z",
              "updatedAt": "2022-04-28T16:31:53Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs45BrSj",
          "commit": {
            "abbreviatedOid": "9a7e36d"
          },
          "author": "ekr",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "",
          "createdAt": "2022-04-28T16:34:38Z",
          "updatedAt": "2022-04-28T16:34:38Z",
          "comments": []
        },
        {
          "id": "PRR_kwDOFEJYQs45Brni",
          "commit": {
            "abbreviatedOid": "a019919"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2022-04-28T16:35:44Z",
          "updatedAt": "2022-04-28T16:35:44Z",
          "comments": [
            {
              "originalPosition": 248,
              "body": "```suggestion\r\n~~~\r\n\r\n[[OPEN ISSUE: consider sending report shares separately (in parallel) to the aggregate instructions. RIght now, aggregation parameters and the corresponding report shares are sent at the same time, but this may not be strictly necessary. ]]\r\n```",
              "createdAt": "2022-04-28T16:35:44Z",
              "updatedAt": "2022-04-28T16:35:44Z"
            }
          ]
        }
      ]
    },
    {
      "number": 224,
      "id": "PR_kwDOFEJYQs42wQic",
      "title": "interop: Add aggregation parameter to AggregateShareReq",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/pull/224",
      "state": "MERGED",
      "author": "cjpatton",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "Without this, the scope of the request is ambiguous.",
      "createdAt": "2022-04-25T20:55:06Z",
      "updatedAt": "2022-04-25T21:22:42Z",
      "baseRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "baseRefName": "cjpatton-tgeoghegan/draft-interop-target",
      "baseRefOid": "87936b475e11402fa23bc924578f1a5b7c53fe28",
      "headRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "headRefName": "cjpatton/interop-agg-share-agg-param",
      "headRefOid": "3d3f05a111506ebe2552790fe51b15b57c71799f",
      "closedAt": "2022-04-25T21:22:42Z",
      "mergedAt": "2022-04-25T21:22:42Z",
      "mergedBy": "cjpatton",
      "mergeCommit": {
        "oid": "b88f684b8845f33aafab1ece8583e8c9a7960c6e"
      },
      "comments": [
        {
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "body": "I had the same thought while implementing `/aggregate_share` but concluded that it's not needed. The scope of the `AggregateShareReq` is clear based on the `batch_interval`. The aggregation parameter gets provided to helper during `AggregateInitReq`. What do you need it for while handling `AggregateShareReq`, which should just be a matter of compiling the results of all the aggregation jobs described by `AggregateShareReq.batch_interval`?",
          "createdAt": "2022-04-25T20:59:42Z",
          "updatedAt": "2022-04-25T20:59:42Z"
        },
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "Consider the case where the leader simultaneously runs two aggregation flows for the same batch interval but with different aggregation parameters.",
          "createdAt": "2022-04-25T21:03:51Z",
          "updatedAt": "2022-04-25T21:03:51Z"
        }
      ],
      "reviews": [
        {
          "id": "PRR_kwDOFEJYQs44xXoc",
          "commit": {
            "abbreviatedOid": "3d3f05a"
          },
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "",
          "createdAt": "2022-04-25T21:20:17Z",
          "updatedAt": "2022-04-25T21:20:17Z",
          "comments": []
        },
        {
          "id": "PRR_kwDOFEJYQs44xYGw",
          "commit": {
            "abbreviatedOid": "3d3f05a"
          },
          "author": "divergentdave",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "",
          "createdAt": "2022-04-25T21:22:34Z",
          "updatedAt": "2022-04-25T21:22:34Z",
          "comments": []
        }
      ]
    },
    {
      "number": 225,
      "id": "PR_kwDOFEJYQs420gur",
      "title": "interop: Fix media types",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/pull/225",
      "state": "MERGED",
      "author": "cjpatton",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "",
      "createdAt": "2022-04-26T18:16:36Z",
      "updatedAt": "2022-04-26T18:37:13Z",
      "baseRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "baseRefName": "cjpatton-tgeoghegan/draft-interop-target",
      "baseRefOid": "b88f684b8845f33aafab1ece8583e8c9a7960c6e",
      "headRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "headRefName": "cjpatton/interop-media-types",
      "headRefOid": "8389e9c216f4599a16fe6221a2bcf987ae6d65c4",
      "closedAt": "2022-04-26T18:37:13Z",
      "mergedAt": "2022-04-26T18:37:13Z",
      "mergedBy": "cjpatton",
      "mergeCommit": {
        "oid": "cedcb1a4cc3fd96bc6faa4c66fa54d73d1071f5f"
      },
      "comments": [],
      "reviews": [
        {
          "id": "PRR_kwDOFEJYQs442mS1",
          "commit": {
            "abbreviatedOid": "8389e9c"
          },
          "author": "BranLwyd",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "",
          "createdAt": "2022-04-26T18:31:35Z",
          "updatedAt": "2022-04-26T18:31:35Z",
          "comments": []
        }
      ]
    },
    {
      "number": 227,
      "id": "PR_kwDOFEJYQs42407w",
      "title": "Add problem type for batch checksum/report count",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/pull/227",
      "state": "MERGED",
      "author": "tgeoghegan",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "# This targets the interop branch\r\n\r\nAdds a problem document type for the case where the helper and leader\r\ncompute different checksums or report counts when constructing aggregate\r\nshares. The error is chosen to match what was added in #223.",
      "createdAt": "2022-04-27T16:30:56Z",
      "updatedAt": "2022-04-27T17:22:19Z",
      "baseRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "baseRefName": "cjpatton-tgeoghegan/draft-interop-target",
      "baseRefOid": "cedcb1a4cc3fd96bc6faa4c66fa54d73d1071f5f",
      "headRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "headRefName": "timg/batch-mismatch-error",
      "headRefOid": "922c00786603e63be2ec3dbe9b850d7d7dfb1ae6",
      "closedAt": "2022-04-27T17:22:19Z",
      "mergedAt": "2022-04-27T17:22:19Z",
      "mergedBy": "tgeoghegan",
      "mergeCommit": {
        "oid": "79462d9f8703f908b6d4d21d9297cffb626b3ce2"
      },
      "comments": [],
      "reviews": [
        {
          "id": "PRR_kwDOFEJYQs4472M0",
          "commit": {
            "abbreviatedOid": "922c007"
          },
          "author": "divergentdave",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "",
          "createdAt": "2022-04-27T16:41:05Z",
          "updatedAt": "2022-04-27T16:41:05Z",
          "comments": []
        },
        {
          "id": "PRR_kwDOFEJYQs4472YV",
          "commit": {
            "abbreviatedOid": "922c007"
          },
          "author": "BranLwyd",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "",
          "createdAt": "2022-04-27T16:41:41Z",
          "updatedAt": "2022-04-27T16:41:41Z",
          "comments": []
        },
        {
          "id": "PRR_kwDOFEJYQs448C1R",
          "commit": {
            "abbreviatedOid": "922c007"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "Beat me to it!",
          "createdAt": "2022-04-27T17:13:26Z",
          "updatedAt": "2022-04-27T17:13:26Z",
          "comments": []
        }
      ]
    },
    {
      "number": 229,
      "id": "PR_kwDOFEJYQs4254JX",
      "title": "Update reference to VDAF draft",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/pull/229",
      "state": "MERGED",
      "author": "cjpatton",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "Closes #189.",
      "createdAt": "2022-04-27T21:52:51Z",
      "updatedAt": "2022-04-27T22:02:56Z",
      "baseRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "baseRefName": "main",
      "baseRefOid": "7e9e7a534cf14c945d68be3f092396dc9cb42227",
      "headRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "headRefName": "cjpatton/issue189",
      "headRefOid": "dfb7a0deff911485810e2c90e83cac7b9759a8bb",
      "closedAt": "2022-04-27T22:02:55Z",
      "mergedAt": "2022-04-27T22:02:55Z",
      "mergedBy": "cjpatton",
      "mergeCommit": {
        "oid": "0b888c477c8b5edac305e458286fb39435151881"
      },
      "comments": [],
      "reviews": [
        {
          "id": "PRR_kwDOFEJYQs449P-S",
          "commit": {
            "abbreviatedOid": "f3c8823"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "Maybe change each reference to `{{?VDAF=I-D.draft-irtf-cfrg-vdaf}}`? That way it'll render like `[VDAF]` in the text, which reads a bit nicer.",
          "createdAt": "2022-04-27T21:55:39Z",
          "updatedAt": "2022-04-27T21:55:39Z",
          "comments": []
        }
      ]
    },
    {
      "number": 231,
      "id": "PR_kwDOFEJYQs429f3l",
      "title": "Clarify encoding",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/pull/231",
      "state": "MERGED",
      "author": "chris-wood",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "Closes #228.",
      "createdAt": "2022-04-28T16:48:54Z",
      "updatedAt": "2022-04-28T17:45:54Z",
      "baseRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "baseRefName": "main",
      "baseRefOid": "a1db69a015476da0b423cbb2af6ff53a14dd8c3a",
      "headRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "headRefName": "clarify-encoding",
      "headRefOid": "19b4b987d31efb7acd150f715ada9801f0712495",
      "closedAt": "2022-04-28T17:45:54Z",
      "mergedAt": "2022-04-28T17:45:54Z",
      "mergedBy": "chris-wood",
      "mergeCommit": {
        "oid": "3aa0e86a4261cd749f5fa0b2569f5a44f482f042"
      },
      "comments": [],
      "reviews": [
        {
          "id": "PRR_kwDOFEJYQs45B4F3",
          "commit": {
            "abbreviatedOid": "19b4b98"
          },
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "",
          "createdAt": "2022-04-28T17:17:22Z",
          "updatedAt": "2022-04-28T17:17:22Z",
          "comments": []
        },
        {
          "id": "PRR_kwDOFEJYQs45CAty",
          "commit": {
            "abbreviatedOid": "19b4b98"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "",
          "createdAt": "2022-04-28T17:39:33Z",
          "updatedAt": "2022-04-28T17:39:33Z",
          "comments": []
        }
      ]
    },
    {
      "number": 232,
      "id": "PR_kwDOFEJYQs42-8Al",
      "title": "Replace helper_state with index into per-aggregator storage",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/pull/232",
      "state": "MERGED",
      "author": "chris-wood",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "Since aggregators already need to store nonce sets for the purpose of replay prevention, it doesn't make much sense to also offload part of their state to the leader. Instead, aggregators might benefit from a unique index into some local storage for keeping track of per-aggregation job state. This change drops the helper_state in favor of such an index.\r\n\r\nCloses #185.",
      "createdAt": "2022-04-28T23:07:12Z",
      "updatedAt": "2022-05-10T14:21:24Z",
      "baseRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "baseRefName": "main",
      "baseRefOid": "9884610ca4102df6e370f3061f9d6223b3244d9c",
      "headRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "headRefName": "remove-helper-state",
      "headRefOid": "82c4bb91693852afc751d6148dc6c4771eb28e0d",
      "closedAt": "2022-05-10T14:21:24Z",
      "mergedAt": "2022-05-10T14:21:24Z",
      "mergedBy": "chris-wood",
      "mergeCommit": {
        "oid": "40fc7c55dfa4c7f699c6239ef5fe3734bd23a8a8"
      },
      "comments": [
        {
          "author": "ekr",
          "authorAssociation": "COLLABORATOR",
          "body": "A few points:\r\n1. This seems strictly less flexible. The helpers could already store an index if they wanted, but now they are required to do so.\r\n2. Can't you store nonce sets in the helper state? \r\n",
          "createdAt": "2022-04-28T23:09:20Z",
          "updatedAt": "2022-04-28T23:09:20Z"
        },
        {
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "body": "> This seems strictly less flexible. The helpers could already store an index if they wanted, but now they are required to do so.\r\n\r\nYeah, they could store an index in helper_state. However, helper_state is a \"per-aggregation\" storage mechanism, not a \"per-task\" mechanism, and (I think) the replay state needs to cover the entire task. So we could (a) change helper_state to be a per-task thing, in which case it's not clear 2^16 is enough space, or if we want to be paying that bandwidth for the duration of the task, or (b) go with the layer of indirection as in here. On balance, I think (b) is probably better?   ",
          "createdAt": "2022-04-28T23:18:24Z",
          "updatedAt": "2022-04-28T23:18:24Z"
        },
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "\r\n>     2. Can't you store nonce sets in the helper state?\r\n\r\nThis can get really hairy. Think of this way: Storing nonce sets is required for report replay protection, which is needed for privacy.  Depending on what state the helper has locally for managing the \"version\" of the state blob, it may be possible for the leader to \"replay\" an old state and bypass replay protection for reports.\r\n\r\nThere are other ways that helper state gets hairy. For example, we haven't been precise yet about how handling concurrent aggregation flows: If the helper state is \"per-task\", then concurrent flows would be a problem.\r\n\r\nOverall the goal of this change is to remove this complexity altogether. We can always add it back later if we need to.",
          "createdAt": "2022-04-28T23:26:53Z",
          "updatedAt": "2022-04-28T23:26:53Z"
        },
        {
          "author": "ekr",
          "authorAssociation": "COLLABORATOR",
          "body": "I don't agree that this change reduces complexity. AFAICT, this is two changes:\r\n\r\n1. It has the leader assign the ID.\r\n2. It restricts the ID space to uint32.\r\n\r\nISTM that it's just as straightforward for the helper to assign the id at the start of the job, and then use any format it chooses, which the current system allows. I get that you think that certain ways of assigning and using that ID are complex, but that's not our problem because the helper can figure it out for themselves.\r\n\r\n\r\n\r\n\r\n\r\n",
          "createdAt": "2022-04-28T23:41:13Z",
          "updatedAt": "2022-04-28T23:41:13Z"
        },
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": ">     2. It restricts the ID space to uint32.\r\n\r\nYou mean 32-byte strings, right? uint32 is just 8 bytes, whereas the AggregationJobID is 32 bytes.\r\n\r\nAnther important thing it does is remove the state blob from the AggregateShareReq. Here's the bit I think you're missing: Right now we require the leader to send the same `helper_state` it received in the helper's previous response. This means that all aggregate requests, i.e., AggregateInitReq, AggregateContReq, and AggregateShareReq, need to be issued one after the other. In particular, it's not possible to run multiple aggregation flows concurrently. You're forced to do\r\n\r\n```\r\nAggregateInitReq(report_set_1, helper_state_0)\r\n<- helper_state_1\r\nAggregateContReq(report_set_1, helper_state_1)\r\n<- helper_state_2\r\n```\r\n\r\n*before* you do\r\n\r\n```\r\nAggregateInitReq(report_set_2, helper_state_2)\r\n<- helper_state_3\r\nAggregateContReq(report_set_2, heper_state_3)\r\n<- helper_state_4\r\n```\r\n\r\n(Note that the \"aggregation flow\" excludes the AggregateShareReq, which is used to combine the results across multiple aggregation flows.) It's going to be important for scalability that we can run multiple aggregation flows simultaneously. That means that we need, at a minimum, the following things:\r\n1. Don't carry state across aggregation flows\r\n2. Make sure there's a way for a helper to \"link\" aggregate requests pertaining to the same aggregation flow\r\n\r\nThis PR accomplishes both of these, but as you point out, is more strict than necessary. Perhaps we could keep the helper state blob as-is, but remove it from the AggregateShareReq and mandate only that the helper state is maintained for the duration of a single aggregation flow.",
          "createdAt": "2022-04-29T00:10:45Z",
          "updatedAt": "2022-04-29T00:10:45Z"
        },
        {
          "author": "ekr",
          "authorAssociation": "COLLABORATOR",
          "body": "> Here's the bit I think you're missing: Right now we require the leader to send the same helper_state it received in the helper's previous response.\r\n\r\nI'm undecided about whether this is a good or bad change, but it should be decided on its own merits, not buried in a PR entitled \"Replace helper_state with index into per-aggregator storage\"\r\n\r\n\r\n\r\n",
          "createdAt": "2022-04-29T00:21:46Z",
          "updatedAt": "2022-04-29T00:21:46Z"
        },
        {
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "body": "I believe this change does yield a significant reduction in complexity, because we no longer have to spell out how the helper needs to protect its state from the leader. Aggregation job IDs do not need to be kept secret from the leader, nor does the helper need to need to implement any anti-replay protections for them (because all the sensitive state is now assumed to be in the helper's database).",
          "createdAt": "2022-04-29T00:31:58Z",
          "updatedAt": "2022-04-29T00:31:58Z"
        },
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "@ekr: The reasoning for this was originally discussed on issue #185. This issue didn't get much attention, so we didn't expect the change to be controversial. We certainly didn't intend to bury it. We tried implementing both and thought this approach solved several problems compared to the status quo. Would you prefer that we take this too the list?",
          "createdAt": "2022-04-29T00:35:20Z",
          "updatedAt": "2022-04-29T00:35:20Z"
        },
        {
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "body": "Let's just move this discussion to the list \ud83d\ude03 ",
          "createdAt": "2022-04-29T00:36:54Z",
          "updatedAt": "2022-04-29T00:36:54Z"
        },
        {
          "author": "ekr",
          "authorAssociation": "COLLABORATOR",
          "body": "> \r\n\r\nI don't understand these points. Modulo the parallelism points @cjpatton raises, nothing prevents the helper from simply issuing each task a fresh ID and sending that as the helper state. The change in this PR is that it prevents the helper from doing something fancier because the leader issues the ID. Yes, in the latter case, it might need some kind of crypto to protect the state, but those design choices are out of our purview.\r\n\r\n\r\n\r\n\r\n\r\n",
          "createdAt": "2022-04-29T00:36:58Z",
          "updatedAt": "2022-04-29T00:36:58Z"
        },
        {
          "author": "ekr",
          "authorAssociation": "COLLABORATOR",
          "body": "> @ekr: The reasoning for this was originally discussed on issue https://github.com/ietf-wg-ppm/ppm-specification/issues/185. This issue didn't get much attention, so we didn't expect the change to be controversial. We certainly didn't intend to bury it. We tried implementing both and thought this approach solved several problems compared to the status quo. Would you prefer that we take this too the list?\r\n\r\nI've just read that issue several times and I don't really see much discussion of issuing aggregation requests in parallel.\r\n\r\nThe question here is not primarily about the list versus not the list. It's about the process we are going to follow for landing changes. In general, substantive changes should be getting the consensus of the WG prior to being landed. \r\n\r\nAt this relatively early phase, IETF sometimes allows editors some latitude to make design decisions ahead of time that will then be reviewed by the group when the next draft is published. However, typically the way to do this would be to email the list with a clear explanation of what the changes were and a notification that you were going to land a set of PRs unless someone objected by (say) a week away.\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n",
          "createdAt": "2022-04-29T00:44:49Z",
          "updatedAt": "2022-04-29T00:45:00Z"
        },
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "@chris-wood mind rebasing to fix conflicts?",
          "createdAt": "2022-05-04T16:53:12Z",
          "updatedAt": "2022-05-04T16:53:12Z"
        },
        {
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "body": "@cjpatton done.\r\n",
          "createdAt": "2022-05-04T17:58:11Z",
          "updatedAt": "2022-05-04T17:58:11Z"
        }
      ],
      "reviews": [
        {
          "id": "PRR_kwDOFEJYQs45DS9g",
          "commit": {
            "abbreviatedOid": "5a4a07e"
          },
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "state": "CHANGES_REQUESTED",
          "body": "",
          "createdAt": "2022-04-29T00:32:43Z",
          "updatedAt": "2022-04-29T00:34:36Z",
          "comments": [
            {
              "originalPosition": 9,
              "body": "\"at most one\" suggests an aggregation job could be associated with zero PPM tasks.\r\n```suggestion\r\njob. Each aggregation job is associated with exactly one PPM task, and a PPM\r\n```",
              "createdAt": "2022-04-29T00:32:43Z",
              "updatedAt": "2022-04-29T00:34:36Z"
            },
            {
              "originalPosition": 52,
              "body": "I think the idea is that reports 11-20 would be job `M` where `M !=N`.",
              "createdAt": "2022-04-29T00:33:49Z",
              "updatedAt": "2022-04-29T00:34:36Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs45Fkaz",
          "commit": {
            "abbreviatedOid": "d6b4e6f"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2022-04-29T13:43:31Z",
          "updatedAt": "2022-04-29T13:43:32Z",
          "comments": [
            {
              "originalPosition": 55,
              "body": "```suggestion\r\nAggregate request (Reports 11-20, Job = M) -------------->  \\\r\n<----------------------------- Aggregate response (Job = M) | Reports\r\nAggregate request (continued, Job = M) ------------------>  | 11-20\r\n<----------------------------- Aggregate response (Job = M) /\r\n```",
              "createdAt": "2022-04-29T13:43:31Z",
              "updatedAt": "2022-04-29T13:43:32Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs45Gfgl",
          "commit": {
            "abbreviatedOid": "6655c0f"
          },
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "The changes LGTM, but of course we should take this to the ppm list before merging.",
          "createdAt": "2022-04-29T16:53:13Z",
          "updatedAt": "2022-04-29T16:53:13Z",
          "comments": []
        },
        {
          "id": "PRR_kwDOFEJYQs45W3Ug",
          "commit": {
            "abbreviatedOid": "82c4bb9"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "",
          "createdAt": "2022-05-04T18:19:49Z",
          "updatedAt": "2022-05-04T18:19:49Z",
          "comments": []
        }
      ]
    },
    {
      "number": 233,
      "id": "PR_kwDOFEJYQs42_Pg8",
      "title": "HTTP problem document construction details",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/pull/233",
      "state": "MERGED",
      "author": "tgeoghegan",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "Defines more error types to represent various failure modes, updates\r\nprotocol text to indicate when the new error types should be used, and\r\naffirms that the task ID should be encoded as base64url with no padding\r\n(since task ID has a fixed size).",
      "createdAt": "2022-04-29T00:45:28Z",
      "updatedAt": "2022-05-10T17:17:39Z",
      "baseRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "baseRefName": "main",
      "baseRefOid": "9884610ca4102df6e370f3061f9d6223b3244d9c",
      "headRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "headRefName": "timg/http-problem-docs",
      "headRefOid": "797117a45546a9f5fdd3a97888d1e1815ebd409b",
      "closedAt": "2022-05-10T17:15:45Z",
      "mergedAt": "2022-05-10T17:15:45Z",
      "mergedBy": "tgeoghegan",
      "mergeCommit": {
        "oid": "4c76096818c6bfc3635b58a7a922aa995cef559c"
      },
      "comments": [],
      "reviews": [
        {
          "id": "PRR_kwDOFEJYQs45DUOw",
          "commit": {
            "abbreviatedOid": "26541fd"
          },
          "author": "ekr",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2022-04-29T00:48:46Z",
          "updatedAt": "2022-04-29T00:54:58Z",
          "comments": [
            {
              "originalPosition": 5,
              "body": "I would probably call these `reportTooLate` and `reportTooEarly`",
              "createdAt": "2022-04-29T00:48:46Z",
              "updatedAt": "2022-04-29T00:54:58Z"
            },
            {
              "originalPosition": 7,
              "body": "Are all of these fatal?\r\n\r\n\r\n\r\n",
              "createdAt": "2022-04-29T00:51:49Z",
              "updatedAt": "2022-04-29T00:54:58Z"
            },
            {
              "originalPosition": 20,
              "body": "I would put the parenthetical after the word \"task ID\" rather than after the text about b64.",
              "createdAt": "2022-04-29T00:53:20Z",
              "updatedAt": "2022-04-29T00:54:58Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs45GY3c",
          "commit": {
            "abbreviatedOid": "26541fd"
          },
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2022-04-29T16:26:14Z",
          "updatedAt": "2022-04-29T16:26:14Z",
          "comments": [
            {
              "originalPosition": 7,
              "body": "Yes, inasmuch as they represent conditions that the aggregators cannot recover from. `insufficientBatchSize` for instance means there aren't enough reports in `CollectReq.batch_interval` to satisfy the task's `min_batch_size`, which means the resulting aggregate would violate client privacy. The description text could be improved on this one.",
              "createdAt": "2022-04-29T16:26:14Z",
              "updatedAt": "2022-04-29T16:26:14Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs45GgMw",
          "commit": {
            "abbreviatedOid": "26541fd"
          },
          "author": "ekr",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2022-04-29T16:56:11Z",
          "updatedAt": "2022-04-29T16:56:12Z",
          "comments": [
            {
              "originalPosition": 7,
              "body": "Well, but could I aggregate some more into the batch and then ask for collect?",
              "createdAt": "2022-04-29T16:56:12Z",
              "updatedAt": "2022-04-29T16:56:12Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs45GkyQ",
          "commit": {
            "abbreviatedOid": "26541fd"
          },
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2022-04-29T17:15:53Z",
          "updatedAt": "2022-04-29T17:15:54Z",
          "comments": [
            {
              "originalPosition": 7,
              "body": "Yes, absolutely. Getting this error is how a collector would know to either try again with a bigger `batch_interval` or wait for more reports to arrive.",
              "createdAt": "2022-04-29T17:15:53Z",
              "updatedAt": "2022-04-29T17:15:54Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs45GlCn",
          "commit": {
            "abbreviatedOid": "26541fd"
          },
          "author": "ekr",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2022-04-29T17:16:58Z",
          "updatedAt": "2022-04-29T17:16:58Z",
          "comments": [
            {
              "originalPosition": 7,
              "body": "OK, so I think we're going to need to somehow note which errors are recoverable and which are not.",
              "createdAt": "2022-04-29T17:16:58Z",
              "updatedAt": "2022-04-29T17:16:58Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs45R7dq",
          "commit": {
            "abbreviatedOid": "26541fd"
          },
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2022-05-03T20:18:26Z",
          "updatedAt": "2022-05-03T20:18:26Z",
          "comments": [
            {
              "originalPosition": 7,
              "body": "That makes sense. And for this error, we should add some text to the section on collecting explaining what a collector could do if they encounter it.\r\n\r\n- [x] explain in `collect-flow` what collectors should do in the face of `insufficientBatchSize`",
              "createdAt": "2022-05-03T20:18:26Z",
              "updatedAt": "2022-05-10T17:14:32Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs45SNt-",
          "commit": {
            "abbreviatedOid": "797117a"
          },
          "author": "BranLwyd",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "",
          "createdAt": "2022-05-03T20:50:57Z",
          "updatedAt": "2022-05-03T20:50:57Z",
          "comments": []
        },
        {
          "id": "PRR_kwDOFEJYQs45WZ-L",
          "commit": {
            "abbreviatedOid": "797117a"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "Looks great!",
          "createdAt": "2022-05-04T16:44:34Z",
          "updatedAt": "2022-05-04T16:44:34Z",
          "comments": []
        },
        {
          "id": "PRR_kwDOFEJYQs45dT3P",
          "commit": {
            "abbreviatedOid": "797117a"
          },
          "author": "divergentdave",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "",
          "createdAt": "2022-05-05T21:40:47Z",
          "updatedAt": "2022-05-05T21:40:47Z",
          "comments": []
        },
        {
          "id": "PRR_kwDOFEJYQs45sLBJ",
          "commit": {
            "abbreviatedOid": "797117a"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "LGTM pending one suggestion, which we can definitely address separately if desired.",
          "createdAt": "2022-05-10T14:24:37Z",
          "updatedAt": "2022-05-10T14:25:24Z",
          "comments": [
            {
              "originalPosition": 33,
              "body": "```suggestion\r\nLeaders can buffer reports while waiting to aggregate them. The\r\n```\r\n\r\nI realize this is just relocated text, but I don't really see how we can have a MUST here without any further constraints (how long must they buffer them?), and in the end it's an implementation-specific decision, so I'd just remove the normative language here.",
              "createdAt": "2022-05-10T14:24:38Z",
              "updatedAt": "2022-05-10T14:25:24Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs45sLhX",
          "commit": {
            "abbreviatedOid": "26541fd"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2022-05-10T14:25:51Z",
          "updatedAt": "2022-05-10T14:25:52Z",
          "comments": [
            {
              "originalPosition": 7,
              "body": "@tgeoghegan can we file an issue to track this?",
              "createdAt": "2022-05-10T14:25:52Z",
              "updatedAt": "2022-05-10T14:25:52Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs45tLN-",
          "commit": {
            "abbreviatedOid": "26541fd"
          },
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2022-05-10T17:14:29Z",
          "updatedAt": "2022-05-10T17:14:30Z",
          "comments": [
            {
              "originalPosition": 7,
              "body": "Done: #239 ",
              "createdAt": "2022-05-10T17:14:30Z",
              "updatedAt": "2022-05-10T17:14:30Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs45tMGo",
          "commit": {
            "abbreviatedOid": "797117a"
          },
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2022-05-10T17:17:38Z",
          "updatedAt": "2022-05-10T17:17:39Z",
          "comments": [
            {
              "originalPosition": 33,
              "body": "Sorry, I mashed \"MERGE\" before I noticed this. I captured this as #240",
              "createdAt": "2022-05-10T17:17:38Z",
              "updatedAt": "2022-05-10T17:17:39Z"
            }
          ]
        }
      ]
    },
    {
      "number": 234,
      "id": "PR_kwDOFEJYQs43LR58",
      "title": "Remove trailing whitespace",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/pull/234",
      "state": "MERGED",
      "author": "cjpatton",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "",
      "createdAt": "2022-05-02T15:59:03Z",
      "updatedAt": "2022-05-02T16:32:46Z",
      "baseRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "baseRefName": "main",
      "baseRefOid": "3aa0e86a4261cd749f5fa0b2569f5a44f482f042",
      "headRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "headRefName": "cjpatton/editorial",
      "headRefOid": "1556b310e3a53ca7e34d26dad704dcf0ee6ebfdc",
      "closedAt": "2022-05-02T16:32:46Z",
      "mergedAt": "2022-05-02T16:32:46Z",
      "mergedBy": "cjpatton",
      "mergeCommit": {
        "oid": "004020f88c38785af23adfa909e4d0c646434bb1"
      },
      "comments": [
        {
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "body": "You can submit these right to main. No need for a PR, IMO.",
          "createdAt": "2022-05-02T15:59:51Z",
          "updatedAt": "2022-05-02T15:59:51Z"
        }
      ],
      "reviews": [
        {
          "id": "PRR_kwDOFEJYQs45LQBx",
          "commit": {
            "abbreviatedOid": "1556b31"
          },
          "author": "divergentdave",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "",
          "createdAt": "2022-05-02T15:59:47Z",
          "updatedAt": "2022-05-02T15:59:47Z",
          "comments": []
        }
      ]
    },
    {
      "number": 235,
      "id": "PR_kwDOFEJYQs43LYs-",
      "title": "Update security considerations",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/pull/235",
      "state": "MERGED",
      "author": "cjpatton",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "Closes #211.\r\n\r\nThis change is primarily editorial and includes the following changes:\r\n\r\n* Replace references to \"Prio\" with references to a generic VDAF. (This\r\n  section was written long ago when we had Prio in mind.)\r\n* Elaborate on known issues for collect requests.\r\n* Discuss Sybil attacks, including enumerating the different types\r\n  (#211).",
      "createdAt": "2022-05-02T16:28:54Z",
      "updatedAt": "2022-05-10T14:22:57Z",
      "baseRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "baseRefName": "main",
      "baseRefOid": "9884610ca4102df6e370f3061f9d6223b3244d9c",
      "headRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "headRefName": "cjpatotn/editorial-sec-cons",
      "headRefOid": "edea17ef8f4902bf49564b0340405a05454a72b1",
      "closedAt": "2022-05-10T14:22:57Z",
      "mergedAt": "2022-05-10T14:22:56Z",
      "mergedBy": "chris-wood",
      "mergeCommit": {
        "oid": "92bb26e0f4b9b6dde37761496d7b39dba590b07d"
      },
      "comments": [],
      "reviews": [
        {
          "id": "PRR_kwDOFEJYQs45SrI8",
          "commit": {
            "abbreviatedOid": "8fc3d2b"
          },
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2022-05-03T23:52:46Z",
          "updatedAt": "2022-05-03T23:58:05Z",
          "comments": [
            {
              "originalPosition": 30,
              "body": "```suggestion\r\nDAP assumes an active attacker that controls the network and has the ability to\r\n```\r\nSince #220 ",
              "createdAt": "2022-05-03T23:52:46Z",
              "updatedAt": "2022-05-03T23:58:05Z"
            },
            {
              "originalPosition": 34,
              "body": "```suggestion\r\nshares for aggregation or coerce an aggregator into diverting from the\r\n```",
              "createdAt": "2022-05-03T23:52:53Z",
              "updatedAt": "2022-05-03T23:58:05Z"
            },
            {
              "originalPosition": 79,
              "body": "```suggestion\r\n   such a mechanism beyond requiring server authentication for HTTPS sessions.\r\n```",
              "createdAt": "2022-05-03T23:55:47Z",
              "updatedAt": "2022-05-03T23:58:05Z"
            },
            {
              "originalPosition": 67,
              "body": "Does \"core\" mean a deployment that doesn't use report extensions or any kind of client authentication mechanism?",
              "createdAt": "2022-05-03T23:57:42Z",
              "updatedAt": "2022-05-03T23:58:05Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs45TEZs",
          "commit": {
            "abbreviatedOid": "8fc3d2b"
          },
          "author": "csharrison",
          "authorAssociation": "CONTRIBUTOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2022-05-04T02:43:18Z",
          "updatedAt": "2022-05-04T02:48:22Z",
          "comments": [
            {
              "originalPosition": 67,
              "body": "Beyond the protocol extensions it is also the case that some VDAFs have Sybil protections (against privacy) built-in e.g. with noise addition / differential privacy. DAP _could_ enforce that the aggregation function provide this kind of privacy but we choose not to.",
              "createdAt": "2022-05-04T02:43:19Z",
              "updatedAt": "2022-05-04T02:50:43Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs45VluG",
          "commit": {
            "abbreviatedOid": "8fc3d2b"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2022-05-04T14:24:03Z",
          "updatedAt": "2022-05-04T14:24:04Z",
          "comments": [
            {
              "originalPosition": 30,
              "body": "This change needs to be applied elsewhere, better to do it in a follow-up PR I think.",
              "createdAt": "2022-05-04T14:24:04Z",
              "updatedAt": "2022-05-04T14:33:16Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs45VpLj",
          "commit": {
            "abbreviatedOid": "b78edc4"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2022-05-04T14:32:35Z",
          "updatedAt": "2022-05-04T14:33:20Z",
          "comments": [
            {
              "originalPosition": 67,
              "body": "@tgeoghegan \"core\" refers to the bits of the spec that apply to all implementations. In particular, not every implementation will be required to interpret extensions the same way.\r\n\r\n@csharrison It's not clear to me that DP always provides adequate protection against Sybil attacks. I think it ultimately depends on how you define privacy. That said, requiring DP is totally on the table, but before doing this I think we should start by spelling out what this would look like as an optional feature of the protocol. I think the first question to ask is whether this mechanism lives here or in the underlying VDAF. I would love to have your help on this.",
              "createdAt": "2022-05-04T14:32:36Z",
              "updatedAt": "2022-05-04T14:33:20Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs45VsdC",
          "commit": {
            "abbreviatedOid": "8fc3d2b"
          },
          "author": "csharrison",
          "authorAssociation": "CONTRIBUTOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2022-05-04T14:40:59Z",
          "updatedAt": "2022-05-04T14:40:59Z",
          "comments": [
            {
              "originalPosition": 67,
              "body": "> @csharrison It's not clear to me that DP always provides adequate protection against Sybil attacks. I think it ultimately depends on how you define privacy. That said, requiring DP is totally on the table, but before doing this I think we should start by spelling out what this would look like as an optional feature of the protocol. I think the first question to ask is whether this mechanism lives here or in the underlying VDAF. I would love to have your help on this.\r\n\r\nI think if you can prove that the system achieves user-level DP you should be able to show that even with worst-case Sybil attacks, a user's privacy is still protected to some degree. That being said, this is a property of the whole system, not just the VDAF.\r\n\r\nI am fairly sure that DAP / PPM does not want to require DP in its deployments. This brings on a lot of baggage, and for instances where these kinds of attacks are truly not a problem (e.g. with airtight client authentication) it might not be that useful. The main point here is that we might want to call out that the particular VDAF used may mitigate some of the risks of Sybil.",
              "createdAt": "2022-05-04T14:40:59Z",
              "updatedAt": "2022-05-04T14:41:00Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs45WOaa",
          "commit": {
            "abbreviatedOid": "8fc3d2b"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2022-05-04T16:07:14Z",
          "updatedAt": "2022-05-04T16:07:15Z",
          "comments": [
            {
              "originalPosition": 67,
              "body": "If achievable, I think specifying an optional, generic DP mechanism here (perhaps for some class of VDAFs with a specific property) would have significant advantages. IIUC, tuning and enforcing the privacy budget will require knowledge of how measurements are generated by clients over time. This is something that will be dictated by the deployment, and I think it would be best to avoid bleeding deployment details into VDAF wherever possible.\r\n\r\nThat said, VDAF may need to at least say something about how/when to add noise into an input or aggregate share.",
              "createdAt": "2022-05-04T16:07:14Z",
              "updatedAt": "2022-05-04T16:07:15Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs45Wfo-",
          "commit": {
            "abbreviatedOid": "8fc3d2b"
          },
          "author": "csharrison",
          "authorAssociation": "CONTRIBUTOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2022-05-04T17:01:43Z",
          "updatedAt": "2022-05-04T17:01:43Z",
          "comments": [
            {
              "originalPosition": 67,
              "body": "> If achievable, I think specifying an optional, generic DP mechanism here (perhaps for some class of VDAFs with a specific property) would have significant advantages\r\n\r\nI think this is possible. We can probably have some tunable, exposed property of a VDAF that is a necessary but not sufficient condition for achieving DP. We can describe the rest of the conditions needed in the DAP deployment to get the rest of the way there.\r\n\r\nThis will not be super easy to do, but I am happy to help think through what it will take (maybe in a separate issue).",
              "createdAt": "2022-05-04T17:01:43Z",
              "updatedAt": "2022-05-04T17:02:01Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs45WtJE",
          "commit": {
            "abbreviatedOid": "9e8c636"
          },
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "state": "CHANGES_REQUESTED",
          "body": "",
          "createdAt": "2022-05-04T17:43:05Z",
          "updatedAt": "2022-05-04T17:45:58Z",
          "comments": [
            {
              "originalPosition": 49,
              "body": "```suggestion\r\n1. Privacy. Clients trust that some aggregator is honest. That is, as long as at\r\n   least one aggregator executes the protocol faithfully, the parties learn nothing\r\n   beyond the aggregate result (i.e., the output of the aggregation function computed over\r\n   the honest measurements).\r\n1. Correctness. The collector trusts that the aggregators execute the protocol\r\n   correctly. That is, as long as the aggregators execute the protocol faithfully,\r\n   a malicious client can skew the aggregate result only by reporting\r\n   a false (untruthful) measurement. The result cannot be influenced in any\r\n   other way.\r\n```\r\nFor consistency across the two bullets",
              "createdAt": "2022-05-04T17:43:05Z",
              "updatedAt": "2022-05-04T17:45:58Z"
            },
            {
              "originalPosition": 80,
              "body": "I think we're currently debating this point and thus will need to revisit this text. Perhaps include a bracketed note referencing https://github.com/ietf-wg-ppm/ppm-specification/issues/155 or something else that captures the discussion about mutual auth?",
              "createdAt": "2022-05-04T17:45:53Z",
              "updatedAt": "2022-05-04T17:45:58Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs45WuTy",
          "commit": {
            "abbreviatedOid": "8fc3d2b"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2022-05-04T17:47:24Z",
          "updatedAt": "2022-05-04T17:47:24Z",
          "comments": [
            {
              "originalPosition": 67,
              "body": "Kicking off an issue is probably a good way forward. I'm happy to help with the protocol design, but will need to lean on you to make sure we have all the plumbing we need to implement. A couple seed questions to start:\r\n1. Who adds noise and when? Do we want to support local DP, centralized DP, or both? Also would be helpful to define these (and point to references where needed).\r\n2. What syntactic changes are necessary for VDAF?\r\n\r\nOnce you create the issue, it would also be helpful to ping the list with a brief description of the issue and a link.\r\n",
              "createdAt": "2022-05-04T17:47:24Z",
              "updatedAt": "2022-05-04T17:47:25Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs45W0y-",
          "commit": {
            "abbreviatedOid": "9e8c636"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2022-05-04T18:10:11Z",
          "updatedAt": "2022-05-04T18:10:11Z",
          "comments": [
            {
              "originalPosition": 80,
              "body": "Done",
              "createdAt": "2022-05-04T18:10:11Z",
              "updatedAt": "2022-05-04T18:10:11Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs45W2G-",
          "commit": {
            "abbreviatedOid": "601699b"
          },
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "",
          "createdAt": "2022-05-04T18:15:13Z",
          "updatedAt": "2022-05-04T18:15:13Z",
          "comments": []
        },
        {
          "id": "PRR_kwDOFEJYQs45ajsw",
          "commit": {
            "abbreviatedOid": "601699b"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "The list of attacks is really a list of things we ought to fix in the protocol, so I would not even bother including them in the security considerations. If we want to use this as an opportunity to identify open issues that need to be addressed before we consider the protocol secure, I would simply list the open issues and keep discussion in GitHub. (That is, the text here seems redundant with the issue \ud83e\udd37 )",
          "createdAt": "2022-05-05T12:13:50Z",
          "updatedAt": "2022-05-05T12:15:02Z",
          "comments": [
            {
              "originalPosition": 51,
              "body": "```suggestion\r\nCurrently, the specification does not achieve these goals. In particular, there are several open\r\nissues that need to be addressed before these goals are met. Details for each issue are below.\r\n```",
              "createdAt": "2022-05-05T12:13:50Z",
              "updatedAt": "2022-05-05T12:15:02Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs45cMdI",
          "commit": {
            "abbreviatedOid": "8fc3d2b"
          },
          "author": "csharrison",
          "authorAssociation": "CONTRIBUTOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2022-05-05T17:02:45Z",
          "updatedAt": "2022-05-05T17:02:46Z",
          "comments": [
            {
              "originalPosition": 67,
              "body": "commented on https://github.com/ietf-wg-ppm/ppm-specification/issues/19, I doesn't answer all the questions but it's a start :)",
              "createdAt": "2022-05-05T17:02:46Z",
              "updatedAt": "2022-05-05T17:02:46Z"
            }
          ]
        }
      ]
    },
    {
      "number": 236,
      "id": "PR_kwDOFEJYQs43P2Bq",
      "title": "include task ID in request to hpke_config",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/pull/236",
      "state": "MERGED",
      "author": "tgeoghegan",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "When obtaining an aggregator's HPKE configuration, clients now specify\r\nthe task ID they are interested in. Aggregators are not required to use\r\na distinct HPKE configuration for each task, but now it's possible for\r\nthem to do so. The endpoint is also renamed to `hpke_config` from\r\n`key_config` for clarity.",
      "createdAt": "2022-05-03T18:57:15Z",
      "updatedAt": "2022-05-10T14:22:01Z",
      "baseRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "baseRefName": "main",
      "baseRefOid": "9884610ca4102df6e370f3061f9d6223b3244d9c",
      "headRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "headRefName": "timg/hpke-config-endpoint",
      "headRefOid": "69bde38e65ba0fce31e5fd87550c76e5068eb15f",
      "closedAt": "2022-05-10T14:22:00Z",
      "mergedAt": "2022-05-10T14:22:00Z",
      "mergedBy": "chris-wood",
      "mergeCommit": {
        "oid": "46cfb1b4c79e9862046d3e91b24816f5f92f2f5f"
      },
      "comments": [],
      "reviews": [
        {
          "id": "PRR_kwDOFEJYQs45R8YB",
          "commit": {
            "abbreviatedOid": "69bde38"
          },
          "author": "BranLwyd",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "",
          "createdAt": "2022-05-03T20:21:26Z",
          "updatedAt": "2022-05-03T20:21:26Z",
          "comments": []
        },
        {
          "id": "PRR_kwDOFEJYQs45WaXw",
          "commit": {
            "abbreviatedOid": "69bde38"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "",
          "createdAt": "2022-05-04T16:45:55Z",
          "updatedAt": "2022-05-04T16:45:55Z",
          "comments": []
        },
        {
          "id": "PRR_kwDOFEJYQs45acN4",
          "commit": {
            "abbreviatedOid": "69bde38"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "Nice \ud83d\udc4d ",
          "createdAt": "2022-05-05T11:44:17Z",
          "updatedAt": "2022-05-05T11:44:17Z",
          "comments": []
        },
        {
          "id": "PRR_kwDOFEJYQs45dX4W",
          "commit": {
            "abbreviatedOid": "69bde38"
          },
          "author": "divergentdave",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "",
          "createdAt": "2022-05-05T22:02:57Z",
          "updatedAt": "2022-05-05T22:04:32Z",
          "comments": [
            {
              "originalPosition": 14,
              "body": "This referenced section is by and large particular to the client requesting an HPKE configuration from the leader, but it does include relevant structure definitions. How's this?\r\n\r\n```\r\n... The HPKE configuration of the collector (`HpkeConfig` defined in {{hpke-config}}).\r\n```",
              "createdAt": "2022-05-05T22:02:57Z",
              "updatedAt": "2022-05-05T22:04:33Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs45dgMe",
          "commit": {
            "abbreviatedOid": "69bde38"
          },
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2022-05-05T23:02:30Z",
          "updatedAt": "2022-05-05T23:02:30Z",
          "comments": [
            {
              "originalPosition": 14,
              "body": "IMO we should fix this by moving the definition of `struct HpkeConfig` and its attendant types from `{{hpke-config}}` up to the common type definitions in \"Protocol Definition\" to eliminate this awkward forward reference. I'll do that in a separate change.",
              "createdAt": "2022-05-05T23:02:30Z",
              "updatedAt": "2022-05-05T23:02:30Z"
            }
          ]
        }
      ]
    },
    {
      "number": 238,
      "id": "PR_kwDOFEJYQs43iocw",
      "title": "Add bearer token for HTTP request authentication",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/pull/238",
      "state": "MERGED",
      "author": "cjpatton",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "Defines an HTTP request authentication mechanism and requires its usage\r\nin all collector->leader and leader->helper requests. We intend for this\r\nmechanism to be replaced eventually by something more secure, e.g., TLS\r\nclient authentication.\r\n\r\nFor details see https://mailarchive.ietf.org/arch/msg/ppm/z65FK8kOU27Dt38WNhpI6apc2so/.\r\n\r\n~Closes issue 155.~ As pointed out in the comments, this change may not be sufficient.",
      "createdAt": "2022-05-10T00:50:26Z",
      "updatedAt": "2022-05-11T11:10:27Z",
      "baseRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "baseRefName": "main",
      "baseRefOid": "4c76096818c6bfc3635b58a7a922aa995cef559c",
      "headRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "headRefName": "cjpatton/agg-auth",
      "headRefOid": "9933d1dc6ebe36779b18406b90858a6c0cecf369",
      "closedAt": "2022-05-11T11:10:27Z",
      "mergedAt": "2022-05-11T11:10:27Z",
      "mergedBy": "chris-wood",
      "mergeCommit": {
        "oid": "477e8d5af823f0bfa93bc4a78c2361527e7693ad"
      },
      "comments": [
        {
          "author": "ekr",
          "authorAssociation": "COLLABORATOR",
          "body": "FWIW, I agree with @chris-wood: this isn't necessary for interop testing, where authentication doesn't matter that much (as an example, we did much of our TLS 1.3 interop testing with self-signed certs). Obviously, if people want to deploy a system with real data, then some authentication is required, but enabling people to do that does not need to be a priority for the WG at this point; they can just make their own arrangements. I'm OK to land something, but let's just do the minimum.",
          "createdAt": "2022-05-10T17:24:05Z",
          "updatedAt": "2022-05-10T17:26:38Z"
        },
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "Alright, it sounds like after seeing an actual PR, folks are converging on leaving this unspecified for now. I'm OK with this result. Just one quick note here: Cloudflare/ISRG have both implemented the HMAC construction described in #179, so we will likely stick with that for the time being.\r\n\r\nI'll ping the list to make sure folks know where we've landed.",
          "createdAt": "2022-05-10T17:35:19Z",
          "updatedAt": "2022-05-10T17:35:19Z"
        }
      ],
      "reviews": [
        {
          "id": "PRR_kwDOFEJYQs45sJXB",
          "commit": {
            "abbreviatedOid": "aad7312"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "I've no objections to this, but I don't think it needs to be codified in the spec. I think experimental deployments should be free to choose whatever header and bearer token content they want to make this work. \r\n\r\nAlso, are we sure we want to close #155 with this? I'd suggest we keep that issue open, as it tracks the \"real\" solution to this problem.",
          "createdAt": "2022-05-10T14:20:35Z",
          "updatedAt": "2022-05-10T15:21:17Z",
          "comments": []
        },
        {
          "id": "PRR_kwDOFEJYQs45st0p",
          "commit": {
            "abbreviatedOid": "aad7312"
          },
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "state": "CHANGES_REQUESTED",
          "body": "I agree with Chris W. that we should keep #155 open, especially since this change does not solve the problem of integrity or authenticity of collect parameters from the collector to the helper.",
          "createdAt": "2022-05-10T15:43:24Z",
          "updatedAt": "2022-05-10T15:48:29Z",
          "comments": [
            {
              "originalPosition": 33,
              "body": "```suggestion\r\nFor requests requiring authentication, the sender includes a \"DAP-Auth-Token\"\r\n```",
              "createdAt": "2022-05-10T15:43:25Z",
              "updatedAt": "2022-05-10T15:48:29Z"
            },
            {
              "originalPosition": 40,
              "body": "I think we should require servers to respond with HTTP 403 Forbidden here (our definition of \"abort with error ...\" allows servers to use any 4xx or 5xx status).",
              "createdAt": "2022-05-10T15:47:13Z",
              "updatedAt": "2022-05-10T15:48:29Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs45s4VA",
          "commit": {
            "abbreviatedOid": "aad7312"
          },
          "author": "ekr",
          "authorAssociation": "COLLABORATOR",
          "state": "CHANGES_REQUESTED",
          "body": "",
          "createdAt": "2022-05-10T16:11:06Z",
          "updatedAt": "2022-05-10T16:22:17Z",
          "comments": [
            {
              "originalPosition": 31,
              "body": "```suggestion\r\nPrior to the start of the protocol, the sender and receiver arrange to share a\r\nsecret sender-specific API token, which MUST be suitable for representation in\r\nan HTTP header.\r\n```",
              "createdAt": "2022-05-10T16:11:06Z",
              "updatedAt": "2022-05-10T16:22:17Z"
            },
            {
              "originalPosition": 35,
              "body": "```suggestion\r\nheader in its HTTP request containing the API token.\r\n```",
              "createdAt": "2022-05-10T16:12:58Z",
              "updatedAt": "2022-05-10T16:22:17Z"
            },
            {
              "originalPosition": 40,
              "body": "```suggestion\r\nTo authenticate the request, the receiver looks up the token for the\r\nsender as determined by the task configuration. (See {{task-configuration}}.) If\r\nthe value of the \"DAP-Auth-Token\" header does not match the token, then\r\nthe receiver MUST abort with error \"unauthorizedRequest\".\r\n```",
              "createdAt": "2022-05-10T16:13:20Z",
              "updatedAt": "2022-05-10T17:00:20Z"
            },
            {
              "originalPosition": 40,
              "body": "This seems inconsistent with the guidance of BCP 56 S 8.",
              "createdAt": "2022-05-10T16:21:56Z",
              "updatedAt": "2022-05-10T16:22:17Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs45tG-I",
          "commit": {
            "abbreviatedOid": "aad7312"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2022-05-10T16:59:28Z",
          "updatedAt": "2022-05-10T17:00:34Z",
          "comments": [
            {
              "originalPosition": 31,
              "body": "Why not be prescriptive?",
              "createdAt": "2022-05-10T16:59:28Z",
              "updatedAt": "2022-05-10T17:00:34Z"
            },
            {
              "originalPosition": 35,
              "body": "Same question as above.",
              "createdAt": "2022-05-10T16:59:48Z",
              "updatedAt": "2022-05-10T17:00:34Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs45tKw_",
          "commit": {
            "abbreviatedOid": "aad7312"
          },
          "author": "ekr",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2022-05-10T17:12:56Z",
          "updatedAt": "2022-05-10T17:12:56Z",
          "comments": [
            {
              "originalPosition": 31,
              "body": "First, the actual guidance is not good:\r\n1. 32 bytes is far longer than needed\r\n2. Binary strings are hard to cut and paste, so people will want to actually have them in ASCII, which this prohibits, and even if it didn't then would then have to re-encode them per the rules below.\r\n3. It forbids structure (e.g., the account ID) which might be convenient.\r\n4. If people have existing systems for managing API tokens, this might conflict.\r\n\r\nSecond, it's unenforceable and not required for interoperability, so we it's not our job to tell people what to do.\r\n\r\n\r\n\r\n",
              "createdAt": "2022-05-10T17:12:56Z",
              "updatedAt": "2022-05-10T17:12:56Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs45ta46",
          "commit": {
            "abbreviatedOid": "aad7312"
          },
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2022-05-10T18:03:05Z",
          "updatedAt": "2022-05-10T18:03:05Z",
          "comments": [
            {
              "originalPosition": 40,
              "body": "Thanks for the reference, this is really useful! However I think this paragraph in [section 8](\r\nhttps://datatracker.ietf.org/doc/html/rfc3205#section-8) supports using an HTTP error code:\r\n\r\n>    A layered application should use appropriate HTTP error codes to\r\n>      report errors resulting from information in the HTTP request-line\r\n>      and *header fields associated with the request*.  This request\r\n>      information is part of the HTTP protocol and errors which are\r\n>      associated with that information should therefore be reported\r\n>      using HTTP protocol mechanisms.\r\n\r\nIn this specific case, the error results from information in the `PPM[/DAP]-Auth-Token` HTTP header and so indicating an error in HTTP seems appropriate. However this doesn't matter if we end up deciding not to dictate specific auth mechanisms at this stage or ever.",
              "createdAt": "2022-05-10T18:03:05Z",
              "updatedAt": "2022-05-10T18:03:18Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs45tdY8",
          "commit": {
            "abbreviatedOid": "aad7312"
          },
          "author": "ekr",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2022-05-10T18:12:16Z",
          "updatedAt": "2022-05-10T18:12:17Z",
          "comments": [
            {
              "originalPosition": 40,
              "body": "Agreed. Good point.",
              "createdAt": "2022-05-10T18:12:17Z",
              "updatedAt": "2022-05-10T18:12:17Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs45tw1H",
          "commit": {
            "abbreviatedOid": "9d0cf25"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "After conferring offline, we decided to merge this PR afterall. The branch has been rebased.",
          "createdAt": "2022-05-10T19:19:01Z",
          "updatedAt": "2022-05-10T19:28:13Z",
          "comments": [
            {
              "originalPosition": 31,
              "body": "Good points. ",
              "createdAt": "2022-05-10T19:19:01Z",
              "updatedAt": "2022-05-10T19:28:13Z"
            },
            {
              "originalPosition": 40,
              "body": "Oof, it would be useful to add an error code column to the error table. Will punt on this for now and simply add this to the text.",
              "createdAt": "2022-05-10T19:20:37Z",
              "updatedAt": "2022-05-10T19:28:13Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs45t0yk",
          "commit": {
            "abbreviatedOid": "9933d1d"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "",
          "createdAt": "2022-05-10T19:32:29Z",
          "updatedAt": "2022-05-10T19:32:29Z",
          "comments": []
        },
        {
          "id": "PRR_kwDOFEJYQs45uX_K",
          "commit": {
            "abbreviatedOid": "9933d1d"
          },
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "",
          "createdAt": "2022-05-10T22:05:03Z",
          "updatedAt": "2022-05-10T22:05:03Z",
          "comments": []
        }
      ]
    },
    {
      "number": 242,
      "id": "PR_kwDOFEJYQs43qExV",
      "title": "Editorial",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/pull/242",
      "state": "MERGED",
      "author": "cjpatton",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "",
      "createdAt": "2022-05-11T14:33:58Z",
      "updatedAt": "2022-05-11T14:57:49Z",
      "baseRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "baseRefName": "main",
      "baseRefOid": "477e8d5af823f0bfa93bc4a78c2361527e7693ad",
      "headRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "headRefName": "cjpatton/edit-agg-structs",
      "headRefOid": "5eed0ec2b182df29880d4064fd30f4e33df0c8fa",
      "closedAt": "2022-05-11T14:57:49Z",
      "mergedAt": "2022-05-11T14:57:49Z",
      "mergedBy": "cjpatton",
      "mergeCommit": {
        "oid": "c6c70ec9b3dc795a39039c110ccf4e0470641e68"
      },
      "comments": [],
      "reviews": [
        {
          "id": "PRR_kwDOFEJYQs45yT4r",
          "commit": {
            "abbreviatedOid": "97071bd"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "CHANGES_REQUESTED",
          "body": "",
          "createdAt": "2022-05-11T14:36:13Z",
          "updatedAt": "2022-05-11T14:36:21Z",
          "comments": [
            {
              "originalPosition": 56,
              "body": "I realize this is a bike shed, but I think we should keep the previous name. Abbreviating for the sake of less characters (thanks, Unix) just makes the overall intent less clear.",
              "createdAt": "2022-05-11T14:36:13Z",
              "updatedAt": "2022-05-11T14:36:21Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs45yWqJ",
          "commit": {
            "abbreviatedOid": "97071bd"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2022-05-11T14:42:30Z",
          "updatedAt": "2022-05-11T14:42:30Z",
          "comments": [
            {
              "originalPosition": 56,
              "body": "Then I would suggest changing \"AggregateInit\" to \"AggregateInitialize\" for consistency. (My preference would be shorter names for both, but my main concern is being consistent.)",
              "createdAt": "2022-05-11T14:42:30Z",
              "updatedAt": "2022-05-11T14:42:30Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs45yXDR",
          "commit": {
            "abbreviatedOid": "e84af3e"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "@chris-wood please have another look as I also replaced PPM with DAP in this change.",
          "createdAt": "2022-05-11T14:43:24Z",
          "updatedAt": "2022-05-11T14:43:24Z",
          "comments": []
        },
        {
          "id": "PRR_kwDOFEJYQs45yXlM",
          "commit": {
            "abbreviatedOid": "97071bd"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2022-05-11T14:44:26Z",
          "updatedAt": "2022-05-11T14:44:27Z",
          "comments": [
            {
              "originalPosition": 56,
              "body": "Making them consistent seems good \ud83d\udc4d  ",
              "createdAt": "2022-05-11T14:44:26Z",
              "updatedAt": "2022-05-11T14:44:27Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs45yX6c",
          "commit": {
            "abbreviatedOid": "e84af3e"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "The s/PPM/DAP/g changes look good.",
          "createdAt": "2022-05-11T14:45:10Z",
          "updatedAt": "2022-05-11T14:45:10Z",
          "comments": []
        },
        {
          "id": "PRR_kwDOFEJYQs45yd-T",
          "commit": {
            "abbreviatedOid": "97071bd"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2022-05-11T14:54:58Z",
          "updatedAt": "2022-05-11T14:54:59Z",
          "comments": [
            {
              "originalPosition": 56,
              "body": "Done",
              "createdAt": "2022-05-11T14:54:59Z",
              "updatedAt": "2022-05-11T14:54:59Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs45yfVX",
          "commit": {
            "abbreviatedOid": "5eed0ec"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "",
          "createdAt": "2022-05-11T14:57:30Z",
          "updatedAt": "2022-05-11T14:57:30Z",
          "comments": []
        }
      ]
    },
    {
      "number": 243,
      "id": "PR_kwDOFEJYQs43qM0q",
      "title": "Replace \"ppm\" with \"dap\" and align context strings with next draft",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/pull/243",
      "state": "MERGED",
      "author": "cjpatton",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "This change is basically a search-and-replace for /ppm/dap/. However, I have also re-aligned the context strings to match the next draft that will be cut (-01).\r\n\r\nI think the change is mostly correct, my main concern is the \"URN Sub-namespace for PPM (urn:ietf:params:dap)\" section. \ud83d\udeb2 \ud83c\udfe0 \u23f0: Does it make sense for all drafts in the PPM WG to share the namespace, or do we want to define one specifically for DAP?",
      "createdAt": "2022-05-11T14:57:16Z",
      "updatedAt": "2022-05-12T15:20:58Z",
      "baseRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "baseRefName": "main",
      "baseRefOid": "c6c70ec9b3dc795a39039c110ccf4e0470641e68",
      "headRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "headRefName": "cjpatton/ppm-die-die-die",
      "headRefOid": "26dafdd1322a544f98e6872f4582365555f83c3e",
      "closedAt": "2022-05-12T15:20:58Z",
      "mergedAt": "2022-05-12T15:20:58Z",
      "mergedBy": "cjpatton",
      "mergeCommit": {
        "oid": "6c7c1b722f26ea626214e34420311fe269c0abb0"
      },
      "comments": [
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "> LGTM pending the conflict comment.\r\n\r\nBefore merging I would appreciate an answer on the question I raised above. I want to make sure the URN bits are correct.",
          "createdAt": "2022-05-11T15:03:38Z",
          "updatedAt": "2022-05-11T15:03:38Z"
        },
        {
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "body": "> Does it make sense for all drafts in the PPM WG to share the namespace, or do we want to define one specifically for DAP?\r\n\r\nSeparate namespaces seems better, especially if we're thinking of DAP and STAR. Names are cheap, after all.",
          "createdAt": "2022-05-11T15:05:03Z",
          "updatedAt": "2022-05-11T15:05:03Z"
        },
        {
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "body": "> Does it make sense for all drafts in the PPM WG to share the namespace, or do we want to define one specifically for DAP?\r\n\r\nSeparate namespaces, because otherwise I think we'd have to write a further document enumerating the error type URNs that both this document and other PPM drafts like STAR could reference. We should avoid spreading the specification across multiple documents more than necessary. Maybe including the WG in the URN path like `urn:ietf:params:ppm:dap:error` helps?",
          "createdAt": "2022-05-11T16:45:18Z",
          "updatedAt": "2022-05-11T16:45:18Z"
        },
        {
          "author": "divergentdave",
          "authorAssociation": "COLLABORATOR",
          "body": "Here's the RFC defining `urn:ietf:params` https://www.rfc-editor.org/rfc/rfc3553.html. It's pretty loosely structured, and the existing sub-namespaces from published RFCs appear to just be named after protocols and formats, not working groups. https://www.iana.org/assignments/params/params.xhtml",
          "createdAt": "2022-05-11T16:54:56Z",
          "updatedAt": "2022-05-11T16:54:56Z"
        },
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "I took @tgeoghegan's suggestion of prefixing the dap space with ppm.",
          "createdAt": "2022-05-11T16:56:04Z",
          "updatedAt": "2022-05-11T16:56:19Z"
        }
      ],
      "reviews": [
        {
          "id": "PRR_kwDOFEJYQs45ygH8",
          "commit": {
            "abbreviatedOid": "4752c36"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "LGTM pending the conflict comment.",
          "createdAt": "2022-05-11T14:59:22Z",
          "updatedAt": "2022-05-11T14:59:34Z",
          "comments": [
            {
              "originalPosition": 115,
              "body": "I assume this will conflict now that it's AggregateInitializeReq/Resp?",
              "createdAt": "2022-05-11T14:59:23Z",
              "updatedAt": "2022-05-11T14:59:34Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs45yh3f",
          "commit": {
            "abbreviatedOid": "4752c36"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2022-05-11T15:03:10Z",
          "updatedAt": "2022-05-11T15:03:11Z",
          "comments": [
            {
              "originalPosition": 115,
              "body": "Fixed after rebase.",
              "createdAt": "2022-05-11T15:03:11Z",
              "updatedAt": "2022-05-11T15:03:11Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs45yiKg",
          "commit": {
            "abbreviatedOid": "7d219f0"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2022-05-11T15:03:56Z",
          "updatedAt": "2022-05-11T15:03:56Z",
          "comments": [
            {
              "originalPosition": 6,
              "body": "```suggestion\r\n```",
              "createdAt": "2022-05-11T15:03:56Z",
              "updatedAt": "2022-05-11T15:03:56Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs45yioi",
          "commit": {
            "abbreviatedOid": "7d219f0"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2022-05-11T15:05:09Z",
          "updatedAt": "2022-05-11T15:05:09Z",
          "comments": [
            {
              "originalPosition": 6,
              "body": "Oops, that was sloppy. Fixed.",
              "createdAt": "2022-05-11T15:05:09Z",
              "updatedAt": "2022-05-11T15:05:09Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs45zFVa",
          "commit": {
            "abbreviatedOid": "4cdc2ca"
          },
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "",
          "createdAt": "2022-05-11T16:43:07Z",
          "updatedAt": "2022-05-11T16:43:07Z",
          "comments": []
        }
      ]
    },
    {
      "number": 244,
      "id": "PR_kwDOFEJYQs43rGW9",
      "title": "remove unneeded MUST",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/pull/244",
      "state": "MERGED",
      "author": "tgeoghegan",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "Per @chris-wood's [suggestion](https://github.com/ietf-wg-ppm/ppm-specification/pull/233#discussion_r869306691)\r\nResolves #240",
      "createdAt": "2022-05-11T19:03:21Z",
      "updatedAt": "2022-05-11T19:27:25Z",
      "baseRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "baseRefName": "main",
      "baseRefOid": "c6c70ec9b3dc795a39039c110ccf4e0470641e68",
      "headRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "headRefName": "timg/leader-buffer-MUST",
      "headRefOid": "98e4ed5685a23c7b2d2818df9fb882a5417a8a9f",
      "closedAt": "2022-05-11T19:27:25Z",
      "mergedAt": "2022-05-11T19:27:25Z",
      "mergedBy": "tgeoghegan",
      "mergeCommit": {
        "oid": "dac00320cefce8193c37a3a305f25f7eb11f4c99"
      },
      "comments": [],
      "reviews": [
        {
          "id": "PRR_kwDOFEJYQs45zwBS",
          "commit": {
            "abbreviatedOid": "98e4ed5"
          },
          "author": "divergentdave",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "",
          "createdAt": "2022-05-11T19:06:09Z",
          "updatedAt": "2022-05-11T19:06:09Z",
          "comments": []
        },
        {
          "id": "PRR_kwDOFEJYQs45zyOg",
          "commit": {
            "abbreviatedOid": "98e4ed5"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "",
          "createdAt": "2022-05-11T19:14:56Z",
          "updatedAt": "2022-05-11T19:14:56Z",
          "comments": []
        },
        {
          "id": "PRR_kwDOFEJYQs45zy-4",
          "commit": {
            "abbreviatedOid": "98e4ed5"
          },
          "author": "BranLwyd",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "",
          "createdAt": "2022-05-11T19:17:58Z",
          "updatedAt": "2022-05-11T19:17:58Z",
          "comments": []
        }
      ]
    },
    {
      "number": 245,
      "id": "PR_kwDOFEJYQs43rNxT",
      "title": "Specify HTTP method for HPKE Configuration Request",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/pull/245",
      "state": "MERGED",
      "author": "jbr",
      "authorAssociation": "CONTRIBUTOR",
      "assignees": [],
      "labels": [],
      "body": "",
      "createdAt": "2022-05-11T19:37:52Z",
      "updatedAt": "2022-05-11T19:46:08Z",
      "baseRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "baseRefName": "main",
      "baseRefOid": "dac00320cefce8193c37a3a305f25f7eb11f4c99",
      "headRepository": "jbr/ppm-specification",
      "headRefName": "specify-http-verb-for-config-req",
      "headRefOid": "0d5724474631e95cb57d371e19d78225f343ddfa",
      "closedAt": "2022-05-11T19:46:08Z",
      "mergedAt": "2022-05-11T19:46:08Z",
      "mergedBy": "cjpatton",
      "mergeCommit": {
        "oid": "de6b2698ad671d7de0a37e183a732115b5f54fec"
      },
      "comments": [],
      "reviews": [
        {
          "id": "PRR_kwDOFEJYQs45z41M",
          "commit": {
            "abbreviatedOid": "0d57244"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "",
          "createdAt": "2022-05-11T19:40:14Z",
          "updatedAt": "2022-05-11T19:40:14Z",
          "comments": []
        },
        {
          "id": "PRR_kwDOFEJYQs45z5Md",
          "commit": {
            "abbreviatedOid": "0d57244"
          },
          "author": "divergentdave",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "",
          "createdAt": "2022-05-11T19:41:47Z",
          "updatedAt": "2022-05-11T19:41:47Z",
          "comments": []
        }
      ]
    },
    {
      "number": 246,
      "id": "PR_kwDOFEJYQs43ucJ1",
      "title": "Use consistent HTTP response status code phrasing",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/pull/246",
      "state": "MERGED",
      "author": "chris-wood",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "Closes #192.",
      "createdAt": "2022-05-12T14:35:52Z",
      "updatedAt": "2022-05-12T20:28:53Z",
      "baseRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "baseRefName": "main",
      "baseRefOid": "6c7c1b722f26ea626214e34420311fe269c0abb0",
      "headRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "headRefName": "caw/consistent-status-codes",
      "headRefOid": "e56eeb3a23389fd39a46838ed22117b4dee4c1b8",
      "closedAt": "2022-05-12T20:28:52Z",
      "mergedAt": "2022-05-12T20:28:52Z",
      "mergedBy": "chris-wood",
      "mergeCommit": {
        "oid": "994ba9b5e45673b455d3a216944098f8090c311d"
      },
      "comments": [],
      "reviews": [
        {
          "id": "PRR_kwDOFEJYQs454KHS",
          "commit": {
            "abbreviatedOid": "29cfa46"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "I didn't check if this change is complete, in the sense of making all the language in the doc consistent, but it's at least self-consistent. \ud83d\udea2 !",
          "createdAt": "2022-05-12T15:05:02Z",
          "updatedAt": "2022-05-12T15:05:02Z",
          "comments": []
        },
        {
          "id": "PRR_kwDOFEJYQs454lPj",
          "commit": {
            "abbreviatedOid": "e56eeb3"
          },
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "",
          "createdAt": "2022-05-12T16:16:55Z",
          "updatedAt": "2022-05-12T16:16:55Z",
          "comments": []
        }
      ]
    },
    {
      "number": 247,
      "id": "PR_kwDOFEJYQs43ug64",
      "title": "HPKE configuration compliance suite",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/pull/247",
      "state": "OPEN",
      "author": "chris-wood",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "Closes #216.",
      "createdAt": "2022-05-12T14:49:44Z",
      "updatedAt": "2022-05-12T16:26:56Z",
      "baseRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "baseRefName": "main",
      "baseRefOid": "de6b2698ad671d7de0a37e183a732115b5f54fec",
      "headRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "headRefName": "caw/hpke-complaince-and-refs",
      "headRefOid": "4c5800799bd09e7c73fab8451c3c3a0a30ddcd76",
      "closedAt": null,
      "mergedAt": null,
      "mergedBy": null,
      "mergeCommit": null,
      "comments": [
        {
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "body": "Premature in what way?",
          "createdAt": "2022-05-12T15:16:06Z",
          "updatedAt": "2022-05-12T15:16:06Z"
        },
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "> Premature in what way?\r\n\r\nThis PR guides folks towards using a particular ciphersuite, which is simply not useful at this stage. I think people will read this and think \"I can't implement DAP because I need NIST curves (and only NIST curves)\".",
          "createdAt": "2022-05-12T15:17:35Z",
          "updatedAt": "2022-05-12T15:23:53Z"
        },
        {
          "author": "ekr",
          "authorAssociation": "COLLABORATOR",
          "body": "I think we need an MTI eventually and I would be pretty surprised if it didn't end up being the one indicated here. However, I could also defer writing it down if people feel strongly. With that said, I think one could address @cjpatton's concern by adding a MAY for a P256-based KEM.",
          "createdAt": "2022-05-12T15:24:34Z",
          "updatedAt": "2022-05-12T15:24:34Z"
        },
        {
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "body": "> This PR guides folks towards using a particular ciphersuite, which is simply not useful at this stage.\r\n\r\nWell, this doesn't make much sense to me, since getting folks to use the same algorithm for interop _is_ useful.\r\n\r\n>  I think people will read this and think \"I can't implement DAP because I need NIST curves (and only NIST curves)\".\r\n\r\nDoesn't the text say \"if you want to do something else, you can\"? Explicitly saying one MAY implement another suite seems fine, too. I really don't feel strongly. ",
          "createdAt": "2022-05-12T15:26:55Z",
          "updatedAt": "2022-05-12T15:27:58Z"
        },
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "Yes, an explicit MAY would make me happy. I'll add a suggestion.\r\n\r\n",
          "createdAt": "2022-05-12T15:39:50Z",
          "updatedAt": "2022-05-12T15:39:50Z"
        },
        {
          "author": "ekr",
          "authorAssociation": "COLLABORATOR",
          "body": "As a process point, we clearly do need to get WG consensus before landing a MTI",
          "createdAt": "2022-05-12T16:25:09Z",
          "updatedAt": "2022-05-12T16:25:09Z"
        }
      ],
      "reviews": [
        {
          "id": "PRR_kwDOFEJYQs454GNp",
          "commit": {
            "abbreviatedOid": "6594073"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "CHANGES_REQUESTED",
          "body": "There's one bit of text I think needs to be loosened before merging. Otherwise, as an implementer I don't object to the choice of MTI suite, but I think specifying an MTI suite at this stage is premature. However, providing a bit of guidance on this interop issue may be useful.",
          "createdAt": "2022-05-12T14:56:36Z",
          "updatedAt": "2022-05-12T15:01:30Z",
          "comments": [
            {
              "originalPosition": 31,
              "body": "> Each task ID corresponds to exactly one HPKE configuration ...\r\n\r\nThis seems more restrictive than is useful/necessary. As a DAP aggregator, I may want to advertise a different ciphersuite depending on what I know about the client from information outside the scope of the DAP protocol. For instance I might use X25519 by default, but if the user agent is \"I-Only-Use-NIST-Stuff\" I would fallback to P-256.",
              "createdAt": "2022-05-12T14:56:36Z",
              "updatedAt": "2022-05-12T15:01:30Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs454K8z",
          "commit": {
            "abbreviatedOid": "6594073"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2022-05-12T15:07:11Z",
          "updatedAt": "2022-05-12T15:07:12Z",
          "comments": [
            {
              "originalPosition": 31,
              "body": "Well, I don't know why one would do that, but it's a fair point. Let's just drop this bit.",
              "createdAt": "2022-05-12T15:07:11Z",
              "updatedAt": "2022-05-12T15:07:12Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs454LDY",
          "commit": {
            "abbreviatedOid": "6594073"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2022-05-12T15:07:26Z",
          "updatedAt": "2022-05-12T15:07:27Z",
          "comments": [
            {
              "originalPosition": 31,
              "body": "```suggestion\r\nconfiguration of each aggregator. See {{compliance}} for information on HPKE configuration algorithms.\r\n```",
              "createdAt": "2022-05-12T15:07:26Z",
              "updatedAt": "2022-05-12T15:07:27Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs454Nxt",
          "commit": {
            "abbreviatedOid": "31814b3"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "No objection, but I still think this is premature. We should make sure to get more eyes on this before merging.",
          "createdAt": "2022-05-12T15:14:31Z",
          "updatedAt": "2022-05-12T15:15:03Z",
          "comments": [
            {
              "originalPosition": 80,
              "body": "This make it sound like we only intend to support one suite. It may be worth adding a note here that we will consider adding new MTI suites as needed. ",
              "createdAt": "2022-05-12T15:14:31Z",
              "updatedAt": "2022-05-12T15:15:03Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs454Sqe",
          "commit": {
            "abbreviatedOid": "6594073"
          },
          "author": "ekr",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2022-05-12T15:26:07Z",
          "updatedAt": "2022-05-12T15:26:08Z",
          "comments": [
            {
              "originalPosition": 31,
              "body": "I don't think removing the text helps here, as it's implicit in the protocol. Isn't the fix here for the server to provide a list of HpkeConfigs?\r\n",
              "createdAt": "2022-05-12T15:26:07Z",
              "updatedAt": "2022-05-12T15:26:08Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs454WO9",
          "commit": {
            "abbreviatedOid": "6594073"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2022-05-12T15:35:55Z",
          "updatedAt": "2022-05-12T15:35:55Z",
          "comments": [
            {
              "originalPosition": 31,
              "body": "They could do that, or just change what config they send out on a per-request basis. In any case, this is a separate issue, so let's address it in a separate PR.",
              "createdAt": "2022-05-12T15:35:55Z",
              "updatedAt": "2022-05-12T15:35:55Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs454XKe",
          "commit": {
            "abbreviatedOid": "6594073"
          },
          "author": "ekr",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2022-05-12T15:38:31Z",
          "updatedAt": "2022-05-12T15:38:31Z",
          "comments": [
            {
              "originalPosition": 31,
              "body": "Won't that require the client to indicate its capabilities then?\r\n\r\nAnyway, I agree it's a separate PR. https://github.com/ietf-wg-ppm/ppm-specification/issues/248",
              "createdAt": "2022-05-12T15:38:31Z",
              "updatedAt": "2022-05-12T15:38:32Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs454XlN",
          "commit": {
            "abbreviatedOid": "6594073"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2022-05-12T15:39:46Z",
          "updatedAt": "2022-05-12T15:39:46Z",
          "comments": [
            {
              "originalPosition": 31,
              "body": "Yeah, that's true, it would need to do that.",
              "createdAt": "2022-05-12T15:39:46Z",
              "updatedAt": "2022-05-12T15:39:46Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs454YnL",
          "commit": {
            "abbreviatedOid": "31814b3"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2022-05-12T15:42:42Z",
          "updatedAt": "2022-05-12T15:42:50Z",
          "comments": [
            {
              "originalPosition": 30,
              "body": "```suggestion\r\nconfiguration of each aggregator.\r\n\r\n{{compliance}} specifies HPKE ciphersuites that DAP implementations MUST provide.\r\nIn addition, implementations MAY implement any ciphersuite compatible with {{!RFC9180}}.\r\n```",
              "createdAt": "2022-05-12T15:42:42Z",
              "updatedAt": "2022-05-12T15:42:50Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs454Y9C",
          "commit": {
            "abbreviatedOid": "31814b3"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2022-05-12T15:43:41Z",
          "updatedAt": "2022-05-12T15:43:41Z",
          "comments": [
            {
              "originalPosition": 30,
              "body": "Hmm, this doesn't seem to add anything new beyond \"In the absence of an application profile standard specifying otherwise,...\" What am I missing?",
              "createdAt": "2022-05-12T15:43:41Z",
              "updatedAt": "2022-05-12T15:43:42Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs454cFO",
          "commit": {
            "abbreviatedOid": "31814b3"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2022-05-12T15:51:41Z",
          "updatedAt": "2022-05-12T15:51:42Z",
          "comments": [
            {
              "originalPosition": 30,
              "body": "My worry is that the current text says that the only option is X25519. Here we just point to {{compliance}}, which says:\r\n\r\n> In the absence of an application profile standard specifying otherwise,\r\n> a compliant DAP application MUST implement the following ciphersuite:\r\n\r\nSo if I'm interested in implementing DAP, my choice is to either use X25519 or get the WG to adopt an alternative \"application profile standard\".",
              "createdAt": "2022-05-12T15:51:41Z",
              "updatedAt": "2022-05-12T15:51:42Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs454cVO",
          "commit": {
            "abbreviatedOid": "31814b3"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2022-05-12T15:52:25Z",
          "updatedAt": "2022-05-12T15:52:26Z",
          "comments": [
            {
              "originalPosition": 30,
              "body": "This might make sense in the end game, but at this early stage, I think this adds an unnecessary burden to implementors.",
              "createdAt": "2022-05-12T15:52:25Z",
              "updatedAt": "2022-05-12T15:52:26Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs454dOb",
          "commit": {
            "abbreviatedOid": "31814b3"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2022-05-12T15:54:52Z",
          "updatedAt": "2022-05-12T15:54:52Z",
          "comments": [
            {
              "originalPosition": 30,
              "body": "Ah, I understand the disconnect now. An application profile is not something a WG has to adopt or specify! On the contrary, it's just something a specific deployment of PPM can pick and then use as needed. ",
              "createdAt": "2022-05-12T15:54:52Z",
              "updatedAt": "2022-05-12T15:55:09Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs454d_1",
          "commit": {
            "abbreviatedOid": "31814b3"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2022-05-12T15:56:59Z",
          "updatedAt": "2022-05-12T15:56:59Z",
          "comments": [
            {
              "originalPosition": 30,
              "body": "Ohh I see. Perhaps adding some non-jargony language would help, in the {{compliance}} section.",
              "createdAt": "2022-05-12T15:56:59Z",
              "updatedAt": "2022-05-12T15:57:32Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs454ead",
          "commit": {
            "abbreviatedOid": "31814b3"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2022-05-12T15:58:10Z",
          "updatedAt": "2022-05-12T15:58:10Z",
          "comments": [
            {
              "originalPosition": 30,
              "body": "Maybe we could say \"application or deployment specific profile\"? I agree that \"application profile\" isn't the most clear term.",
              "createdAt": "2022-05-12T15:58:10Z",
              "updatedAt": "2022-05-12T15:58:27Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs454eq_",
          "commit": {
            "abbreviatedOid": "31814b3"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2022-05-12T15:58:54Z",
          "updatedAt": "2022-05-12T15:58:55Z",
          "comments": [
            {
              "originalPosition": 82,
              "body": "```suggestion\r\nIn the absence of an application or deployment-specific profile specifying otherwise,\r\n```",
              "createdAt": "2022-05-12T15:58:54Z",
              "updatedAt": "2022-05-12T15:58:55Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs454fj5",
          "commit": {
            "abbreviatedOid": "31814b3"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2022-05-12T16:01:31Z",
          "updatedAt": "2022-05-12T16:01:32Z",
          "comments": [
            {
              "originalPosition": 82,
              "body": "@cjpatton thoughts on this alternative phrasing?",
              "createdAt": "2022-05-12T16:01:31Z",
              "updatedAt": "2022-05-12T16:01:32Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs454gEK",
          "commit": {
            "abbreviatedOid": "31814b3"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2022-05-12T16:03:04Z",
          "updatedAt": "2022-05-12T16:03:05Z",
          "comments": [
            {
              "originalPosition": 82,
              "body": "Much better.",
              "createdAt": "2022-05-12T16:03:05Z",
              "updatedAt": "2022-05-12T16:03:05Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs454ocN",
          "commit": {
            "abbreviatedOid": "4c58007"
          },
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "",
          "createdAt": "2022-05-12T16:26:49Z",
          "updatedAt": "2022-05-12T16:26:56Z",
          "comments": [
            {
              "originalPosition": 30,
              "body": "\"HPKE configuration algorithms\" is an awkward phrase. I think \"algorithm\" is meant to refer to the KDF, KEM, AEAD used in HPKE, but it suggests that DAP specifies an algorithm for configuring HPKE, which isn't what the \"compliance\" section describes.\r\n```suggestion\r\nconfiguration of each aggregator. See {{compliance}} for information on HPKE\r\nalgorithm choices.\r\n```",
              "createdAt": "2022-05-12T16:26:49Z",
              "updatedAt": "2022-05-12T16:26:56Z"
            }
          ]
        }
      ]
    },
    {
      "number": 249,
      "id": "PR_kwDOFEJYQs43v0B2",
      "title": "Revise usage of HPKE encryption.",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/pull/249",
      "state": "MERGED",
      "author": "BranLwyd",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "Specifically:\r\n  * Specify use of the \"one-shot\" HPKE APIs defined in RFC9180,\r\n    replacing equivalent use of the \"multi-shot\" APIs. (This change is\r\n    intended to be a clarification, not a functional change.)\r\n  * Move the task_id parameter from the \"info\" parameter to the \"aad\"\r\n    parameter. This is intended to protect against\r\n    key-commitment-related attacks[1]. (This is a functional change.)\r\n  * Clarify that the HpkeCiphertext.enc field is an encapsulated key,\r\n    rather than an encryption context. (This is a clarification, not a\r\n    functional change.)\r\n\r\n[1] See discussion in https://github.com/ietf-wg-ppm/ppm-specification/issues/221.\r\n\r\nCloses #221.",
      "createdAt": "2022-05-12T21:21:35Z",
      "updatedAt": "2022-05-13T16:38:40Z",
      "baseRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "baseRefName": "main",
      "baseRefOid": "994ba9b5e45673b455d3a216944098f8090c311d",
      "headRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "headRefName": "update-hpke-usage",
      "headRefOid": "1a452ba40db4acfee964af2b58c48d848935fa1b",
      "closedAt": "2022-05-13T16:23:02Z",
      "mergedAt": "2022-05-13T16:23:02Z",
      "mergedBy": "BranLwyd",
      "mergeCommit": {
        "oid": "149c8c08a7ae7ad9f75ccbd14c815d38fd587bbe"
      },
      "comments": [],
      "reviews": [
        {
          "id": "PRR_kwDOFEJYQs455-tN",
          "commit": {
            "abbreviatedOid": "1a452ba"
          },
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "",
          "createdAt": "2022-05-12T21:59:05Z",
          "updatedAt": "2022-05-12T21:59:42Z",
          "comments": [
            {
              "originalPosition": 21,
              "body": "Should we take the opportunity to bump this to `dap-02 input share` since we plan to submit `draft-ietf-ppm-dap-02` soon? Same goes for `dap-02 aggregate share` elsewhere in the doc.",
              "createdAt": "2022-05-12T21:59:05Z",
              "updatedAt": "2022-05-12T21:59:42Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs456e-K",
          "commit": {
            "abbreviatedOid": "1a452ba"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "Perfect, great work!",
          "createdAt": "2022-05-13T02:16:37Z",
          "updatedAt": "2022-05-13T02:19:07Z",
          "comments": [
            {
              "originalPosition": 21,
              "body": "We're at -00 right now: https://datatracker.ietf.org/doc/draft-ietf-ppm-dap/",
              "createdAt": "2022-05-13T02:16:37Z",
              "updatedAt": "2022-05-13T02:19:07Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs4590rl",
          "commit": {
            "abbreviatedOid": "1a452ba"
          },
          "author": "BranLwyd",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2022-05-13T16:21:28Z",
          "updatedAt": "2022-05-13T16:21:28Z",
          "comments": [
            {
              "originalPosition": 21,
              "body": "Leaving as `dap-01` for now since we are currently at `dap-00` and per Tim's comment we will soon be bumping versions.",
              "createdAt": "2022-05-13T16:21:28Z",
              "updatedAt": "2022-05-13T16:21:28Z"
            }
          ]
        }
      ]
    },
    {
      "number": 250,
      "id": "PR_kwDOFEJYQs43y-i3",
      "title": "Lock spec to draft-irtf-cfrg-vdaf-00",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/pull/250",
      "state": "MERGED",
      "author": "cjpatton",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "The current draft is compatible with vdaf-00, and there will likely be\r\nAPI-breaking changes in vdaf-01. For planned changes see\r\nhttps://mailarchive.ietf.org/arch/msg/cfrg/Fvd_m64V9bC4VVJm2Zsuwr441mM/.",
      "createdAt": "2022-05-13T16:26:57Z",
      "updatedAt": "2022-05-24T22:41:20Z",
      "baseRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "baseRefName": "main",
      "baseRefOid": "149c8c08a7ae7ad9f75ccbd14c815d38fd587bbe",
      "headRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "headRefName": "cjpatton/vdaf-draft",
      "headRefOid": "944454bc26cf6e29d821aeced8014181726b26c0",
      "closedAt": "2022-05-24T22:41:20Z",
      "mergedAt": "2022-05-24T22:41:20Z",
      "mergedBy": "cjpatton",
      "mergeCommit": {
        "oid": "68c2a0c98fcf7880fc1f3924d043f2ea77cc6e16"
      },
      "comments": [
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "@divergentdave, done (nice catch).",
          "createdAt": "2022-05-13T16:35:05Z",
          "updatedAt": "2022-05-13T16:35:05Z"
        },
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "> No objections from me, but we could also just wait until VDAF-01 is out and then pin \ud83e\udd37\r\n\r\nThe big task remaining for VDAF-01 is finishing Poplar1, which likely won't happen for several weeks. I suppose we could cut VDAF-01 w/o Poplar1 and save it for VDAF-02? ",
          "createdAt": "2022-05-18T18:33:03Z",
          "updatedAt": "2022-05-18T18:33:03Z"
        },
        {
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "body": "I'm going to merge this now, it'll be easy enough to point to the next draft once we're ready.",
          "createdAt": "2022-05-24T22:41:11Z",
          "updatedAt": "2022-05-24T22:41:11Z"
        }
      ],
      "reviews": [
        {
          "id": "PRR_kwDOFEJYQs4593MR",
          "commit": {
            "abbreviatedOid": "c6e44bb"
          },
          "author": "divergentdave",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "Looks good, but there are two more references that should be updated under #task-configuration and #sec-considerations.",
          "createdAt": "2022-05-13T16:31:11Z",
          "updatedAt": "2022-05-13T16:31:11Z",
          "comments": []
        },
        {
          "id": "PRR_kwDOFEJYQs45-Kc9",
          "commit": {
            "abbreviatedOid": "944454b"
          },
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "",
          "createdAt": "2022-05-13T17:49:02Z",
          "updatedAt": "2022-05-13T17:49:02Z",
          "comments": []
        },
        {
          "id": "PRR_kwDOFEJYQs46QmTg",
          "commit": {
            "abbreviatedOid": "944454b"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "No objections from me, but we could also just wait until VDAF-01 is out and then pin \ud83e\udd37 ",
          "createdAt": "2022-05-18T18:28:53Z",
          "updatedAt": "2022-05-18T18:28:53Z",
          "comments": []
        }
      ]
    },
    {
      "number": 251,
      "id": "PR_kwDOFEJYQs43zDTN",
      "title": "Revise usage of HPKE encryption (take two).",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/pull/251",
      "state": "MERGED",
      "author": "BranLwyd",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "Specifically:\r\n  * Specify use of the \"one-shot\" HPKE APIs defined in RFC9180,\r\n    replacing equivalent use of the \"multi-shot\" APIs. (This change is\r\n    intended to be a clarification, not a functional change.)\r\n  * Move the task_id parameter from the \"info\" parameter to the \"aad\"\r\n    parameter. This is intended to protect against\r\n    key-commitment-related attacks[1].) This is a functional change.\r\n  * Clarify that the HpkeCiphertext.enc field is an encapsulated key,\r\n    rather than an encryption context. (This is a clarification, not a\r\n    functional change.)\r\n\r\nThis is a second copy of a previous PR (#249) which was merged too\r\nhastily, and then reverted. There are no changes from that PR.\r\n\r\n[1] See discussion in #221.\r\n\r\nCloses #221.",
      "createdAt": "2022-05-13T16:53:01Z",
      "updatedAt": "2022-05-21T10:57:15Z",
      "baseRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "baseRefName": "main",
      "baseRefOid": "0f507171aaad51c9eefccd1075df9874a1a8f7a8",
      "headRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "headRefName": "update-hpke-usage-redux",
      "headRefOid": "fb89e349ba00c180d3de1f6fb59c3b38bc89bd14",
      "closedAt": "2022-05-21T10:57:14Z",
      "mergedAt": "2022-05-21T10:57:14Z",
      "mergedBy": "chris-wood",
      "mergeCommit": {
        "oid": "06ac0f17aafb1dc3f9f007dd30f042d64283abd8"
      },
      "comments": [],
      "reviews": [
        {
          "id": "PRR_kwDOFEJYQs45-Koy",
          "commit": {
            "abbreviatedOid": "fb89e34"
          },
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "",
          "createdAt": "2022-05-13T17:49:30Z",
          "updatedAt": "2022-05-13T17:49:30Z",
          "comments": []
        },
        {
          "id": "PRR_kwDOFEJYQs45-PW-",
          "commit": {
            "abbreviatedOid": "fb89e34"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "",
          "createdAt": "2022-05-13T18:09:49Z",
          "updatedAt": "2022-05-13T18:09:49Z",
          "comments": []
        },
        {
          "id": "PRR_kwDOFEJYQs45_vYn",
          "commit": {
            "abbreviatedOid": "fb89e34"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "",
          "createdAt": "2022-05-14T12:10:10Z",
          "updatedAt": "2022-05-14T12:10:10Z",
          "comments": []
        }
      ]
    },
    {
      "number": 252,
      "id": "PR_kwDOFEJYQs43zQnV",
      "title": "Update repository reference",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/pull/252",
      "state": "MERGED",
      "author": "cjpatton",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "",
      "createdAt": "2022-05-13T18:09:20Z",
      "updatedAt": "2022-05-18T18:04:35Z",
      "baseRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "baseRefName": "main",
      "baseRefOid": "c9a07318214c3503aab30d1d1ea5afa5655f47c5",
      "headRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "headRefName": "cjpatton/update-repo",
      "headRefOid": "f63a981d835ce4cb51d4dedb15effc2321435045",
      "closedAt": "2022-05-18T18:04:35Z",
      "mergedAt": "2022-05-18T18:04:35Z",
      "mergedBy": "cjpatton",
      "mergeCommit": {
        "oid": "a9d046da0b4a7b8b8b80658e68572dc8ecdf74c5"
      },
      "comments": [],
      "reviews": [
        {
          "id": "PRR_kwDOFEJYQs46EUXR",
          "commit": {
            "abbreviatedOid": "435b9ee"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "COMMENTED",
          "body": "",
          "createdAt": "2022-05-16T16:00:52Z",
          "updatedAt": "2022-05-16T16:00:52Z",
          "comments": [
            {
              "originalPosition": 12,
              "body": "```suggestion\r\nsecurity analysis.\r\n```",
              "createdAt": "2022-05-16T16:00:52Z",
              "updatedAt": "2022-05-16T16:00:52Z"
            }
          ]
        },
        {
          "id": "PRR_kwDOFEJYQs46PjnC",
          "commit": {
            "abbreviatedOid": "f63a981"
          },
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "",
          "createdAt": "2022-05-18T15:15:12Z",
          "updatedAt": "2022-05-18T15:15:12Z",
          "comments": []
        }
      ]
    },
    {
      "number": 253,
      "id": "PR_kwDOFEJYQs435BfY",
      "title": "Rename repo references",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/pull/253",
      "state": "CLOSED",
      "author": "chris-wood",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "",
      "createdAt": "2022-05-16T16:09:23Z",
      "updatedAt": "2022-05-16T16:10:12Z",
      "baseRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "baseRefName": "main",
      "baseRefOid": "0f507171aaad51c9eefccd1075df9874a1a8f7a8",
      "headRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "headRefName": "caw/rename-repo",
      "headRefOid": "53c11f10fcfda4b517c9b239e696b05e10c5157d",
      "closedAt": "2022-05-16T16:10:12Z",
      "mergedAt": null,
      "mergedBy": null,
      "mergeCommit": null,
      "comments": [],
      "reviews": []
    },
    {
      "number": 254,
      "id": "PR_kwDOFEJYQs435C_v",
      "title": "Re-run repo setup using new name",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/pull/254",
      "state": "MERGED",
      "author": "chris-wood",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "",
      "createdAt": "2022-05-16T16:15:27Z",
      "updatedAt": "2022-05-16T16:20:20Z",
      "baseRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "baseRefName": "main",
      "baseRefOid": "0f507171aaad51c9eefccd1075df9874a1a8f7a8",
      "headRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "headRefName": "caw/rename-repo-2",
      "headRefOid": "23858f01136dd332847b51e0a48908e3d4cf62e4",
      "closedAt": "2022-05-16T16:20:20Z",
      "mergedAt": "2022-05-16T16:20:20Z",
      "mergedBy": "cjpatton",
      "mergeCommit": {
        "oid": "85c42e767b3474c2aabfba01a03a9ac560b2bb55"
      },
      "comments": [],
      "reviews": [
        {
          "id": "PRR_kwDOFEJYQs46EanN",
          "commit": {
            "abbreviatedOid": "23858f0"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "",
          "createdAt": "2022-05-16T16:19:58Z",
          "updatedAt": "2022-05-16T16:19:58Z",
          "comments": []
        }
      ]
    },
    {
      "number": 256,
      "id": "PR_kwDOFEJYQs44B41Y",
      "title": "Fix AggregateShareReq",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/pull/256",
      "state": "MERGED",
      "author": "tgeoghegan",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "AggregateShareReq should have an aggregation parameter field instead of\r\naggregation job ID.",
      "createdAt": "2022-05-18T14:02:45Z",
      "updatedAt": "2022-05-18T14:27:59Z",
      "baseRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "baseRefName": "main",
      "baseRefOid": "85c42e767b3474c2aabfba01a03a9ac560b2bb55",
      "headRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "headRefName": "timg/agg-share-req-agg-param",
      "headRefOid": "2d6a14d259c2e86f4de4155e56977f1ba8e77e8f",
      "closedAt": "2022-05-18T14:27:59Z",
      "mergedAt": "2022-05-18T14:27:59Z",
      "mergedBy": "tgeoghegan",
      "mergeCommit": {
        "oid": "01571a49c2ce5db69784724c5a0deb3f6d79e82d"
      },
      "comments": [
        {
          "author": "tgeoghegan",
          "authorAssociation": "COLLABORATOR",
          "body": "Thanks @simon-friedberger for spotting this!",
          "createdAt": "2022-05-18T14:04:40Z",
          "updatedAt": "2022-05-18T14:04:40Z"
        }
      ],
      "reviews": [
        {
          "id": "PRR_kwDOFEJYQs46PDqg",
          "commit": {
            "abbreviatedOid": "2d6a14d"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "",
          "createdAt": "2022-05-18T14:03:37Z",
          "updatedAt": "2022-05-18T14:03:37Z",
          "comments": []
        },
        {
          "id": "PRR_kwDOFEJYQs46PFzl",
          "commit": {
            "abbreviatedOid": "2d6a14d"
          },
          "author": "divergentdave",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "",
          "createdAt": "2022-05-18T14:07:14Z",
          "updatedAt": "2022-05-18T14:07:14Z",
          "comments": []
        }
      ]
    },
    {
      "number": 257,
      "id": "PR_kwDOFEJYQs44CD05",
      "title": "Remove references to helper state",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/pull/257",
      "state": "MERGED",
      "author": "divergentdave",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "This is a follow-up to #232, removing a few dangling references to the helper state blob.",
      "createdAt": "2022-05-18T14:38:13Z",
      "updatedAt": "2022-05-18T15:09:23Z",
      "baseRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "baseRefName": "main",
      "baseRefOid": "01571a49c2ce5db69784724c5a0deb3f6d79e82d",
      "headRepository": "divergentdave/ppm-specification",
      "headRefName": "helper-state-cleanup",
      "headRefOid": "17d5b4d09d4eba0f12359e26594ece92658d6644",
      "closedAt": "2022-05-18T15:02:31Z",
      "mergedAt": "2022-05-18T15:02:31Z",
      "mergedBy": "chris-wood",
      "mergeCommit": {
        "oid": "c9a07318214c3503aab30d1d1ea5afa5655f47c5"
      },
      "comments": [],
      "reviews": [
        {
          "id": "PRR_kwDOFEJYQs46Pdff",
          "commit": {
            "abbreviatedOid": "17d5b4d"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "",
          "createdAt": "2022-05-18T15:01:04Z",
          "updatedAt": "2022-05-18T15:01:04Z",
          "comments": []
        },
        {
          "id": "PRR_kwDOFEJYQs46Pd5d",
          "commit": {
            "abbreviatedOid": "17d5b4d"
          },
          "author": "chris-wood",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "",
          "createdAt": "2022-05-18T15:02:03Z",
          "updatedAt": "2022-05-18T15:02:03Z",
          "comments": []
        }
      ]
    },
    {
      "number": 258,
      "id": "PR_kwDOFEJYQs44DEmK",
      "title": "Fix section reference in Anti-replay section",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/pull/258",
      "state": "MERGED",
      "author": "divergentdave",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "This fixes a reference that was pointing at the wrong section. The behavior relating to `ReportShareError.report-replayed` is under \"Input Share Validation\".",
      "createdAt": "2022-05-18T19:06:14Z",
      "updatedAt": "2022-05-19T01:27:11Z",
      "baseRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "baseRefName": "main",
      "baseRefOid": "a9d046da0b4a7b8b8b80658e68572dc8ecdf74c5",
      "headRepository": "divergentdave/ppm-specification",
      "headRefName": "patch-1",
      "headRefOid": "7cb1f0ca652374cc729da5f6f082179ad58d9fa1",
      "closedAt": "2022-05-19T01:27:11Z",
      "mergedAt": "2022-05-19T01:27:11Z",
      "mergedBy": "cjpatton",
      "mergeCommit": {
        "oid": "14ff0679a9781cd13a95486b5b199e9c8c508087"
      },
      "comments": [],
      "reviews": [
        {
          "id": "PRR_kwDOFEJYQs46SFER",
          "commit": {
            "abbreviatedOid": "7cb1f0c"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "",
          "createdAt": "2022-05-19T01:27:02Z",
          "updatedAt": "2022-05-19T01:27:02Z",
          "comments": []
        }
      ]
    },
    {
      "number": 262,
      "id": "PR_kwDOFEJYQs44JhD8",
      "title": "Drop job_id from Aggregate{Initialize,Continue}Resp.",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/pull/262",
      "state": "OPEN",
      "author": "BranLwyd",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "Closes #261. (see that issue for justification of this change)",
      "createdAt": "2022-05-19T21:07:23Z",
      "updatedAt": "2022-05-28T00:47:16Z",
      "baseRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "baseRefName": "main",
      "baseRefOid": "14ff0679a9781cd13a95486b5b199e9c8c508087",
      "headRepository": "BranLwyd/draft-ietf-ppm-dap",
      "headRefName": "drop-job-id-in-agg-resps",
      "headRefOid": "0e2da079a0289218dd33cec4c5fbbfd12350c86b",
      "closedAt": null,
      "mergedAt": null,
      "mergedBy": null,
      "mergeCommit": null,
      "comments": [],
      "reviews": [
        {
          "id": "PRR_kwDOFEJYQs46oc_p",
          "commit": {
            "abbreviatedOid": "0e2da07"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "",
          "createdAt": "2022-05-24T18:29:26Z",
          "updatedAt": "2022-05-24T18:29:26Z",
          "comments": []
        }
      ]
    },
    {
      "number": 263,
      "id": "PR_kwDOFEJYQs44JjgE",
      "title": "Include task_id in AggregateContinueReq.",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/pull/263",
      "state": "OPEN",
      "author": "BranLwyd",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "See https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/issues/260 for the\r\nreasoning behind this change. In short, this keeps aggregation job IDs\r\nscoped to be unique-per-task rather than universally-unique.\r\n\r\nNote this isn't the only possible solution -- I'm opinionatedly sending this PR, if the discussion on #260 leads to a different conclusion, I'll update the PR accordingly.\r\n\r\nCloses #260.",
      "createdAt": "2022-05-19T21:16:43Z",
      "updatedAt": "2022-05-28T00:46:48Z",
      "baseRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "baseRefName": "main",
      "baseRefOid": "14ff0679a9781cd13a95486b5b199e9c8c508087",
      "headRepository": "BranLwyd/draft-ietf-ppm-dap",
      "headRefName": "agg-continue-include-task",
      "headRefOid": "6b3f8a0588bf67a2bfe428e6afc5285bc7d3120e",
      "closedAt": null,
      "mergedAt": null,
      "mergedBy": null,
      "mergeCommit": null,
      "comments": [],
      "reviews": [
        {
          "id": "PRR_kwDOFEJYQs46oc2m",
          "commit": {
            "abbreviatedOid": "6b3f8a0"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "",
          "createdAt": "2022-05-24T18:28:53Z",
          "updatedAt": "2022-05-24T18:28:53Z",
          "comments": []
        }
      ]
    },
    {
      "number": 265,
      "id": "PR_kwDOFEJYQs44Umtp",
      "title": "Switch all messages from the \"message\" to the \"application\" media type.",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/pull/265",
      "state": "OPEN",
      "author": "BranLwyd",
      "authorAssociation": "COLLABORATOR",
      "assignees": [],
      "labels": [],
      "body": "Closes #264. (opinionatedly: please see discussion on that issue)",
      "createdAt": "2022-05-23T21:27:33Z",
      "updatedAt": "2022-05-24T19:04:27Z",
      "baseRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "baseRefName": "main",
      "baseRefOid": "06ac0f17aafb1dc3f9f007dd30f042d64283abd8",
      "headRepository": "BranLwyd/draft-ietf-ppm-dap",
      "headRefName": "media-type-application",
      "headRefOid": "6e971da0655d8333d3cbd978dcace5ba8997587c",
      "closedAt": null,
      "mergedAt": null,
      "mergedBy": null,
      "mergeCommit": null,
      "comments": [],
      "reviews": [
        {
          "id": "PRR_kwDOFEJYQs46odpD",
          "commit": {
            "abbreviatedOid": "6e971da"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "Approving based on the text quoted by @BranLwyd in the linked issue. It would be great to get feedback from folks who have more experience working on HTTP-based applications.",
          "createdAt": "2022-05-24T18:31:45Z",
          "updatedAt": "2022-05-24T18:31:45Z",
          "comments": []
        },
        {
          "id": "PRR_kwDOFEJYQs46omv3",
          "commit": {
            "abbreviatedOid": "6e971da"
          },
          "author": "divergentdave",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "",
          "createdAt": "2022-05-24T19:04:27Z",
          "updatedAt": "2022-05-24T19:04:27Z",
          "comments": []
        }
      ]
    },
    {
      "number": 268,
      "id": "PR_kwDOFEJYQs44zi2o",
      "title": "Venue stuff",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/pull/268",
      "state": "MERGED",
      "author": "martinthomson",
      "authorAssociation": "CONTRIBUTOR",
      "assignees": [],
      "labels": [],
      "body": "Remove some cruft",
      "createdAt": "2022-06-01T06:10:18Z",
      "updatedAt": "2022-06-01T20:10:19Z",
      "baseRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "baseRefName": "main",
      "baseRefOid": "68c2a0c98fcf7880fc1f3924d043f2ea77cc6e16",
      "headRepository": "martinthomson/ppm-dap",
      "headRefName": "venue-stuff",
      "headRefOid": "6a88651fc3d3ece58fede307e722877678da8420",
      "closedAt": "2022-06-01T20:10:19Z",
      "mergedAt": "2022-06-01T20:10:19Z",
      "mergedBy": "cjpatton",
      "mergeCommit": {
        "oid": "1225fa8f19288f4de093f341397d7c8028203b20"
      },
      "comments": [],
      "reviews": [
        {
          "id": "PRR_kwDOFEJYQs47ITea",
          "commit": {
            "abbreviatedOid": "6a88651"
          },
          "author": "cjpatton",
          "authorAssociation": "COLLABORATOR",
          "state": "APPROVED",
          "body": "\u2764\ufe0f \r\n",
          "createdAt": "2022-06-01T14:04:01Z",
          "updatedAt": "2022-06-01T14:04:01Z",
          "comments": []
        }
      ]
    },
    {
      "number": 269,
      "id": "PR_kwDOFEJYQs45XXUJ",
      "title": "Pretty pictures",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/pull/269",
      "state": "OPEN",
      "author": "martinthomson",
      "authorAssociation": "CONTRIBUTOR",
      "assignees": [],
      "labels": [],
      "body": "Anyone running builds locally will need a few extra pieces of software to manage this, but the result is something like this:\r\n\r\n![image](https://user-images.githubusercontent.com/67641/172771593-c22d2278-d803-4391-9c95-5e6e60b9af29.png)\r\n\r\n...with the appropriate palette inversion for people using dark mode.",
      "createdAt": "2022-06-09T05:33:19Z",
      "updatedAt": "2022-06-09T14:33:03Z",
      "baseRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "baseRefName": "main",
      "baseRefOid": "1225fa8f19288f4de093f341397d7c8028203b20",
      "headRepository": "martinthomson/ppm-dap",
      "headRefName": "aasvg",
      "headRefOid": "f6371656ecf00415d7a820828a13c5c3e83a8abc",
      "closedAt": null,
      "mergedAt": null,
      "mergedBy": null,
      "mergeCommit": null,
      "comments": [
        {
          "author": "martinthomson",
          "authorAssociation": "CONTRIBUTOR",
          "body": "Oh, the software in question is 'svgcheck' (installed with pip3/python) and 'aasvg' (installed with npm/nodejs).",
          "createdAt": "2022-06-09T05:34:00Z",
          "updatedAt": "2022-06-09T05:34:00Z"
        },
        {
          "author": "ekr",
          "authorAssociation": "COLLABORATOR",
          "body": "Before we land this can we adjust the Makefiles to alert the user about this--and even better, fail gracefully. I found it kind of surprising when my drafts just stopped building.",
          "createdAt": "2022-06-09T14:33:03Z",
          "updatedAt": "2022-06-09T14:33:03Z"
        }
      ],
      "reviews": []
    },
    {
      "number": 275,
      "id": "PR_kwDOFEJYQs451uST",
      "title": "Clarify meaning of out-of-band.",
      "url": "https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/pull/275",
      "state": "OPEN",
      "author": "simon-friedberger",
      "authorAssociation": "NONE",
      "assignees": [],
      "labels": [],
      "body": "Proposal for https://github.com/ietf-wg-ppm/draft-ietf-ppm-dap/issues/271",
      "createdAt": "2022-06-17T08:53:37Z",
      "updatedAt": "2022-06-17T08:53:38Z",
      "baseRepository": "ietf-wg-ppm/draft-ietf-ppm-dap",
      "baseRefName": "main",
      "baseRefOid": "1225fa8f19288f4de093f341397d7c8028203b20",
      "headRepository": "simon-friedberger/draft-ietf-ppm-dap",
      "headRefName": "oob",
      "headRefOid": "3231dd80fb030c31e3bcbd59b63db1391abeee43",
      "closedAt": null,
      "mergedAt": null,
      "mergedBy": null,
      "mergeCommit": null,
      "comments": [],
      "reviews": []
    }
  ]
}